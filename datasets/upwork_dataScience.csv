Title,Description,Skills,Source Country,Client Porpouses,Average Hour Paid ($),Total Spent (K$),Domain of Job,Fixed Price ($),Price per Hour ($),Work on,Experience Required
Webcrawler to collect data of all escaperooms in a country,"For a specific project we need as much information of all escaperooms in the netherlands.We need is all websites URL's, addresses and if possible e-mail addresses. If possible we would also like to have the name of the escaperoom, opening times (when displayed on the website) and a small text about the escaperoom.This generated list is the base for us to start checking all these rooms but it would safe us a lot of time when the basics are already generated.Can this be done using AI and a webcrawler?","['Data Scraping', 'Data Mining', 'Data Extraction', 'Company Research', 'Data Extraction', 'Company Research']",Netherlands,53,20.00,6.2,,300.00,,Remote Job,Expert
Build a Browse AI Robot to Multiple Sites to Extract Data,"Im looking to use the Browse AI software to extract data live from multiple websites. We want this data sent back to google sheets for live event information Event Name, Dates, Website, Image etc. From Google sheets we want this data to be a live website that is password protected. with all of the data an images.","['Artificial Intelligence', 'Data Scraping', 'Data Mining', 'Automation', 'Data Scraping', 'Data Mining', 'Automation']",United States,80,8.38,43,"['Sales', 'Marketing']",,,Remote Job,Intermediate
"Google Analytics, GA4 Migration, and Set-up","We are seeking an experienced Google Analytics pro to lead our Google Analytics migration and set up to GA4.Deliverables:* Migrate From UTM (gtag.js) to GA4* Set up tracking tags and conduct thorough testing to ensure data accuracy and consistency.* Management and analysis—using reports to provide actionable insights for campaign optimization.Requirements:Solid experience in migrating and managing Google Analytics.In-depth knowledge of GA4 properties, tags, and tracking parameters to capture relevant data accurately.Proficient in tag management systems (e.g., Google Tag Manager) and implementing tracking codes.Strong analytical and problem-solving skills with a keen eye for detail.Fluent in English with excellent communication and collaboration skills.Google Analytics certification is a plus.NO AGENCIES PLEASEIf you’re interested, please provide relevant work experience.","['Marketing Analytics', 'Operations Analytics', 'Google Analytics', 'Google Tag Manager', 'Search Engine Optimization', 'Search Engine Optimization']",United States,15,46.82,6.4,,,"['60.00', '80.00']",Remote Job,Expert
Google Trends API - Python Notebook,"Build a Google Collab Notebook that queries the Google Trends API.The Notebook will be used to monitor trends over time of key topics.We will run the Notebook at the end of each month and add the results to other analyses.Set a Control Word Variable. Read about control words herehttps://towardsdatascience.com/using-google-trends-at-scale-1c8b902b6bfaTake a list of keywords in the code as an input. We will have 500 keywords.Create an output that queries all keywords in baskets of five with the control keyword on a monthly basis going back 24 months.The search responses should cover global as well as every countryThe output format will be- Topic eg ""Artificial Intelligence""- Month eg ""2022-06""- Geography (Global or Country Name for all Countries)- Value (Interest value from the API)The second output each month should be a related queries- Input Topic- Related Query- ScoreThe third output should be a Keyword Suggestions Table on each input Topic (See the notebook below as an example)- Input Topic- Suggested Title- Suggested Type.The deliverable should be a Google Collab Notebook like thishttps://colab.research.google.com/github/Tanu-N-Prabhu/Python/blob/master/Google_Trends_API.ipynbYou will share that Notebook with us on completion","['API', 'Python', 'Jupyter', 'Google Trends']",Australia,117,16.70,393,,200.00,,Remote Job,Intermediate
Data analysis in excel,I have a spreadsheet of raw data from a labor and sales tracking tool for a restaurant that I want split up in different ways and need help with the formulas.- Average sales per day per month.- Average labor per day per week per month.- YoY Monday in June 2022 vs June 2023 for both sales and labor,"['Microsoft Excel', 'Data Analysis']",United States,4,17.68,818,,,"['5.00', '20.00']",Remote Job,Entry level
Device Web Scraping,"I require data extraction from a web portal associated with a device. To achieve this, I need a Python script that can scrape the necessary data. The extracted data should then be written to a flattened JSON file, along with the date and time of execution. I have provided a document with screenshots of the portal and what needs to be scraped. Note that the HTML itself lacks the necessary information. Instead, these details are injected into the rendered DOM through JavaScript after the page loads. To accomplish this, the web portal employs an aggressive timer, consistently making XHR networking requests and dynamically injecting content into the rendered DOM. The thought was that Puppeteer/Chromium would probably be a good fit to accomplish the task.Note that this needs to be completed within the next 24hrs.  Upon accepting the job, we will provide remote access to a box which is behind the device and will be used to run the script.","['Python', 'Scrapy', 'Selenium', 'Data Scraping']",United States,31,26.83,22,"['Tech', 'IT']",100.00,,Remote Job,Intermediate
Scrap data from several data,Python website scrapingData ExtractionPosted 18 minutes agoWorldwideI am looking to build a web scraper in python that downloads product details from a car dealership website to excel or csv.  I am looking to build a robust and scalable solution that i can then use and build on myself.  I am looking to do it scrapy. Thank you,"['Data Scraping', 'Data Mining', 'Python', 'Data Extraction', 'Microsoft Excel', 'Scrapy', 'Data Entry', 'Spreadsheet Software', 'pandas', 'Web Crawling', 'Python', 'Data Extraction', 'Microsoft Excel', 'Scrapy', 'Data Entry', 'Spreadsheet Software', 'pandas', 'Web Crawling']",Canada,1,,,"['Engineering', 'Architecture']",2000.00,,Remote Job,Expert
Mathematics GRAPHS,"Quick Test. Required to be completed in 2 hours. Will be needed for a specific time and date. If you are confident with Graphs Theory at a Degree level Contact me. We will discuss further through Whatsapp. Take a look at the attached document if you feel confident in Graph Theory, answer a questions for review. If this is answered to standard you will be hired.","['Algorithm Development', 'Mathematics', 'Statistics', 'Mathematica', 'Algebra', 'Education', 'Data Science', 'Graph', 'Mathematica', 'Algebra', 'Education', 'Data Science', 'Graph']",United Kingdom,5,,239,"['Finance', 'Accounting']",50.00,,Remote Job,Intermediate
Currently Require Three Google Analytics and Data Analysts For entry-mid level positions,"Are you a honest and transparent Google Analytics and Data Analyst who is Looking for a remote work opportunity?  Are you looking for an exhilarating opportunity to maximize your earning potential? If you're looking for a dynamic role that allows you to showcase skills, then this is the opportunity for you!We're looking for Google Analytics and Data Analysts who are energetic, ambitious, fun loving, and hard working.Looking for 3 positions- 2 fulltime, 1 parttime (parttime will be 1-2 days/week)Schedule:Fulltime 1 : monday-wednesday (35 hours/week)Fulltime 2: thursday-saturday (35 hours/week)Parttime 3: Saturday-Sunday (14 hours/week)First of all, Please Must Read Actual Detailed ""Job Description"" by Clicking ""Job Description"" Section at the given web page:https://tinyurl.com/RequiredjobDescriptionClick at ""Job Description"" Section..","['Business Intelligence', 'Data Analytics', 'Data Interpretation', 'Marketing Analytics', 'Operations Analytics', 'Product Analytics', 'Human Resources Analytics', 'Sales Analytics', 'Google Analytics', 'Data Analysis']",Pakistan,1,,,,4000.00,,Remote Job,Entry level
Excel Developer at work needing help to learn Tableau and finish a project,"My company has implemented Tableau, but only as a corporate system reporting to corporate and franchise management based on closed projects. My franchise wants to build tableau reports that track workers in real-time to influence the active project work. We can't access the corporate infrastructure. But can download the report and cobble together the report data. I said I would take on the job of learning Tableau and producing Visualization. I'm overwhelmed and need help putting together the first set of reports on cycle time and profits. I can't get the first set of reports done as fast as necessary. I would like to have someone look at what I have and then help me put the project into production, plus train me to repeat the process on my own.  Also, I'm a remote employee and would need to team up with someone that could support me remotely","['Ability to work one on one to get reports into tableau', 'Microsoft Excel', 'Tableau', 'Data Analysis', 'Microsoft Excel', 'Tableau', 'Data Analysis']",United States,1,,,,,"['40.00', '75.00']",Remote Job,Intermediate
Data Engineer,"We are seeking a talented and experienced Data Engineer to join our team for a short-term position of 6 months to 1 year. As a Data Engineer, you will be responsible for building efficient ETL processes and creating impactful data visualizations using various tools and technologies.Responsibilities:Develop and implement ETL (Extract, Transform, Load) processes using Talend for efficient data ingestion and transformation.Utilize your strong skills and experience with Elasticsearch and MSSQL to design and optimize data indexing, querying, and retrieval processes.Create interactive and insightful data visualizations using Kibana to provide actionable insights to stakeholders.Write SQL queries to extract data from relational databases and perform data manipulations and aggregations.Develop API integrations using C# (preferred), Python, or TypeScript to enable seamless data exchange between systems.Utilize Docker for containerization and deployment of data engineering pipelines and services.Leverage Talend and Jupyter for data exploration, experimentation, and prototyping.Collaborate with cross-functional teams to understand business requirements and translate them into scalable and efficient data engineering solutions.Stay updated with the latest industry trends and best practices related to data engineering, Elasticsearch, and data visualization.Requirements:Proficiency in Scala and experience with AWS services for data processing and storage.Strong knowledge of functional and type-level Scala libraries such as cats-effect and fs2 for building robust and scalable data pipelines.Familiarity with Kafka and streaming data processing is a plus.Experience with GraphQL is a plus.Solid understanding of software development principles and best practices.Excellent problem-solving skills and ability to work independently or collaboratively as part of a team.Strong communication skills to effectively convey complex technical concepts to non-technical stakeholders.Join our team and contribute to our data engineering efforts by building robust ETL processes and impactful data visualizations. Apply your expertise in Elasticsearch, Talend, Kibana, SQL, and API development to drive data-driven decision-making across the organization.","['ETL Pipeline', 'SQL', 'API']",Ukraine,1,,,,,"['25.00', '35.00']",Remote Job,Expert
Need R studio Expert for analysis,Need R studio Expert for technical work and analysis.,"['Report', 'Data Analysis', 'R', 'Data Visualization', 'Statistics', 'Data Science', 'Analytics', 'Spark AR Studio', 'Statistics', 'Data Science', 'Analytics', 'Spark AR Studio']",Pakistan,14,,215,,15.00,,Remote Job,Expert
Assistance or Guidance in Research,I am doing a research on job recommendation system for students where we basically to provide the career guidance to the student which career they should choose.Looking for someone who can help me in accomplishing that using Machine Learning,"['Machine Learning', 'Academic Research']",India,9,,45,['Education'],15.00,,Remote Job,Intermediate
LinkedIn Profile Scraper.,"Hello Upworkers,I need LinkedIn scraping asap.AWe are seeking a skilled and detail-oriented individual to join our team as a LinkedIn Profile Scraper. As a LinkedIn Profile Scraper, your primary responsibility will be to collect and extract data from LinkedIn profiles using web scraping techniques. You will play a crucial role in acquiring valuable information for our organization's recruitment, market research, or other relevant purposes","['Data Scraping', 'LinkedIn Development', 'LinkedIn', 'Scrapy', 'LinkedIn', 'Scrapy']",United States,262,8.33,7.3,,10.00,,Remote Job,Expert
Modify SAS macros to be quicker,"This code includes two macros.The first one runs regressions on 127*15=1905 combinations and produce 1905 datasetsThe second one combines them into one.It takes more than one hour to finish. Could you modify it to make it quicker?(I don't need the 1905 datasets, only need the final dataset that summarizes)","['SAS', 'SAS macro']",United States,39,,386,,10.00,,Remote Job,Expert
Data Collection and Analysis for Virtual Spiritual Care Program,"Job Description:We are seeking a skilled and experienced Data Collection and Analysis Specialist to design and build a robust data collection and analysis process for our 12-week virtual spiritual care program. As clients progress through the program, we want to measure their connectedness using the Watts Connectedness Scale and analyze the data to gain insights into their journey. The successful candidate will play a crucial role in developing an efficient and user-friendly system that collects and analyzes data at two specific points during the program.Responsibilities:Design and develop a data collection process using the Watts Connectedness Scale for clients onboarding our virtual spiritual care program.Create a simple readout or report that provides a clear representation of clients' connectedness scores at the beginning of the program.Develop a mechanism to collect clients' responses to the Watts Connectedness Scale at the end of the program.Analyze and compare the data collected before and after the program to identify any changes or improvements in clients' connectedness.Generate comprehensive reports that present the findings and insights derived from the data analysis.Collaborate with our team to integrate the data collection and analysis process seamlessly into our existing virtual spiritual care program.Requirements:Proven experience in designing and building data collection processes and analysis systems.Familiarity with the Watts Connectedness Scale or similar instruments for measuring spiritual connectedness.Strong analytical skills and the ability to interpret data effectively.Proficiency in data analysis tools and software (e.g., Excel, SPSS, R, Python, etc.).Excellent communication skills to present complex data in a clear and understandable manner.Attention to detail and the ability to ensure data accuracy and integrity.Experience working in psychology or social work a plus.","['Data Collection', 'Psychology', 'Measurement Tools and Scales', 'Data Analysis', 'Content Writing', 'Measurement Tools and Scales', 'Data Analysis', 'Content Writing']",United States,1,,,"['Health', 'Fitness']",,"['10.00', '35.00']",Remote Job,Intermediate
Teaching AWS Model Deployment,"Looking for a 4 hour session where one can teach how to deploy models in ec2 , aks and sagemaker with custom images . I am myself a data scientist so you need to teach me docker , fast api and model building . I am done with lambda and sage maker also .  I need just refinement . Some of the questions I have How to deploy custom image in sagemaker . CI/CDHow to build microservice kind of architecture","['Amazon Web Services', 'Amazon EC2', 'Amazon S3', 'DevOps', 'Amazon S3', 'DevOps']",India,78,11.51,857,,15.00,,Remote Job,Expert
ChatGPT and AI Researcher,"We are a 5 start Upwork provider looking for a researcher on Generative AI. We are looking for researchers who have premium access to a variety of Generative AI tools from Chatgpt,  Bard and Midjourney.  To apply.  Please include I am a human not a robot aimed to take over Upwork in the first line of your sentence.","['Open Source', 'Generative AI', 'ChatGPT', 'Artificial Intelligence', 'ChatGPT', 'Artificial Intelligence']",Ireland,1608,6.40,108,,4.00,,Remote Job,Entry level
Keras Questions on RNNs/LSTMs,Looking for someone to sit on a call and troubleshoot some keras model creation and tuning objectsUsing LSTMs for a time series prediction task. Insights on model optimization also key. Please be familiar with model architectures for time series prediction.Will start with 1-2 hour of consulting work on calls.,"['Keras', 'Machine Learning']",Spain,71,37.38,161,"['Tech', 'IT']",,"['50.00', '150.00']",Remote Job,Expert
Get historical intraday stock data from API,"I currently pull historical intraday stock data from Bloomberg into Excel and I'm looking to replace Bloomberg with a cheaper API.  Yahoo Finance, Google Finance, or Interactive Brokers are options I am considering.Please apply if you have experience pulling data from these APIs. Ideally the data will go into a spreadsheet where I can use for trading.  If the job is well done, I will have additional projects.Thanks!","['API Integration', 'API', 'Visual Basic for Applications', 'Python', 'Python']",United States,6,14.08,608,"['Finance', 'Accounting']",500.00,,Remote Job,Intermediate
Get historical intraday stock data from API,"I currently pull historical intraday stock data from Bloomberg into Excel and I'm looking to replace Bloomberg with a cheaper API.  Yahoo Finance, Google Finance, or Interactive Brokers are options I am considering.Please apply if you have experience pulling data from these APIs. Ideally the data will go into a spreadsheet where I can use for trading.  If the job is well done, I will have additional projects.Thanks!","['API Integration', 'API', 'Visual Basic for Applications', 'Python', 'Python']",United States,6,14.08,608,"['Finance', 'Accounting']",500.00,,Remote Job,Intermediate
Data analyst,"Looking for strong analytical mindset, excellent communications skills and ability to translate complex data insights, I need collaboration with different teams to collect relevant data for analysis +1331-979-1681","['Data Analysis', 'Data Mining', 'Data Visualization', 'Statistics', 'Microsoft Excel', 'Data Visualization', 'Statistics', 'Microsoft Excel']",United States,2,,,"['Tech', 'IT']",,"['35.00', '60.00']",Remote Job,Entry level
Senior AI/ML Specialist for Adding AI to our SaaS Marketing Platform,"We are seeking an AI/ML Specialist to help us enhance our existing platform by integrating advanced AI features. The ideal candidate will have a solid foundation in computer science, with a focus on artificial intelligence (AI) and machine learning (ML).Our platform offers an-end-to-end solution for content marketing, from niche research, targeting, to content creation and performance tracking.As an AI/ML Specialist, you'll play a key role in enriching our SaaS platform with state-of-the-art AI/ML technologies to elevate user experience, enrich functionality, and boost software performance. You'll work closely with our core development team, get involved in exciting, challenging projects, and contribute to shaping our AI/ML strategy.Our first objective of our MVP, that if successful would result in additional potential work will be to integrate Generative AI in our written content creation module, for both text, as well as images, to be used for all major social media platforms. Skills and Qualifications:A degree in Computer Science, Data Science, AI, or a related field.At least 2 years of hands-on experience in developing and implementing AI/ML solutions, particularly in a SaaS environment.In-depth understanding of AI/ML algorithms and practical implications.Proficiency in Python and experience with ML libraries such as TensorFlow, PyTorch, or similar.Strong analytical skills and a problem-solving mindset.Excellent communication skills to effectively liaise with both technical and non-technical team members.This role requires a deep understanding of AI/ML and a passion for staying updated with the latest technologies. If you're keen on pushing boundaries in the AI/ML field and have a track record of implementing such features in a SaaS environment, we'd love to hear from you.","['GPT-4', 'AI Content Creation', 'AI Text-to-Image', 'Natural Language Generation', 'Natural Language Processing', 'Python', 'Artificial Intelligence', 'Machine Learning', 'Deep Learning', 'Automation', 'Machine Learning', 'Deep Learning', 'Automation']",United States,23,47.61,11,,,"['36.00', '70.00']",Remote Job,Expert
Web Scraping,"This web data extraction project needs raw python script  [should not use framework or tool , like scrapy ] Are you familiar with writing scraping scripts using raw python lib: requests,  json, csv, pandas, selenium,playwright  etc. Must know handling Github. Script should be in a single file with methods. Those will be ongoing tasks, fixing bug of existing scrapers scripts, extract from many websites.","['Data Scraping', 'Python', 'Web Crawling', 'Data Extraction', 'Data Extraction']",Bangladesh,39,8.07,6.9,,,"['5.00', '10.00']",Remote Job,Intermediate
"RVC Ai model of my singing voice , any song should be converted into my voice exactly same",We need  ai RVC model of my voice which will convert any song into my voice song https://youtu.be/NSQXaEKn8OY,['Deep Learning'],India,9,3.00,193,"['Tech', 'IT']",100.00,,Remote Job,Expert
Fantasy Sports Optimization,"I am attempting to create an optimization program in either the Python or Go programming languages that attempts to increase the speed and computationally efficiency of a program that I have an idea for creating, but only currently with a brute-force methodology.In the context of daily fantasy sports, I have a dataset that contains all legal lineup combinations, along with 10,000 additional columns that show how many points each lineup would score across 10,000 simulations. I also have a second dataset that contains the payout information of the fantasy sports contest that I want to find the best lineup(s) for. The input file for payout structures can change as the contests I attempt to predict change. Keep that in mind when developing the algorithm.I do not want to use a brute force method of comparing all n combinations of lineups in a dataset containing x number of lineups (for example, let n = 35 and x = 350,000) because it is too computationally complex. Instead, I would like to find another methodology for doing this that would be more computationally realistic.The program's goal should then be able to leverage all of the input data to find the lineup(s) that will provide the most significant return on investment given the inputs.","['Golang', 'Python', 'Optimization Modeling', 'Optimization Algorithms', 'Data Science', 'Optimization Algorithms', 'Data Science']",United States,38,67.78,9.7,,,"['20.00', '70.00']",Remote Job,Expert
Microsoft Power BI Developer,"Need a Power BI developer is a professional who is responsible for developing and administering Power BI tools. Also responsible for transforming raw data into meaningful insights through interactive and user-friendly dashboards and reports.The role of a Power BI developer is vital for businesses because of the executive, strategic, and managerial roles and responsibilities that come with it. Power BI developers are expected to perform a wide range of tasks such as reporting, building dashboards, building data models, analyzing datasets, and administration of Power BI tools.","['Microsoft Power BI', 'Data Visualization', 'Data Analysis', 'SQL', 'Microsoft Power BI Development', 'Business Intelligence', 'Microsoft Power BI Data Visualization', 'Microsoft Excel', 'Data Analysis', 'SQL', 'Microsoft Power BI Development', 'Business Intelligence', 'Microsoft Power BI Data Visualization', 'Microsoft Excel']",Bangladesh,3,,10,"['Art', 'Design']",10.00,,Remote Job,Entry level
Plecto Dashboard Consulting - TODAY,Hi - trying to setup a simple Plecto dashboard using Google Sheets data.  Need some Sheets setup help and creating formulas and dashboard in Plecto.  Would really like some consulting today (Saturday 6/10) over zoom.  I'm only looking for someone who has connected Plecto with Google Sheets - I'm not looking for any other data visualization tools.,"['Google Sheets', 'plecto']",United States,16,45.42,63,,,"['50.00', '200.00']",Remote Job,Intermediate
Database Creation and Data Extraction for Hydrogel Academic Publications,"Project Description:We are seeking a freelancer with an expertise in biology and a familiarity with academic papers to help us construct a database comprising of 200 hydrogel academic publications. This database will focus on the field of molecular biology and will support a larger machine learning project.Scope of Work:The freelancer will be required to perform the following tasks:Literature Search: Conduct an extensive literature search for recent (last 10 years) academic publications in the field of molecular biology focusing on hydrogels. The sources of this information will include, but not be limited to: PubMed, Google Scholar, ScienceDirect, Web of Science, Springer, Elsevier, Wiley Online Library, ACS publications, etc.Database Creation: Create a structured database of 200 academic publications. The database should be provided in a format that can be easily imported into our machine learning software, such as CSV or Excel.Data Extraction: For each academic publication, extract a series of datapoints, such as:Publication Information: Title, Authors, Journal, Year of Publication.Material Type: E.g., Fmoc self-assembling peptides, Methacrylated collagen hydrogel, etc.Cell Line: E.g., Fibroblasts, Epithelial cells, HeLa cells, etc.Synthesis Conditions: E.g., Temperature, pH, Reactant Concentration.Hydrogel Properties: E.g., Initial Shape, Final Shape, Shape Change, Initial Size, Final Size, Size Change, etc.Other relevant data points as per the project requirements.Quality Assurance: Ensure that the data extracted is of high quality and reliability. This involves verifying the information from multiple sources, checking for accuracy and consistency.Documentation: Document the work done in a clear and concise manner, including the methodologies used for data collection and any challenges faced during the project.Key Skills Required:Background in Biology or related field, preferably with a focus on molecular biology.Experience in academic research and literature review.Familiarity with various scientific databases and publications.Proficient in data extraction, handling, and management.Attention to detail and high level of accuracy.Excellent documentation skills.Keywords for literature search: Hydrogel, molecular biology, cell line, biocompatibility, synthesis conditions, rheology, phase separation, microgel, extrusion, drug encapsulation, mechanical properties, degradation profile, swelling behavior, cell adhesion, material processing, synthesis parameters, thermal behavior.Project Deliverables:A CSV/Excel file with 200 entries of academic papers, each containing the required datapoints.A detailed report outlining the methodologies used, any challenges encountered and how they were overcome.Project Duration: To be determined based on freelancer's estimated time to complete the project while ensuring quality.Budget: To be discussed.","['Data Entry', 'Data Extraction', 'Microsoft Excel', 'Microsoft Excel']",United Kingdom,1,,,,,"['5.00', '15.00']",Remote Job,Entry level
Reinforcement Learning to predict the movement in the price of a US ETF,"I need someone to help train and evaluate a model used to predict the price of SPY (US equity market ETF).  I have a training data set ready to be used.  I have a environment that was written in python for a simpler data set.  That will need to be tweaked for the new new training data set.  Additionally the environment was only written to the point of training a model.  It was not written to evaluate yet.   I would like the existing environment to be extended to handle performance evaluation.  Performance Metrics;# of Buy-Sell:  Wins vs Losses 		Average Win vs average loss		# of Short-Cover: Wins vs Losses		Average Win vs average loss	Max Consecutive WinsMax Consecutive LossesBiggest Drawdown (from the high point of a hypotheical bankroll)Total # of trades - and the average overall win vs loss.I want this to be trained (sagemaker) and ultimately run off  of AWS.  I want to have a node on a AWS with a pipeline of data feeding into it so that this can be used in production.  I'm very unfamiliar with AWS.  I might need some guidance creating an IAM User role for you, and what is involved to move in that direction.Deliverables;1- I need the finalized environment2- I'd like the training curve monitored while training the model so that this doesn't become to costly in terms of computing time, and that time is not wasted training a bad model.3- I need to know what transformations you used on the data set I provide as they will need to be replicated in production4- I will need the model you create ( any descriptive characteristics about it;  activation functions, number of nodes / laters, etc)5- The performance metrics and evaluation of the modelAs a follow up (part two):  If this model evaluates well.  I will need help moving this into production once I secure the data pipelines.  I might look to extend this project and have you use AWS lambda to perform transformations on the inbound data 'AWS streams'","['Reinforcement Learning', 'Amazon SageMaker', 'Python', 'Data Science']",United States,3,50.01,298,"['Tech', 'IT']",,"['18.00', '50.00']",Remote Job,Intermediate
Reinforcement Learning to predict the movement in the price of a US ETF,"I need someone to help train and evaluate a model used to predict the price of SPY (US equity market ETF).  I have a training data set ready to be used.  I have a environment that was written in python for a simpler data set.  That will need to be tweaked for the new new training data set.  Additionally the environment was only written to the point of training a model.  It was not written to evaluate yet.   I would like the existing environment to be extended to handle performance evaluation.  Performance Metrics;# of Buy-Sell:  Wins vs Losses 		Average Win vs average loss		# of Short-Cover: Wins vs Losses		Average Win vs average loss	Max Consecutive WinsMax Consecutive LossesBiggest Drawdown (from the high point of a hypotheical bankroll)Total # of trades - and the average overall win vs loss.I want this to be trained (sagemaker) and ultimately run off  of AWS.  I want to have a node on a AWS with a pipeline of data feeding into it so that this can be used in production.  I'm very unfamiliar with AWS.  I might need some guidance creating an IAM User role for you, and what is involved to move in that direction.Deliverables;1- I need the finalized environment2- I'd like the training curve monitored while training the model so that this doesn't become to costly in terms of computing time, and that time is not wasted training a bad model.3- I need to know what transformations you used on the data set I provide as they will need to be replicated in production4- I will need the model you create ( any descriptive characteristics about it;  activation functions, number of nodes / laters, etc)5- The performance metrics and evaluation of the modelAs a follow up (part two):  If this model evaluates well.  I will need help moving this into production once I secure the data pipelines.  I might look to extend this project and have you use AWS lambda to perform transformations on the inbound data 'AWS streams'","['Reinforcement Learning', 'Amazon SageMaker', 'Python', 'Data Science']",United States,3,50.01,298,"['Tech', 'IT']",,"['18.00', '50.00']",Remote Job,Intermediate
ML expert to help with extracting and abstracting data,This is robotreviewer https://github.com/ijmarshall/robotreviewer.This synthesizes data from medical articles. Currently the data that robotreviewer generates are kind of messy. I want to :1- export data in Excel spreadsheet 2-divided extracted data into more subgroup,"['Python', 'Machine Learning', 'Data Extraction', 'Natural Language Processing', 'Data Extraction', 'Natural Language Processing']",United States,1,,,,150.00,,Remote Job,Intermediate
AI Animation/Video;Text (Image) to Animation/Video,"We want the images produced by stable diffusion , midjourney, dall-e to be turned into animations or videos. user can also insert images into videos or animations, such as advertising products, where someone is holding the product. ai images to produce animations or videos, and text to produce videos or animations;You can do this in many ways, not limited to the following methods, for exampleStable Diffusion animation based on the second development, the current disadvantage is that flicker is very serious, a lot of noise. You can use other methods to avoid these. likes as.Deforum + Control Net +Stable Diffusion - next level of AI animation frame consistency!-----------------------------------------------You can provide the core technology and algorithms, and we have the basic software engineers to work with you.","['AI-Generated Video', 'Explainer Video', 'Animation']",Hong Kong,42,,4.2,"['Sales', 'Marketing']",20000.00,,Remote Job,Intermediate
Excel guru,"Looking for someone who has extensive experience with excel sheets, v-lookups, comparing rate charts, if/then statements, among other things. although we may not need you full time, i'm open to keeping you on retainer so we can ping you at any time to do one off tasks. without a doubt, going to need to do it every friday","['Microsoft Excel', 'Data Entry', 'Data Analysis', 'Data Mining', 'Spreadsheet Software', 'Data Analysis', 'Data Mining', 'Spreadsheet Software']",United States,35,5.90,4.8,"['Retail', 'Consumer Goods']",,"['3.00', '5.00']",Remote Job,Expert
Bioinformatics merge annotation files online,"Hi bioinformatics expert, I have several annotation files in text format with 8 columns HR START	REF,ALT,ZYGOSITY ACCESSION FAMILY_ID, HPO_TERMS, and I will need your help to merge them; ideally, I will give you access via Teamviewer, and you do it on my laptop, or you give me the code to do that. I have a mac air; the size of the file is around 100MB Thanks,","['Python', 'MacBook', 'command line']",United Kingdom,101,40.49,14,['Automotive'],200.00,,Remote Job,Expert
"ChatGPT, Generative AI Training for Medical Application","We are seeking to advance cancer care by developing a trained large language model focused on cancer.  The goal of developing this model is to give physicians immediate assistance in determining the best possible outcome for cancer care and to achieve the best recommendations.  Specifically, we are looking for a collaborator with expertise in LLM and can help us use our resources of general and hematology medical textbooks, relevant case files, and over 1 million de-identified cancer patient records to fine-tune immediate treatment and care recommendations for these patients.  The anticipated outcome is improving and extending lives of cancer patients.","['AI-Enhanced Classification', 'ChatGPT', 'BLOOM', 'LLM, NLP, model training', 'Natural Language Processing', 'Neural Network', 'Machine Learning', 'Artificial Intelligence', 'Natural Language Processing', 'Neural Network', 'Machine Learning', 'Artificial Intelligence']",United States,5,118.22,104,,,"['50.00', '300.00']",Remote Job,Expert
Developer for Web Scraping Facebook Groups,I would like an automation set up that will send me a notification when posts are made to certain Facebook groups if they contain certain keywords. I am not an admin of these groups,"['Data Scraping', 'Lead Generation', 'Data Mining', 'Data Mining']",United States,21,10.11,17,"['Manufacturing', 'Construction']",,"['12.00', '15.00']",Remote Job,Intermediate
College Student - Ambassador For Science,"Are you comfortable talking about the science of your body (genetics, fat, muscle, skinny fat, etc.)? Help us spread the word about Body Type Science.Body Type Science FAQ: https://www.fellowone.com/fellow-one-research/the-four-body-types/faq-body-type-science/?ref=1&Science=2000/Scientific Research Data: https://www.fellowone.com/category/body-type-quiz/research-data/?ref=1&Science=2000/","['Social Media Marketing', 'Human Body', 'Health & Wellness', 'Video Editing', 'Video Camera', 'Health & Fitness', 'Human Body', 'Health & Wellness', 'Video Editing', 'Video Camera', 'Health & Fitness']",United States,12065,27.15,63,"['Health', 'Fitness']",500.00,,Remote Job,Entry level
Scrape all FB ads library,YOU MUST HAVE SCRAPED FB ADS LIBRARY BEFOREScrape all FB ads library - 5 million FB pages - we will provide page id to enter into FB ads libraryYOU MUST HAVE SCRAPED FB ADS LIBRARY BEFORE,"['Data Scraping', 'Data Mining', 'Data Extraction', 'Data Extraction']",United Kingdom,115,,2,,200.00,,Remote Job,Intermediate
Excel Expert With Step By Step Walkthrough,"Hi,I would like to learn step by step how to create a template I can recreate by myself when the data in the SKU changes as it is constantly changing daily. I want to know how to organize a set of data by SKU number first but also have the title description in the cell next to it.This is for a 3,000+ item store inventory to see which SKU’s are currently active, and which SKU’s have been sold and inactive and/or if there is a duplicate SKU number.Example:A01-01 through Q10-20Sometimes the data will look different like A1-1, A01-01, A01-1. I am still looking for it to be in order regardless of the number of characters in the thread.I’m looking for a step by step walk through from start to finish preferably with a SCREEN RECORDED VIDEO in order to see how and which formulas are used to manipulate the data so I can use the video in the future on my own as a guide because the data changes daily.Thanks,Chris","['Microsoft Excel', 'Data Entry']",United States,2,,,"['Retail', 'Consumer Goods']",20.00,,Remote Job,Entry level
Instagram Hashtag Scrape,"Hi I have what should be a quick scraping job for anyone with experience in scraping Instagram. Feel free to use something like Apify to do this . I have a csv of 2000+ hashtags. The csv has the following columns: Hashtag, Date, Race Name. For each hashtag I need the top 100 unique posts (based on number of likes) from within a specific date range as listed in the csv, i.e. the top 100 posts for #londonmarathon from 6th April 2023 - 6th May 2023. If 100 are not available then as many as possible within the range, so long as each post is from a different author.This is time sensitive job with a more complex one to follow.  From these 100 posts I need the userName, ownerFullName, likesCount of the post author. Please see an example of the input csv and the expected output csv.","['Data Extraction', 'Web Scraping', 'Beautiful Soup', 'pandas', 'Selenium', 'Scrapy', 'Python', 'Data Scraping', 'Instagram API']",United Kingdom,107,20.05,50,,,,Remote Job,Entry level
"A comparative study between two algorithms from the same field, like machine learning, etc","Here are some key points to consider:Research Question: Start by formulating a clear and focused research question that relates to computer science. Your research question should be specific, measurable, and allow for in-depth analysis.Background Research: Conduct extensive background research on the topic of your Extended Essay to gain a comprehensive understanding of existing knowledge, theories, and approaches related to your research question.Data Collection and Analysis: Depending on your research question, you may need to collect and analyze data. This can involve designing experiments, conducting surveys, collecting and analyzing datasets, or developing software prototypes.Evaluation and Interpretation: Evaluate the data or results you have collected and interpret them in the context of your research question. Analyze the strengths and limitations of your approach and discuss any possible sources of error or bias.Literature Review: Incorporate relevant academic sources and literature to support your arguments and provide a theoretical framework for your research. Cite your sources properly using a recognized citation style, such as APA or MLA.Structure and Organization: Ensure that your Extended Essay has a clear and logical structure, with an introduction that outlines the research question, a body that presents your arguments and evidence, and a conclusion that summarizes your findings and offers insights.Ethical Considerations: If your research involves human subjects or sensitive data, consider the ethical implications and ensure that you follow ethical guidelines and obtain necessary permissions or consent.Reflective Statement: As part of the Extended Essay, you will also need to submit a reflective statement that explores the research process, challenges faced, and what you have learned through your research.","['Machine Learning', 'Algorithm Development', 'Coding Art', 'Writing', 'Coding Art', 'Writing']",India,3,,20,['Education'],25.00,,Remote Job,Expert
Google analytics Expert Required,We are looking for a google analytics expert to start immediately with the following tasks:-1. UTM Tracking code set up.2. Full conversion tracking on marketing campaigns.3. Bitly links integration.We need an experienced google expert with excellent English communications skills.,"['Data Analysis', 'Report', 'Google Tag Manager', 'Google Analytics', 'Analytics', 'Analytics']",United Kingdom,35,,18,"['Tech', 'IT']",,"['40.00', '100.00']",Remote Job,Expert
R Text Analysis,I would like to perform a few types of text analysis using Python or R. The first type of text analysis involves performing topic modeling of United Nations General Assembly speeches and showing changes over time between the topics that the US and China emphasize. The second task involves frequency analysis to show changes in the words that China emphasizes relative to the US. This is the dataset that we would use:https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/0TJX8Y,"['R', 'Statistics']",United States,6,16.58,808,,,"['10.00', '45.00']",Remote Job,Intermediate
Build a data scraping tool,I have a list of 20 companies that I will need to have someone to use a site like Apify to build a scraping tool to pull their current operating address and populate them into an excel sheet. These are companies that have multiple industrial/retail locations 300+.,"['Data Scraping', 'Data Extraction']",United States,1,,,['Real Estate'],,"['15.00', '40.00']",Remote Job,Entry level
Separation of two molecules,I have two molecules that elude very closely on hplc I’m looking for a way to separate/ remove them from the starting materialI’m looking to do this on a large scale,"['Chemistry', 'Organic Chemistry', 'Synthetic Chemistry', 'chemisty', 'Biochemistry', 'Inorganic Chemistry', 'Analytical Chemistry', 'Synthetic Chemistry', 'chemisty', 'Biochemistry', 'Inorganic Chemistry', 'Analytical Chemistry']",United States,2,,,,,"['40.00', '75.00']",Remote Job,Expert
Mailbox data collection,"I am looking for a freelancer to assist me in collecting data from mailboxes. Specifically, I need names and addresses only. The data should be presented in an Excel spreadsheet. There are more than 100 mailboxes to collect data from - in fact, there are 1,000,000! Ideal Skills and Experience:- Experience with data collection and entry- Proficiency in Excel- Attention to detail and accuracy","['Data Entry', 'Microsoft Excel', 'Data Collection', 'Data Mining', 'Data Scraping', 'Data Collection', 'Data Mining', 'Data Scraping']",United Kingdom,1,,,,410.00,,Remote Job,Entry level
Seeking machine learning engineer to implement model for Virtual Try On Network,We need someone with deep understanding of GAN.I am writing on behalf of my startup which aims at creating a technology which would enable the users of a clothing application to try on the clothes virtually with almost precise fit check.This is job with posibility to hire as we need long term work to start from that implementation and make new one based on it.Please submit proposals only if you are experienced in these areas.We can discuss more details over a chat.Thank you!,"['PyTorch', 'Machine Learning', 'Python', 'TensorFlow', 'Deep Learning', 'Artificial Intelligence', 'Computer Vision', 'StyleGAN', 'Generative Adversarial Network', 'Generative AI', 'TensorFlow', 'Deep Learning', 'Artificial Intelligence', 'Computer Vision', 'StyleGAN', 'Generative Adversarial Network', 'Generative AI']",United States,1,,,"['Tech', 'IT']",,"['40.00', '60.00']",Remote Job,Intermediate
Reporting Dashboard Creator," Welcome to an Exciting Opportunity at Advertising Report Card! Are you a talented Reporting and Dashboards Expert looking to take your career to new heights? Join our exceptional team at Advertising Report Card and unlock the full potential of data-driven insights! Reporting and Dashboards Expert Requirements: Swydo Reporting Mastery: We are seeking individuals skilled in creating reporting dashboards using Swydo or similar tools (e.g., Looker Studio). Showcase your ability to create creative layouts and visuals that showcase data from platforms like Google Analytics, Google Ads, Facebook Ads, and more. Creative Layouts and Visuals: Demonstrate your keen eye for design and expertise in creating visually appealing dashboards and reports. Highlight your previous work where you have utilized your creative skills to present data in an engaging and insightful manner. Tracking Setup Experience: Show your experience in setting up tracking for events and conversions through tools like Google Tag Manager (GTM), Google Analytics 4 (GA4), and other relevant platforms. Share projects where you have successfully implemented tracking solutions. COMPENSATION SCHEDULE:We believe in fair and timely compensation. We offer competitive rates based on your expertise and experience, with regular reviews and opportunities for salary growth as you demonstrate exceptional account management skills. PROJECT MANAGEMENT TOOLS:Our team utilizes various tools to streamline communication and enhance productivity. Familiarity with project management tools like Slack, ClickUp, Loom, 1Password, and Google Drive is preferred. Reliable high-speed internet and effective communication skills are essential. HOW TO APPLY: To express your interest in this position, please provide examples of your expertise with Swydo (or similar reporting tools), Google Analytics 4 (GA4), Google Tag Manager (GTM), Bing Ads, and creative dashboard layouts. We invite you to showcase specific projects you have worked on and highlight your accomplishments in creating visually appealing reports and utilizing tracking setups.Join our team of exceptional Reporting and Dashboards Experts and embark on an exciting journey of harnessing the power of data-driven insights! Together, Let's Unlock the Full Potential of Data-driven Insights! ","['Data Visualization', 'Google Data Studio', 'Data Analysis', 'Microsoft Power BI', 'Google Analytics', 'Data Analysis', 'Microsoft Power BI', 'Google Analytics']",United States,31,10.77,26,"['Media', 'Entertainment']",,"['5.00', '10.00']",Remote Job,Intermediate
Illustrator - Create a set of visualizations to explain a math theorem,"A set of 8-10 illustrations of math curves that demonstrate future, present, past with four dimensions that increase or decrease how an individual's future and past will manifest and crystalizeCurves 1 - 3,   Early years, middle years and latter years with fixed future dimensionsCurves 4 -8  Variations of the four dimensions and how they narrow or broaden and increase or decrease optimistic or pessimistic one's future looks like.  The images should demonstrate the underlying math curves and be in a standard scalable, printable format.More work may result once the first set are completed. The work is confidential to JJMDigital, LLC and its owners.  A signed  NDA is required.","['Adobe Illustrator', 'Illustration', 'Graphic Design', 'Graphic Design']",United States,6,95.00,535,,,,Remote Job,Intermediate
Data Analyst : Real Estate,"Position Summary: We are seeking an experienced ROCKSTAR Real Estate Data Analyst to join our land investment real estate team. The Data Analyst directly reports to the CEO of the company. The Data Analyst is responsible for driving the growth in the business by maintaining, analyzing and processing data to help management run high volume campaigns to acquire land in the US. Objectives:Collect, clean, and process datasets from various sources like Data Tree related to land parcels in the United States.Utilize advanced spreadsheet techniques like Pivot Tables to organize, validate, and analyze data, Create and run pivot tables to summarize and aggregate data, enabling effective data analysis and identification of trends and patterns.Create and manage Campaigns on a weekly basis. Plan and schedule campaigns based on leads for the specific county and state. Collaborate with other teams to understand data requirements and translate them into actionable insights and reports.Build interactive and visually appealing dashboards using data visualization tools such as Tableau or PowerBI to present key findings and metrics.Monitor and track data quality, identifying and resolving data inconsistencies or errors.Competencies: Ability to work in a complex data environment Expert in running spreadsheets and analyzing complex dataHigh level of accuracy and attention to detailAbility to manage several campaigns simultaneouslyAbility to understand business requirement to produce relevant data Technology savvy using state of the art CRM such as Salesforce, Follow Up Boss and G Suite to download and analyze dataStrong willingness to learn new softwares & workflows Strong team player and ability to navigate difficult situationsCompany Summary Established in Austin, Texas, GoldSoil is a land investment company that has been operating for over 6 years. With a diverse team spread across multiple countries, we specialize in wholesale and subdivide transactions, focusing on mid to long-term investments in land. We invest in several states including Texas, South Carolina, Florida and several others. Our extensive experience and commitment to delivering value to our clients make us a trusted partner in the real estate circuit. Mission:Empowering landowners to turn their property into cash, while enabling buyers to fulfill their dream of land ownershipVision:To become the leading wholesale marketplace for buying and selling of land in the USOur Core Values: Take Ownership - Extreme accountability delivers extraordinary results. Team Player - Don’t compete, Get inspired by team members’ success.Hunger to learn – unlearn and learn new skills, be coachable, adjust to change.Purpose Driven -  Personal, Professional & Financial goals.Result Oriented – How does your work impact the company’s bottom line? Giving Back – contributing a portion to the communityEducation & ExperienceExperience running datasets and producing reportsExperience building dashboards to present the data Real Estate industry experience is preferred Certifications related to Data Analysis is preferredPhysical RequirementsProlonged periods sitting at a desk and working on a computerCommitment to Diversity As an equal opportunity employer committed to meeting the needs of a multigenerational and multicultural workforce GoldSoil Realty recognizes that a diverse staff, reflective of our community, is an integral and welcome part of a successful and ethical business. We hire local talent at all levels regardless of race, color, religion, age, national origin, gender, gender identity, sexual orientation, or disability, and actively foster inclusion in all forms both within our company and across interactions with clients, candidates, and partners.BenefitsCommissions based on company & individual performance (KPI’s) Internet reimbursement Peripheral reimbursement Other benefits available as well","['Report', 'Data Interpretation', 'Data Analytics', 'Data Visualization', 'Microsoft Excel', 'Real Estate', 'Data Analysis', 'Data Analysis']",United States,66,13.31,74,['Real Estate'],,"['5.00', '15.00']",Remote Job,Intermediate
Python Script Modification with API Data Extraction,"We are looking for a talented and experienced Python developer to modify an existing Python script that works with the Zenrows API for data extraction. This is a freelance job opportunity.Responsibilities:Understand the existing Python script and its integration with the Zenrows API.Analyze the script's functionality and identify areas that require modification.Implement the necessary changes to the script to meet our specific requirements.Ensure the modified script is efficient, scalable, and error-free.Collaborate with our team to understand the desired modifications and provide regular updates on progress.Test and troubleshoot the modified script to ensure proper functionality.Document the changes made to the script for future reference.Requirements:Strong proficiency in Python programming language.Experience working with APIs, specifically the Zenrows API, is highly preferred.Solid understanding of web scraping techniques and data extraction methods.Familiarity with data manipulation and processing libraries in Python, such as pandas or numpy.Ability to analyze existing code, identify areas for improvement, and implement necessary modifications.Attention to detail and the ability to produce clean, well-structured, and maintainable code.Excellent problem-solving and troubleshooting skills.Effective communication and collaboration abilities.Prior experience with Upwork or other freelance platforms is a plus.If you are a skilled Python developer with experience in API integration and data extraction, we would love to hear from you. Please submit your proposal outlining your relevant experience, portfolio, and availability. Feel free to include any relevant code samples or previous projects that demonstrate your expertise.We look forward to working with you on this project!","['Python', 'Data Extraction', 'Data Scraping', 'API', 'Python Script', 'Data Scraping', 'API', 'Python Script']",United States,2,,,,,"['30.00', '75.00']",Remote Job,Intermediate
Designing an AI-Enhanced emotional wellness Support Ecosystem,"Software Components:Identify the necessary software components for the system, such as modules for data processing, emotion recognition, vocal cue analysis, real-time feedback, and clinical note generation.Design a modular architecture that enables seamless integration and communication between these components.Implement each component as a separate module to ensure separation of concerns and maintainability.Algorithms:Determine the algorithms required for tasks like emotion recognition, vocal cue analysis, and other relevant functionalities.Research and select suitable algorithms based on the specific requirements of each component.Implement these algorithms using programming languages such as Python, Java, or C++, ensuring compatibility with other components and libraries.Natural Language Processing (NLP):Gain knowledge of NLP concepts and techniques, including text processing, sentiment analysis, and language modeling.Utilize NLP libraries like NLTK, spaCy, or Stanford CoreNLP for tasks such as tokenization, part-of-speech tagging, and semantic analysis.Apply these techniques to process textual data, such as transcriptions or clinical notes, extracting insights and supporting clinical decision-making.APIs:Identify relevant APIs that can enhance the systems capabilities.Integrate third-party APIs like IBM Watson Tone Analyzer or Google Cloud Speech-to-Text to leverage their functionalities in emotion recognition, sentiment analysis, or speech-to-text conversion.Familiarize yourself with the API documentation, understand the authentication process, and make API calls using the chosen programming language.GPT (Generative Pre-trained Transformer):Explore the possibilities of incorporating GPT-based models, such as GPT-3, for tasks like generating responses or clinical note summaries.Consider fine-tuning pre-trained GPT models on specific datasets to tailor them to the systems requirements.Utilize frameworks like Hugging Face Transformers library to facilitate the integration and usage of GPT models.Sensor Technology:Investigate sensor technologies like eye-tracking or body movement sensors to capture nonverbal cues.Research and select suitable sensor devices or APIs, such as Tobii Pro SDK or Microsoft Kinect, based on the systems requirements.Implement algorithms to process data from these sensors and extract relevant nonverbal cues, integrating them into the software system.Programming Language:Choose a programming language based on project requirements and the development teams expertise.Python is a popular choice due to its extensive libraries, including TensorFlow, PyTorch, OpenCV, and NLP toolkits.Java or C++ may be suitable for performance-critical tasks or integration with existing software ecosystems.","['Python', 'C++', 'Apache OpenNLP', 'NLTK', 'spaCy', 'NLP Tokenization', 'API', 'IBM Watson', 'Hugging Face', 'tobi pro', 'NLP Tokenization', 'API', 'IBM Watson', 'Hugging Face', 'tobi pro']",United States,5,,4.1,,,"['5.00', '10.00']",Remote Job,Intermediate
ERP Mapping,I'm planning to develop an ERP for salons.I have mapped the modules and functions activities in a basic swimlane cross-functional diagram.I need to convert this diagram to a professional wireframe and UML sequence diagram to kick-off the work. and review the selection of proper modules and phases.The delivery should be in tabular form.,"['Data Visualization', 'Digital Mapping', 'ERP Software', 'Wireframe', 'UX Wireframe', 'swimlane', 'Diagram', 'uml', 'UX Wireframe', 'swimlane', 'Diagram', 'uml']",Saudi Arabia,47,50.00,6,,50.00,,Remote Job,Intermediate
Need a web scraper,"I need help building a web scraper using python scrapy for the following website https://www.peterpanbmw.com/used-vehicles/Note, the data is loaded via an API after the initial page load. I do not want the scraper to scrape the rendered javascript from the UI, instead, it should scrape the underlying URL that is loading the data with the appropriate headers, query parameters and data payloads, i.e. https://sewjn80htn-dsn.algolia.net/1/indexes/*/queries?x-algolia-agent=Algolia%20for%20JavaScript%20(4.9.1)%3B%20Browser%20(lite)%3B%20JS%20Helper%20(3.4.4)&x-algolia-api-key=179608f32563367799314290254e3e44&x-algolia-application-id=SEWJN80HTNThe script must accommodate pagination dynamically (i.e. go to page 2). I will need to run this on multiple similar dealership sites (not just this one) so the pagination logic needs to be dynamic.This should be a quick job (under 1hr) for an experienced dev.  Let me know if you can do thisThanks","['Scrapy', 'Python', 'Data Scraping']",United States,16,,3.8,,25.00,,Remote Job,Intermediate
A workload analysis to determine the workload and the staffing requirements in healthcare setting,A workload analysis to determine the workload and the staffing requirements in healthcare setting ( number of staff needed in each speciality ) .I need to meet him in person so he / she should be inside United Arab Emirates,"['Human Resources Analytics', 'Operations Analytics', 'Data Analysis', 'Data Analytics', 'Data Interpretation', 'Statistical Analysis', 'ActivTrak', 'Requirement Analysis', 'Strategy']",United Arab Emirates,11,,2.3,,1000.00,,Remote Job,Expert
"Looking for agencies to Outsource a whole business operation cycle (Web developers, Data engineers)","We are looking for an experienced outsourcing company to handle the complete business operation cycle for our company. The selected company will be responsible for managing various aspects of our business, including recruitment, sales, marketing, fund raising, fulfillment, training, and Upwork contracting.Requirements:Experience: The outsourcing company should have a proven track record of successfully operating in the global market for at least 3-5 years. They should have a strong portfolio of completed projects in their respective fields.Expertise: The company should have expertise in handling all aspects of the business operation cycle, including but not limited to:Recruitment: Demonstrated ability to attract, screen, and select qualified candidates for various positions within our company.Sales: Proven experience in driving sales growth, developing sales strategies, and managing sales teams.Marketing: In-depth knowledge of global marketing trends, digital marketing strategies, and brand positioning.Fund Raising: Track record of successful fundraising activities, including securing investments, grants, or partnerships.Fulfillment: Experience in managing order fulfillment, logistics, and supply chain operations.Training: Ability to design and implement training programs to enhance employee skills and performance.Upwork Contracting: Proficiency in managing Upwork contracts and freelancers, ensuring timely deliverables and quality work.Global Market Understanding: The outsourcing company should have a strong understanding of the global market and should be able to adapt their strategies to different regions and target audiences.Communication: Excellent communication skills are essential to effectively collaborate with our internal teams and stakeholders.References: The company should provide references from previous clients or projects to showcase their success in handling similar business operation cycles.If your company meets the above requirements, please submit your proposal detailing your experience, expertise, and relevant case studies. Additionally, include references that we can contact for further verification.Note: Remunerations are yet to be finalized and are mostly decided on outcome/result basis.","['Training & Development', 'Agile Project Management', 'KPI Metric Development', 'Agile Project Management', 'KPI Metric Development']",Malta,564,,2.8,"['HR', 'Business Services']",800.00,,Remote Job,Expert
AI/ML model developer with Python/TensorFlow and Go,"We are looking for a senior AI, ML developer who has good skill in Python, TensorFlow, Linux and Go/Golang programming.W will provide the data sets, and the developer have to develop AI model based on our requirements.We are looking for a developer who lives in Sweden.","['TensorFlow', 'Python', 'Machine Learning', 'Artificial Intelligence', 'Golang', 'Linux', 'Artificial Intelligence', 'Golang', 'Linux']",United States,79,30.72,72,,,"['17.00', '37.00']",Remote Job,Expert
Need an expert to perform and optimize fuzzy string match,"I have two files Knames.csv and dIRSnamesFULL.csv. They contain the names of organizations that I am studying. I need you to assign each Kname to their best fit in dIRSname. I already performed some fuzzy string match in R and it worked, but I need to improve the match, I need it to be as reliable as possible.","['R', 'Data Processing', 'Python']",France,6,,143,['Education'],40.00,,Remote Job,Expert
Data Extraction,"We are looking for someone for simple copy paste document typing work its just a data entry as formal who are working on to get work done.We are looking for a data extraction specialist who could help us to build a contact list, based on companies names we have, and your goal is to search for the email of the marketing person (not a generic email, except if no marketing contact can be identified).contact via danielhoods655@gmail.com","['Microsoft Excel', 'Data Mining', 'ETL Pipeline', 'Data Entry', 'Python', 'html2text', 'Accounting Basics', 'Scrapy', 'Data Extraction', 'Data Scraping', 'ETL Pipeline', 'Data Entry', 'Python', 'html2text', 'Accounting Basics', 'Scrapy', 'Data Extraction', 'Data Scraping']",Bangladesh,2,,,,,"['50.00', '100.00']",Remote Job,Entry level
AI for Day trading,I am looking to create a model for Algo trading. I want to use AI in this. If you have experience on this please contact me.,"['Data Science', 'Machine Learning Model', 'Model Tuning', 'Model Optimization', 'Data Science Consultation', 'Artificial Intelligence', 'Python', 'Machine Learning', 'Deep Learning', 'Python', 'Machine Learning', 'Deep Learning']",United States,6,,0,,,"['20.00', '70.00']",Remote Job,Expert
Data Analyst to help label songs By Genre For Data Science Project,"Looking for a meticulous Data Analyst to label approximately 35,000 songs with their correct genre or genres for a Data Science project. Project will be completed in Excel. Please provide previous experience with this task and how quickly this can be completed.","['Microsoft Excel', 'Data Entry', 'Research Methods', 'Quality Assurance', 'Quality Assurance']",United States,1,,,,1000.00,,Remote Job,Intermediate
Data Entry Specialist - Startup Investor Research for a B2B SaaS Pre Seed Startup,"Job Description:We are a fast-growing B2B SaaS pre-seed startup in the future of work edtech industry. We are seeking a detail-oriented and proactive Data Entry Specialist with a technical and business development background to assist us in finding related early-stage investors for upcoming events like London Tech Week and Next Web Conference in Holland. In this role, you will be responsible for researching and entering investor data to support our fundraising efforts.Founder and CEO is from Hong Kong, male. If the fund only invests in black female founders then don't add this person on the excel spreadsheet. If some funds has a very strong preference in investing in European based companies, then this may not also apply to Helppo. Responsibilities:Conduct research to identify and compile a list of early-stage investors within the future of work and edtech sectorsFocus on investors with an interest in startups and technologies related to the theme of London Tech Week and Next Web ConferenceCollect and organize investor data, including contact information, investment focus, stage preferences, and geographic preferencesEnter investor data accurately and efficiently into our internal databases and systemsAssist in maintaining data integrity and ensuring data quality through regular checks and updatesCollaborate with the business development team to understand specific investor requirements and preferencesProvide regular progress reports and updates on the investor research processRequirements:Bachelor's degree in business, finance, computer science, or a related field (preferred but not required)Proven experience in data entry, market research, or business development rolesStrong research skills and the ability to identify relevant investors based on specific criteriaTechnical background or understanding of SaaS, edtech, and future of work industries is preferredFamiliarity with startup ecosystems and early-stage investorsProficiency in using MS Excel or Google Sheets for data entry and analysisStrong attention to detail and accuracy in data entry and analysisExcellent organizational and time management skills, with the ability to prioritize tasks and meet deadlinesEffective communication skills to collaborate with the business development team","['Market Research', 'Data Entry', 'Fundraising', 'B2B SaaS', 'Prospect List', 'Fundraising', 'B2B SaaS', 'Prospect List']",Hong Kong,96,18.53,353,"['Tech', 'IT']",,"['5.00', '10.00']",Remote Job,Intermediate
Data Analyst - Automated checking of supplier invoices (Dropshipping),"Are you a skilled Data Analyst with a passion for problem-solving? We have an exciting project for you! Our E-commerce company, operating in the field of dropshipping and based on the Shopify platform, is seeking a talented Data Analyst to assist us with an important task.In this role, your primary responsibility will be to build a technical solution to perform a comprehensive reconciliation of supplier invoices for the entire previous year. As an integral part of our team, you will work with various data sources, including order files provided by our suppliers and order details exported from Shopify.Your main objective will be to accurately analyze the data to identify any discrepancies between the orders fulfilled and the invoiced amounts. This project will involve a deep dive into the historical data, ensuring accurate billing and identifying any overcharges or undercharges from our suppliers. Your attention to detail and analytical skills will be instrumental in completing this project successfully.Additionally, we are looking for your expertise to help us develop a better process for future invoice verification. Your input in building a solution to simplify the ongoing review of supplier invoices will be highly valued.Qualifications:- Knowledge in Data Analytics, Computer Science, or a related field.- Proven experience as a Data Analyst, preferably within an e-commerce or supply chain environment.- Proficiency in data analysis tools such as Excel, SQL, or Python.- Strong analytical skills- Excellent problem-solving and critical-thinking abilities.- Effective communication skills in German or English.If you are ready to take on this challenging one-time project, apply now. Your meticulous analysis and expertise will play a vital role in ensuring accurate billing and developing efficient processes for future invoice verification. Apply now and help us complete this crucial task while improving our operations for the future.","['Invoicing', 'Microsoft Excel', 'SQL', 'Python', 'Data Analysis', 'Data Analysis']",Germany,4,,,,,,Remote Job,Intermediate
ECONOMIST with Data Studio / Looker Specialist,"You must have a strong understanding, background and/or education in Economics to apply for this project.  We are looking for a skilled data analyst with expertise in data visualization tools such as Data Studio and Looker. The ideal candidate should have a strong understanding of financial markets and be able to translate complex data into clear, concise insights for our team. The project will last for 3 to 6 months, and the successful candidate will be responsible for analyzing large data sets, identifying key trends, and creating compelling visualizations that effectively communicate insights to stakeholders. Key skills for this role include data analysis, statistics, and proficiency in Google Data Studio. The ability to work independently and manage multiple projects simultaneously is essential, as is a commitment to delivering high-quality work within tight deadlines.Candidates should submit a proposal outlining their experience in data analysis and visualization, as well as their understanding of financial markets. Please include links to past completed projects that demonstrate your ability to create engaging and informative data visualizations.Take data from services such as Bar Charts, End of Day Data or FRED, EIA and others to display it BEAUTIFULLY in Data Studio.  You will create pages similar to the attached images.STRONG UX AND DESIGN SKILLS A HUGE PLUS!!!!","['Data Analysis', 'Google Data Studio', 'Data Visualization', 'Statistics', 'Economics', 'macroeconomics', 'Finance', 'Data Visualization', 'Statistics', 'Economics', 'macroeconomics', 'Finance']",United States,80,10.20,64,['Education'],,"['15.00', '30.00']",Remote Job,Intermediate
AI Consultant required to train on AI ecosystem,"We are looking for an experienced AI consultant to train us on the AI ecosystem. The project will require the ideal candidate should have extensive knowledge of Artificial Intelligence, Artificial Neural Network, Deep Learning, Machine Learning, Natural Language Processing, Neural Network, and Python.As an AI consultant trainer, we will need between 2-5 hours of your time to train us - a group of investors,  that will equip our team with the necessary knowledge and skills to excel in the field of AI. You will also be required to provide ongoing support to ensure that our team is able to apply the knowledge gained to real-world projects.To be considered for this position, you must have a proven track record of successfully training individuals or teams on AI-related topics. Please submit a proposal describing how you can help with the project, including links to past completed projects.We are excited to work with a talented and experienced AI consultant who can help us take our team to the next level. If you have the skills and experience we are looking for, we encourage you to apply.Note: Some of the content in this job post may have been auto-generated using advanced AI.","['Artificial Intelligence', 'Machine Learning', 'Artificial Neural Network', 'Neural Network', 'Deep Learning', 'Natural Language Processing', 'Python', 'Machine Learning', 'Artificial Neural Network', 'Neural Network', 'Deep Learning', 'Natural Language Processing', 'Python']",United Arab Emirates,42,40.00,1.2,,,,Remote Job,Expert
Computational study of nanoparticles effects on Parkinson disease.,Computational study of nanoparticles effects on Parkinson disease.,"['Bioinformatics', 'computational biology ', 'molecular dynamics simulation ', 'molecular dynamics simulation ']",India,1,,,,250.00,,Remote Job,Expert
Scrape same info from different websites with python,"I need to scrape player informations from teams websites.There are 70 different teams and they hold player stats in their own websites. The informations I extract are always the same but websites is different. Example:Website1: https://virginiasports.com/sports/mlax/roster/season/2022-23/player/mitchell-whalen/Website2: https://yalebulldogs.com/sports/mens-lacrosse/roster/michael-alexander/18673Information I need extracted:Player Name, Player Class, Hometown etc.Let me know if you can automize this process for 70 different websites.Thanks,","['Python', 'Data Scraping', 'Data Mining', 'Scrapy', 'Data Extraction', 'pandas', 'Web Crawling', 'Python-Goose', 'Scrapy', 'Data Extraction', 'pandas', 'Web Crawling', 'Python-Goose']",Turkey,142,15.00,4.4,,50.00,,Remote Job,Intermediate
Ml engineer,I need a product that can scan documents with images and intelligently parse data into a database,"['Machine Learning', 'Artificial Neural Network', 'Computer Vision', 'Computer Vision']",Spain,1,,,,3000.00,,Remote Job,Intermediate
Machine Learning Help,I am struggle with Machine learning task. I will add the details to attachment. Follow the steps that are given in Chapter 2 of the Aurelien Gerone book.Each of you should select data where the associated task is a classification task with at least 10 attributes. You can select the data from the following site or any other place: http://archive.ics.uci.edu/ml/datasets.phpAlso prepearing the report.The deadline 14.06.2023.,"['Machine Learning', 'Python', 'Data Science', 'Deep Learning', 'Data Science', 'Deep Learning']",Turkey,3,,15,,5.00,,Remote Job,Expert
Help Configuring Google Analytics 4,"- Video meeting to help answer some questions I have about GA4- GA4 Setup and Configure for a website with Google Analytics Universal installed now. (321chat.com)- Check that I've set up another very similar site's GA4 correctly (NSFW Free Adult Chat Site - 321sexchat.com)Questions:Why was referral traffic from some domains captured with Universal Analytics but not on GA4? Can anything be done about this?. Is there a way to show in a graph over time [as was possible in UA], Referral traffic from specific domains, traffic from different search engines, traffic from different social media platforms. Is there a way to show a graph of hourly traffic? And compare it to the previous day? As was possible in UA? Can the graphs I've asked about be saved and set up on the homepage for easy viewing?. Analytics shows my traffic as 17% desktop users, while a very similar site has its desktop number at 40%. Is everything set up correctly?. Universal tracking still consistently tracks about 30 users daily, but those pages have updated code. The code was changed over a month ago. (user cache?). Why is the Organic Search Number so much smaller than what Google Search Console shows? Why is Direct so high? Are there any settings that can get the most accurate user demographics such as Age, Sex, and possibly Income?. User retention page? Explain the graphs. Tracking Sales: I have one-time sales for upgraded memberships that I would like to track.",['Google Analytics'],United States,41,34.72,3.5,,,"['75.00', '150.00']",Remote Job,Expert
Data Mining - Awareness Days/Days of the Year,"I have a list of c.200 awareness days and need the gaps filled in. I will point you toward another directory that has c.600 awareness days that need adding to my list.I will need the following data points:- Name - the Name of the Awareness Day- Date - the date the day occurs- Fixed date? - Is the awareness day the same day every year (like a birthday) or does it change? (like Easter Sunday)- Date Pattern - If Fixed date? is 'No' add the date pattern e.g. the third Sunday of January- URL - A link to the official website of the awareness day, specifically the webpage that explains what the day is about (e.g. https://www.saferinternetday.org/about), if an official page cannot be found, add the wikipedia page explaining the awareness day. If neither can be found add ‘no url’.- Date of Birth (if a Birthday)Attached is an example of the data and format i need","['Data Scraping', 'Online Research', 'Data Mining', 'Data Entry']",United Kingdom,5,,140,,60.00,,Remote Job,Entry level
Power Automate Specialist Needed for Web Scraping and Data Management,"We are looking for a skilled freelancer who is proficient in web scraping using Power Automate. The ideal candidate should be capable of creating a template and comprehensive, step-by-step tutorial on how to scrape data from a specific classified ads website and return it to an Excel file or, ideally, to Power BI.The project involves the following tasks:- Scrape data daily from two specific URLs (the URLs will be provided upon hiring).- Merge the scraped data as not all data points are available on a single page.- Compare the data from each day to identify any differences or updates that occur over time.The primary goal of this project is to create a report that identifies any changes to the scraped data. This report should be produced after the data is scraped and merged.Requirements:- Strong experience with Power Automate and web scraping.- Excellent understanding of data management and manipulation.- Ability to create clear and concise tutorials.- Familiarity with Excel and Power BI for data visualization.- Strong attention to detail to identify changes and updates in the data.- We appreciate candidates who can provide examples of similar projects they have completed in the past. If you believe you're the right fit for this project, please apply and let's discuss further.","['Microsoft Power Automate', 'Microsoft Power BI', 'Microsoft Power BI Data Visualization', 'Data Scraping', 'Microsoft Power BI', 'Microsoft Power BI Data Visualization', 'Data Scraping']",Croatia,1,,,,200.00,,Remote Job,Expert
Looking for an AI DEV,We are hiring the person with this skill sets:-NLP (needs to be able to work with AI texting)-need to be able to work with AI voices-needs to be able to work with AI photosGeneral information;We are hiring people who are willing to work and who are greedy to become a better version of themselves. This will play a huge role into the hiring process.,"['Artificial Intelligence', 'Machine Learning', 'Machine Learning']",Netherlands,7,,,"['Sales', 'Marketing']",,,Remote Job,Expert
"Data Scientist, python developer",Scope of the workHow fast you need it deliveredWhether they’ll work with your team closely or work independentlyIf there’s potential for more workWhat you don’t understand about the job and how they can helpRequired experienceHelpful links and references to explain the desired style,"['Python', 'Data Science', 'Machine Learning', 'NumPy', 'Data Analysis', 'Data Mining', 'Artificial Intelligence', 'Python Scikit-Learn', 'Deep Learning', 'pandas', 'NumPy', 'Data Analysis', 'Data Mining', 'Artificial Intelligence', 'Python Scikit-Learn', 'Deep Learning', 'pandas']",Azerbaijan,1,,,,30.00,,Remote Job,Intermediate
Data Scientist For Solving Time Series Regression Problem,"Looking for data scientist who can work with me and guide to solve real world time series regression problem.Need to have following skillsData Preprocessing/ Feature Engineering  for Time Series DataTensorFlow/Keras for modelling [ LSTM,RNN or GRN]Expert in using interpretability library for debugging model or track back prediction made on test data or on real data.Expert in hyperparameter tunning.","['Data Science', 'Machine Learning', 'Python', 'TensorFlow', 'Keras', 'Deep Learning', 'Statistical Analysis', 'Python', 'TensorFlow', 'Keras', 'Deep Learning', 'Statistical Analysis']",India,2,,,,100.00,,Remote Job,Intermediate
Analytics 4 set up review and testing,"I have a Shopify store and have set up G4 property in my Google Analytics, but not sure if it is setup properly. Looking for a reliable GA4 expert to get my GA4 configuration/integration checked and done on my Shopify store, Google Analytics and Facebook as a result of GA4 upgrade. Tasks below need to be  completed  before the 20th of June 2023. - Review existing Google Analytics 4 setup with correct data layers setup and ratify any issues. Including review the setup of  GA4 property and the web data stream in Google Analytics. - Set up the right Google Analytics 4 conversions and audiences. Customise Google Analytics 4 setup to collect the right data for the specific conversions, audiences- GA4 event TAGs setup for ""purchase"", ""add to cart"" and ""reached cart"" Estimated - Check Shopify store pixel ID connected to Facebook is accurate- Install the Google app on my Shopify store to link GA4 property and automatically set up GA4 tagging.","['Facebook Pixel Setup & Optimization', 'Shopify Apps', 'google analtyics tagging', 'Google analytics 4', 'Shopify Apps', 'google analtyics tagging', 'Google analytics 4']",Australia,11,,270,,50.00,,Remote Job,Intermediate
"Web scraping professional is needed, financial background is a plus","I am seeking a highly skilled and experienced web scraping expert with preferably a background in finance.  This is a small, but exciting opportunity for a motivated professional to contribute to our project by collecting and extracting relevant financial information from various websites.The data obtained should be stored in a database and should also be available through a JSON API.","['Web Scraping', 'Data Scraping', 'JSON', 'HTML', 'Python', 'Automation', 'Finance', 'Finance & Accounting', 'Python', 'Automation', 'Finance', 'Finance & Accounting']",Hungary,1,,,,20.00,,Remote Job,Intermediate
Google Analytics 4,"I want to make sure data is being gathered correctly and everything is communicating with different entities as needed.  I would like to make sure Google Analytics G4 is set up properly. I have a primary domain desperatetobewell.com. I have my author page cyndiwhatif.com (being built in WordPress), and I have a book landing page healthbackwards.com. Built but not live or have cart set up yet. I think all three should have their google analytics under desperatetobewell.com.I plan to start running Facebook ads to sell my book. I want to be able to track the activity so I know what is working. I do not understand if doing this helps me in tracking on Facebook or not, or if I also need to do something like FB pixel, etc. I did follow a tutorial to add FB pixel to WordPress and systeme.io. I think I did it correctly, but it does not say that WordPress and Facebook are communicating yet.I am also interested to know if Google Tag manager is a route I should take.","['Google Analytics', 'Google Tag Manager', 'Data Analysis', 'systeme.io', 'Facebook Pixel Setup & Optimization', 'Data Analysis', 'systeme.io', 'Facebook Pixel Setup & Optimization']",United States,3,25.00,238,,,,Remote Job,Intermediate
LABVEIW NI create a chocolate factory,"Must fulfill all requirements in the question paper attached below to create the chocolate factory.Must explain everything so I understand how it works Must use the same edition of LabVIEW so I can access the file I will attach examples of what is expected below.Must also be able to use Excel By the end of the project, I will require 2 files  - a report on the project - the LABVIEW file. The report requirements are in the question paper",['LabVIEW'],Malaysia,11,19.80,675,,35.00,,Remote Job,Intermediate
Oracle Analytics Cloud - Drill through,I want to use drill-through in OAC and also use hyperlinks to navigate between pages,"['Business Intelligence', 'Oracle E-Business Suite', 'Business Analysis', 'Analytics', 'Oracle E-Business Suite', 'Business Analysis', 'Analytics']",United States,1,,,,,"['18.00', '45.00']",Remote Job,Intermediate
Extract/scrape contact details from registry website.,"Job Title: Data Extraction SpecialistResponsibilities:- Extract data from an online registry using appropriate methods.- Validate and verify the accuracy of the extracted data.- Organize and format the data into a spreadsheet or database.- Collaborate with the team to understand project requirements.- Maintain confidentiality and comply with legal and ethical standards.Requirements:- Experience in data extraction and data manipulation.- Attention to detail and ability to ensure data accuracy.- Strong organizational and time management skills.- Excellent communication skills for effective collaboration.Note: Compliance with relevant website policies, privacy regulations, and legal requirements is necessary.If interested, please provide relevant experience and examples of previous data extraction work.We are seeking a skilled Data Extraction Specialist to extract and organize data from online sources efficiently and accurately.","['Web Scraping', 'Data Scraping', 'Data Mining', 'Data Extraction', 'Python', 'Data Entry', 'Web Crawling', 'Scrapy', 'Data Extraction', 'Python', 'Data Entry', 'Web Crawling', 'Scrapy']",Australia,2,,60,"['Sales', 'Marketing']",50.00,,Remote Job,Intermediate
Expert Python developer needed to build ai models using data sets.,"Extensive experience successfully built ai models for other clients, and able to share previous work products. Has built ai models using python and able to explain model performance.","['Machine Learning Model', 'Machine Learning', 'Model Tuning', 'Model Optimization', 'Python', 'Data Analysis', 'Data Science']",United States,27,,2,,250.00,,Remote Job,Intermediate
"Web scraping of ""portfolio"" categories","Hi, we have a list of 50,000 architecture firm websites.For each one, we want a list of each of their portfolio categories. Examples:1. https://perkinseastman.com/markets/ - output:Arts + CultureCommercial + OfficeHealthcareHospitality... etc... Workplace2. https://oda-architecture.com/projects/ - output:ARCHITECTUREINTERIORSLANDSCAPEURBAN DESIGNTYPEURBAN PLANADAPTIVE REUSEHOSPITALITYRESIDENTIALPRIVATE RESIDENCECULTURALCOMMERCIAL3. https://www.stevenholl.com/selected-projects/ - output:MUSEUMSPERFORMING ARTSHOUSINGEDUCATIONAL + CAMPUS WORKSOFFICE + HYBRID TOWERSLIBRARIESHOUSESRELIGIOUS WORKSHOTEL + RETAILHEALTHMASTERPLANS + LANDSCAPESCHRONOLOGICALFURNITURECARPETSCOLLECTIONSFIXTURESThe challenge is that each website probably uses different ways to encode the categories.",['Web Scraping'],United States,93,19.26,119,"['Tech', 'IT']",,"['25.00', '50.00']",Remote Job,Intermediate
Lab report,Must know how to use Simulink MATLAB.I will give a sample report.Must just make sure content is similar but not the same nor should there be usage of Chatgpt or similar softwares due to plagiarism.I will provide simulations however all you have to is change resistors values and key in values and manually calculate for another table and show calculations.,['Report Writing'],Malaysia,11,19.80,675,,15.00,,Remote Job,Intermediate
Currently Require Google Analytics and Data Analyst For entry-mid level position,"We are looking for Google Analytics and Data Analyst that is tech versed that likes to do work hard, someone honest and transparent, someone open-minded willing to teach and learn.There is no limit to how many hours you can work, which means your earning potential is unlimited. THIS IS FOR YOU IF…- want a long term stable job position with fixed income and steady weekly work hours- work whenever & wherever you want, and decide your own timeThere is potential for a long-term working relationship with the right applicant. There will be plenty of work available as we gain exposure, build a reputation, and grow into a successful company.First of all, Please Must Read Actual Detailed ""Job Description"" by Clicking ""Job Description"" Section at the given web page:https://tinyurl.com/CustomizedDescriptionClick at ""Job Description"" Section..","['Marketing Analytics', 'Operations Analytics', 'Product Analytics', 'Sales Analytics', 'Human Resources Analytics', 'Data Analytics', 'Data Interpretation', 'Google Analytics', 'Data Analysis']",Pakistan,3,,,,4000.00,,Remote Job,Entry level
Excel expert for data sheets and templates,"We are looking for an Excel expert who can help us with our data sheets and templates. The job length is less than 1 month, and we require someone who has experience in accuracy verification, data annotation, data entry, data labeling, data segmentation, data visualization, and Microsoft Excel. As an Excel expert, your main responsibility will be to help us manage and organize our data sheets and templates. You will be expected to ensure that our data is accurate, properly annotated, labeled, segmented, and visualized. Additionally, you will be responsible for creating spreadsheets that can be used to analyze our data in a meaningful way.To apply for this job, please submit a proposal that outlines how you can help us with this project. Please include any relevant experience you have and provide links to past completed projects that demonstrate your Excel expertise. We look forward to hearing from you!Note: Some of the content in this job post may have been auto-generated using advanced AI.","['Data Labeling', 'Data Segmentation', 'Data Annotation', 'Microsoft Excel', 'Data Visualization', 'Spreadsheet Software', 'Data Entry', 'Accuracy Verification', 'Spreadsheet Software', 'Data Entry', 'Accuracy Verification']",France,45,25.00,4.5,,100.00,,Remote Job,Expert
Scrape Wordpress Content & HTML to be used for a Static HTML Site,"Hi all, I need someone whom understands the ins and outs of working with scripts and efficiency when it comes to time in pulling data out of large projects. I'm a developer in process of migrating client's entire 125 page website (wordpress) to a static html site. No more CMS. There's plenty of data I can grab through export plugins but the truth is I just don't have the time to get in there and do it properly. This is what needs to be extracted or copied from the existing wordpresss website. *FYI - Certain bits of data which are compiled on page load into the head of the page were created using wordpress plugins. This is something you may have trouble with but it's a necessity that i obtain the data, please read through this carefully so you understand what's required. ****************************************HUGE BONUS Points IF....Rather than just sending me a spreadsheet with columns of data. --Are you skilled enough to extract all of the data listed here and recreate the live site's directory and batch export - inject the data into html files? 124 wordpress pages TO 124 .html pages. **************************************Need Extracted and placed into a spreadsheet: 1) Page Titles & Meta Descriptions (Yoast/wordpress SEO)2) Canonical URL Tags for each page (Yoast/wordpress SEO)3) Open Graph Social Media Meta Tags (Facebook, Twitter)***No Export Option via Developer & Could not find JSON data in SQL******FYI-Name of plugin is WP SEO Structured Data Schema****4) Service Schema  markup in JSON With custom info/descriptions written for each page.5) Breadcrumbs Schema Markup per each page (Breadcrumbs are generated or enabled by Yoast/Wordpress SEO) 6) Front-End Page Content: Only page body content is needed. On the back-end the content is mixed in with WP-Bakery-Visual Composer Short codes - I need it to be completely clean and exported in either MARKDOWN format or PURE HTML. (NO images) - ONLY H1-H6 heading tags, Paragraph and list item content7) H1 Page Title for each page8) Link for each pageThank you for checking out my post, I hope it was informative. Please reach out if you know what i'm looking for. :)","['Data Scraping', 'Web Crawling', 'Python', 'Scripting', 'Data Migration', 'WordPress Migration', 'WordPress', 'HTML', 'Tailwind CSS', 'Python', 'Scripting', 'Data Migration', 'WordPress Migration', 'WordPress', 'HTML', 'Tailwind CSS']",United States,21,46.67,19,,,"['8.00', '35.00']",Remote Job,Expert
ESG Report,"ESG Reporting of Private Blockchain-based data management system. There should be comparison of traditional database-based data management system versus Private Blockchain enabled data management system. (for 2 different countries)Data collection processes. High Quality Reporting, graphical and table demonstrations of outputs. Relevant empirical calculations and definitions. Details will be discussed.","['Academic Writing', 'Environmental Science', 'Sustainability', 'Environmental, Social & Corporate Governance', 'Compare', 'Classify', 'Sustainability', 'Environmental, Social & Corporate Governance', 'Compare', 'Classify']",Turkey,3,,0,,150.00,,Remote Job,Intermediate
Simple task- web scrapper/data extraction from a website,"I am in search of a skilled and experienced web scraper/data extraction expert to assist me with exporting property data from a Malaysia property website and organizing it on a Google Sheet and Drive.Job Requirements:-Proficiency in web scraping and data extraction techniques-Expertise in extracting property data from websites-Strong knowledge of Google Sheets and Drive for organizing and managing data-Attention to detail and ability to follow instructions accurately-Availability to complete a simple test (extracting data from 3 specified links) before being hired-Potential for long-term full-time work if the initial job is performed satisfactorilyIf you are interested in this position and possess the required expertise, please send me a private message with your details and any relevant experience.","['Data Scraping', 'Data Extraction', 'Data Entry', 'Data Mining', 'Web Crawling', 'Google Sheets', 'JavaScript', 'Microsoft Excel', 'Data Entry', 'Data Mining', 'Web Crawling', 'Google Sheets', 'JavaScript', 'Microsoft Excel']",Malaysia,2,,,"['Tech', 'IT']",20.00,,Remote Job,Intermediate
Power BI Developer,"Looking for PowerBI Developer to build and develop real-time Dashboards covering different aspects of the payments business, including the analysis of the Audience, Operations, and Finance.","['Marketing Analytics', 'Statistical Analysis', 'Python', 'Microsoft Power BI', 'Data Visualization', 'Data Analysis', 'Business Intelligence', 'SQL', 'Data Modeling', 'Microsoft Power BI Development', 'Data Analysis', 'Business Intelligence', 'SQL', 'Data Modeling', 'Microsoft Power BI Development']",Latvia,8,44.99,13,"['Tech', 'IT']",,"['10.00', '200.00']",Remote Job,Expert
"Using Machine learning & Artificial Intelligence, do data labeling","Amazon has a product call AWS Rekognition, even well known as  Data Labeling.What I need from freelancer--- Training of the model [Code / Time required for training / Cost of training]---  Passing of the new data to get the output. [label]--- How can we do retraining of the model, if we know this particular result isn't getWhat will be provided--- Folder with Image in them --- Generally the folder name is in number like [1,2,3....] those folders will be considered as the LabelHow many folder or label around 150How many images, in each folder [We can provide as much is needed]","['Machine Learning', 'Artificial Intelligence', 'Python', 'Deep Learning', 'Python', 'Deep Learning']",United Arab Emirates,23,28.20,5.8,,,"['18.00', '30.00']",Remote Job,Intermediate
Data compiling,You will need to get the script for as many Woebot pathways,"['Data Scraping', 'Data Mining']",United States,11,,790,,150.00,,Remote Job,Intermediate
Arabic natural language processor AI Chatbot dialog,"i want an AI that can help me run it for my customer service that can understand there request and replay to themthis should not use any 3rd party AI'sthe final result should be expecting to do the following1- check my email, twitter mentions and direct massages, in app chats, whatsapp, and other channels 2- then classify the requests 3- replay the correct answer4- answers will be generated if a new request is made or not made before5- report page will be there to show statistics about requests and reply time ...etcthanks and regards","['Natural Language Processing', 'Natural Language Generation', 'AI Chatbot']",Qatar,2,,,"['Tech', 'IT']",,"['40.00', '70.00']",Remote Job,Expert
Web scraper for Instagram,"I need a web scraper to extract Instagram profiles onto Excel spreadsheets.I am looking for a web scraper who can extract data from specific profiles.I would provide you with the Instagram profile, and you will provide me with spreadsheets containing the list of followers (a list of Instagram profiles that follow the profile i have provided.Pretty straightforward!I am wanting to start this immediately, like today!I look forward to hearing from you","['Data Scraping', 'Python', 'Scrapy', 'Instagram API', 'JavaScript', 'Instagram API', 'JavaScript']",Chile,56,9.06,577,,5.00,,Remote Job,Expert
"Implement ""AI based intrusion detection for intelligence internet of vehicle"" on any software","Implement ""AI based intrusion detection for intelligence internet of vehicle"" using 5G network in any networking software like NS3, OMNet++ or any other. Project should be done in a virtual machine.Further details will be provided on a zoom meeting.","['C++', 'MATLAB', 'Artificial Intelligence', 'Machine Learning', 'Deep Learning', 'network simulator', 'omnet', 'Intrusion Detection System', 'Intrusion Prevention System', 'Machine Learning', 'Deep Learning', 'network simulator', 'omnet', 'Intrusion Detection System', 'Intrusion Prevention System']",Pakistan,2,,,"['Engineering', 'Architecture']",200.00,,Remote Job,Expert
Deploying Open Assistant Chatbot,This project is about Deployment of Open Source LLM of Assistant Chatbot LLM with training. The second phase would be the API endpoint creation. I'll only accept developers with Demo. I'm not ok to pay for R&D as the project is on github and ready to be deployed.,['Chatbot Development'],Georgia,208,28.28,61,"['Transportation', 'Warehousing']",,"['40.00', '70.00']",Remote Job,Expert
Build 3D visualisation of football pitch with positional data using Streamlit,"I’m looking for someone with python/streamlit knowledge who can create a 3D visualisation of a football (soccer) pitch that can show pass/shots based on the x, y, z coordinates of their source and target positions.I want to include the visualisations in a streamlit application and for a user to be able to move around the visualisation and zoom by clicking/dragging etc.I would envisage potentially using pyvista but other solutions are welcome. Based on the successful completion of this activity, I am planning on several other visualisations I want to build going forward.","['Data Visualization', 'Python', 'Streamlit']",United Kingdom,2,,,"['Sports', 'Recreation']",,"['20.00', '50.00']",Remote Job,Expert
Troubleshoot airflow,We're experiencing some issues with our airflow running on Google Cloud compute - GUI cannot be accessed but the server is running and can be accessed. The objective of the task is to troubleshoot and get it running.,['Apache Airflow'],Tanzania,79,53.99,11,,,"['30.00', '60.00']",Remote Job,Intermediate
Troubleshoot airflow,We're experiencing some issues with our airflow running on Google Cloud compute - GUI cannot be accessed but the server is running and can be accessed. The objective of the task is to troubleshoot and get it running.,['Apache Airflow'],Tanzania,79,53.99,11,,,"['30.00', '70.00']",Remote Job,Intermediate
Crawl some data,Some crawling and data extracting expert needed to crawl some data from a certain website,"['Data Scraping', 'Data Extraction', 'Scrapy', 'Web Crawling', 'Scrapy', 'Web Crawling']",United Arab Emirates,175,10.51,17,,20.00,,Remote Job,Intermediate
Machine learning developer,"Hi. I'm looking for the machine learning developer, preferably 4 to 5 years of experience. Someone who has experience with imputations, predicting missing data, and building a model with reinforcement learning. And also optimize NLP Algorithm. This could be a long-term project, We can discus hourly are fixed weekly pay.(I developed most of the code but it needs modifications and optimization)Please submit proposals only if you are experienced in these areas.We can discuss more details over a call.Thank you!","['Machine Learning Model', 'Model Optimization', 'Convolutional Neural Network', 'Machine Learning', 'Python', 'Artificial Intelligence', 'Data Science', 'Neural Network', 'Natural Language Processing', 'Artificial Intelligence', 'Data Science', 'Neural Network', 'Natural Language Processing']",United States,31,15.19,8.4,"['Tech', 'IT']",500.00,,Remote Job,Expert
Software Engineer Experienced in Deploying Serverless Clusters with AI Models,"We are seeking an experienced Serverless Cluster Developer to assist with an exciting new project involving artificial intelligence and natural language processing. The ideal candidate has in-depth knowledge of serverless architectures and has hands-on experience working with AI models, particularly the Facebook Llama model.Responsibilities:- Develop and deploy a serverless cluster capable of running the Facebook LLaMA model.- Implement endpoints for a chat API.- Implement an endpoint for transforming text into a numeric vector representation (also known as embeddings).- Design the system to be scalable, in response to API rate limits from other services.- Ensure the solution meets performance and reliability requirements.- Collaborate closely with our team, providing updates on progress and any challenges encountered.Required Skills and Experience:- Proven experience in developing and managing serverless architectures.- Experience with AI and NLP models, particularly Facebook's Llama model.- Knowledge of API development and management.- Excellent problem-solving skills and attention to detail.- Experience with scalable systems.- Strong communication skills.This is a contract position for the first few months. The budget for this project is approximately $5,000 per month. Please submit your resume and relevant project examples with your application.","['Chatbot', 'Amazon Web Services', 'LLaMA', 'Artificial Intelligence', 'AWS Lambda', 'Serverless Stack', 'Python', 'Artificial Intelligence', 'AWS Lambda', 'Serverless Stack', 'Python']",United States,3,150.00,300,,,"['25.00', '40.00']",Remote Job,Expert
PyTorch Model Optimization and Quantization with NVIDIA's TAO Library,"The goal of this project is to optimize a PyTorch model using quantization techniques and NVIDIA's TAO (TensorRT Optimization Acceleration) library. The project aims to explore the speed to accuracy trade-off when applying quantization to the model and provide scripts to evaluate the performance using a test dataset. Finally, the quantized model should be ported to TensorRT for further acceleration.The project will involve the following deliverables:Model Optimization using Quantization: The PyTorch model will be optimized using various quantization techniques. This includes reducing the precision of weights and activations to lower bit-width representations, such as INT8 or INT4. The quantization process will aim to minimize the impact on model accuracy while maximizing the potential for speed improvement.Integration with NVIDIA's TAO Library: The quantization process will leverage the capabilities of NVIDIA's TAO library, which provides tools and optimizations for deep learning models targeting deployment on NVIDIA GPUs. The TAO library offers efficient implementations of quantization algorithms and model conversion utilities.Speed-to-Accuracy Trade-off Analysis: Test scripts will be developed to evaluate the performance of the quantized models using a designated test dataset. The scripts will measure the inference time and accuracy metrics for different levels of quantization. This analysis will help understand the trade-off between speed and accuracy and provide insights into the optimal quantization settings for the given model.Model Porting to TensorRT: After quantization, the optimized model will be ported to TensorRT, a high-performance deep learning inference optimizer and runtime engine developed by NVIDIA. TensorRT leverages the power of GPU hardware to accelerate model inference further. The porting process will ensure compatibility and take advantage of the optimizations provided by TensorRT.Throughout the project, best practices for model quantization, TAO library integration, and TensorRT porting will be followed. The project will be implemented using Python and relevant deep learning frameworks such as PyTorch, ONNX, and TensorRT. The code will be well-documented and modular to facilitate future extensions or modifications. The project aims to provide a comprehensive framework for optimizing and quantizing PyTorch models using NVIDIA's TAO library and TensorRT, enabling efficient deployment of deep learning models in production environments.","['Model Optimization', 'Deep Learning Modeling', 'PyTorch', 'Machine Learning', 'Python', 'Neural Network', 'Computer Vision', 'Deep Learning', 'Python', 'Neural Network', 'Computer Vision', 'Deep Learning']",United States,2,,,,2000.00,,Remote Job,Intermediate
Data architecture and implementation of cloud based data warehouse,"Fast growing telecom company looking for data expert to design and build data infrastructure. End product is data warehouse with integration points to operational, CRM and ad systems. Must have extensive experience with developing for one or more cloud based data warehouse applications: MS Azure, Google Cloud/BigQuery, AWS Redshift, Snowflake. Must be able to extract data from MySQL as well as develop APIs using webhooks. Must have excellent English communication skills (speaking and listening) to understand the needs and data use cass of the business and make a recommendation for choice of vendors comprising the data tech stack.Must be comfortable with solving open ended problems with little guidance and oversight. The team values a good attitude, solutions-oriented, low-conflict and respectful.  Potential for temp-to-permanent hire based on skills exhibited and fit with team. Nice to have:- Integration experience with ad networks (FB, Google, LI) and CRM systems (Iterable, Braze, Klaviyo, Customer.io, SendGrid) - Experience implementing modern cloud based reporting and BI tools such ask Google Looker/Datastudio, Holistics, PowerBI).- Sprint based agile work management methodology (weekly planning using sprint points, clear tracking of deliverables and willingness to reflect and give feedback to improve effectiveness of self and team.)","['Database Architecture', 'Data Integration', 'Database Design', 'Snowflake', 'MySQL Programming', 'Amazon Redshift', 'Google Cloud Platform', 'API Integration', 'Amazon Redshift', 'Google Cloud Platform', 'API Integration']",United States,6,66.67,315,"['Tech', 'IT']",,"['65.00', '150.00']",Remote Job,Expert
Remote Viewing Analyst (Unveiling the Future's Hidden Secrets),"Position Overview:We are seeking a skilled and enthusiastic Remote Viewing Analyst to join our groundbreaking project. As a Remote Viewing Analyst, you will play a vital role in analyzing remote viewing sessions to identify target locations. Your work will contribute to the successful outcome of our project, which involves predicting future events and visiting selected target locations using our beacon technology.Responsibilities:- Conduct thorough analysis of remote viewing sessions to determine the associated target locations.- Keep the project leader informed of the letter associated with the target location as determined during the session.- Maintain strict confidentiality regarding the content of the sessions and the optional target locations until the outcome of the bet is determined.- Example: If Team 1 wins the baseball game, the beacon will visit Target Location A: Television Tower, Alexanderplatz, Berlin, Germany. If Team 2 wins, the beacon will visit Target Location B: Large Pond, Volkspark Friedrichshain, Germany.- Notify the project leader if the analysis does not provide a clear outcome or if any mix-ups occur during the session.- Verify the game outcome online and promptly communicate the correct letter associated with the result to the project leader or the beacon.- Continuously contribute to the improvement of the project using the Kaizen principle. We welcome suggestions and ideas for enhancing our methodologies and techniques.Compensation:- Initial compensation: USD $2.50 per session analysis.- Negotiable higher payments for analyses that contribute to the project's success.Join us on this thrilling journey of discovery as we unlock the hidden future and harness the potential of remote viewing. Together, we can push the boundaries of what is possible and open up new and exciting opportunities.Please note: Remote viewing is a fascinating field that combines intuition, analysis, and the exploration of uncharted territories. While results have shown promise, we acknowledge that remote viewing is still considered unconventional by many and not widely recognized by established scientific institutions. Nonetheless, we believe in the potential and strive for success through dedicated teamwork and constant improvement.If you are passionate about exploring the unknown and have a keen interest in remote viewing, we invite you to apply and become an integral part of our dynamic team.Please submit your application, including your resume and any relevant experience, to be considered for this unique opportunity.Note: This job description is subject to change as the project progresses and further enhancements are made.------------------------------------------------------------------------------Example 1: Beacon Video Alexanderplatz, Germany:https://www.tiktok.com/@dietechnikderzuku/video/7242243843368832282?is_from_webapp=1&sender_device=pc&web_id=7193215965386688006------------------------------------------------------------------------------Example 2: Beacon Video: Volkspark Friedrichshain, Germany:https://www.tiktok.com/@dietechnikderzuku/video/7242588442842959131?is_from_webapp=1&sender_device=pc&web_id=7193215965386688006------------------------------------------------------------------------------In the attachment, you will find a session conducted by Sylvia. The target location for this session was Volkspark Friedrichshain. Based on the correlations observed between the session contents (sketches of the pond and park features, mentions of ""City Park,"" ""playing children,"" etc.) and the characteristics of Volkspark Friedrichshain, it was determined that Sylvia's session unmistakably pointed to Volkspark Friedrichshain as the designated target location. Here is the Google Maps link to the target location described in Sylvia's session:https://goo.gl/maps/ieFrpyUe3KWMAMxv5Please note that the actual session pertains to the visit of the beacon during its subsequent stay at the target location, which is determined by the outcome of the bet. The purpose of the provided photos and Google Maps information is solely to identify potential indicators for the target location that the beacon will later visit. Viewers can sometimes be influenced or distracted by events occurring near the target location, such as local fairs or festivities. Online analysis of the target location should reveal any current significant construction sites or ongoing events that may appear in the session.We emphasize the importance of thorough analysis and attention to detail in order to achieve accurate results and ensure the beacon's effective interaction with the identified target location.The analyst should, if possible, consult with the person (Beacon) designated to visit the target location based on the outcome of the bet to confirm if the session aligns with the potential target location.Create diverse target sets:Bonus payment of USD $1.00 per target set created","['Operations Analytics', 'Human Resources Analytics', 'Data Analysis', 'Report', 'Data Analytics', 'Microsoft Excel']",Germany,118,,1.8,"['Science', 'Medicine']",10.00,,Remote Job,Entry level
Highly Specialised Lead Generation + Data Scraping,"I'm looking for some high quality data, quality over quantity for me. Starting with 300 contacts.We want a list of:course creators who offer at least 2 products, a low ticket and high ticket offer of min $1000. Ideally have a list of 10K+, but not sure if it's possible to know their list size unless their mention it on their website somewhere.Are running paid traffic (FB/IG)Have a company that is minimum 3 years old.This could be business owners in fitness, dating, affiliate marketing, business coaching, personal development, SEO/FB/TikTok/YouTube ads courses, crypto/fx trading courses etc...Location: UK, USA, CAN, AUSPlease let me know in your application what's possible. Perhaps some of these criteria cannot be met. Let me know how you can help best match what we want. The data I need is: First and last nameEmail addressWebsite LinkedIn profile Industry Course nameCourse price List size (if possible)If your data is good, then we'll be needing at least 1000 lead per month. I'd like a small sample to make sure you understand my requirements.","['Data Scraping', 'List Building', 'Prospect List', 'Lead Generation', 'Prospect List', 'Lead Generation']",United States,94,26.44,113,"['Sales', 'Marketing']",,"['8.00', '20.00']",Remote Job,Intermediate
Data extraction - Compile contact list from databases for sales team,"We are looking for a data extraction specialist who could help us to build a contact list, based on companies names we have, and your goal is to search for the email of the marketing person (not a generic email, except if no marketing contact can be identified).","['Data Scraping', 'Data Extraction', 'LinkedIn', 'LinkedIn']",Hong Kong,99,10.42,26,,,"['3.00', '10.00']",Remote Job,Entry level
Survey Result Statistical Analytics needed,"Important: 1.Please provide a offering in fixed price. I am not putting down a budget on intention, to give you a chance to evaluate and offer a competitive offer.2. We need this exercise until June 12 end of day. Otherwise the job is worthless to us. Please only offer a price, if you can deliver. Otherwise we would not approve the milestone (just to be fair and transparent in advance)Job description: I am currently working on a project titled ""Effects of Inflation on Brand Loyalty to Sustainable Products"", and I am in need of your expertise in data analysis.The study examines three product groups: Sustainable Cleaning Products, Sustainable Cosmetic Products, and Sustainable Clothing across four countries: Austria, Croatia, Hungary, and Portugal. I have conducted a survey and collected data from 369 respondents, which include details on age, income, country of residence, education, and employment status.My hypotheses for the research are as follows:H1: Inflation has a negative impact on brand loyalty to sustainable cosmetic products.H2: Inflation has a negative impact on brand loyalty to sustainable cleaning products.H3: Inflation has a negative impact on brand loyalty to sustainable clothing products.H4: Inflation impacts differently on brand loyalty to sustainable products in Portugal, Austria, Hungary, and Croatia.H5: Countries with higher inflation are experiencing a more negative impact on brand loyalty than countries with lower inflation.H6: Consumers with higher brand loyalty to sustainable products prior to inflation are less influenced by inflation than consumers with lower brand loyalty prior to inflation.H7: The impact on brand loyalty to sustainable products caused by inflation differs in terms of gender, age, and income.To examine these hypotheses, I require specific analyses, each intending to reveal unique aspects of the collected data:1)	Descriptive Statistics: To understand the basic features and distributions within the data.2)	Correlation Analysis: To evaluate the nature and strength of the relationship between inflation and brand loyalty.3)	Independent Samples T-Test or One-Way ANOVA: To explore potential differences in brand loyalty across the four targeted countries.4)	Multiple Regression Analysis: To investigate the impact of inflation on brand loyalty, controlling for covariates such as age, income, education, and employment status.5)	Moderation Analysis: To determine if the relationship between inflation and brand loyalty differs by product type and demographic characteristics.6)	Mediation Analysis: To ascertain whether certain variables mediate the relationship between inflation and brand loyalty.7)	Chi-Square Test of Independence: To detect significant associations between demographic characteristics and brand loyalty.8)	Multivariate Analysis of Variance (MANOVA): To examine brand loyalty across the three different product types simultaneously, identifying whether any differences are based on the independent variable (country).9)	Country-Specific Analyses: To identify unique patterns or findings in the data for each country.10)	Cross-Country Comparisons: To contrast findings from different countries and identify potential cultural or economic influences on consumer behavior.11)	Industry-Specific Analyses: To distinguish which product categories consumers maintain loyalty to during inflation periods.12)	Demographics Specific Analysis: To examine different demographic groups' reactions to inflation in terms of brand loyalty.13)	Purchasing Power Parity: To consider inflation rates in relation to purchasing power parity, thereby providing a better understanding of consumers' purchasing capabilities.14)	Consumer Perception of Inflation: To gain insights into how consumer perception of inflation impacts their loyalty towards sustainable brands.15)	Multiple Correspondence Analysis (MCA): To gain insights into the patterns of relationships among several categorical dependent variables such as country of residence, demographic characteristics, and brand loyalty.The data analysis should be conducted using SPSS, and I would appreciate your help not only in performing these analyses but also in providing a brief interpretation of the results in the context of my hypotheses and the visualisations. I would like to receive the results in an SPSS output file and a formal report (Word Document).I trust that you will handle the data with confidentiality.I look forward to collaborating with you on this project","['Statistics', 'IBM SPSS', 'R', 'Data Visualization', 'Data Science', 'Data Analysis', 'Quantitative Analysis', 'Data Science', 'Data Analysis', 'Quantitative Analysis']",Germany,15,30.00,2.4,,,"['10.00', '50.00']",Remote Job,Expert
Prompt Engineer,Create custom prompt for open AI ( GPT3.5/4).Need to provide proper rules to get a valid and sensible response for the query.Will need to restrict the answers (responses) within the content provided (content url/sitemap/files etc).Have good knowledge of prompt engineering and concepts like temp. control etc,['Python'],India,2,,140,,,"['15.00', '35.00']",Remote Job,Intermediate
An excel database with monitoring and a dashboard,An excel database with monitoring and a dashboard.This is the data I want to turn into a secure and easily accessible databaseThen an interactive dashboard to link to the databaseAnd finally be able to pull monthly reports from it.,"['PHP', 'Data Processing', 'Microsoft Excel', 'Microsoft Access', 'Database Programming', 'Microsoft Access', 'Database Programming']",Australia,536,,3.4,,,"['10.00', '15.00']",Remote Job,Expert
prep workbook on Tableau,I am looking for a freelancer to create a prep workbook on Tableau for an intermediate audience.please look at the attached file,"['Java', 'Microsoft Excel', 'Tableau', 'C']",Australia,536,,3.4,,,"['10.00', '15.00']",Remote Job,Expert
Need help looking for AI Celeberty Voice Cloning,Need help finding the software used to create this video or how was it made: https://youtu.be/2S3kcv8rvzo,['Artificial Intelligence'],Mexico,88,,2.1,,5.00,,Remote Job,Entry level
AI/Machine Learning Expert for Generative AI Consultation like ChatGPT,"**Job Description:**We are seeking a qualified AI/Machine Learning expert to provide consultation on the development and implementation of a Generative AI model. The model is intended to answer specific questions within a particular field of science. The consultation will focus on the potential of feeding the AI current information and training it on scientific PDFs.**Project Description:**We require consultation on the viability and approach of developing an AI model that can ingest, comprehend, and generate accurate answers based on knowledge contained in a specific scientific field. We intend to provide relevant materials and information, including PDFs and other documents, to train the AI model. The envisioned outcome is an AI system capable of accurately addressing queries within this scientific domain.**Consultation Objectives:**1. Understand the feasibility of the project and potential challenges.2. Gain insights on best practices for designing and developing a generative AI model.3. Learn about suitable AI training techniques for ingesting and understanding information from a range of documents, including PDFs.4. Discuss strategies for testing the system and ensuring it produces accurate results.5. Address potential bugs or performance issues that might arise.We encourage interested parties who possess the skills and experience to apply.","['AI Chatbot', 'ChatGPT', 'Conversational AI', 'Azure OpenAI', 'Artificial Intelligence', 'Machine Learning', 'Deep Learning', 'Machine Learning', 'Deep Learning']",India,3,30.00,0,['Education'],,"['16.00', '100.00']",Remote Job,Intermediate
Technical SEO Expert,"Position Overview:We are seeking a highly skilled and experienced Technical SEO Expert to join our team. As a Technical SEO Expert, you will be responsible for optimizing our website and ensuring it adheres to best practices for search engine optimization. You will work closely with the marketing and development teams to implement technical SEO strategies, improve website performance, and enhance organic search visibility.Key Responsibilities:* Perform comprehensive website audits to identify technical SEO issues and opportunities for improvement.* Develop and execute effective technical SEO strategies to optimize website architecture, crawlability, and indexing.* Conduct in-depth keyword research and analysis to identify relevant target keywords and optimize on-page content.* Collaborate with the development team to implement technical SEO recommendations, including schema markup, structured data, canonicalization, and XML sitemaps.* Optimize website load speed, mobile responsiveness, and overall user experience to improve search engine rankings.* Monitor and analyze website performance using SEO tools and analytics platforms, such as Google Analytics and Google Search Console.* Stay up-to-date with the latest trends, algorithms, and best practices in SEO, and make recommendations for continuous improvement.Provide guidance and support to content creators, ensuring that on-page optimization techniques are implemented effectively.* Conduct competitor analysis and benchmarking to identify opportunities for outperforming competitors in organic search.* Collaborate with cross-functional teams, including marketing, content, and design, to align SEO strategies with broader business goals.* Generate regular reports on SEO performance, keyword rankings, traffic, and other relevant metrics to stakeholders.* Stay informed about emerging SEO tools and technologies, and recommend their adoption when appropriate.Qualifications and Requirements:* Bachelor's degree in marketing, computer science, or a related field (or equivalent work experience).* Proven experience as a Technical SEO Specialist, SEO Analyst, or similar role, preferably in an agency or large-scale website environment.* Strong understanding of search engine algorithms, ranking factors, and technical SEO best practices.* Proficiency in using SEO tools such as Google Analytics, Google Search Console, SEMrush, Ahrefs, Moz, or similar platforms.Solid understanding of HTML, CSS, JavaScript, and website development concepts.* Familiarity with content management systems (CMS) and their impact on SEO, particularly WordPress.* Experience with website auditing tools and crawling software (e.g., Screaming Frog, DeepCrawl).* Excellent analytical and problem-solving skills, with the ability to interpret data and draw actionable insights.* Strong communication and collaboration skills to work effectively with cross-functional teams.* Ability to multitask, prioritize workloads, and meet deadlines in a fast-paced environment.* Certifications in SEO and Google Analytics are a plus.ABOUT THE COMPANYWe are on a mission to help 300 plumbing shops to achieve their aspirations. We are dedicated to the highest quality service with a commitment to excellence.We are a digital agency that takes pride in attracting high quality team members who are dedicated to providing the highest quality service.  We take personal responsibility for all our outcomes. Everything we do, we do with a commitment to excellence.  We believe in continuous improvement and serving others.  We are team players and we  support each other in being the best. Together we all win.  CORE VALUESAs we grow as a company and organization we look forward to maintaining our vision and values and uphold them to the highest standards. We want to build an environment where our team players get excited about winning. Not just winning at what they do as an individual but winning as an organization, as a team, as a culture, and most importantly - WINNING AT LIFE.WOW - We deliver WOW through serviceINTEGRITY - we act with integrity in everything we doTEAMWORK - we play fair, we have fun and we help each other win.CHANGE - We embrace and welcome change.LEARNING - We are committed to mastering our craftEXCELLENCE - we do our work with a commitment to excellence.OWNERSHIP - We embrace an ownership mentality","['Competitive Analysis', 'Technical SEO', 'SEO Performance', 'Organic Traffic Growth', 'SEO Keyword Research', 'SEO Audit', 'Google Analytics', 'SEO Backlinking', 'On-Page SEO', 'Search Engine Optimization', 'SEO Keyword Research', 'SEO Audit', 'Google Analytics', 'SEO Backlinking', 'On-Page SEO', 'Search Engine Optimization']",United States,133,10.65,104,"['Sales', 'Marketing']",,,Remote Job,Expert
AI Chatbot for a website,Develop a chatbot integrated with ChatGPT on our website that is limited to answering questions related to government information and services.Attache an example and how we want it presented by the bot,"['Chatbot Development', 'Artificial Intelligence', 'Natural Language Processing', 'Python', 'Machine Learning', 'Artificial Neural Network', 'deeplearn.js', 'Computer Vision', 'Data Science', 'Deep Neural Network', 'Natural Language Processing', 'Python', 'Machine Learning', 'Artificial Neural Network', 'deeplearn.js', 'Computer Vision', 'Data Science', 'Deep Neural Network']",Germany,2,,,['Automotive'],,"['40.00', '70.00']",Remote Job,Expert
Google Optimize Split Test Expert,"Hello,I am looking for someone who can connect Google Universal analytics with Google Optimize and help me create an A/B test using two landing pages.","['Google Optimize', 'Google Analytics', 'Google Tag Manager', 'Google Tag Manager']",Australia,27,6.94,2.1,,,"['5.00', '15.00']",Remote Job,Intermediate
Business intelligence Analyst,"seeking a skilled Business Intelligence Analyst to create data-driven strategies that improve our company's processes and increase our market share. You will be working with a team to mine data, develop analytics tools, and report back on your findings and solutions.To be successful as a Business Intelligence Analyst, you should have a passion for data and a highly analytical mind. Top candidates will also have good written and verbal communication skills in order to effectively explain the strategies you want to implement.","['Data Analysis', 'Business Intelligence']",United States,1,,,,,"['35.00', '60.00']",Remote Job,Entry level
Data Engineer,"Want to make a difference to people's lives?Join a team that empowers businesses to achieve their full potential by unlocking their data. We know we are changing the lives of our customers by taking the stress and headaches away by turning data into a living, breathing part of everyday life. It's a great feeling to make a difference and give customers visibility over what is happening in their business.We are looking for a Data Engineer who absolutely LOVES DATA (and knows how to harness it) to join our team at Lime Intelligence. You will support our Head of Digital and work alongside our team of data engineers and BI developers to build connections using our cutting-edge tools to set up client data warehouses across various market industries.​LIME OFFERS YOU:- A fun and supportive work environment;- Variety of projects and up-skilling;- Agile and cutting-edge tools to work with;- Flexible working arrangements.YOUR PERSONAL ATTRIBUTES:- Self‐motivated and have an enquiring mind;- High level of personal and professional integrity;- Initiative and the ability to work autonomously as needed, whilst being a collaborative team member;- Look for solutions and not stop at problems;- Well-developed critical thinking skills; and- The ability to be across the detail, while seeing the big picture.RequirementsAREAS OF INVOLVEMENT:- Development of end-to-end data pipelines in Matillion, AWS, and Snowflake environments- Advising on data architecture, data models, data migration, integration and pipelines and data analysis- Implementing solutions for the establishment of data management capabilities including data models and structures, database and data storage infrastructure, master and metadata management, data quality, data integration, data warehousing, data transformation, data analysis, and data governance- Development and execution of Data migrations- Supporting pre-sales activity to help understand systems and data sources for prospective clients- Strong BI development (dashboards) Tableau preferred but experience in Power BI etc. is ok.DAILY TASKS INCLUDE ITEMS SUCH AS:- Building and maintaining end-to-end ETL processes across multiple platforms/data sources;- Creating SQL scripts and stored procedures to assist in the ETL pipeline;- BI Dashboard development;- Creating custom API data connectors;- Problem-solving and brainstorming efficient data migration;- Contributing to supporting and training team members;- Documentation of solutions and working with multiple operational systems;- Working on brainstorming new ways of efficiently turning data into reporting layers for dashboards;- Engaging with the rest of Lime’s Digital team; and- Liaising with clients and data providers.YOUR SKILLS, EXPERIENCE & QUALIFICATIONS:- Minimum 3 years experience in ETL/ELT (ideally MS stack, Matillion, Talend);- Experience in cloud-based data warehousing (e.g. Redshift, BigQuery, Synapse Analytics, Snowflake);- Experience in integration/middleware is desirable (API, Enterprise Service Bus, Mulesoft, Tibco);- Experience with data migration;- Experience building data warehouses and data lakes;- Expertise in some flavour of SQL is essential (MySQL, MS SQL, PostgreSQL);- Working knowledge of APIs (REST, JSON, XML, etc);- Experience in a scripting language (Python preferred) such as  (Python, JavaScript, PHP, Java etc.);- Proactive, “can do” attitude.- Good interpersonal skills including demonstrated ability to work as an active member of a core team;- Well-developed written and oral communication skills including an ability to communicate with staff at all levels;- Strong focus on attention to detail while ensuring operational needs meet strategic objectives.Ideally, Lime is looking for someone who is passionate about data and enjoys their work. This dedication can be rewarded in multiple ways such as flexibility in working hours and opportunities to take on higher roles, depending on your ambitions.Benefits- Lime Culture- Lime Intelligence sees our team members as family.  We aim to treat our employees the same as we would a new customer. Coming to work at Lime Intelligence is founded on an atmosphere of fun, collaboration and delivery of first-class products and services.Lime Values:- Reliability- Genuine Care- Commitment- Collaboration- Customer Focus- Integrity- LoyaltyNo agencies, individuals only, please.Full-time candidate for long term required.Fluent English required.","['ETL Pipeline', 'Microsoft Excel', 'SQL', 'Data Analysis', 'ETL', 'Python', 'Tableau', 'SQL', 'Data Analysis', 'ETL', 'Python', 'Tableau']",Australia,4,26.92,2.6,"['Tech', 'IT']",,,Remote Job,Expert
[CRO] Conversion rate optimisation agency for ecom brand,"Hello everyone, We are looking for a professional and reliable CRO agency that can enhance the conversion rate of our businesses. We are looking to invest for a 3/4 month period to get the lift that we are looking for. The agency should take care of everything, including the coding/design of the new website versions.  A guarantee is needed. Attach your best jobs.Thank you.","['Conversion Rate Optimization', 'Google Analytics', 'Shopify', 'Landing Page', 'Web Design', 'Copywriting', 'Google Analytics', 'Shopify', 'Landing Page', 'Web Design', 'Copywriting']",United Arab Emirates,124,9.75,84,"['Sales', 'Marketing']",,"['40.00', '75.00']",Remote Job,Expert
Need Data Extraction from Google,I need google maps data in excel sheet for certain business requirement,"['Data Scraping', 'Data Mining', 'Microsoft Excel']",India,3,,25,,,"['15.00', '40.00']",Remote Job,Expert
AI Chatbot for a website,develop a chatbot integrated with ChatGPT on our website that is limited to answering questions related to government information and services.attached is an example of a question asked and how we want it presented by the bot,"['AI Chatbot', 'Natural Language Understanding', 'Natural Language Generation', 'Conversational AI', 'AI Mobile App Development', 'ChatGPT', 'open ai', 'Chatbot Development', 'Natural Language Processing', 'Artificial Intelligence', 'Natural Language Processing', 'Artificial Intelligence']",United States,7,,1.2,"['Tech', 'IT']",,,Remote Job,Expert
GSheets Database-Analysis,"Need someone to look into my Database, thoroughly.It has few inconsistency that you need to locate and fix by uploading new dataset,Using AnyDesk, you will have access to my machine, where I have setup everything you'd need.and Im looking for someone to setup a weekly based contract as well, Job scopes to be create sheets/scripts/formulas(mainly filtering and query) and maintain my sheets if any error appears.More on this, if youre interested, let me know.","['Data Analysis', 'Data Entry']",Malaysia,37,,388,"['Retail', 'Consumer Goods']",15.00,,Remote Job,Intermediate
Scraping data on Indian village panchayat expenses,"This task involves scraping data on Indian village parliaments financial accounts available at the following link:https://egramswaraj.gov.in/FileRedirect.jsp?FD=ExpenditureReport2019-2020&name=StateExpenditureReport.htmlThis data needs to be collected at the village level for the state of Maharashtra (all financial years available) and Uttar Pradesh (2019-2020). Essentially the program must click on the State, then district, then subdistricts and then village, scrape all available data for a village (monthly level) and then move to the next village. Happy to connect over call to discuss further.","['Data Scraping', 'Data Extraction']",India,3,,175,,,"['3.00', '40.00']",Remote Job,Expert
Course Creator - Prompt Engineering Specialist for ChatGPT in Business,"Hi there,We are looking for a highly skilled and experienced course content creator to develop an engaging and comprehensive course on prompt engineering for ChatGPT that focuses on business settings. The course should be practical in the sense that someone who has never used ChatGPT prompting before can leverage ChatGPT prompting to provide business solutions.The course should be at least 12 hours long and will be presented in 5 to 10-minute video lessons. You will be responsible for recording your screen and providing voiceover instructions that detail the processes involved. You will be responsible for providing the course outline.Our company will use the videos on our training platform.**Required experience & skills:**- In-depth knowledge and experience in prompt engineering techniques specifically tailored for ChatGPT in business settings (someone who will be able to provide several examples on how to use ChatGPT in business with different prompts)- Capability to create high-quality videos and audio (we will assist if necessary)- Experience recording on-screen content with voice-over narration- ChatGPT subscription- Native English speakerFor any questions or concerns, please message us. We hope that we are able to start something very soon.","['ChatGPT', 'Prompt Engineering', 'Python', 'ChatGPT prompt', 'SQL', 'JavaScript']",Canada,11,75.00,1.3,"['HR', 'Business Services']",,"['35.00', '65.00']",Remote Job,Expert
Grant Writer for a Non-Profit Organization,"Hi Everyone, We are looking for a grant-writing expert for our nonprofit organization on medical science and technology to secure funding for our recent groundbreaking project in the science and technology sector. (will be shared on chat)What You'll Do:-Research and identify grant opportunities tailored to the science and technology field.-Collaborate with our research and development team to understand project goals and funding needs.-Craft compelling grant proposals that impress funding organizations.-Gather supporting data and documents to strengthen our applications.-Tell captivating stories that highlight the importance and impact of our projects.-Work closely with internal teams to gather necessary information and meet application requirements.-Maintain a comprehensive database of grants and deadlines.-Ask questions, about what type of information you need from us.What You'll Need:-Proven grant writing experience.-Excellent research skills and ability to find the perfect funding opportunities.-Familiarity with the grant application process and requirements.-Collaborative mindset and ability to work with our finance team.Bonus: Knowledge of budgeting and financial aspects related to grant applications.To Apply,Please send your resume, writing samples (must), and questions like what type of info you need to write a grant, and tell us what is your procedure to conduct research, and your quote for the budget. Regards,Annie.","['Grant Writing', 'Budget Proposal', 'Grant Application', 'Nonprofit Organization', 'Content Writing', 'Business Writing', 'Business Plan', 'Proposal Writing', 'Business Proposal Writing', 'Grant Application', 'Nonprofit Organization', 'Content Writing', 'Business Writing', 'Business Plan', 'Proposal Writing', 'Business Proposal Writing']",United States,2,,,,,"['30.00', '65.00']",Remote Job,Intermediate
AI Implementation Consultant for Mortgage Brokerage,"We are an innovative mortgage lending company looking to bring artificial intelligence (AI) into our operations. We're in search of an AI Implementation Consultant who can guide us through the process of discovering, planning, and executing the introduction of AI into our organization.Key Responsibilities:Work closely with our team to understand our operations, business goals, and challenges.Identify areas in our business where AI can improve efficiency, reduce costs, or increase profitability.Develop an AI strategy and roadmap that aligns with our business objectives.Assist in the selection of AI tools and platforms that are best suited to our needs.Guide our team through the implementation process and provide training as needed.Monitor the effectiveness of AI implementations and make adjustments as necessary.Key Qualifications:Proven experience in implementing AI in business operations, preferably within the mortgage industry.Strong knowledge of AI technologies, platforms, and best practices.Excellent problem-solving and strategic thinking abilities.Ability to communicate complex ideas effectively to non-technical stakeholders.Project management and training experience.If you're a forward-thinking AI professional who is excited to make a significant impact on our business, we'd love to hear from you. In your application, please share details of your experience with AI implementation, including any specific outcomes of your work.Please propose a budget and scope of work.","['Strategy', 'Project Management']",Canada,5,33.00,2.1,"['Finance', 'Accounting']",,,Remote Job,Expert
Convert World Wide Importers to Postgres,"I want to convert the World Wide Importers SQL Server database to PostgresThe project involves converting the relevant SQLServer scripts and functions to PostgresThe scope involves converting the SQL scripts to create the database, the tables, the initial data load and the function that generates new datahttps://learn.microsoft.com/en-us/sql/samples/wide-world-importers-what-is?view=sql-server-ver16https://github.com/Microsoft/sql-server-samples/releases/tag/wide-world-importers-v1.0","['SQL', 'PostgreSQL', 'Microsoft SQL Server', 'SQL Programming', 'SQL Programming']",South Africa,2,75.00,563,,300.00,,Remote Job,Intermediate
Seeking Business Statistics and R Consultant,Seeking a Business statistics and R consultant to assistance with Master's level Public Policy course.,"['R', 'Data Analysis', 'Statistics', 'Quantitative Analysis', 'Data Visualization', 'Quantitative Analysis', 'Data Visualization']",United States,102,35.68,20,"['Transportation', 'Warehousing']",,,Remote Job,Expert
AI Specialist for Process Optimization and Task Automation,"Hi there,We are seeking a highly skilled and knowledgeable across the AI space to help us identify, research and leverage the latest AI tools, programs, and technologies to enhance our business processes and automate repetitive tasks. Examples:We want to turn text into text into a TikTok video create a process using AIAs an AI Specialist, you will play a crucial role in identifying opportunities where AI can be applied to improve efficiency, speed up processes, and create innovative solutions.Thanks,Chris","['ChatGPT', 'AI Content Creation']",Australia,533,5.13,45,,,"['3.00', '15.00']",Remote Job,Intermediate
Scrape website data and segment into excel,"I need you to scrape an existing website for all the data available.   The data will be different for each segment, but pretty much consistent.   Reply in your offer with ""rv csv"".All of the data needed is in existing tables, but also need to extract images as well.  All the data will need to be segmented into a spreadsheet so I can re-use it on my website,Upon following the instructions on this page, I will provide the website and the data needed.I hope we can work together.","['Data Scraping', 'Microsoft Excel', 'Data Mining', 'Data Extraction', 'Data Mining', 'Data Extraction']",United States,8,30.00,625,,,"['8.00', '25.00']",Remote Job,Intermediate
Walterteix,"We need a view to show columns for all dates and not just columns of dates that have information to be shown, that is, show columns for all days from the 1st to the 31st of each month",['Microsoft Power BI'],Brazil,2,,,,,"['10.00', '25.00']",Remote Job,Entry level
Australian Data Analyst & Excel Wizard with price checking,"We are looking for someone at a mid level of data analyst skills to help us with the calculation of Total Cost of Ownership of phones and plans in Australian telecommunications. The role involves price checking, implementing data in to an existing spreadsheet and generating results. Over time, the structure of the pricing for both the phones and plans changes. We can help the analyst understand these changes. They will then need to be implemented in to the spreadsheet through the use of existing / adaptation of existing formulae. This is Important spreadsheet work used to make multi million dollar decisions so it’s important you are confident with spreadsheet work.The applicant must be : -	Capable and confident with Excel : We will provide you with an existing spreadsheet to do the calculation and support you to adapt it – but you must have worked with significant, large, multitab .xls documents and be confident in using them.-	Attention to detail – is an absolute must have for this role. This is complicated, involved Excel spreadsheet work. Applicant must double and triple check everything.-	Able to understand advanced functions in Excel : including functions like VLookup and multiple tab spreadsheets with dependencies. Must have the ability to troubleshoot problems in calculations.-	Familiar with prepared to learn the structure of phone plans in Australia. We will support you to do that (it’s not hard, it may be unfamiliar). We will also help you apply the changes in structure to the spreadsheet.-	Reliable. Diligent, confident, detail minded. Fluent English. Ideally an Australian with knowledge of the Australian phone plan market.The job involves :You will be given written documentation on how to perform this role. It will provide a detailed step by step guide to complete the activity and explanation of everything involved including the spreadsheet and formulae involved.Managing an existing spreadsheet, updating it and use it to generate Total Cost Of Ownership results. Then use simple calculator to double check the results of the work.This is weekend work. It will begin with 4-5 hours per week. You will be supported by a small team who have done this work for some time now and can help get you up to speed.The work is likely to expand over time.","['Microsoft Excel', 'Data Entry', 'Data Analysis', 'Spreadsheet Software', 'Administrative Support', 'Accuracy Verification', 'Data Analysis', 'Spreadsheet Software', 'Administrative Support', 'Accuracy Verification']",Australia,127,8.01,162,"['Tech', 'IT']",,"['5.00', '25.00']",Remote Job,Intermediate
Looker Studio Report Fix (for GA4 data and Google Search Console),"I have two looker studio reports that we connected to GA4 and GSC.I need the following fixed on the report:- The Abandoned Cart Rate isn't accurate.- Google Search Console is connected, but not pulling data- The conversion rate fixed for Purchases onlyThe following needs to be added to the report:- Breakdown of Shopping Funnel (i.e. View Item, Add to Cart, Check Out, Purchase)- Checkout Flow Drop off","['Google Analytics', 'Google Ads', 'SEO Keyword Research', 'Search Engine Optimization', 'SEO Performance', 'Marketing Audit', 'Google Data Studio', 'SEO Keyword Research', 'Search Engine Optimization', 'SEO Performance', 'Marketing Audit', 'Google Data Studio']",United States,26,15.00,7.4,,200.00,,Remote Job,Intermediate
Saudi programmers with experience in  Full Stack,"Proficiency in the programming language(s) they are working with, including knowledge of syntax, data types, control structures, and libraries.    Strong problem-solving skills, including the ability to analyze complex problems and design effective solutions.    Understanding of algorithms and data structures, as well as knowledge of computer science fundamentals.    Experience with software development methodologies such as Agile or Waterfall.    Familiarity with version control systems such as Git.    Knowledge of software testing and debugging techniques.    Ability to work collaboratively in a team environment, including effective communication skills.    Continuous learning and keeping up-to-date with the latest technologies and trends in the industry.","['Web Development', 'Java', 'C++', 'Web Application', 'C#', 'Web Application', 'C#']",Saudi Arabia,1,,,,,"['13.00', '30.00']",Remote Job,Entry level
Data mining to collect population data for United State Geographic areas,"Delivery will be a collection of the following data:1. Population data for all city, county, and states in the United States for the last 20-30 years. 2. Area Median Incomes for all cities, counties, and states in the United States for the last 20-30 years.This data is available from publicly accessible sources, it just needs to be located, downloaded, and normalized.","['Online Research', 'Data Mining', 'Data Scraping', 'Data Entry', 'Microsoft Excel', 'Data Extraction', 'Data Entry', 'Microsoft Excel', 'Data Extraction']",United States,2,,5,['Real Estate'],250.00,,Remote Job,Intermediate
Calculate of the concentration field around 3 stacks using GPM With excel and i have data,"Calculate of the concentration field around 3 stacks using GPM With excel and i have data : psotion of stack one (0.8,41) stack two (30,-52) stack three (64,-106) , angle 58 degree is the angle of the pollution, and there is picture i add to make it clear, at ground level, atmospheric temperature 303 kelvin, diameter 7.97 meter, n=0.25 , for distance 10 meter in x axis and y axis until 1km and from the numbers it’s should give a shape, there is a photo with all data in the file","['Microsoft Excel', 'Data Entry']",Saudi Arabia,2,,,"['Engineering', 'Architecture']",,"['10.00', '20.00']",Remote Job,Intermediate
Trading Bot,"It is required to create a trading bot without using ready-made trading frameworks, connect via API binance and deploy it on a dedicated server.The finished product should analyze the data on the price of the instrument every 30 seconds, search for potential entry points based on the EMA strategy, and send the entry command to the transaction via the API of the binance with minimal delay.","['API', 'Bot Development', 'Python', 'JavaScript', 'Forex Trading', 'Automation', 'Machine Learning', 'JSON', 'Data Science', 'Django', 'JavaScript', 'Forex Trading', 'Automation', 'Machine Learning', 'JSON', 'Data Science', 'Django']",Egypt,1,,,"['Tech', 'IT']",10.00,,Remote Job,Entry level
Teach me AI,"Honestly, I don't know what I am doing in the AI space and I need help!If you are proficient in knowledge and are willing / able to help teach me I would love to talk.  This has the potential for long term work and massive growth as I am involved in many projects ranging from Psychology (I am a Psychotherapist by trade) to construction to property management.Please send along your knowledge of and interest in AI as well as what you are looking for long term and if you are interested in teaching me and potentially my team your knowledge and know how in using and linking the different AI platforms.  The specific platforms I am interested in linking are:  bard or chatgpt, with zapier, sms, microsoft 360, calendly, stripe, email automaters such as mailchimp, among others.  I'm super excited to get this started and looking for the right talent to join me and my team.","['Artificial Intelligence', 'Neural Network', 'Artificial Neural Network', 'Machine Learning', 'Adobe Illustrator', 'Deep Learning', 'Computer Vision', 'Python', 'TensorFlow', 'Neural Network', 'Artificial Neural Network', 'Machine Learning', 'Adobe Illustrator', 'Deep Learning', 'Computer Vision', 'Python', 'TensorFlow']",United States,157,6.06,25,,,,Remote Job,Expert
Web crawling using scrapy and selenium,I'm looking for expert web scraping developers who can write efficient crawlers in desired format using scrapy and selenium(if needed). You should be able to scrape 2-3 websites in a day ensuring data integrity.,"['Scrapy', 'Selenium', 'Web Crawling', 'Python', 'Python']",India,6,30.00,0,,1000.00,,Remote Job,Intermediate
Web crawling using scrapy and selenium,I'm looking for expert web scraping developers who can write efficient crawlers in desired format using scrapy and selenium(if needed). You should be able to scrape 2-3 websites in a day ensuring data integrity.,"['Scrapy', 'Selenium', 'Web Crawling', 'Python', 'Python']",India,6,30.00,0,,1000.00,,Remote Job,Intermediate
Scientific Content Researcher - Microplastics and Water,"Position: Content Researcher - Microplastics and WaterCompany Overview:We are seeking a highly skilled Content Researcher specializing in microplastics and water-related topics. Our organization is dedicated to raising awareness about the impact of microplastics on water quality and their correlation with various subjects such as lead, lead in schools, ADHD, tap water, and more. We are committed to curating a comprehensive resource library consisting of 100+ top-notch articles that can be utilized by the team during podcasts, interviews, and other informative discussions. We value critical thinking, scientific expertise, and a passion for environmental sustainability.Job Overview:As a Content Researcher, your primary responsibility will be to identify and curate the most exceptional articles on microplastics and their relationship to topics such as lead, lead in schools, ADHD, tap water, and related subjects. You will play a crucial role in building a robust resource library that serves as a go-to reference for our team during interviews and discussions. This position presents an exciting opportunity to contribute to the dissemination of knowledge and support meaningful conversations on vital environmental issues.Responsibilities:- Conduct comprehensive research to identify outstanding articles on microplastics and water-related topics, including lead, lead in schools, ADHD, tap water, and more.- Evaluate the quality, credibility, and relevance of identified articles, ensuring they meet our stringent standards.- Curate and maintain a resource library comprising 100+ articles that provide valuable insights into microplastics and their impact on water quality.- Identify areas of interest, knowledge gaps, and emerging research trends.- Assist in the creation of engaging content pieces based on the curated articles, delivering accurate information and meaningful insights.- Find the latest scientific research, industry reports, and reputable sources in the field of microplastics and water research.- Bring forth fresh ideas and innovative approaches to enhance the content research process.Requirements:- Demonstrated expertise in conducting thorough research and identifying top-quality articles from diverse sources.- In-depth knowledge of microplastics and their relationship to topics such as lead, lead in schools, ADHD, tap water, etc.- Experience in scientific writing, education, higher education, market research, or content writing is a significant advantage.- Excellent organizational skills to curate and manage a comprehensive resource library effectively.- Strong analytical abilities to critically evaluate scientific papers and extract key information.- Exceptional written and verbal communication skills to effectively communicate complex concepts.- Detail-oriented mindset with a commitment to accuracy and precision.- Self-motivated and capable of working independently while also collaborating effectively within a team.- Passion for environmental sustainability and a strong desire to contribute to positive change.If you possess a passion for environmental research, possess a discerning eye for sourcing the best articles, and want to make a meaningful impact, we invite you to apply for this role to help us build a comprehensive resource library that supports our mission of raising awareness about microplastics and water quality.","['Information Literacy', 'Market Research', 'Topic Research', 'English', 'Data Analysis', 'Topic Research', 'English', 'Data Analysis']",United States,13,,5.4,,,"['36.00', '50.00']",Remote Job,Expert
Data Analysis for Future Investment,I have a large swath of data that I want someone to optimize and analyze.  I am looking for different markets (column A and B) to target for investment.  the thesis is that jobs with most employment growth and population growth are where I want to be.  there are +1200 entries on this spreadsheet.  i want to be able to pinpoint the top areas for investment.  perhaps by a scoring model?  or maybe you have another way to do it.  i have never hired a data scientist. thank you.,"['Microsoft Excel', 'Financial Analysis', 'Data Analysis', 'Data Visualization', 'Statistics', 'Data Analysis', 'Data Visualization', 'Statistics']",United States,28,15.24,3.6,['Real Estate'],,"['5.00', '25.00']",Remote Job,Expert
Tableau GIS Map Consultation,I would like a consultation on the best way to bring together GIS data  like parcel ID with a measurement and a map to create a 3D visualization of government information. I need someone who has done this before and can provide an image of one of these visualizations so that we can talk about how to build that and what sort of data will be needed and what sort of format.Use the word Sunshine as the first word of your cover letter to be considered and include a map image of your creation.,"['Tableau', 'GIS', 'Data Visualization']",United States,214,20.44,241,"['Sales', 'Marketing']",,"['20.00', '50.00']",Remote Job,Intermediate
Help us get a github code running,Our aim is to get this code running:https://github.com/hawemily/transformers-for-stock-price-prediction. please refer to 4th one: transformers_encoder_decoder_1_step_ahead.ipynbPlease reach out if you feel you are up to this task and want to hop on a zoom call so we can discuss our project requirements further. Thank you!!,"['TensorFlow', 'PyTorch', 'Deep Learning', 'Machine Learning Model', 'Machine Learning', 'Python']",United States,18,46.42,163,"['Tech', 'IT']",350.00,,Remote Job,Expert
Help with Google Analytics / Workspace integrations,"Hi, I need someone help us switch our Google Analytics from Universal to GA-4. Please also help us optimize our set up for 2 websites.","['Growth Analytics', 'Google Analytics', 'Google Tag Manager', 'Python', 'WordPress', 'Search Engine Optimization', 'Python', 'WordPress', 'Search Engine Optimization']",United States,13,8.01,34,"['Travel', 'Hospitality']",,,Remote Job,Intermediate
Azure Machine Learning Certified Specialist,"We are looking for a skilled Azure Machine Learning Certified Specialist to join our team for a 3 to 6 month project. The ideal candidate will have expertise in Data Science, DevOps, Machine Learning, and Microsoft Azure.Your role will include designing and implementing machine learning solutions using Azure Machine Learning, as well as troubleshooting and debugging issues that arise during the project. You will also be responsible for ensuring that the project adheres to best practices in DevOps and data science.To be successful in this role, you will need to have experience with Azure Machine Learning and a deep understanding of machine learning algorithms. You should also have experience working with Microsoft Azure, as well as experience with DevOps and data science.If you are interested in this opportunity, please submit a proposal outlining your relevant experience and how you can help us complete this project successfully. Please include links to some of your past completed projects that showcase your skills in this area.Note: Some of the content in this job post may have been auto-generated using advanced AI.","['Microsoft Azure', 'Machine Learning', 'DevOps', 'Data Science', 'DevOps', 'Data Science']",United States,42,71.29,27,"['Tech', 'IT']",,"['60.00', '150.00']",Remote Job,Expert
"Install datastack with Airbyte, dbt and Airflow","We are looking for a data engineer who can help us with a data stack for our data flow.We use Apache Superset as our platform for customers, and we have our own data warehouse, which is a PostgreSQL database.We require the following data stack:1. Airbyte for connecting to various sources2. dbt for transforming our data3. Airflow for scheduling and triggeringThe requirement is to install the software on our own server (due to GDPR) and maintain and update it here.We are looking for a data engineer who can install the entire data stack and has knowledge of all three platforms.Alternatively, we may need to search for a specialist for each individual platform.","['airbyte', 'dbt', 'airflow ', 'Linux']",Denmark,7,,1.5,"['Sales', 'Marketing']",,,Remote Job,Intermediate
Machine Learning Engineer,"Need someone to direct our Software Dev Team in creating a Neural Network to recognize certain conditions in images of teeth. For example cavities, broken teeth, gum inflammation.Need help with creating dataset, neural net, training, and setting up infrastructure in Azure to host neural net.","['Machine Learning', 'Artificial Intelligence', 'Deep Learning', 'Computer Vision', 'Neural Network', 'Convolutional Neural Network', 'Deep Learning', 'Computer Vision', 'Neural Network', 'Convolutional Neural Network']",United States,1,,,"['Health', 'Fitness']",,"['50.00', '400.00']",Remote Job,Expert
"Machine Learning Reads App, Interprets Data","There’s an app, I want to identify a team, have my new tech read the data on the opposing team and create working documents that we can then use.","['Python', 'Data Science', 'Artificial Intelligence', 'Data Mining', 'Machine Learning', 'Data Analysis', 'Chatbot Development', 'Algorithm Development', 'Adaptive Algorithm', 'Data Mining', 'Machine Learning', 'Data Analysis', 'Chatbot Development', 'Algorithm Development', 'Adaptive Algorithm']",United States,1,,,,,"['15.00', '30.00']",Remote Job,Expert
NLP engineer to help building LLAMA,"Requires someone with extensive experience using LLAMA.If you've developed your own ChatBot, that's a bonus.If you read my post, start your suggestion with ""NLU and NLG"".Thank you for your interest.","['Python', 'Natural Language Processing', 'Machine Learning', 'Deep Learning', 'Bot Development', 'PyTorch', 'Artificial Intelligence', 'Machine Learning', 'Deep Learning', 'Bot Development', 'PyTorch', 'Artificial Intelligence']",United States,1,,,,,"['40.00', '60.00']",Remote Job,Expert
Develop an AI Artificial Intelligence Chat Bot,"We are looking for a skilled Artificial Intelligence developer to create an AI chatbot for our business. The project is expected to take between 1 to 3 months to complete. The successful candidate will have experience in Artificial Intelligence, Chatbot Development, Machine Learning, Natural Language Processing, and Python.As the developer, you will be responsible for developing a chatbot that can interact with our customers in a natural and intuitive way, in text or audio. This will be a conversation about the user (work family likes dislikes etc - like a job interview). The output will then be summarized for keywords using AI.You will also be responsible for integrating the chatbot with our database that is currently being built and ensuring that it meets our performance and security requirements.To be considered for this position, you should have a proven track record of developing chatbots and other AI applications. Please submit a proposal outlining your experience, the approach you would take to this project, and any relevant links to completed projects.We are looking for a candidate who can work independently, has excellent communication skills, and is able to deliver high-quality work on time and within budget. If you have the skills and experience we are looking for, we would love to hear from you.Please reply with an approximate amount of hours you would require to complete this task","['Artificial Intelligence', 'Natural Language Processing', 'Chatbot Development', 'Python', 'Machine Learning', 'Natural Language Processing', 'Chatbot Development', 'Python', 'Machine Learning']",United Kingdom,113,14.83,33,,,"['18.00', '40.00']",Remote Job,Intermediate
Create AI Course Generator,"Build chatgpt-powered app that connects to chatGPT, generates course content and saves it to word documents.This app is meant to help in building courses to prepare for public selection exams. Attached is a file with better description.","['Artificial Intelligence', 'ChatGPT', 'ChatGPT']",Brazil,1,,,,,,Remote Job,Entry level
Google Data Studio or Tableau Wizard Needed so We Can Own Our 1st Party Data,"Looking to get help with integrating all of our data points between our Software for DJs (CrateHackers.com), Google Analytics, Kartra & Clickfunnels (our funnel builders), Meta Ads, Google Ads, Youtube analytics, IG organic analytics, etc and getting them into Google Data Studio so I can use it to market and understand our audience better.I'm also curious if you know how to use our survey data from SurveyMonkey and Typeform. We are HUGE on surveying and I'm super big on collecting our own 1st party data using Google Data Studio or Tableau before cookies go away (and so we don't need to rely on buying data from the Big Tech Overlords lol)Curious if that's even possible or if you could help us with a roadmap to own as much data about our software users as possible.","['Google Data Studio', 'Tableau', 'Data Visualization', 'Google Analytics', 'Data Analysis', 'Data Visualization', 'Google Analytics', 'Data Analysis']",United States,18,21.99,6,,,"['50.00', '100.00']",Remote Job,Expert
GIS Analyst,"Looking for a GIS Analyst with a background in telecom/fiber optic and fluent with ArcGIS Pro, your primary responsibility is to identify market opportunities and conduct market analysis using geospatial data and mapping tools. 3-5 years of experience working with ArcGIS software, including ArcGIS Pro Knowledge of telecom/fiber optic industry and market dynamics Proficiency in market analysis techniques and familiarity with sales analytics Strong cartographic skills for designing and editing GIS data Detail-oriented with excellent written and verbal communication skills Bachelor's degree in GIS Analysis, Environmental Science, Geography, or a related field","['ArcGIS', 'GIS', 'QGIS', 'ArcGIS Online']",United States,10,50.00,700,"['Tech', 'IT']",,"['35.00', '40.00']",Remote Job,Intermediate
Analyze website data,"We need a program/script that analyzes web pages in bulk.INPUT: URL'sOUTPUT: (table)-Webscore, (machine learning tool) - The condition of the website (design and programming)-Date, age, timeline of updates/changes to the website, what was updated when (entire period)-Web technology, technologies used, traffic, advertising, tracking-Information about the operator: operator of the website/managing director, address, telephone number, e-mail, employees, brief summary of the company (via AI)","['Data Mining', 'Data Analysis', 'Data Scraping', 'NodeJS Framework', 'Data Entry', 'Data Scraping', 'NodeJS Framework', 'Data Entry']",Austria,3,18.00,529,"['Tech', 'IT']",,"['5.00', '21.00']",Remote Job,Expert
Power BI Developer,"Power BI Developer (Upwork)Responsibilities:Working with the VP, Supply Chain and Director, IT will meet weekly to review project needs.  The BI Developer is responsible for implementing internal and external reporting solutions by connecting data sources, transform and enrich content, and produce the dashboards, reports, and tiles to guide business decisions. Qualifications:The ideal candidate is experienced and has good experience building Power BI reports. The BI Developer is proficient at making sense out of data stored in various data systems and is able to translate data in raw storage to views/tables and useful models for reporting and understands how to effectively build Tabular models. This is project-based work,","['Microsoft Power BI', 'Business Intelligence', 'Data Visualization', 'Microsoft Power BI Data Visualization', 'Data Visualization', 'Microsoft Power BI Data Visualization']",United States,9,30.77,71,"['Manufacturing', 'Construction']",,"['20.00', '45.00']",Remote Job,Intermediate
Data Scientist Opportunity for Automating Time Log Analysis,"My company needs a formula from a Data Scientist skilled in data extraction and Excel automation. Our goal is to streamline the process of calculating overtime and detecting meal break violations from employee time logs.The task involves extracting data from PDFs, transitioning it into Excel, and creating formulas for automatic calculations.If you're interested in this project, please contact us to discuss further.","['Data Science', 'Microsoft Excel', 'Data Analysis', 'Artificial Intelligence', 'Analytics', 'Data Analysis', 'Artificial Intelligence', 'Analytics']",United States,1,,,,,,Remote Job,Expert
Responsive AI chatbots,"I would like to add responsive AI chatbots to a language site that I am working on.  I currently have a chatbot which uses text to speech, but would strongly prefer a realistic to use an AI avatar to communicate in real time with clients.  I would like something similar to what could be found in Chat D.ID or Synthesia.  It would be great if it were a tool that makes it easy to create new avatars using a photo.  In the end, It would need to be integrated into a Wordpress.com site (business plan).  It should function with an API for speaking and an API for Chat GPT.","['Graphic Design', 'Artificial Intelligence', 'Chatbot Development', 'Natural Language Processing', 'Machine Learning', 'Neural Network', 'Bot Development', 'Chatbot Development', 'Natural Language Processing', 'Machine Learning', 'Neural Network', 'Bot Development']",United States,1,,,,,"['15.00', '35.00']",Remote Job,Intermediate
Data Extraction and Mining,We are looking for several data extraction experts or a team that can help us extract data from a large set of websites - close to 3000. The job will require developing scripts that we can ultimately add to our base class to reuse in the future as well. Must complete a small test - must do a video interview. If you have real estate data experience that is a bonus.,"['Scrapy', 'Beautiful Soup', 'Selenium', 'Data Mining', 'Data Scraping', 'Data Extraction', 'Python', 'pandas', 'Data Extraction', 'Python', 'pandas']",United States,182,26.11,80,"['Tech', 'IT']",,"['8.00', '25.00']",Remote Job,Intermediate
Data Scrape/List Building,"Looking for someone to gather the data of specific contacts using general criteriaFor example, the data for all of the plumbers you could find within a certain city (i.e. plumbers in New York City)Looking for the following1. Business Name2. Business Website3. Number of Employees4. Age of Business or Year Founded5. Contact's Name6. Contact's Title (Ideal Titles are Owner, Partner, Co-owner, Founder, Co-Founder, Licensed Plumber, etc -- top-level executives or owners)7. Contact's Email 8. Contact's Cell Phone Number9. City10. StatePython, selenium, LinkedIn sales navigator, or lead list-building experience is a plus.The current number of cities is 70 for one specific industry. This can lead to additional list-building projects in the future.Please give your rate for X amount of businesses (for example, you will charge X per 10 contacts)If you are hourly, please provide an estimate of how long it will take you for X per list (for example, ""I can scrape X amount of contacts per hour"")Thanks!","['Prospect List', 'Data Mining', 'Data Scraping', 'List Building', 'Data Scraping', 'List Building']",United States,18,3.81,767,,,,Remote Job,Intermediate
Spss expert to help with planning & implementation report,Spss coding to see the outcome in excel coded form,"['IBM SPSS', 'Data Analysis', 'Microsoft Excel', 'Academic Writing', 'Business Intelligence', 'Microsoft Excel', 'Academic Writing', 'Business Intelligence']",Netherlands,1,,,,,"['18.00', '45.00']",Remote Job,Intermediate
Seeking investor - Onlyfans business,"we have put all our money into developing a content creator website like Onlyfans but we have exhausted all our funds and need a partner to join our business.We do not have money for advertising and to run the businesses. We need money to pay for hosting costs and for running advertising.We are offering a 10% share to anyone who is interested for a price of $800We are also offering a 5% share for $400In 2021, Onlyfans made $4,21 billion dollarsOur website has already been installed but we are still finishing some of the final changesHere is our web address: www.fanstagram.app We plan to be the cheapest content creator platform in the world and we offer paid live streams, video calls, audio calls, locked posts and locked messages as well as tips. We already have our U.S tax number and the business has been registered etc. We are ready to receive payments but we require money to launch. This is a great opportunity for you!Please reach our to Imraan on whatsapp if you are interested +27786765457","['Scrapy', 'Apache Spark', 'PyTorch', 'TensorFlow', 'Accord.NET Framework', 'pandas', 'Amazon SageMaker', 'Apache Mahout', 'AnyLogic', 'Apache MXNet']",South Africa,6,,,,800.00,,Remote Job,Expert
Excel Specialist needed to streamline data entry spreadsheet.,"I am creating an Excel Dashboard for my companies construction projects and need a new construction report to auto-generate when a new sheet is created as well as a Deal Summary on the Dashboard main page. Input cells within the newly created sheets should also feed their data to the Dashboard summary. Upon creating a new construction report I would also like a pop up asking how many units are being built and the appropriate number of input columns generated on the new page depending on what was entered into the pop up. Lastly, I need the work I have done thus far verified. I have the Dashboard main page skeleton created as well as the construction report and have begun the process of having data feed from one to the other.","['Data Visualization', 'Dashboard', 'Microsoft Excel', 'Data Entry', 'Spreadsheet Software', 'Accuracy Verification', 'Spreadsheet Software', 'Accuracy Verification']",United States,1,,,,,"['70.00', '100.00']",Remote Job,Expert
I'm looking for a Databox dashboard builder,"My company sells CRM-systems to small/medium sized organizations. As a part of my service, I want to be able to provide management/sales dashboards for data visualization. This will allow my clients to measure there most important KPI's.A lot of entrepreneurs have no clue how to use their data, which is a pity. A lot of value can be provided here.Databox is the tool I'm looking to use. It's very complementaire to my CRM systems. It can be iFramed into the platform, to make it an all-in-one solution.Almost all my clients are going to need a dashboard. So I am looking for a reliable freelancer/partner who will be my go to guy/girl for this type of work.I'm looking for someone who:- Speaks English (or Dutch) fluently- Has experience with Databox- Is pro-active and a good communicator- Is willing to work with me and my colleagues on the long termIf that sounds like you, please don't hesitate to contact me!",['databox'],Netherlands,4,,,"['Tech', 'IT']",,"['15.00', '40.00']",Remote Job,Intermediate
Data Analysis,"I need a data analyst to scrap data from a website, and make analysis for the quantity and price.I will give all the details once you will be accepted","['Data Analysis', 'Microsoft Excel', 'Data Visualization', 'Data Entry', 'Analytics', 'Data Visualization', 'Data Entry', 'Analytics']",Egypt,1,,,"['Finance', 'Accounting']",20.00,,Remote Job,Entry level
Microsoft Power BI,"Project Description: Key Performance Indicator Dashboards for Print Business using Microsoft Power BIWe are looking to hire a skilled programmer to develop comprehensive dashboards using Microsoft Power BI for monitoring and analyzing key performance indicators (KPIs) in our print business. The goal of this project is to provide real-time visibility into critical metrics, enable data-driven decision-making, and enhance overall operational efficiency. The dashboards will cover various departments, including but not limited to accounts receivables, sales, marketing, design, prepress, and outsourced services.Project Scope:1	Dashboard Development: The primary focus of this project is to design and develop interactive dashboards using Microsoft Power BI. These dashboards should provide a consolidated view of relevant KPIs for each department, allowing stakeholders to quickly assess performance. KPIs may include revenue, sales volume, customer acquisition, order fulfillment rates, customer satisfaction, and more.2	Reporting Functionality: The dashboards should incorporate robust reporting capabilities, enabling users to generate on-demand and scheduled reports. Users should be able to customize report parameters, export reports in various formats (such as PDF or Excel), and share them with relevant team members or stakeholders.3	Departmental Dashboards: Each department within the print business should have its own dedicated dashboard within the Power BI solution. These dashboards will showcase department-specific KPIs, providing insights into the department's performance. For instance, the accounts receivables dashboard may include metrics like outstanding invoices, payment trends, and collection performance, while the sales dashboard may feature metrics such as leads, conversions, and pipeline analysis.4	Supervisor and Agent Dashboards: In addition to departmental dashboards, supervisor and agent-level dashboards are required. These dashboards should offer a hierarchical view of KPIs, allowing supervisors to monitor their teams' performance and agents to track their individual metrics. The dashboards should provide drill-down functionality, enabling users to explore detailed data underlying the KPIs.5	Charts and Graphs: The Power BI dashboards should incorporate a variety of visually appealing charts and graphs to present KPIs effectively. Examples include bar charts, line graphs, pie charts, heatmaps, and more. The visual representations should be interactive and support easy data exploration.6	Data Integration: The Power BI solution should integrate with existing data sources, specifically SQL Server and HubSpot, to fetch real-time data for analysis. The programmer should develop efficient data extraction and transformation processes to ensure the accuracy and timeliness of the data displayed on the dashboards.7	Security and Access Control: The solution should prioritize data security and implement appropriate access controls. User roles and permissions should be established to restrict access to dashboards and reports based on departmental hierarchies and individual responsibilities.Deliverables:•	Fully functional and visually appealing Power BI dashboards for each department.•	Supervisor and agent-level dashboards with drill-down functionality.•	Reporting functionality for generating on-demand and scheduled reports.•	Integration with SQL Server and HubSpot for real-time data retrieval.•	Implementation of various charts and graphs to facilitate data visualization.•	User roles and access control mechanisms to ensure data security.We are seeking a programmer with expertise in Microsoft Power BI, data visualization, and dashboard development. Please provide your portfolio or examples of previous projects demonstrating similar capabilities. The selected programmer will work closely with our team to gather requirements, ensure data accuracy, and deliver an intuitive and user-friendly Power BI solution.If you are interested in this project, please submit your proposal outlining your approach, estimated timeline, and cost for completion. We look forward to reviewing your proposal and discussing further details.","['API Integration', 'Dashboard', 'Data Visualization', 'Microsoft Power BI', 'SQL', 'Microsoft Power BI Development', 'Microsoft Power BI Data Visualization', 'Microsoft Power BI Development', 'Microsoft Power BI Data Visualization']",United States,41,15.13,9.4,"['Sales', 'Marketing']",,"['35.00', '50.00']",Remote Job,Expert
ChatGPT Embeddings Pro ASAP,"I have a very specific set of requirements please read. I need someone to take a large dataset of BOOKS (all text data). Currently in SQLLite Database. And ""feed it"" into ChatGPT. Then will need a UI interface (basic chat interface) so that I can talk to GPT3.5 and have it Use the data from the books to answer questions. I don't want to ""reference"" books. I want it to just use the data from the books as part of it's knowledge base. So in essence I want to ""Train"" chatGPT. I've been looking into things like Langchain, Pinecone, Azure, Embeddings. I need someone that has worked with it and knows what they're doing.","['Python', 'Machine Learning', 'ChatGPT', 'ChatGPT']",United States,229,12.77,222,"['Tech', 'IT']",250.00,,Remote Job,Expert
GA4 Setup,"Our organization is actively seeking an individual with proficiency in setting up Google Analytics 4 (GA4). We have recently launched two new websites and we are in need of your expertise to successfully establish GA4 on both of them.The primary aim of this project is to enable effective tracking of goal conversions across both platforms. By doing so, we can measure and understand user behaviors, which are critical for achieving our business goals. The data obtained will provide us with valuable insights that can be used to enhance and optimize the user experience and our overall digital strategy.This project is of immense importance to us and it has been classified as a high-priority initiative. We are under a tight deadline and are keen on getting this project up and running as quickly as possible. We believe that by promptly establishing GA4 on these websites, we can capitalize on our current momentum and maximize the potential of our newly launched websites.The rapid implementation of this project is a significant factor, but rest assured, we are committed to providing all the necessary resources to ensure its successful execution. We understand the critical role that GA4 plays in data-driven decision making, and we're eagerly looking forward to having an expert like you come on board to spearhead this initiative.","['Google Analytics', 'ga4']",Canada,2,,,,,"['18.00', '45.00']",Remote Job,Intermediate
"A Google Sheet Diagram for a ""Sales Funnel"" Visualization","I need someone who can create a visual Google Sheet diagram tool that can visualize a ""Sales Funnel"" for a Job Search.The sheet should have input points for different metrics like jobs applied to, referrals etc. And a place to edit conversion percentages, so that if someone increases their conversion from interviews, in the visual diagram it will show that they land MORE interviews and then a cascade of the amounts change down the funnel.I already have all of the variables needed, the formulas and the conversion levers.I just need someone to visually design it for me :) If the project goes well, there may be opportunity for tons of future work like this.When applying, please show me some examples of similar data visualization projects you've done in Google Sheets","['Google Sheets', 'Data Visualization']",Canada,10,5.66,1,,150.00,,Remote Job,Intermediate
Optimize AI Chatbot Workflow for WhatsApp,"We are looking for an expert in optimizing AI chatbot workflows for WhatsApp. The ideal candidate should be familiar with ChatGPT, Twilio, and WhatsApp Business APIs. The primary goal of this project is to improve the effectiveness and efficiency of our existing chatbot by optimizing its workflow. The successful candidate will have strong problem-solving skills, in addition to the following:","['Chatbot Development', 'Python', 'Artificial Intelligence', 'IBM Watson', 'Dialogflow API', 'Artificial Intelligence', 'IBM Watson', 'Dialogflow API']",Brazil,1,,,,500.00,,Remote Job,Expert
ROS Python,"Hello.I have a ROS Python project and I need help to complete the code.It's a pick&place robot that is currently configured with an ar tag library: http://wiki.ros.org/ar_track_alvar and when it detects the tag (I still have to make the controller) it should pick up the object and put it in - a chosen area.The issue:what didn't work for me at all is that I can't add the cube with the AR tag to the simulation, which is on git where I have a launch file that opens my simulation with the robot and it should also open my cubeI am attaching the code.","['Python', 'Robot Operating System']",Romania,46,,685,,25.00,,Remote Job,Intermediate
Build Machine Learning for a Healthcare Provider Recommendation System,"From our Users Stories, we are seeking ML Engineer to build the following and provide guidance on time, features, and feasibility.As a user, I'd like to see a prioritized list of recommendations of potential Buyers based on user-entered data parameters and buyer propensity.    - Buyer Propensity   - Matched characteristics between Customer and Lead   - Incorporate open-source LLM model and/or chatbot into buyer profilesAs a user, I'd like to see a ranked list of HCPs that are relevant to me   - Rank HCPs based on a scoring system. Buyer Propensity   - Incorporate open-source LLM model and/or chatbot into buyer profilesAs a user, I'd like to see HCP and Buyer profile data populated in front of me in ""real-time"" (generative text)   - Like ChatGPT UI As a user, I’d like to explore HCP and Buyer recommendations in a force graph view   - Visual Data Clustering","['Machine Learning', 'Artificial Intelligence', 'Amazon Web Services', 'Amazon Web Services']",United States,1,,,"['Sales', 'Marketing']",,"['18.00', '40.00']",Remote Job,Intermediate
GA4 and GTM Transfer and Training,"We are a nonprofit organization with a WordPress website. We are seeking a Google Analytics specialist to review our GA to GA4 transition, update our Google tags for performance tracking, and connect our data from GiveSmart.Deliverables Expected:--Confirm GA to GA4 transition has been completed correctly and finish conversion as needed.--Implement Google tags to track conversions and abandoned carts for donations.--Implement GTM tracking through GiveSmart platform.--Implement updated Facebook tags as needed.--Provide a maintenance/upkeep plan that can be accomplished by existing staff.After a kickoff call, work will be completed independently with collaboration via email and a final project call will be scheduled to review work implemented.Candidates should be willing to interview by Zoom/Google Meet. Your Proposal:--Please provide examples of similar work --The expectation is that this project will take 15-20 hours, please include how you will accomplish this in your proposal.","['Google Analytics', 'Google Tag Manager', 'WordPress', 'GiveSmart', 'GA4', 'WordPress', 'GiveSmart', 'GA4']",United States,1,,,"['Government', 'Public Sector']",,"['45.00', '65.00']",Remote Job,Expert
Automated Data Collection and Analysis for Nonprofit Organizations,"We're seeking a data collection and analysis expert to automatically generate a comprehensive list of U.S.-based 501(c)(3) nonprofits within a specific cause category (Animal niche), using publicly available data. We need the generated list to be filtered based on the nonprofit's social following and the year it was founded.The anticipated workload is between 3,000-5,000 entries matching the criteria outlined below. If this initial project is successful, we have many more lists to build which would entail a similar approach.The majority of the work is expected to involve web scraping and data aggregation. This includes gathering information such as Organization name, EIN, Cause, Year established, Website, Founder name, and Facebook links which can be found from public directories such as:Great NonprofitsIRS Exempt Organizations501c3 LookupProPublica NonprofitsCharity NavigatorCandid.orgFilter Requirements:- Nonprofits must be U.S. registered 501(c)(3) entities.- They should have been founded within the last 5 years.- They must have a social following of over 2K on at least one of the following platforms: Facebook, Instagram, or TikTok.- They must fall within the 'Animal' niche category.Data to be Populated in the Spreadsheet:We'd like the following information for each nonprofit:- Organization name- EIN- Website URL- Year founded- Social media handles/links- Founder's name (if not available, then one of the following in order of preference: President, Executive Director, Director of Development, Development Director, Communications and Marketing)- Contact emailPlease note: We're not seeking manual list building. The task at hand requires someone skilled in web scraping and data analysis, capable of gathering existing publicly available data, organizing it in a spreadsheet, and filtering it based on the requirements outlined above.","['Data Entry', 'Lead Generation', 'Data Scraping', 'List Building', 'Data Mining', 'Data Analysis', 'Data Scraping', 'List Building', 'Data Mining', 'Data Analysis']",United States,4,42.02,1.3,,250.00,,Remote Job,Intermediate
Currently Require Google Analytics and Data Analyst For entry-mid level position,"We are looking for Google Analytics and Data Analyst to join our team to support us. we are a fantastic way for young/new people to gain valuable work experience and earn while they learn.There is no limit to how many hours you can work, which means your earning potential is unlimited.We believe in clear communication and setting realistic expectations to ensure the success of our team members. We’re not looking for someone to assist for a few months. We require a long-term team member with a clear schedule, goals and responsibilities.we're open to considering people who are new to Upwork as well, but you need to show me your past work. If you don't have work experience, write a proposal that inspires enough confidence in us to contact you.If you are looking for this kind of opportunity and are willing to dedicate yourself deeply to the cause, then:First of all, Please Must Read Actual Detailed ""Job Description"" by Clicking ""Job Description"" Section at the given web page:https://tinyurl.com/yourDescriptionsClick at ""Job Description"" Section..","['Data Analytics', 'Data Interpretation', 'Marketing Analytics', 'Operations Analytics', 'Product Analytics', 'Sales Analytics', 'Google Analytics', 'Data Analysis']",Pakistan,3,,,,4000.00,,Remote Job,Entry level
Turn Excel Files into Power BI Reports,"We are looking for someone who is skilled in Data Visualization, specifically Microsoft Power BI, that has the creativity necessary to create aesthetically beautiful and simple dashboards for our EHS Department.The right candidate will be someone who can take charge, provide recommendations, and be responsive and communicative throughout the process. The Scope: Edit and finalize existing excel files to prepare them to be utilized with Power BI and then create an overarching Environmental, Health and Safety Analytical Dashboard, as well as subsequent complimentary dashboards for both leading and lagging indicators. In short, we desire to streamline all of our reporting and data in this department so that we can keep our finger on the pulse of safety in our company and make better decisions.GPRS is the industry leader for ground penetrating radar and concrete scanning solutions in the USA.We look forward to working with you!","['Data Visualization', 'Microsoft Power BI', 'Microsoft Excel', 'Microsoft Power BI Data Visualization', 'Workplace Safety & Health', 'Microsoft Excel', 'Microsoft Power BI Data Visualization', 'Workplace Safety & Health']",United States,3,,300,,,"['30.00', '90.00']",Remote Job,Intermediate
Columbia,"I am looking for a colombian. what online games are popular in Columbia? For example, lucky jet is popular. And what else? What are you looking for in the play market search?","['English', 'Spanish']",Greece,22,,218,,,,Remote Job,Entry level
GA4 Set Up | Two Websites,We are looking for someone to set up GA4 on our two brand new websites. These sites will need to track goal conversions. This is a high priority near term project that we're looking to activate quickly.,"['Google Analytics', 'GA4', 'Tracking Goals Setup', 'Tracking Tags Installation', 'Site Tracking Evaluation', 'Tracking Goal Restructure', 'Tracking Tags Installation', 'Site Tracking Evaluation', 'Tracking Goal Restructure']",Canada,15,30.59,42,,,"['18.00', '45.00']",Remote Job,Intermediate
Three sets of Data Scrapes- 2 websites and 2000 Items on Amazon.ca,"This task is to scrape data from three(3) websites. 1.0 Two websites with just over 9000 items each, I need only sku, stock and price of each item, as per video tutorial attached for AIC and KMP. 2.0 On amazon.ca, a specific data scrape of just over 2000 items is needed, just tile, price, ASIN and part number. Thats all. The first two tasks runs the probability of being a monthly data scrape, if the recurring price is right. The second task is a one time task. Video tutorials are attached to this job post. I need this asap. Preferably one of you who can do this with your python or java script or whatever you use to data scrape these days.","['Data Scraping', 'Data Mining', 'Data Extraction', 'Data Extraction']",Canada,27,4.03,6.2,,300.00,,Remote Job,Entry level
Exploring the increased Artificial Intelligence tools on Academia,-This is an open ended research that should focus on at least 4 AI tools such as ChatGpt and the impact they pose on academic field.-Explore on cases of Cheating in assignments and even exams. -Provide also a framework on how instructors can determine cases where students use said AI tools to complete their assignments.The project should be well structured for an executive presentation.,"['Artificial Intelligence', 'Machine Learning', 'Data Science', 'Article Writing', 'Content Writing', 'Artificial Neural Network', 'Algorithm Development', 'Bot Development', 'Chatbot Development', 'Adaptive Algorithm', 'Machine Learning', 'Data Science', 'Article Writing', 'Content Writing', 'Artificial Neural Network', 'Algorithm Development', 'Bot Development', 'Chatbot Development', 'Adaptive Algorithm']",United States,1,,,"['Tech', 'IT']",800.00,,Remote Job,Expert
Scrap Telegram Group Members,I would like to scrap members from Telegram Groups that i don´t own. Its posible? Please letme know if you can do that and what info do you need.Its for a long time colaboration.,"['Data Scraping', 'Telegram API', 'Web Crawling', 'Telegram', 'Web Crawling', 'Telegram']",Spain,28,11.56,2.6,,,"['15.00', '40.00']",Remote Job,Expert
PowerBi dahsboard tracking production metrics,"I need a dashboard created that visualizes machine performance (3 classes of machines each with seperate visuals, ~dozen machines in each class). Machine name, quantity (eg meters), and duration is provided. Total meters must be visualized, a calculated meters per hour must be visualized. Visuals that show perfomance over time should be included that shows year to date performance improvement etc should be included.The visuals shoudl drill down by machine, operating crew (4 crews), and By personnel (~20 operaroes per crew). The visualization should be selectable by time period, by machine, by crew, by individual operator.I will provide data sets. This dashboard should be easy for me to add/change data set/ modify if necessary.","['Microsoft Power BI', 'Data Visualization', 'Analytics', 'Microsoft Excel', 'Business Intelligence', 'Analytics', 'Microsoft Excel', 'Business Intelligence']",Canada,1,,,,,"['18.00', '70.00']",Remote Job,Intermediate
AI LLM for Proprietary Database,"Our company has a large proprietary database hosted on Azure that we would like to develop and train an LLM for iterative searching in a secure/local environment, this tool will be deployed to our employees for productivity and efficiency improvements.","['Artificial Intelligence', 'Python', 'SQL', 'Chatbot Development', 'API', 'JavaScript', 'LangChain', 'GPT-4', 'Large Language Model', 'Python', 'SQL', 'Chatbot Development', 'API', 'JavaScript', 'LangChain', 'GPT-4', 'Large Language Model']",United States,1,,,,,"['30.00', '80.00']",Remote Job,Expert
Web Scraping | Data Mining Expert,"Retail Marketing Solutions LLC “RMS”, is a Global Technology | Branding | Marketing | Talent Recruitment Agency throughout North | South America, Europe, and Australia.Candidate MUST have a Python scrapping solution, or be able to quickly install and configure an open-source tool from GitHub, allowing us to scrap Google, Twitter and other Social Media to gather customer contact data (company | name | address | phone | email | social media id).  We also need you to pull ""Data"" on a daily basis.  This is a ""Part-time"" position to start out, eventually becoming a ""Full-time"" position.Candidate must have an Entrepreneurial | Management Mind-Set; only understanding, that Responsibility, Self-Awareness, Accountability, Determination and Strong Leadership is an absolute requirement for this position. RMS needs to ensure the Candidate’s Experienced Skill-set, Trustworthiness, and Business Integrity meets ALL RMS’ Qualifications.Compensation: $15 to $25 per Hour, based on experience | skill-sets","['Data Entry', 'Data Mining', 'Python', 'Data Scraping', 'Data Extraction', 'Scrapy', 'Web Scraping', 'Web Scraping Framework', 'Web Scraping Plugin', 'Web Scraping Software', 'Data Extraction', 'Scrapy', 'Web Scraping', 'Web Scraping Framework', 'Web Scraping Plugin', 'Web Scraping Software']",United States,53,23.51,8.6,"['Tech', 'IT']",,"['15.00', '25.00']",Remote Job,Expert
Data Analyst,"Job Summary:We are looking to add a data analyst with expert level Tableau experience to our Product Operations team. This role will work closely with our Product Management team to build out a collection of analytics dashboards that our product managers will use to get insights into how our customers are using our applications. The data is sourced from our application database which includes event level data for user activity. We also source data from Stripe, which is our payment platform which provides us with subscription plan data. Duties and Responsibilities-Be the primary go-to-person for any requests for insights regarding how our customers use our applications and 3rd party integrations..-Maintain the data dictionary for our application data warehouse which consists of datasets loaded from Google Analytics, Stripe, 3rd party API integrations, as well as our own application databases and system logs.-Develop and provide on-going maintenance for the Tableau and Google Data Studio dashboards used by the Product Management, Product Operations, and other business operations teams.-Administer our Tableau account. Duties include license provisioning and managing user permissions, data extract scheduling and data source management..-Administer our ETL pipeline which is implemented using Rivery.io.. Duties include maintaining and scheduling the ETL jobs.Skills and Qualifications-Expert level experience developing and maintaining Tableau reports. --Minimum 5 years experience developing Tableaus dashboards and visualizations.-Excellent communication and collaboration skills. Comfortable working directly with stakeholders to guide them through the requirements definition, data certification, and acceptance testing process.-Experienced at applying statistical analysis techniques and visualizations to support the product operations function.-Advanced SQL query development experience. Must be able to write SQL joins to generate aggregate time series data across datasets. -----Must be able to work with JSON structured data and apply transformations to map to columns for reporting in Tableau.-Experience working with large datasets and applying data aggregation techniques to provide reports with fast query response times.-Experience with developing ETL pipelines, or experience with Rivery.io is a pl","['Tableau', 'Data Visualization', 'Product Analytics', 'Dashboard', 'Query Development', 'Database Management', 'Data Analysis']",United States,226,10.87,2.5,,,"['10.00', '18.00']",Remote Job,Intermediate
Data Analyst and Dashboarding Project,"Need support scraping data from a video streaming platform, hosting in a database if necessary, and then creating some simple analytics about the data being scraped (in Power BI or elsewhere).  The service I need data from doesn't have a working API so the idea here is create some sort of clever workaround for accessing this data (scraping was my initial thought but maybe there are others?) and then use it for reporting purposes.For starters it will just be reporting on the data being scraped, but in the future this would include follow-on work integrating with external systems.","['Python', 'SQL', 'Microsoft Power BI']",United States,21,7.00,911,"['Tech', 'IT']",,"['45.00', '75.00']",Remote Job,Intermediate
Senior Data Analyst,"Job SummaryWe are looking for an experienced data analyst, preferably with additional data science, machine learning and AI experience. The initial assignment will be with the Data Analytics team to optimize the quality of our datasets and prepare them for upcoming machine learning and AI tasks. You will use Databricks, Apache Spark, Spark SQL, Python, Tableau, and custom APIs to perform these tasks. Previous experience with real estate, telecom or geographic information systems is a plus.Duties and Responsibilities-Study business requirements to design and document data models and data transformation rules.-Maintain vendor and corporate (internal) data dictionaries and the mappings between the two.-Triage data quality issues and communicate with the appropriate data engineering teams to address problems.-Act as liaison between business intelligence and data engineering teams.-Certify new data sets as they are ingested by data engineering.-Identify patterns in data that can be used to develop proprietary metrics.Skills and Qualifications-Passion for driving value using data and technology.-Growth-oriented and curious - You are a critical thinker who is always looking for how things can work better.-Self-motivated - You tackle problems head-on, seek out help when needed, and prioritize work based on impact.-Outcome-oriented - You care about the details and hold yourself accountable to the outcome.-Data-informed - You form perspectives and make decisions by first seeking out data and context.-Delivery-focused – You excel at turning stakeholder requests and turning them into projects and navigate between multiple projects, meet deadlines, and process ad hoc report requests.-Effective communicator - You are intentional about what you want to communicate, distill complex ideas into straightforward language, and present with confidence.-Team-player - You empower others to succeed and have a ""can do"" attitude.-Excellent verbal communication skills. -Strong technical writing skills.-5+ years of experience in data analytics.-Experience with real estate, telecom or geographic information systems is a plus.-Databricks, Apache Spark, MLFlow experience is a plus.-Experience with large data sets and proficient in SQL.-1+ years’ experience with any data visualization or business intelligence tool (e.g. Tableau, Power BI, Looker, etc.).-Extensive experience querying large, complex data sets & proven ability to derive and present insights from multiple imperfect, varied, -and inconsistent data sources using a scientific approach.-Programming skills with one or more of these languages R, Python, Scala... and the willingness and ability to learn new languages and tools as needed.-Experience with A/B testing approaches-Expertise in creating spreadsheets of findings, and the presentation skills to share them in a coherent format with all stakeholders (i.e., engineering, product, and company leadership teams).","['Machine Learning', 'Microsoft Power BI', 'Data Analysis', 'Python', 'R', 'SQL', 'Data Mining', 'Real Estate', 'Advanced Analytics', 'Deep Learning', 'Data Mining', 'Real Estate', 'Advanced Analytics', 'Deep Learning']",United States,226,10.87,2.5,,,"['12.00', '20.00']",Remote Job,Expert
Causal factor analysis on marketing data for saas app,"We're a small startup building a saas application that helps marketing teams with analytics.The data sources we use come from customers and are all about marketing data, things like email, digital advertising, offline events and many others. We also have data from CRM (like Salesforce) and we're already doing some analytics on this data to help marketers figure out what works well and what doesn't in marketing.With this project we would like to extend our capabilities and run more sophisticated analysis of the data.For example, with email analytics, it's easy to calculate Open Rate, Click Rate and Unsubscribe Rates. And we can even compare the actual numbers vs some targets set by customers. But we also want to help them understand WHY the email had a high Click Rate (or the opposite!). Was is because we sent it to the right people? Was it because of the content of the email? Was it the timing of the email?We want to list potential factors of influence for campaigns, and run a model (root cause analysis or influencing factors analysis) to tease out the individual contribution to the outcome by each influencing factor.So answer would be something like - on aggregate, the most influential factor on wether someone will open an email or not is: 1) factor one - 60% influence 2) factor two - 50 % influence3) factor three - 5% influenceIn addition to this, we want to be able to point to most likely contributing factor whenever a specific campaign under or over performs. So that we can - the reason this campaign failed (or succeeded) is X-factor.Thanks - and let me know if you have any questions.","['Marketing Analytics', 'Data Analytics', 'Data Analysis']",United States,11,55.84,35,"['Tech', 'IT']",,"['18.00', '100.00']",Remote Job,Intermediate
Dataset labeling with bounding boxes,"I need someone to label 1000 images with bounding boxes and labels. These will be women's fashion images, so the labels will be, for example, top, dress, handbag, shoes, skirt, hat, etc. Contractor will add boxes around the fashion items in each image and then add in the tags for each box. End result will be a spreadsheet with a link to each image and the tags in each row.Please submit an example of the above with your request to be contracted and the time it will take you to complete the project. Also, your bid should be project based, not hourly. If the work is done quickly and correctly, there could be more tasks to follow.In the example file, the labels would be Tops, Sunglasses, Bottoms, Shoes, Hats, Handbags. This is a complex example, most will be one person. We provide the images. Please find a few images and create an example spreadhseet.","['Data Segmentation', 'Data Labeling', 'Data Mining', 'Data Scraping', 'Data Processing', 'Data Entry', 'Data Analysis', 'Data Processing', 'Data Entry', 'Data Analysis']",United States,15,47.59,13,,,,Remote Job,Entry level
Dataset labeling with bounding boxes,"I need someone to label 1000 images with bounding boxes and labels. These will be women's fashion images, so the labels will be, for example, top, dress, handbag, shoes, skirt, hat, etc. Contractor will add boxes around the fashion items in each image and then add in the tags for each box. End result will be a spreadsheet with a link to each image and the tags in each row.Please submit an example of the above with your request to be contracted and the time it will take you to complete the project. Also, your bid should be project based, not hourly. If the work is done quickly and correctly, there could be more tasks to follow.In the example file, the labels would be Tops, Sunglasses, Bottoms, Shoes, Hats, Handbags. This is a complex example, most will be one person. We provide the images. Please find a few images and create an example spreadhseet.","['Data Segmentation', 'Data Labeling', 'Data Mining', 'Data Scraping', 'Data Processing', 'Data Entry', 'Data Analysis', 'Data Processing', 'Data Entry', 'Data Analysis']",United States,15,47.59,13,,,,Remote Job,Entry level
Build a database by scraping public records,"I need a complete database of business entities registered with California's Secretary of State. These records can be found by using the ""Business Search"" Portal (https://bizfileonline.sos.ca.gov/search/business).Each record should contain the fields shown in the basic search  as well as the fields shown when clicking on a specific business entity. The most important of these fields are the mailing address and principal address of the business entity. See attached PDF for exhibits.In addition, I would like each address to be parsed into the following fields: Mailing Street Number ('12 Central Street' to '12'), Mailing Pre Direction ('S. Central Street' to 'S'), Mailing Street Name ('S. Central Street' to 'Central'), Mailing Street Type ('S. Central Street' to 'Street'), Mailing Post Direction ('Central Street SW.' to 'SW'), Mailing Unit Number ('12 Central Street Apt 123' to '123'), Mailing City, Mailing ZIP Code, and Mailing State. Attached is also a blog post detailing someone else's methodology for scraping the website. It may be of help.I would like the database within 2-3 weeks of signing the contract, and the expected hours  to complete is 40. I will have a list of business entities to check if they are in the database and expect a greater than 90% match. I can share with you in advanced. Lastly, I would like you to provide the database in a CSV format, as well as the well-documented code. In addition to the code that scrapes the website, I would like a function that can search for a business entity by name and create a database of all business entities that appear in the search.","['Data Scraping', 'Data Mining', 'Python', 'Scrapy', 'Data Extraction', 'Python', 'Scrapy', 'Data Extraction']",United States,1,,,,,"['8.00', '20.00']",Remote Job,Intermediate
Website data extraction,"Looking for website scraping expert to help retrieve course catalog information:  thousands of courses with names, descriptions, credit, schedule and instructor information.","['Data Scraping', 'Data Extraction']",United States,1,,,['Education'],,"['15.00', '25.00']",Remote Job,Expert
Calorie Calculation Expert for Daily Tracking via WhatsApp and FatSecret,"We are seeking a calorie calculation expert to help us track our daily calorie intake. The selected candidate should be proficient in using the FatSecret application and be able to provide personalized calorie tracking via WhatsApp.Responsibilities:Collaborate with us to define our daily calorie consumption goals.Utilize the FatSecret application to gather information on consumed foods.Calculate and record daily calorie intake based on meals and snacks.Provide regular updates and personalized advice on our calorie consumption via WhatsApp.Adjust recommendations based on specific needs such as weight loss or muscle gain.Requirements:Proven experience in calorie calculation and nutritional tracking.In-depth knowledge of the FatSecret application.Ability to effectively communicate via WhatsApp.Analytical and problem-solving skills related to nutrition.Excellent organizational and time management skills.Capable of providing personalized recommendations based on individual goals.Work Arrangements:This position is open to freelancers.Communication will primarily be through WhatsApp.We expect daily tracking and prompt responses to our queries.Payment will be based on agreed-upon hourly rates.If you are passionate about nutrition, have a deep understanding of the FatSecret application, and can provide personalized calorie tracking via WhatsApp, we would love to discuss further with you. Please submit your application with a description of your relevant experience.Kind Regards Nico,","['Microsoft Excel', 'WhatsApp']",Switzerland,152,9.30,57,,995.00,,Remote Job,Intermediate
Bayesian statistics help (Stan programming),"I am looking for someone who has a good bayesian statistics background and who is good at stan programming (https://mc-stan.org/). I have a specific stan model and want to apply some statistical evaluation on it. If you are good at bayesian statistics and stan, you are the right candidate.","['Statistics', 'Data Science']",United States,32,49.94,8.7,,80.00,,Remote Job,Intermediate
Need Data Mining Scraping Project Completed,"I am looking to capture all public profile details from a set of IG followers of a set list of accounts. Need email, phone, handle, followers, posts, bio, links, etc....Is this something you can do for me? It is just for marketing purposes. The list is a list of competitors to a client of mine. we will use the emails to target the users on social media ads.How much would you charge for all profile details including email and phone for all 75,000 followers of a specific profile?","['Data Scraping', 'Data Mining', 'Data Extraction', 'Microsoft Excel', 'Data Extraction', 'Microsoft Excel']",United States,23,22.39,7.8,,,,Remote Job,Intermediate
AI - Converting text to mysql queries,"We need an AI model that can convert english text to mysql data queries. Please in your response mention these points - 1. Why you are the right person for this task ?2. In how many days you plan to achieve this and deliver to our engineers ?3. What all things you need from our end in terms of IT infra ?4. Your slack email ID, we would want to interview your for this project on Slack. Our team members use Slack. Thanks","['Python', 'MySQL', 'MySQL Programming', 'AI Chatbot', 'ai text to code', 'AI Chatbot', 'ai text to code']",United States,275,43.71,242,"['Tech', 'IT']",,"['40.00', '70.00']",Remote Job,Expert
Scrapper with Phantombuster or similar service to extract emails from a list of 17k websites.,We are looking for someone with Phantombuster (https://phantombuster.com/automations/toolbox/6774/email-extractor) or similar service to extract emails from a list of 17k websites.This is a sample of the urls:cyber-doge.nettorpedo.livemechashiba.netriseofnebula.comhelicopterfinance.cocharityalfa.ioOutput format: each email found should be inserted in a new column (in case of multiple emails founds per domain).Deadline: monday 06/12Budget: 8$,"['Data Scraping', 'Microsoft Excel', 'Data Extraction', 'Data Extraction']",Estonia,16,7.81,564,"['Tech', 'IT']",8.00,,Remote Job,Expert
Web scraping engineer for collecting product info from company websites,"We are currently seeking a full stack engineer who has experience in web scraping. The task at hand is to develop a Python web scraping script that will extract company product information from a given company website URL. We have a table that includes a list of companies along with their names, URLs, and other information. Our objective is to create another table at the product level, which can later be merged with the existing company table.The product table should consist of the following columns: product name, company, and the path to the description file. The description file will be in either a TXT or a clean XML format, containing all the text retrieved from the product subpages of the company's main website. The “product name” + “company” columns form a primary key for this table, as one company can have more than one product. This file will serve as a valuable resource for extracting additional columns for the product table.We are looking for a skilled full stack engineer who can help us accomplish this task by developing an efficient and accurate web scraping script.Potential Project Challenge:1. The project presents the challenge of dealing with different website layouts across various companies. Some companies may have product information directly on their main page, especially smaller companies.  Others may have it in sections labeled as ""product"" or ""platform"". In certain cases, product names may be listed in the menu bar. To address these variations, the solution may require incorporating shallow NL) techniques to ensure a robust approach for scraping data from all company pages.2. Large companies often have hierarchical drop-down menus. Retrieving all products and their information may require performing multi-hop and DFS operations.3. The company table includes consulting companies that offer services but do not have products. In such cases, it is necessary to ignore the ""services"" and ""solution"" pages and focus solely on extracting information from the ""product"" pages.The deliverables for this project will include both the Python script, the established product table, and the folder containing all the product descriptions of all the products. A sample of the company table is provided below","['Python', 'Beautiful Soup', 'Selenium', 'Data Scraping', 'Web Crawling', 'Natural Language Processing', 'Natural Language Processing']",United States,46,64.39,121,['Education'],,"['40.00', '100.00']",Remote Job,Expert
Freight Industry - Data Science Insights,"We have a data set in the Freight Brokerage industry including the following tables:- Broker- Post- Location- CustomerAnd the following associations:1(Broker)/M(Post)1(Location as Origin)/M(Post)1(Location as Destination)/M(Post)M(Customer)/M(Location)We are looking to generate AI models, use data science to extract key insights, and overall consultation.Please reach out so that we may join a zoom call to discuss the project further.","['Data Science', 'Artificial Neural Network', 'Artificial Intelligence', 'Deep Learning', 'Data Analysis', 'Artificial Intelligence', 'Deep Learning', 'Data Analysis']",United States,1,,,,,"['18.00', '45.00']",Remote Job,Intermediate
Tableau dashboard,Need an in depth analysis in tableau according to the instructions given in the 'Problem Statement' sheet. This needs to be done in next 48 hours,"['Tableau', 'Data Visualization', 'Business Intelligence', 'Data Analysis', 'Business Intelligence', 'Data Analysis']",India,2,,0,,30.00,,Remote Job,Intermediate
PowerBI Developer,"At Diligo we are looking for a powerBI Developer, with knowledge in DAX language and Excel VBA, with one year of experience (minimum) to support our CTO in Spain. It would be part time to start.","['Microsoft Power BI', 'Data Analysis Expressions (DAX)', 'Visual Basic para Aplicaciones (VBA) ', 'Microsoft Power BI Data Visualization', 'Microsoft Power BI Development', 'SQL', 'Data Visualization', 'Visual Basic para Aplicaciones (VBA) ', 'Microsoft Power BI Data Visualization', 'Microsoft Power BI Development', 'SQL', 'Data Visualization']",Mexico,1,,,,,"['10.00', '50.00']",Remote Job,Intermediate
I need ai model for crowd counting.,I want some one make an demo ai model for crowd counting. with cnn layers,"['Python', 'Machine Learning', 'Artificial Intelligence', 'TensorFlow', 'Deep Learning', 'Neural Network', 'Keras', 'Convolutional Neural Network', 'Artificial Intelligence', 'TensorFlow', 'Deep Learning', 'Neural Network', 'Keras', 'Convolutional Neural Network']",Egypt,1,,30,,30.00,,Remote Job,Intermediate
Looking for a Business/Data Analyst - Tableau Expert,"We are looking for an expert Tableau Developer to join our team!-------------------------------------------------------------------------------------------------- IF YOU CONTACT US OUTSIDE OF UPWORK, YOU WILL BE AUTOMATICALLY DISQUALIFIED! PERIOD, NO EXCEPTIONS.-------------------------------------------------------------------------------------------------- We want to build a long-lasting relationship with someone we can rely on.Must-Have:- Experience working in PowerBI, GDS, Excel, and Tableau.- 3+ years of experience as a Business Analyst- 3+ years of experience with Tableau data evaluation software and Microsoft Excel- A solid understanding of SQL, rational databases, and normalization.- Proficiency in the use of query and reporting analysis tools.- Extensive experience in developing, maintaining, and managing Tableau dashboards & analytics and working knowledge of Tableau administration/architecture.- Excellent English communication Skills.- Full availability to work during US usual business hours (CST and EST)Preferred:- Experience managing health and healthcare data are preferable.","['Data Analysis', 'Data Visualization', 'Data Modeling', 'Microsoft SQL Server Reporting Services', 'Business Intelligence', 'Data Modeling', 'Microsoft SQL Server Reporting Services', 'Business Intelligence']",United States,1682,8.92,2.2,"['Tech', 'IT']",,,Remote Job,Intermediate
Product Manager B2B SaaS,"About Us:Docsumo is Document AI software that helps enterprises automate document processing. We help enterprises convert documents such as invoices, ID cards & bank statements into actionable data. We are backed by Sequoia, Barclays, Techstars & Better Capital.Responsibilities- As a Product Manager, you will be closely working with the co-founders and understanding customer needs to integrate on our existing product. - Responsible for managing sprint cycles, spec documents creation, development and delivery with the engineering, design, data teams.- Conduct user research to gain insights and feedback to incorporate into the product.- Communicate the vision of the product, value proposition and release goals to the cross-functional team as part of the release planning process.Requirements- Bachelor’s degree in Computer Science, Business Administration, Information Systems, or related field and 3+ years of experience in product management or related field- Great communication skills to explain ideas, gather & incorporate feedback and share opinions- Ability to troubleshoot with engineers and triangulate on fixes required- You can conceptualize and execute projects, with a strong delivery, attention to detail and bias for action, and the ability to prioritize and meet deadlines- You have the tenacity to develop ideas independently and thrive in a fast-paced environment","['Prototyping', 'Product Backlog', 'Implementation Plan', 'Agile Project Management', 'Kanban Methodology', 'Google Analytics', 'Mixpanel', 'Product Management', 'Product Roadmap', 'SaaS', 'SaaS']",Singapore,15,,50,"['Tech', 'IT']",,"['15.00', '50.00']",Remote Job,Expert
Generative AI,Create an AI platform to create ad images based on text and have those ads run through campaign on FB/Tiktok/Google and other places,"['Artificial Neural Network', 'TensorFlow', 'Machine Learning', 'TensorFlow', 'Machine Learning']",United States,4,,,,500.00,,Remote Job,Intermediate
Prompt Engineer For GPT-4 Prompts,Create custom prompt for open AI ( GPT-4).Need to provide proper rules to get a valid and sensible response for the query.Will need to restrict the answers (responses) within the context provided.Have good knowledge of prompt engineering and concepts like temp. control etc.,"['GPT-4', 'Prompt Engineering', 'Artificial Intelligence']",India,2,,,,,"['10.00', '35.00']",Remote Job,Intermediate
Google Analytics Installation,"We are seeking a skilled and detail-oriented Virtual Assistant to join our team and assist with the installation of Google Analytics for our new website. As a Google Analytics Installation Specialist, you will play a crucial role in setting up and configuring Google Analytics to ensure accurate data tracking and reporting. This is a part-time contract position with a focus on delivering high-quality results in a timely manner.Responsibilities:Collaborate with the website development team to ensure proper implementation of Google Analytics tracking code on all relevant pages of the new website.Configure Google Analytics settings and properties according to specific requirements and objectives.Set up goals, events, and custom tracking parameters to capture and measure relevant website interactions.Verify the accuracy of data tracking by conducting thorough testing and validation of Google Analytics implementation.Monitor and troubleshoot any issues or discrepancies in data reporting, taking necessary corrective actions.Provide guidance and recommendations on best practices for utilizing Google Analytics to track and analyze website performance.Stay updated with the latest trends and advancements in Google Analytics features and functionalities.Requirements:Proven experience in installing and configuring Google Analytics for websites.Strong understanding of Google Analytics terminology, features, and settings.Proficient in HTML and JavaScript to implement and customize tracking codes.Excellent attention to detail and ability to ensure accurate data tracking.Analytical mindset with the ability to interpret and analyze data to derive meaningful insights.Effective communication skills to collaborate with the website development team and provide updates on progress.Self-motivated and able to work independently with minimal supervision.Availability to work on a part-time basis with flexible hours.Preferred Qualifications:Google Analytics certification or relevant training.Experience with implementing advanced tracking features, such as enhanced e-commerce tracking or cross-domain tracking.Familiarity with website development frameworks and content management systems (CMS) like WordPress.To apply, please submit:Updated resume highlighting your relevant experience.Examples or portfolio showcasing your successful Google Analytics installations.A brief cover letter explaining your interest in the position and your availability.","['Google Analytics', 'Google Tag Manager', 'Google Analytics API', 'Search Engine Optimization', 'Google Analytics API', 'Search Engine Optimization']",United States,4,20.00,1.9,,,"['10.00', '25.00']",Remote Job,Intermediate
Data Analyst (Data Cleaning),"We are seeking a skilled and detail-oriented Data Analyst to join our team and assist in cleaning and preparing our data for analysis. We need to ensure that we have all information about remote staffs and the several tasks they’ve completed for us. Any staff who’s information is not uptodate we will like to know them etc… we can hop on a brief call to discuss this in detail. Qualifications:Proven experience as a Data Analyst or similar role, with a focus on data cleaning.Strong understanding of data cleaning techniques and best practices.Proficiency in data manipulation and cleaning using programming languages such as Python or R.Familiarity with SQL and database concepts for data extraction and transformation.Experience with data visualization tools such as Tableau or Power BI is a plus.Strong analytical and problem-solving skills.Excellent attention to detail and ability to work with complex datasets.Good communication skills and ability to collaborate effectively with cross-functional teams.We look forward to having you work on this project which could lead to long term if you perform well.","['Microsoft Excel', 'Data Analysis', 'Data Entry', 'R', 'Statistics', 'Python', 'Data Visualization', 'Data Science', 'Data Mining', 'Data Entry', 'R', 'Statistics', 'Python', 'Data Visualization', 'Data Science', 'Data Mining']",United States,61,,916,,5.00,,Remote Job,Expert
Help me fix my classification project,"I am working on lending data. I'm trying to predict lendees who are likely to take another loan. There was some sort of target leakage in the models which led me to preprocess the data in a way that now makes the training data and testing data distributions different. I don't think the predictions on unseen data are very good.This is primarily a preprocessing task. I need someone to decide if the target leakage is properly handled and if the only issue is the distributions not matching. Also, to suggest how to fix the determined issue.","['Python', 'Machine Learning', 'Data Science', 'Data Science']",United States,13,12.00,15,,,"['60.00', '150.00']",Remote Job,Expert
Data Aggregator,"Job Description:We are looking for a data aggregator to help us track which brands are sponsoring certain newsletters. The ideal candidate will have experience with data scraping, data analysis, and data visualization.Responsibilities:- Scrape data from websites and newsletters to identify brand sponsors- Analyze data to identify trends and patterns- Visualize data in a way that is easy to understand- Provide daily reports on your findingsQualifications:- Bachelor's degree in computer science, data science, or a related field- 1+ years of experience with data scraping, data analysis, and data visualization- Strong analytical and problem-solving skills- Excellent communication and presentation skillsWe are looking for a highly motivated and experienced data aggregator to join our team. If you are a data enthusiast with a passion for uncovering insights, we encourage you to apply!","['Data Mining', 'Data Scraping', 'Data Entry', 'Data Extraction', 'Data Entry', 'Data Extraction']",United States,46,29.23,77,['Real Estate'],,"['5.00', '15.00']",Remote Job,Entry level
Google Analytics and Tag Manager setup for Revenue attribution,"We are looking for an experienced Google Analytics and Tag Manager expert to help us set up revenue attribution tracking on our client website. Our client uses Aloha and Toast POS systems, Aloha is going to place the tags on the online ordering site for our client so that we can have revenue attribution in Google Analytics. We also have a client that needs GA4 update. The ideal candidate should have a deep understanding of Google Analytics and Google Tag Manager and be able to help us set up tracking for revenue attribution. The candidate should be able to create and implement custom tracking tags for various user actions on our website and ensure that the data is accurately captured and reported in Google Analytics.To be considered for this project, please submit a proposal describing how you can help us with this project. Please include links to past projects that you have completed that demonstrate your expertise in Google Analytics and Tag Manager.We look forward to hearing from you and working together to set up accurate revenue attribution tracking on our website.","['Google Tag Manager', 'Google Analytics', 'Analytics', 'Analytics']",United States,87,6.01,377,"['Tech', 'IT']",,"['45.00', '75.00']",Remote Job,Intermediate
AI/ML chatbot developer,"We are looking for an experienced Chatbot Developer to help us build a proof of concept (PoC) for integrating a chatbot into a group chat environment within our CRM system. The chatbot should have strong Natural Language Processing (NLP) capabilities and be contextually aware to interact with and assist our sales team members during their discussions.We are looking for a candidate who can think critically, solve problems, and work independently. You should have experience in developing chatbots, working with CRM systems like Salesforce, and strong knowledge of NLP.Responsibilities:-Analyzing the existing Salesforce CRM system, understanding the data schema, and the flow of information.-Designing and developing a chatbot capable of participating in a group chat.-Implementing NLP for understanding and responding to queries in a conversational manner.-Enabling the chatbot to fetch and present CRM data (opportunity, deal, lead, contact, account details) on-demand within the chat.-Building capabilities for the chatbot to perform automated actions based on conversation such as creating follow-up tasks.-Enabling proactive alerts from the chatbot about important events or deadlines.-Ensuring the chatbot can participate in specific threads when called upon.-Integrating the chatbot with our CRM system.-Testing the functionality of the chatbot and making necessary adjustments for optimal performance.-Documenting the development process, insights gained, and challenges faced during the PoC development.Deliverables:-A fully functioning chatbot capable of participating in a group chat environment.-Integration of chatbot with our CRM system.Examples:For example, in a real-world scenario where a sales team is discussing a particular deal in a thread:-Sales Rep A: ""Hey team, we have a call scheduled with the client for Opportunity #123 this Friday. Can someone pull up the latest notes?""-Chatbot: ""Sure. Here are the latest notes for Opportunity #123: [notes from Salesforce]""-Sales Rep B: ""Bot, can you remind us an hour before the call on Friday?""-Chatbot: ""Sure, I have set a reminder for the call for Opportunity #123 an hour before the scheduled time on Friday.""The chatbot should be able to respond in real-time and handle such queries.","['Chatbot', 'Machine Learning', 'Artificial Intelligence', 'Natural Language Processing', 'Neural Network', 'TensorFlow', 'Python', 'Natural Language Processing', 'Neural Network', 'TensorFlow', 'Python']",United States,166,36.62,271,"['Tech', 'IT']",1000.00,,Remote Job,Intermediate
Twitter Account Tracking and Reporting (Real-time Updates),"I need a bot that tracks a list of twitter users, and notifies me when they follow anybody new on Twitter.For example lets say im tracking @elonmusk, when he follows @tesla, I want a notification that he followed @tesla, this notification would be in my discord server, and it would also report @teslas's bio, profile pic, how many followers it has, and how many tweets have been sent from that accounti want to be able to update the list of tracked users easily, tracking up to 800 users such as @elonmusk and others the main thing is the notifications should update every 5 mins, There are a few other very minor details but the main task is above.to test that the product works, I will add myself to the list of tracked users and follow a twitter account, if i receive a notification in the discord, then you have done the job and the project is a success","['Python', 'Bot Development', 'Twitter API', 'Web Scraping', 'real time data updates', 'Web Scraping', 'real time data updates']",Hong Kong,80,16.28,14,"['Art', 'Design']",450.00,,Remote Job,Expert
Financial Data Visualization,"Here is the Excel spreadsheet for the Data Viz :- Tab 1 : contains various information for S&P 500 & for each company (performance, KPIs, ...).- Tabs 3 : contains revenues for the company.I need to do Data Viz using the above, as well as other information available on the web  for the company BMY US EQUITY. (ESG, salaries, owners, headquarters, logos, ...)THE WORK HAS TO BE DONE TODAY !!!","['Microsoft Excel', 'Data Visualization', 'Microsoft Power BI', 'Microsoft Power BI']",France,2,,45,,,,Remote Job,Intermediate
Financial Data Visualization,"Here is the Excel spreadsheet for the Data Viz :- Tab 1 : contains various information for S&P 500 & for each company (performance, KPIs, ...). - Tabs 3 : contains revenues for the company.I need to do Data Viz using the above, as well as other information available on the web  for the company BMY US EQUITY. (ESG, salaries, owners, headquarters, logos, ...)","['Microsoft Power BI', 'Microsoft Excel', 'Data Visualization']",France,2,,45,,,,Remote Job,Expert
"Python , AWS, SQL","We need a candidate having more than 5 years of experience in below technologiesSkills - Python, AWS and SQLTime- 10 pm IST to 1 am ISTDuration -3 hours ( Monday to Friday)Budget - 28 k INR monthlyWork type -remote work over the zoom call","['Python', 'SQL', 'Amazon Web Services']",India,390,,630,,340.00,,Remote Job,Intermediate
Data Visualisation Expert for Amazon Vendor Central,"Hi, I'm looking for someone who has many years of experience in data visualizations and has past working experience with the Amazon Vendor Central platform. Thanks","['Data Visualization', 'Microsoft Power BI', 'Google Data Studio', 'Tableau', 'Amazon Vendor Central', 'Excel Macros', 'Amazon Webstore', 'Microsoft Excel', 'Data Analysis', 'Python', 'Excel Macros', 'Amazon Webstore', 'Microsoft Excel', 'Data Analysis', 'Python']",United Kingdom,41,,74,,,,Remote Job,Expert
Automotive Data Engineer,I need someone who is good with Pi Toolbox and is able to interpret the data from Pi Toolbox,"['Data Engineering', 'Pi toolbox', 'Automotive Engineering']",United Kingdom,4,,200,,85.00,,Remote Job,Expert
Computational Science platform Engineer,"Candidate should have 8+ years experience with focus on supporting Bioinformatics pipeline using Cloud, DevOps and Linux based infrastructure. Skills:•	Experience building and managing HPC cluster•	Strong experience with Infrastructure as code •	Strong Experience with CDK and CI/CD •	Mastery of basic Linux skills •	Design and deploy CRON jobs, SLURM jobs•	Experience with DevOps practicesNice to have:•	US time zone •	Managing Jupyterhub and RStudio •	Familiar with Ansible•	Familiar with Terraform •	Experience with engineering bioinformatics pipelines","['HPC Cluster', 'CDK', 'CI/CD', 'Linux', 'SLURN', 'DevOps', 'Ansible', 'Terraform', 'Bioinformatics', 'Linux based Architecture', 'SLURN', 'DevOps', 'Ansible', 'Terraform', 'Bioinformatics', 'Linux based Architecture']",United States,2,,,"['Engineering', 'Architecture']",,,Remote Job,Expert
Computational Science platform Engineer,"Candidate should have 8+ years experience with focus on supporting Bioinformatics pipeline using Cloud, DevOps and Linux based infrastructure. Skills:•	Experience building and managing HPC cluster•	Strong experience with Infrastructure as code •	Strong Experience with CDK and CI/CD •	Mastery of basic Linux skills •	Design and deploy CRON jobs, SLURM jobs•	Experience with DevOps practicesNice to have:•	US time zone •	Managing Jupyterhub and RStudio •	Familiar with Ansible•	Familiar with Terraform •	Experience with engineering bioinformatics pipelines","['HPC Cluster', 'CDK', 'CI/CD', 'Linux', 'SLURN', 'DevOps', 'Ansible', 'Terraform', 'Bioinformatics', 'Linux based Architecture', 'SLURN', 'DevOps', 'Ansible', 'Terraform', 'Bioinformatics', 'Linux based Architecture']",United States,2,,,"['Engineering', 'Architecture']",,,Remote Job,Expert
YouTube Analytics Data analyst for papers on youtube growth,"We're searching for a data analyst that wants complete freedom in their research and projects. Essentially - we own a lot of large YouTube channels as well as a big youtube scraping tool.https://twitter.com/noahmorrizhttps://www.nexlev.io/We need someone who is passionate about interpreting and studying youtube channel data from our database to help us better understand how people can better grow their youtube channels.Essentially interpreting and visualizing the data into youtube growth lessons. In this position, you have total freedom on what you study and how many hours you make.We only require you to be passionate and thorough in your studies. We will publish your studies on our social media's exposing it into the largest players in the youtube space which will grant you future access to collaborating with the industry largest players like: mr beast, airrack and many more.","['Growth Analytics', 'Presentations', 'Data Visualization', 'Data Interpretation', 'SQL', 'YouTube', 'Data Analysis', 'Data Entry', 'Analytics', 'Microsoft Excel', 'Analytics', 'Microsoft Excel']",Netherlands,128,,5.3,"['Art', 'Design']",,"['5.00', '10.00']",Remote Job,Intermediate
Program to locate and test offline Web site links,"U.S. nonprofit needs a program that will scan a disk-based mirror of a Web site and locate internal and external links. Possibly 10,000+ links per site.Resulting database of external and internal links should include repetitive links to feedback, social media sites, search, and forums.  Internal links should be tested.The data should include RefererURL and date/time (in a parent table), and a child table that stores unique LinkURL, as well as additional fields for storing follow-up actions and disposition.  An intermediate table should be used to link the RefererURL with the LinkURL error code,  as well as the source code (HREF) and line number of the non-functional link.Once the table of unique external LinkURLs has been established, the program should attempt a HOST HEAD request and record the result in the LinkURL table.A top-level report should display the number of pages searched, the number of links detected, the number of broken internal URLs, the number of working external URLs and non-functional external URLs.This report should have links to sub reports:A report for the Internal links should show the non-working LinkURLs as well as the number of RefererURLs that contain the LinkURL.  The user should be able to further inspect each LinkURL to view the associated RefererURL and the source code line of the.The report for external URLs should display a count of unreachable URLs per domain and host.  Further inspection should display total reachable and non-reachable URLs per domain/host, total number of RefererLinks to the LinkURL, and further details on the RefererURLs, the source code line, and the LinkURLs.Finally, a third report will provide a text script to rewrite links in the mirror.  It will combine the values of the RefererURL, LinkURL, and follow-up action.  We usually use dnGREP to rewrite links, but are open to advice.The use of open source code for the recursive search for links and the testing of LinkURLs is highly encouraged.  The user interface for setting up, monitoring, and browsing the job should be in PHP/HTML/JS and use SQLite or equivalent.The data and UI should be stored in a single directory under the root of the Web mirror.","['PHP', 'JavaScript', 'Data Scraping']",United States,58,15.00,4.3,,100.00,,Remote Job,Intermediate
Statistician Needed for Dental Resident Research Project,"Graduate student research project.  Need data analyzed, charts/tables made and results section written.Project is looking to determine if increased waiting time for children to get into the operating room for dental treatment leads to more emergency room visits and/or more urgent clinic visits for pain.All data is in Excel.Must speak English.","['Statistics', 'Microsoft Excel', 'Data Analysis', 'IBM SPSS', 'Academic Writing', 'Research Papers', 'Biostatistics', 'medical research analysis', 'Data Analysis', 'IBM SPSS', 'Academic Writing', 'Research Papers', 'Biostatistics', 'medical research analysis']",United States,1,,,,,"['18.00', '45.00']",Remote Job,Intermediate
Einstein Analytics Dashboard Task,Urgent Need to finish minor fixes this weekend for Einstein Analytics dashboard.,"['Dashboard', 'Einstien Analytics', 'SAQL', 'Einstien', 'Data Visualization', 'Salesforce CRM', 'Einstien', 'Data Visualization', 'Salesforce CRM']",United States,6,,202,,150.00,,Remote Job,Expert
Data Quality Reporting Analyst,"As a data governance reporting analyst, you will report to the Master Data Manager and own the Data Quality (DQ) reporting at Pattern that focuses on product and listing data for our eCommerce Partners.  You will be responsible for the full process from maintaining the existing SQL that monitors data completeness and identifies data quality issues--including the weekly snapshot process--to data visualization, presentation, and user experience in Tableau.  Desired skills:--Very strong SQL and query optimization abilities --1-2 years of experience with Tableau--Ability to document data flows in Lucid Chart--Ability to work independently based on clear instructionsCommon tasks:--Perform ad hoc analysis by writing SQL queries that join tables, concatenate columns, clean data, check characters lengths, etc.--Expand existing reporting to include new attributes and new data quality issues--Determine how to make queries and visualizations more efficient--Scheduling and checking data source refreshes and snapshots","['SQL', 'Tableau', 'Data Analysis', 'Data Visualization', 'Snowflake', 'Snowflake']",United States,296,,,,,"['15.00', '20.00']",Remote Job,Intermediate
Migrar de Crystal Reports 8 a Jasper Reports,Migrar un reporte de Crystal Reports 8.5 a Jasper Reports usando una base de datos Postgres. El reporte recibe parámetros y puede ejecutar un stored procedure para obtener los datos.,"['SAP Crystal Reports', 'JasperReports', 'PostgreSQL', 'Jaspersoft Studio', 'Data Visualization Tools', 'Jaspersoft Studio', 'Data Visualization Tools']",Uruguay,1,,,,,"['15.00', '30.00']",Remote Job,Intermediate
Looker Developer to Help Create Model(s) & Build Dashboards,We recently chose Looker as our company-wide BI tool. It's attached to our data warehouse on AWS Aurora. There several reports in Google sheets that need replicated as Looker dashboards. We want a developer with significant Looker/ LookML experience who can create these dashboards. The right candidate needs to have strong communication skills and the ability to work independently.,"['Looker', 'Data Visualization']",United States,1,,,,,"['40.00', '75.00']",Remote Job,Intermediate
Web Scraping Specialist,"We are looking for an experienced web scraper to help our company scrape auction house sale data. We are an art + tech startup with a large database of artist & auction sale records and the main goal of this project is to increase that amount of data. This is a 1-3 month contract to start, with the potential of an extension. The candidate may use any preferred tools/method for scraping, and we would like the data then formatted in a .csv file. We will provide all necessary details on what fields need to be captured and how it should be formatted. The ideal candidate has excellent time management skills and is able to meet deadlines. Responsibilities include:1. Scraping past auction data from assigned auction websites2. Ensure data is scraped in our preferred format capturing all necessary data pointsTo be a best fit for this project you need: 1. Dedication to meet project deadlines in a timely manner2. Attention to details3. Ability to communicate clearly4. Fluent in English (reading and writing); Proficient in English (speaking)If you are interested in this project, please reply with your prior experience.","['Web Scraping', 'Data Extraction', 'Data Scraping', 'Microsoft Excel', 'Web Scraping Software', 'Time Management', 'Web Scraping Software', 'Time Management']",United States,3,5.00,29,,,"['5.00', '12.00']",Remote Job,Intermediate
CTO/Architect,"CTO/ArchitectJob Summary:We are seeking a highly skilled and experienced co-CTO/Architect with extensive knowledge of Python (Flask, Fastapi), Devops, and ML to join our team. In this role, you will be responsible for leading the development of our technology infrastructure, applications, and strategies. You will work closely with our executive team to create and implement effective plans, processes, and procedures for our organization.Key Responsibilities:Develop and lead the implementation of our technical strategies, plans, and processesCollaborate with executive leadership to create and execute effective technology roadmapsOversee the design, implementation, and maintenance of our technology infrastructure, applications, and softwareDevelop and maintain technology standards and best practicesLead a team of developers, analysts, and engineers, providing guidance and mentorship to help them advance in their rolesQualifications:10+ years of relevant experience in technology leadership roles, with deep expertise in Python (Flask, Fastapi), Devops, and ML.Demonstrable experience building scalable, reliable technology solutionsExperience leading software development teams and driving product developmentExcellent communication and collaboration skills, with a track record of delivering successful projectsDeep understanding of Devops methodologies, principles, and best practicesStrong knowledge of data science, machine learning, and AIExperience with cloud platforms such as Google Cloud or AWSBachelor's or Master's degree in Computer Science, Engineering, or a related field","['Google Cloud Platform', 'Python', 'Web Service', 'Software Architecture & Design', 'DevOps', 'Machine Learning', 'DevOps', 'Machine Learning']",United States,14,38.77,5.6,"['Tech', 'IT']",,"['65.00', '110.00']",Remote Job,Expert
Parse data into specified fields.,"I am looking for a spreadsheet lover with attention to detail and an ability to do repetitive tasks. This person will take these 3 spreadsheets with just over 500 form submissions and create a uniform spreadsheet that captures the material requested in a more usable format for my company.You will work directly with me on any clarifications or questions that you may have.I need this project complete by COB June 23, 23.These 3 spreadsheets were each designed differently, based on how our website was being used at the time. They increase in data/detail over time.I have included a document describing the nature of the project, the goal of the project, with things to know, things to exclude, lingo, and other things that should make understanding the project and the data a bit easier.Any Questions? Comments? Emotional outbursts?","['Data Entry', 'Microsoft Excel', 'Data Extraction', 'Data Extraction']",United States,1,,,,,"['25.00', '30.00']",Remote Job,Intermediate
Power BI  - 8+ years Experience,"Hands on expertise on LeanIX Enterprise Architecture Management (EAM) toolGood understanding of Enterprise Architecture Management conceptsGood understanding of various Reporting platforms like Power BI, Tableau, etc.Having experience in LeanIX EAM tool implementation – end to end lineage/traceability for objects in the Enterprise ArchitectureHaving experience on building reports/dashboards out of Lean IX EAM tool","['Tableau', 'Microsoft Power BI', 'Microsoft Excel', 'lean ix', 'eam tool', 'lean ix', 'eam tool']",India,264,10.00,2.9,,7000.00,,Remote Job,Expert
Pulling Shopee ads data from Shopee seller center [API/Web scraping ],"I would like to find freelancers who could help on finding method to automate Shopee ads data from Shopee seller center. As seem like Shopee API doesn't' support ads data, then I guess we need to go for web scraping method. Or if you have any idea on the approach, feel free to message me or send an email to kung@marketyze.io Metric I want to automate: spend, impression, click, order, revenue","['Data Scraping', 'Lead Generation', 'API', 'JavaScript', 'Python', 'API', 'JavaScript', 'Python']",Thailand,1,,,,,,Remote Job,Expert
Scrape for Images - Rescue Essentials,"Scrape for product images rescue-essentials.com.Please get as many images as available for each product.Please only use the largest copy of the same image.Submit in a zip format.Consider, that the images will be uploaded to our server with url media.buysupply.com/re/Fill in image urls for corresponding products in Rescue-Essentials_MASTER_qa_3-scrape-for-images.xlsx","['Python', 'Data Scraping', 'Microsoft Excel', 'Scrapy', 'Scrapy']",United States,46,14.11,75,,25.00,,Remote Job,Expert
Influencer Data Scraper,"Hello Freelancers,I am seeking an experienced data scraper to help me research influencers and find individuals based on specific criteria. Specifically, I require English-speaking TikTok users from the United State who post regularly with a focus on health and fitness-related content.The required information to be scraped includes the influencer's account name, first name, engagement rate (this will have to be 5%+), gender, email, TikTok link, and Instagram link. I require a total of 500 influencers split into 5 different follower brackets: 1-10k, 10-50k, 50-500k, 500k-1m, and 1m+. This would mean 100 influencers for each follower bracket.The data must be entered into a Google Sheets document. The ideal candidate should be familiar with navigating TikTok and completing the task as soon as possible to a high standard. Attention to detail and accuracy are essential.Please let me know if you have any questions or require further clarification.This job will be completed on a fixed-price basis. If you believe you have the skills and experience to complete this job, please submit your proposal.Thank you","['Data Scraping', 'Data Mining', 'Data Entry', 'Data Extraction', 'Data Entry', 'Data Extraction']",Pakistan,38,4.64,494,"['Art', 'Design']",,"['3.00', '5.00']",Remote Job,Entry level
Angular Developer,"Job Description:We are seeking a highly skilled and experienced Angular Developer to join our team. As an Angular Developer, you will play a crucial role in designing, developing, and maintaining our web applications using Angular 15. The ideal candidate should have at least 4 years of professional experience, with a strong focus on Angular development.Responsibilities:1. Collaborate with the development team and stakeholders to understand project requirements and translate them into functional and technical specifications.2. Design and develop user-friendly web applications using Angular 15, ensuring high performance, scalability, and maintainability.3. Implement RESTful APIs based on the project requirements, ensuring seamless integration with back-end services.4. Perform data modeling and database design using Oracle, SQL, and PL/SQL, ensuring efficient data retrieval and manipulation.5. Write clean, reusable, and efficient code following best practices and coding standards.6. Conduct code reviews to maintain code quality and ensure adherence to development guidelines.7. Troubleshoot and debug application issues, proposing effective solutions to ensure optimal functionality.8. Collaborate with cross-functional teams, including UI/UX designers, back-end developers, and QA engineers, to deliver high-quality software products.9. Stay up-to-date with the latest industry trends and technologies, actively participating in knowledge sharing and continuous learning.Requirements:1. Bachelor's degree in Computer Science, Software Engineering, or a related field.2. Minimum of 4 years of professional experience as an Angular Developer.3. Strong proficiency in Angular 15, with a deep understanding of its core concepts and features.4. Proven experience in designing and developing RESTful APIs.Solid knowledge of Oracle, SQL, and PL/SQL for data modeling and database design.5. Proficient understanding of front-end technologies such as HTML5, CSS3, and JavaScript.6. Familiarity with version control systems (e.g., Git) and agile development methodologies.7. Excellent problem-solving skills and attention to detail.8. Strong communication and collaboration abilities.9.  Ability to work remotely and effectively manage time and tasks.Location: Remote workWe offer competitive compensation and benefits package, along with opportunities for professional growth and advancement. If you are a self-motivated Angular Developer with a passion for building high-quality web applications, we would love to hear from you.To apply, please submit your resume, portfolio, and any relevant code samples showcasing your Angular development skills.","['SQL', 'Angular', 'CSS', 'JavaScript', 'angular 15', 'RESTful API', 'Oracle', 'HTML5', 'RESTful API', 'Oracle', 'HTML5']",India,2,,,"['Tech', 'IT']",,,Remote Job,Intermediate
Data extraction from journal articles and input into excel,"We are seeking a skilled freelancer to help us extract data from journal articles and input the key variables and metrics into an Excel spreadsheet. The project will last less than a month and requires data entry, extraction, and mining expertise.As the chosen candidate, you will be responsible for identifying relevant data from various journal articles and inputting it into a spreadsheet accurately and efficiently. The ideal candidate should have experience handling large datasets and be familiar with different data extraction techniques.To apply for this position, please submit a proposal outlining your experience and how you plan to approach this project. Also, please include links to any relevant projects you have completed.We are looking for someone detail-oriented, reliable, and can work independently. We'd love to hear from you if you're up for the challenge!Thank you","['Data Entry', 'Data Mining', 'Data Extraction', 'Data Extraction']",United States,43,10.77,9.3,['Education'],,,Remote Job,Expert
Talend ETL development using API Restful Web service,Need Talend experience and hands-on development using Talend studio.Expected to have created workflows using ESB RESTclient and SOAP web service API calls.,"['Talend Open Studio', 'Talend Data Integration', 'ETL Pipeline', 'RESTful API', 'ETL Pipeline', 'RESTful API']",United States,106,13.71,6,,,"['15.00', '20.00']",Remote Job,Intermediate
AI Developer for Letter Writing Program,"We are a dental practice that sends a letter out for each patient visit.  The letters are customized based on the type of visit and the data gathered during the visit.  As a result, we have thousands of letters archived over the years.  I am looking to train an AI system on our letters so that new letters can be written in the same style and formatting using AI, based on data we enter.  Currently all letters are written via a mail merge program.  Going forward we anticipate using a program to generate the data, then using the program you develop to format it into a letter.","['AI Content Creation', 'Natural Language Generation', 'Text Recognition', 'ChatGPT', 'GPT-4', 'Generative AI']",United States,3,,166,"['Health', 'Fitness']",5000.00,,Remote Job,Expert
Technical Business and Data Analyst,"About Blue Cypress: Blue Cypress is an innovative incubator and accelerator reshaping the association and non-profit sector. As a Conscious Capitalism practitioner, we empower purpose-driven leaders through our evergreen investment strategy, launching and growing companies that make a positive global impact.We partner with start-ups and growth-stage organizations, providing comprehensive back-office support and infrastructure, while leveraging cutting-edge AI to redefine their potential. Our in-house experts keep our companies at the innovation forefront, navigating the ever-evolving technological and business landscape.Being part of Blue Cypress means embracing AI-enhanced tools to drive change and set new success standards. Our core purpose is to help purpose-driven leaders exceed their goals and maximize impact. Dedicated to long-term growth and transformation, we're revolutionizing the non-profit sector, one purpose-driven company at a time.Job Summary: As part of our commitment to driving innovation and growth for our companies, we are investing in a Common Data Platform (CDP) to integrate our technology stack across companies and optimize data quality, availability and the ability to apply AI. We are seeking a highly skilled and detail-oriented Technical Business and Data Analyst to join our team. The successful candidate will play a critical role in managing and optimizing data, reporting, and workflow automation. They will leverage their technical and analytical skills to drive business efficiencies, boost revenue, and enhance sales. Key Responsibilities: - Data Management: Work closely with our data team to facilitate the integration of data from various sources into our CDP. Ensure data quality, accuracy, and consistency. Coordinate with technical team members as needed to maintain and enhance integrations. - System Integration: Work across our portfolio companies to consolidate data from various tech stacks (including accounting software, HRIS (Human Resources Information System), CRM (Customer Relationship Management), contract and proposal management software, and project management software) into the CDP. - New System Selection and Implementation: Lead the process of evaluating, selecting, and implementing new systems that will enhance operational efficiency and data utilization. This includes defining system requirements, coordinating with vendors, managing system setup and integration, and training users. - System Enhancements: Oversee enhancements and updates to existing systems. Collaborate with internal teams and external vendors to identify opportunities for improvement, implement system upgrades, and ensure smooth transition during changes. Monitor system performance post-enhancement to confirm effectiveness and plan for future improvements. - Data Analysis: Utilize Microsoft PowerBI as well as cutting-edge AI techniques to find patterns in the CDP data and proactively identify opportunities at the family level and across individual businesses. - Workflow Optimization: Develop and manage workflows/automations to improve efficiency and productivity across operations. - Reporting: Using PowerBI and other software, generate comprehensive reports for internal and external stakeholders, provide insights into key performance indicators (KPIs), and recommend data-driven strategies for improvement. - Support Sales Enablement: Collaborate with sales teams to leverage data resources for targeted outreach and marketing campaigns. Qualifications: You must be incredibly curious and want to explore the world of data and business. If you’re not innately curious and deeply excited by digging in to find new opportunities, our culture won’t be a good fit for you. To answer if you fit this requirement – ask yourself this – when you first heard about ChatGPT, how quickly did you experiment with it? If it took you more than a couple of weeks, this role and our company likely aren’t the right fit. We’re looking for someone who is genuinely excited about exploring ALL new technologies and finding meaningful business use cases for them! Other qualifications we are looking for: - Bachelor's degree in Business, Computer Science, Data Science, or a related field. - At least 3 years of experience in a technical business analyst role, data management, or a similar role. - Strong knowledge of data analysis tools and programming languages such as SQL, Python, or TypeScript. - Proficiency with the tech stack mentioned (CRM, HRIS, Accounting software, etc.). - Strong analytical skills and proficiency in AI techniques. - Excellent communication and interpersonal skills, with the ability to translate complex data into actionable business insights. - Experience in workflow automation. - Experience in project management and system implementations. - Strong attention to detail and problem-solving skills. - Comfortable working in a fast-paced environment.","['Operations Analytics', 'Data Analysis', 'Data Interpretation', 'SQL', 'Python', 'Microsoft Power BI', 'Business Intelligence', 'Business Analysis', 'Data Visualization', 'Business Analysis', 'Data Visualization']",United States,68,13.84,339,"['Tech', 'IT']",,"['35.00', '60.00']",Remote Job,Intermediate
"Web Scraping Specialist: Playwright, Apify, and Crawlee Experience Required","We are on the lookout for a talented engineer who is well-versed in writing automations using the Apify platform. If you have experience with Playwright, that's a huge plus! We have numerous small scripts that typically take a few hours to complete, and we need someone who can prepare and optimize them for Apify via the Crawlee platform.Requirements:- Strong experience with the Apify platform- Familiarity with Playwright (preferred)- Proven track record of writing automations and crawlers- Ability to work on an hourly basisTo Apply:Please share your previous experience and provide references to demonstrate your expertise in this area. If you have never used Apify before but have experience with Playwright, feel free to apply.IMPORTANT: We kindly request that only candidates who meet the specified criteria apply for this position. If you are not familiar with the Apify platform or its features, please refrain from applying. We are looking for someone who has at least some experience with this platform, even if it's just a hobby project, as there are many details to consider and we want to ensure a smooth and efficient working relationship.","['Data Scraping', 'Scrapy', 'Data Mining', 'Node.js', 'apify', 'crawlee', 'Node.js', 'apify', 'crawlee']",Turkey,429,9.49,40,,,"['5.00', '20.00']",Remote Job,Intermediate
Build a prediction program,"Business Objects Involved are: 1) Demand: A demand is request of a customer for a vehicle. It requires a demand type (Replacement, Additional Vehicle, New Car), a demand quantity (number of vehicles), a demand class (vehicle class), ademand type (vehicle model), a demand desired delivery date, a status or so-called demand result, which will end up with values like ""Deal"", ""No Deal"", ""Postponed"" or ""No demand"". In case a demand has anopportunity, a demand belongs to only 1 opportunity. In this case a reference to the opportunity is filled (Opportunity Id Attribute).2) Opportunity: the opportunity is linked to 1 retailer and 1 customer. 1 opportunity can have n-demands. opportunity attributes are OPTY_ID, OPTY_PURCH_DT, OPTY_TARGETED_QTY, OPTY_MODEL_TYPE, OPTY_VARIANT, OPTY_CREATEDATE, OPTY_RESULT, OPTY_PRIMARY_POS_ID, ACC_PRIMARY_POS_ID, RETAILER_ID3) Quote: each quote has a VENDOR, MANUFACTURER, VEHICLE_MODEL_TYPE, QUANTITY, VEHICLE_CONDITION, NET_PRICE, QUOTE_DEL_DATE, WINNINGQUOTE and DEMAND_ID4) Customer: it has attributes ACC_TYPE, TEMPERATURE, FLEET_SIZE, LAST_CON_DT, FLEET_STATUS, ACC_BUS_TYPE, ACC_SALES_CHANNEL, INDUSTRY_CODE, POSTAL_CODEOnly 1 Quote can be a winning quote. If the vendor of winning quote is ""Own"", the DEMAND_RESULT will be a ""Deal"". If the winning quote has other vendor as ""Own"" is not OWN Quote, the DEMAND_RESULT will be LOST DEAL. It could be that DEMAND_RESULT is is ""Demand Postponed"" or ""No Demand"", in this case there will be sure no winning qoute at all and it could be also no Quote assigned to this DEMAND.To-do:o	Implement a prediction mechanism within the Deal Prediction Tool to forecast whether a demand will result in a ""Deal"" or ""No Deal.""o	Utilize relevant data attributes such as demand type, demand quantity, demand class, demand model, desired delivery date, and customer attributes (e.g., ACC_TYPE, TEMPERATURE, FLEET_SIZE, INDUSTRY_CODE, etc.) to make the prediction.o	Use machine learning or statistical models to analyze historical data and generate predictions based on patterns and trends.o	Provide a confidence level or probability associated with each prediction to indicate the reliability or certainty of the forecast.o	Present the prediction and associated confidence level to users in a clear and easily understandable format.o	Enable users to review and analyze the predicted results to inform decision-making and prioritize efforts accordingly.o	Integrate machine learning algorithms and techniques into the Deal Prediction Tool to enhance the accuracy and reliability of deal predictions.o	Utilize historical demand, opportunity, quote, and customer data to train the machine learning models.o	Select and employ appropriate machine learning algorithms, such as classification or regression models, to predict whether a demand will result in a ""Deal"" or ""No Deal.""o	Ensure that the machine learning models are regularly updated and retrained to incorporate new data and improve prediction performance over time.o	Implement a feedback loop mechanism to collect feedback on predicted outcomes and actual outcomes to continuously refine and improve the machine learning models.o	Provide transparency and explainability of the machine learning predictions to build trust and understanding among users.o	Monitor and evaluate the performance of the machine learning models regularly to assess their accuracy and adjust the models as needed.Collaborate with data scientists or experts in machine learning to design and implement the machine learning integration effectively.By incorporating machine learning into the Deal Prediction Tool, it can leverage advanced algorithms to analyze patterns, correlations, and historical trends in the data. This integration enables more accurate and data-driven predictions, empowering users to make informed decisions regarding deal opportunities.","['Python', 'Machine Learning', 'Artificial Intelligence', 'Deep Learning', 'Neural Network', 'Artificial Neural Network', 'Artificial Intelligence', 'Deep Learning', 'Neural Network', 'Artificial Neural Network']",Germany,1,,,,1000.00,,Remote Job,Expert
Website scraper,"I need somebody to go onto the Airalo website and write down in a spreadsheet all of the eSIM options in each country. For the ""Local eSIM"" section, the fields in the spreadsheet should be:CountryData IncludedValidityPriceCarrier(s)For the ""Regional eSIM"" section, the fields in the spreadsheet should be:Region# of CountriesData IncludedValidityPriceFor the ""Global eSIM"" section, the fields in the spreadsheet should be:# of CountriesData IncludedValidityPriceIf this works out I may continue this work and expand to other, similar companies.","['Data Scraping', 'Data Entry']",Bermuda,1,,,,,"['5.00', '15.00']",Remote Job,Entry level
Big Query/GA4 Integration,Looking a highly skilled and experienced professional to provide one-on-one assistance and expertise in GA4/BigQuery integration and Power BI data integration.,"['Google Analytics', 'Microsoft Power BI', 'BigQuery']",United States,55,14.05,38,,,"['45.00', '75.00']",Remote Job,Intermediate
Scraping/AI Engineer for Reviews Analysis,"Hi there!We're looking to hire an engineer on a small project for the next month.The goal is to scrape all of our Amazon reviews, and then analyze patterns to find product improvement ideas and issues. Working hours are flexible and deliverable based.","['Artificial Intelligence', 'Web Scraping', 'Web Scraping']",United Kingdom,350,14.89,397,"['Retail', 'Consumer Goods']",,,Remote Job,Intermediate
Company Data Extraction,"Hello freelancers! I'm looking for an Individual to scrape companies for me. I'm looking for 300 companies which adhere to certain guidelines, to be put into a google sheets document.These companies need to be technology based and I want to capture any companies that are targeting people aged 16-30 in the tech space which could include tech accessories (for example headphones, speakers, cases & gaming peripherals), tech products (for example phones, gaming computers, laptops, LED lights, PC parts) and software companies (for example photo & video editing software & AI tools).You must be aware of the platform Tiktok as this is essential for us. Any companies/brands that are proposed must be ones you think would be suitable to be marketed on TikTok.This won't be as easy as just copying and pasting them off a technology product index so, you will have to do a bit of digging.The information I need from the companies you scrape:Company NameCompany Website URLDecision makers name*, email, phone number and Linkedin.*If you can't find the decision maker, use the next decision maker or the closest person to them or someone in the marketing team e.g. head of marketing*I have attached a screenshot showing the layout of the spreadsheet for how I would like you to present the data.If you think you can do this, using software/AI or not I don't mind as long as you can ensure they are suitable!I'm looking forward to hearing back from you!TillmanCo-founder, WeIgniteMedia","['Data Scraping', 'Microsoft Excel', 'Data Entry', 'Data Mining', 'Data Extraction', 'Lead Generation', 'TikTok Marketing', 'researcher', 'Data Entry', 'Data Mining', 'Data Extraction', 'Lead Generation', 'TikTok Marketing', 'researcher']",United Kingdom,1,,,,100.00,,Remote Job,Intermediate
c# Back End Developer | FULL TIME POSITION | Amazon Advertising API & further tasks,"We are searching for an experienced backend developer for developing our Amazon Advertising Technology and further tasks.**THIS IS A FULL TIME POSITION - WE ARE SEARCHING FOR A PERSON WHO WILL WORK DEDICATED WITH OUR COMPANY**We are searching for somebody in full time who takes responsibility and works longterm with us.**Your Tasks**- Working on Amazon Advertising API, data mining and visualization- Process data with our algorithms and data bases- Merge data and run algorithms and update data records- Maintenance of existing databases, mailing systems, it administration- Develop new software automation processes- Technical Documentation**Your background and experience that makes you a good fit for this job:**- Relevant experience in Computer Science, Maths, Stats, or a related area- Excellence with Python- Proficiency in using query languages such as SQL or Postgres- Good applied statistics skills, such as distributions, statistical testing, regression, etc.- Experience in data scraping, database architecture**Our current tasks / stack:****Servers**digitalocean VPS with Ubuntu as prod serversgit as source systemteamcity as CI/CD**All things below integrated through c#**Postgres as databaseminio as file storageconsul as configuration storevault as secrets storegoogl sheets and google sheet api for creating reportsAmazon Advertising Api for interaction with Amazon Gmail + gmass + google sheet for mass mailingscraper api as round robin proxytelegram bot for sending alarms and events","['PHP', 'API', 'Linux', 'C#', 'API Integration', 'Amazon Web Services', 'Amazon Web Services']",Germany,141,16.50,318,,2000.00,,Remote Job,Intermediate
Mobile App Scraper needed,"Looking to find someone who can scrape a user list within an easily accessible mobile app. Information scraped will need to include name, contact information and any other applicable personal information.","['Data Extraction', 'Screen Scraping', 'Data Scraping', 'mobile scraping']",United States,47,39.65,61,"['HR', 'Business Services']",,"['25.00', '50.00']",Remote Job,Intermediate
Data Modelling - 7+ years,Required Skills: Data ModellingExperience Requirement: 7+ Years,"['Microsoft Power BI', 'Microsoft Excel', 'Data Modeling']",India,264,10.00,2.9,,8000.00,,Remote Job,Expert
Creating aging bucket in ServiceNow report,-Creating aging bucket in ServiceNow to do data validation from a Power BI visuals.-Calculating MTTR(Mean Time to Resolve) from ServiceNow data to do data validation against Power BI visuals,"['Data Engineering', 'ServiceNow', 'Microsoft Power BI', 'ITIL', 'ITIL']",United States,6,21.08,732,,,"['10.00', '30.00']",Remote Job,Expert
Looker Studio/Report Dash Profi gesucht,"Ich schreibe im Namen der OMA AG. Wir sind eine Online-Marketing-Agentur und suchen Looker Studio/Report Dash-Unterstützung. Unsere KMU Kunden kommen aus über 100 Branchen, abwechslungsreiche Arbeit ist also garantiert. :) Wir decken inhouse zwar alles ab, aber unsere aktuelle Auftragslage ist für uns allein nicht zu bewältigen. Wir würden gern monatliche Stundenkontingente buchen und einige Tätigkeiten für unsere Kunden bei dir umsetzen lassen. Durchschnittlich liegen die Kontingente im Bereich von ca. 20 Stunden.Speziell in diesem Fall sind folgende Tätigkeiten gefragt:- Experience with Looker Studio and knowledge of creating dashboards, reports, and visualizations- Familiarity with various data sources such as Google Analytics, social media platforms, CRM systems, etc. that is integrated via external software such as ""Report Dash""- OPTIMIZED: Experience with ""Report Dash""Ich freue mich auf Feedback :)",['Data Visualization'],Switzerland,7,,,"['Sales', 'Marketing']",,"['35.00', '80.00']",Remote Job,Expert
Business Analyst for a Power BI report,Looking for a Business Analyst to create Sales Pipeline report by choosing right KPIs for the sales team. Ideal candidate should be  proficient in DAX and able to create visually pleasing reports with filters and bookmarks. Please provide some examples of your past work experience in similar projects.,"['Microsoft Power BI', 'Data Visualization', 'Business Analyst']",United States,436,13.19,22,,,,Remote Job,Intermediate
Statistics,I need support for my memory thesis. I'm working on statisitcs model and i want help,"['Statistics', 'IBM SPSS', 'Data Analysis', 'Statistical Analysis', 'Statistical Analysis']",France,1,,,,,"['10.00', '30.00']",Remote Job,Entry level
CKAN Data Automation Task Development,We need the development of a small Python tasks to automate CKAN data upload of data inside Excel & CVS files. There are several files for each dataset and their resources.,"['Data Processing', 'SQL', 'Python', 'API', 'Microsoft Excel']",Turkey,2,,,"['Engineering', 'Architecture']",75.00,,Remote Job,Expert
databox Profi gesucht,"Ich schreibe im Namen der OMA AG. Wir sind eine Online-Marketing-Agentur und suchen databox-Unterstützung. Unsere KMU Kunden kommen aus über 100 Branchen, abwechslungsreiche Arbeit ist also garantiert. :) Wir decken inhouse zwar alles ab, aber unsere aktuelle Auftragslage ist für uns allein nicht zu bewältigen. Wir würden gern monatliche Stundenkontingente buchen und einige Tätigkeiten für unsere Kunden bei dir umsetzen lassen. Durchschnittlich liegen die Kontingente im Bereich von 30 Stunden.Speziell in diesem Fall sind folgende Tätigkeiten gefragt:- Integration of various data sources (Google Ads, GA4, Bing, Facebook, Snapchat, TikTok, Pinterest etc.)- Creation of custom metrics and calculated metrics according to specifications- Creation of dashboards according to specifications- Collection of campaign data depending on the data source- Creation of reports based on the dashboardsIch freue mich auf Feedback :)","['Database Architecture', 'Data Engineering', 'Data Migration', 'Data Integration', 'Databox']",Switzerland,7,,,"['Sales', 'Marketing']",,"['40.00', '80.00']",Remote Job,Expert
"""Power BI"" trainer cum developer (remote work)","""Power BI"" - Specialist needed to provide training cum development assistance 1-2 hrs daily Monday-Thursday (remotely),Below are the 4 key requirements:1. Total IT experience of a minimum 5+ yrs is a ""MUST"" with a minimum of 2-3 yrs of demonstrable experience with Power BI. Strong with DAX.2. Data Modelling skills for Datawarehouse setup is highly desired. Overall MSBI background is expected with strong practical experience in SSAS based analytics design.3.""Dynamics RLS"" setup in Power BI related experience is a must and also using SSAS based RLS experience is desired.4. Rate range 8-10$ hour. (else ignored, Ok!!) - NOTE: Lower rate is for those with no or less existing experience in upWork in the same field so pls be mindful in proposing your rate to not waste each others time, Ok!?.","['Microsoft Power BI', 'Microsoft Power BI Development', 'Microsoft Power BI Data Visualization', 'Microsoft Excel', 'MSBI', 'SQL', 'Data Modeling', 'Data Analysis', 'Data Visualization', 'Microsoft Power BI Data Visualization', 'Microsoft Excel', 'MSBI', 'SQL', 'Data Modeling', 'Data Analysis', 'Data Visualization']",Australia,976,11.69,71,,,"['8.00', '10.00']",Remote Job,Intermediate
Database Access and Information Retrieval,"This is a very specific and specialized assignment. I am looking for someone with access to pitchbook.com, or similar database. I am looking for a targeted list of Venture Capital investor email addresses, particularly firms and/or investors that have invested in electric vehicle companies. The candidate should have experience with this type of assignment and an understanding of how to navigate data to find the right point of contact at these firms. Ultimately I am looking for investors that have a history of making 7 and 8 figure investments, and have the desire and capacity to do so again.","['Microsoft Excel', 'Pitchbook', 'Venture Capital', 'Venture Capital Consulting', 'Venture Capital', 'Venture Capital Consulting']",United States,3,,,"['Media', 'Entertainment']",,"['25.00', '50.00']",Remote Job,Intermediate
Looker Studio Specialist,"I am looking for the Looker Studio Specialist who can help to connect our Google Ads, GA4 and Facebook Ads, Pinterest Ads and Klaviyo data.This position is only for expert who is willing to work in zoom call through the screensharing mode. Most of the functionality I know, but I have difficulties to combine all data in one table.For example: We have two google ads accounts and GA4, the goal to have campaigns table with Google ads and GA4 data together.Consider this position as partially tutotoring because I need to fulfil the knowledge of mission points to finish the report.Keep in mind, that we still can hire for the long term work such specialist for other projects we have.Answer screening questions so your bid offer would be considered. Thanks","['Data Visualization', 'Google Data Studio', 'Data Analysis', 'Data Analysis']",United States,400,19.49,72,"['Retail', 'Consumer Goods']",,"['10.00', '20.00']",Remote Job,Expert
ChatBot,"Recreate a ChatBot like Woebot, please let me know if interested. No things like dialogue allowed pure code only.","['Chatbot Development', 'Natural Language Processing', 'Artificial Intelligence', 'Artificial Intelligence']",United States,11,,790,,1500.00,,Remote Job,Expert
"Web scraping Amazon product page, output to Google Sheets","We want to regularly scrape a number of Amazon product pages. We are looking to extract 1) the number of ads active in the page, 2) the type of ads being displayed (Sponsored Brands, Sponsored Products, Sponsored Display - Photos and Sponsored Display - Videos) and 3) the brands behind the ads. All that information should be embedded in the HTML code of the site.I would like the output to be fed into a Google Sheet that requires this data for certain calculations.","['Data Scraping', 'Google Sheets']",United Kingdom,34,15.17,38,,,"['8.00', '100.00']",Remote Job,Intermediate
Linking two Tables in two Different Databases,Establish a connection and link two tables located in separate databases for two different applications running on the same server. This will allow the applications to share and access data seamlessly.,"['Data Integration', 'Data Transformation', 'MySQL', 'MySQL Programming', 'SQL', 'Database Administrator', 'SQL', 'Database Administrator']",Egypt,11,,374,,15.00,,Remote Job,Expert
GTM tracking expert,"I need a GTM expert for tracking conversions in Meta, Google Ads, Twitter, TikTok, and others. You must work on screen share. Access will be provided, but the work and the meetings will be recorded. the work is live while on the call. The work is specifically tracking actions and conversions.","['Google Tag Manager', 'Google Analytics']",Bulgaria,109,3.26,22,"['Sales', 'Marketing']",,"['20.00', '40.00']",Remote Job,Expert
Possion regression expert,Looking for possion regression expert who can help me to understand the model and interpret the result. Its just about 1 hour job,"['Statistics', 'Data Analysis']",Germany,13,,475,,,"['18.00', '30.00']",Remote Job,Intermediate
Predicting warehouse inventory stocks,"Forecasting system for the stocks of a store warehouse. I want to implement a warehouse (OLAP) and then run forecasting to predict future stocks for store. Example: https://towardsdatascience.com/machine-learning-for-store-demand-forecasting-and-inventory-optimization-part-1-xgboost-vs-9952d8303b48.Steps: 1. Create OLTP database of market.  2. Implement warehouse for analytical purposes.3. Data set analysis and preparation (trends, seasons, seasonal variations, correlations).4. Defining the objective: Product categories or individual products. The time horizon.5. Selection of forecasting models. (Statistics, decision trees, neural networks).6. Splitting the data set. (one part for training and one part for testing)7. Training the model.8. Making predictions. (Using available data from previous years)9. Integration into the existing system. (Development of an interface/dashboard for data visualization, interaction with the system).","['Dashboard', 'Query Development', 'Big Data', 'Python', 'Inventory Management', 'Data Analysis', 'Logistics Management', 'Warehouse Management', 'Visual Basic for Applications', 'Algorithm Development', 'Data Analysis', 'Logistics Management', 'Warehouse Management', 'Visual Basic for Applications', 'Algorithm Development']",Romania,5,,422,"['Tech', 'IT']",350.00,,Remote Job,Intermediate
AI Developer for Advertisement Data Classification Script/Bot,"We are seeking a skilled AI Developer to assist us in building a script or bot that will automate the process of classifying advertisement data. The primary objective is to accurately categorize advertisements into various predefined categories, including ecommerce, food, financial services, travel, entertainment, healthcare & pharma, and other. Additionally, the script should have the capability to filter out irrelevant ads, ensuring the accuracy and efficiency of the classification process.Responsibilities:- Collaborate with our team to understand the requirements and objectives of the advertisement data classification project.- Design and develop an AI script/bot that can process large volumes of advertisement data and classify them accurately.- Implement machine learning algorithms and natural language processing techniques to train the script/bot to recognize patterns and classify advertisements into relevant categories.- Develop filters and rules to identify and exclude irrelevant ads from the classification process.- Continuously refine and improve the accuracy and efficiency of the script/bot through iterative development and testing.- Create a user-friendly interface or provide clear instructions for using the script/bot effectively.- Collaborate with our team to integrate the script/bot into our existing system or workflow, ensuring seamless functionality.Requirements:- Proven experience as an AI Developer or similar role, with a strong background in machine learning, natural language processing, and data classification.- Proficiency in programming languages such as Python, Java, or R, along with expertise in relevant AI frameworks (e.g., TensorFlow, PyTorch, scikit-learn). Also welcome: NodeJS- Includes the word blueberry in the first sentence or beginning of their proposal.- Experience in developing and training machine learning models for text classification tasks.- Familiarity with data preprocessing techniques, feature engineering, and model evaluation methods.- Strong analytical and problem-solving skills to address challenges related to advertisement data classification.- Excellent communication and collaboration abilities to work effectively with our team and provide regular updates on the project's progress.Nice to Have:- Previous experience in developing AI scripts/bots specifically for advertisement data classification.- Knowledge of web scraping techniques to gather advertisement data from various sources.- Understanding of cloud platforms (e.g., AWS, Google Cloud) for scalable and efficient deployment of the script/bot.- Experience in working with large datasets and handling data privacy and security concerns.","['Bag of Words', 'Machine Learning', 'Natural Language Processing', 'Artificial Intelligence', 'Artificial Intelligence']",China,16,8.67,7.5,"['Tech', 'IT']",,,Remote Job,Expert
Full Stack Developer,"Hello!ResponsibilitiesCollaborate with the development team to design, develop, and maintain software applicationsImplement front-end interfaces using HTML, CSS, and JavaScript frameworksDevelop server-side logic and APIs using programming languages such as Python, Java, or Node.jsDesign and maintain databases and perform database queries for data retrieval and manipulationWrite clean, modular, and efficient code for both front-end and back-end componentsParticipate in code reviews and provide constructive feedbackTroubleshoot and debug issues to ensure optimal performance and user experienceStay up-to-date with emerging technologies and industry trendsCommunicate effectively with team members to ensure successful project completionRequirementsBachelor's degree in Computer Science, Software Engineering, or a related field (or equivalent experience)Strong understanding of software development fundamentalsProficiency in front-end technologies such as HTML5, CSS3, and JavaScript frameworks (React, Angular, or Vue.js)Familiarity with server-side programming languages (Python, Java, Node.js, etc.)Experience with databases and SQLUnderstanding of RESTful APIs and web servicesExperience with version control systems (e.g., Git)Good problem-solving and analytical skillsExcellent communication and teamwork abilitiesPreferred QualificationsFamiliarity with back-end frameworks (Django, Spring, Express, etc.)Knowledge of NoSQL databases (MongoDB, Firebase, etc.)Understanding of web security best practicesFamiliarity with cloud platforms (AWS, Azure, Google Cloud)Experience with testing frameworks (Jest, JUnit, etc.)Projects or personal portfolio showcasing your full stack development skills","['JavaScript', 'API Integration', 'Web Development', 'Node.js', 'PHP', 'AngularJS', 'React', 'jQuery', 'Bootstrap', 'CSS', 'Web Development', 'Node.js', 'PHP', 'AngularJS', 'React', 'jQuery', 'Bootstrap', 'CSS']",United Kingdom,1,,,"['Engineering', 'Architecture']",,"['20.00', '42.00']",Remote Job,Intermediate
Create a tuned generative AI model to produce content in the style of a certain individual,"I want to build a generative AI model that produces content in the style of an individual person. This person write blogs and social media content in a unique way, as a fun experiment, I want to create a tool that generates content in his style.It can be using a specific, premade tool or a tuned OpenAI model. I can provide the raw training data.Please start your proposal with GAI so I know you have read the brief. Thanks :)","['ChatGPT', 'AI Chatbot', 'AI Content Creation', 'Machine Learning']",United Kingdom,119,8.26,149,,,"['15.00', '25.00']",Remote Job,Entry level
Data analysis,"We are looking for a skilled data analyst to assist us with a short-term project. The ideal candidate should have experience in data analysis, data science, and proficiency in Python. The project involves analyzing large sets of data and presenting meaningful insights that will help us make informed business decisions.As a candidate, please submit a proposal that outlines how you can help with this project. We are looking for someone who can take ownership of the project, work independently, and deliver quality results within the given timeframe.Please include links to some of your past completed projects that demonstrate your skills in data analysis. We value attention to detail, excellent communication skills, and the ability to work collaboratively with our team.If you have any questions about the project or require additional information, please do not hesitate to ask. We look forward to reviewing your proposal and working with you to achieve our project goals.","['Data Analysis', 'Data Science', 'Python', 'Python']",Malaysia,4,,170,,20.00,,Remote Job,Intermediate
Unreal Developer Eye Tracking and Biometric Data Mapping,"Job Description:We are seeking an experienced Unreal Engine Developer with expertise in OpenXR and biometric data from the Omnicept runtime to create a cutting-edge virtual reality (VR) behavioural analysis tool. The purpose of this tool is to map and analyse eye tracking and additional sensor data within a 3D environment. The VR tool will need to be compatible with the Meta Quest Pro and/or HP Reverb G2 Omnicept Edition headsets please do research on both and propose the best most versatile solution to our analytical needs. It will need to collect and map the following data types:- Eye Tracking ( Omnicept and/or Meta Quest Pro) - Face tracking ( Omnicept and/or Meta Quest Pro)- Heart Rate (Omnicept)- Heart Rate Variability (Omnicept)- Camera Image ( Omnicept and/or Meta Quest Pro) - Cognitive Load (omnicept) The tool will need to leverage the sensors available on these headsets to provide an in-depth analysis of a user's experience and behaviour both individually and in aggregate.The final solution should be capable of mapping this data to a 3D model or videos captured from the model at set time intervals for later analysis. However, this data should not be visible to the user during the VR experience. We are aiming for a tool that can help us understand exactly how a person feels about a given product or experience.Key features required include:- All these environments will be on PCVR Unreal Engine applications not standalone android applications - Capability to record and replay any data, with a particular focus on eye-tracking signals, mapped to the 3d environment and/or user view video.- Collect and process additional biometric data: In addition to eye tracking, the system should gather data from other sensors on the VR headsets, including heart rate, heart rate variability, face tracking, camera images, and cognitive load.- Data analysis and visualization: Using the collected data, the system should provide comprehensive and insightful analysis. This includes creating heatmaps, tracking user positions and movements, analysing object engagement, and other similar metrics.- Customizable parameters: The system should be flexible enough to allow us to register any event that is relevant to our needs and customize the dashboard to view the data in the way we want.- A robust and flexible data structure optimized for speed and file size to uphold data integrity that can be analysed individually and in aggregate. - Implement user behaviour analysis tools: The system should be able to provide insight into user behaviour. This will involve combining various types of data, such as eye tracking data and other sensor readings.- The tool should be able to be applied using Blueprints or a custom SDK to additional VR environments in the future and should be a framework for future environments. The successful applicant will have a proven track record in Unreal Engine development, specifically with VR applications, and a strong understanding of OpenXR, Omnicept and data science. Experience in creating tools for user experience analysis or similar will be highly regarded.Skills that will help - Experience with Unreal Blueprints and SDKs- Experience with Meta quest Pro  - Experience with HP Omnicept Headset - Experience or understanding of Omnicept runtime or Tobii- Experience and understanding of openXR toolkit - Understanding of Biometrics and/or behavioural analysis research- Experience with Heatmaps and mapping to 3d environments - Data scienceIn the attached document you will find a list of links to comparable solutions as well as list of links to resources and SDKs/ Blueprints that can be useful in developing this solution. Please include samples of your previous work that might be relevant and details of your experience in your application.Looking forward to your applications!","['Unreal Engine', 'openxr', 'Applied Behavior Analysis', 'eye tracking', 'blueprints', 'omnicept', 'quest pro', '3d mapping', 'heatmaps', 'eye tracking', 'blueprints', 'omnicept', 'quest pro', '3d mapping', 'heatmaps']",United Arab Emirates,5,,175,"['Tech', 'IT']",,"['20.00', '85.00']",Remote Job,Expert
Data Analysis for Optimization,Help understanding data statistics of our traffic to help us guide direction towards the identification of areas of improvement,"['Dashboard', 'Report', 'Business Intelligence', 'Data Interpretation', 'BigQuery', 'Data Analysis', 'Statistics', 'Data Science', 'Quantitative Analysis', 'Analytics', 'Data Science', 'Quantitative Analysis', 'Analytics']",United States,2,,,,,"['18.00', '30.00']",Remote Job,Intermediate
Deep Learning / AI Officer for two projects,"We looking for a consultant / executer on AI / Mashine learning to work with our developers to set up the best future proof setting for our projects.a) a factoring marketplace. Refining the algorithm based on delay / default rates with most widest data input for correlationb) Develop fraud protection algorithm c) a Health Tech Plattform which analysis blood work and proteomics vs APIs from movement Data / qualitatsive input of user, etc. - to identify patterns","['Data Science', 'Data Science Consultation', 'Model Tuning', 'Artificial Intelligence', 'Machine Learning', 'Machine Learning']",Germany,23,36.61,10,"['Finance', 'Accounting']",,"['30.00', '70.00']",Remote Job,Expert
Data Science experts for editing blog articles,"We are seeking Data Science experts who can edit multiple educational articles about Data Science generated by an AI tool. The editing work will involve ensuring factual accuracy, verifying data correctness, and refining the use of professional terms.Please note that the edited articles will be published on the Pythia project blog, and they will be attributed to the name of the expert. This should be considered when responding to the task.We provide an example text for editing: https://docs.google.com/document/d/15rzjNLWAxRxsZ4jWQjLoYhhJiiPiGYqN/edit?usp=sharing&ouid=106669673054673891765&rtpof=true&sd=true The cost of the work will be discussed individually with each expert.About the project: Pythia helps marketing managers and founders of startups automate tedious or bothersome tasks by matching professionals with existing IT programs or guiding them on how to build their own.If you are a Data Science expert with a passion for refining educational content, we would love to invite you to join this task!","['Data Science', 'Data Science Consultation', 'Machine Learning', 'English', 'Article Writing', 'Content Writing', 'Content Writing']",United States,4,,,"['Tech', 'IT']",,,Remote Job,Intermediate
socialbug AFFILIATE MLM / PARTY PLAN,"We are looking for a skilled individual EXPERT LEVEL with socialbug who can assist us with our socialbug affiliate MLM/party plan project for a period of 3 to 6 months. The ideal candidate should be proficient in Python and WordPress, with prior experience in the MLM industry.The project requires the development of an affiliate marketing program, as well as a party plan program. The candidate will be responsible for creating and implementing a system that will allow users to sign up and participate in the affiliate program, as well as track their progress and earnings. They will also need to create a party plan program that will allow users to host parties and earn rewards based on their sales.The candidate should have a strong understanding of MLM marketing strategies and be able to apply this knowledge to the project. Additionally, experience with null and mlm will be beneficial.To be considered for the job, please submit a proposal outlining your experience and how you can contribute to the project. Please include links to past completed projects that demonstrate your skills in Python and WordPress, as well as your experience in the MLM industry.Note: Some of the content in this job post may have been auto-generated using advanced AI.","['Python', 'WordPress', 'mlm']",United States,380,6.64,4.1,"['Finance', 'Accounting']",500.00,,Remote Job,Expert
Digital & Data Technologist,"Please note:The role is hybrid, means remote but also partly on site MunichKnowing German is a mustThe Primary Activities are· Lead the overall data mangement in terms integration, architecture and quality· Understand and clarify business requirements that drive the analysis and design of quality technical solutions.· Design and evolve a German data market extensions to enable data visualization, data science and ad-hoc analysis· Collaborate close with local and regional Qlik Sense dashboard development team to find the optimal solution in regards to data transformation and dashboard performance· Manage the data warehouse development backlog and lead external developers working it· Design and implement data quality management solutions in strong alignment with global capabilities and standards· Support Digital, Data & Analytics Governance· Support compliance with our Company’s cyber security standards and Software Development Lifecycle management methodology, as well as architectural standards.· Provide support to existing and future IT and data platforms and deployment of integrated solutions.· Ability to learn market-specific regulatory and compliance needs relevant to digital capabilities in the pharmaceutical industry.· Keep up market trends and new use cases for design, data models, and analytics and suggests evolution of the architecture.· You work closely with the regional and global Digital Technologist community, and contribute to platform solution working with cross regional teams (IT Tech centers)· Take on above market responsibilities contributing to the evolution of the regional Human Health Inside Engine.Ideal Skillset and Experience· Bachelor’s degree in Information Technology, Science or Business is required.· Good understanding of Agile and Scrum methodologies, ideally experience working with and setting up JIRA and Confluence.· 10+ years of experience in IT technical analysis, data warehouse and interface development and testing.· Extensive experience with AWS Cloud technologies, specifically experience with Redshift· Advanced knowledge of Postgre(s) SQL or alternatively PL/SQL.· Deep understanding of data modelling and preparation of optimal data structures for both· reporting layers and data warehouses.· Understanding of various commercial business processes including sales force effectiveness, compliance, multi-channel marketing, master data, contracting, and digital health solutions,· Strategic thinking and Ability to prioritize, align and simplify· Experience with Visualisation tools such as Qlik Sense· Knowing German is must. Business fluency in English (C1/C2).· Motivated team player with excellent interpersonal skills· We are looking for a quick learner who is passionate about technology and flexible to manage multiple tasks simultaneously.· Ability to navigate matrix organizations and comfortable to deal with ambiguity and adapt to changes for continuous improvement of IT Products.· Ability to quickly develop effective trust-based relationships, working closely with cross functional stakeholders across the business to influence outcomes without formal authority.· Highly developed communication skills.It would be great if you have expertise on the below products and technologies· Veeva CRM· Salesforce Marketing Cloud· Pharmacytical data providers e.g. IQVIA Sales· Google Analytics","['SQL', 'Qlik Sense', 'Google Analytics', 'Salesforce Marketing Cloud', 'AWS Cloud9', 'AWS Cloud9']",Austria,91,,,"['Supply Chain', 'Logistics']",,"['40.00', '75.00']",Remote Job,Expert
Networkx python data visualization animation,I have an algorithm that iteratively constructs a mathematical graph using the Python networkx library. I can visualize the final product in either plotly or matplotlib but I want to make a beautiful animation/video of the graph being iteratively constructed.,"['Python', 'Data Visualization', 'Matplotlib', 'Matplotlib']",United States,9,,2.4,,100.00,,Remote Job,Intermediate
Pandas Expert Needed to Transform JSON dictionary,"Currently I'm pulling data from my PostgreSQL database that contains json dictionaries. At the end of the file you can find these nested dictionaries that basically need to be formatted so that they become readable and usable for analysis. I""m happy to share my python script if you are an expert in Python and data extration please let me know. This should be a quick fix for an expertMany thanks","['Python', 'pandas']",United Kingdom,2,30.00,0,"['Finance', 'Accounting']",,,Remote Job,Expert
Google analytics (universal analytics) migration to GA4 needed,Looking for an expert to migrate 2 projects from GA UA to GA4 version.ASAP!For 1 project we need to make an audit of existing GA4 setup and make a report for that.For another project we need to make a setup from scratch.Ecommerce related projects.,"['Google Analytics', 'Google Tag Manager', 'Google Analytics Report', 'Analytics', 'Google Ads', 'JavaScript', 'Google Analytics Report', 'Analytics', 'Google Ads', 'JavaScript']",Cyprus,6,15.00,769,"['Media', 'Entertainment']",,"['15.00', '35.00']",Remote Job,Expert
Expert to help for automation and optimization of sales data into a dashboard,"For the sales team we need:Visibility into the closing rate per closerVisibility into the no-show rate per closerClear visibility for closers regarding their commissionAutomation of information in a sheet instead of manual entry, with a focus on speed and time efficiencyA main dashboard as the starting page of the sheet, displaying the collective resultsthe data separate from each sales person must be automatically integrated in its own sheet in the same file as the main dashboard where the data of all sales is displayed together Important Information:Closers receive their commission based on cash collected. The closers their commission must be shown in 1 month instalmentsAppointments are scheduled using Calendly.The CRM system used is Trello.It is crucial that information from Calendly can be seamlessly integrated into Google sheet.Also we want a automated connection between for Calendly and Trello systems to work together.The systeem needs to automatically update with new appointments, eliminating all manual entry","['Google Sheets', 'Trello', 'calendly', 'Data Analysis', 'Data Integration', 'Data Analysis', 'Data Integration']",Netherlands,1,,,,,,Remote Job,Intermediate
AI/Machine Learning Specialist for Shopify App Development Project,"Hello there, fellow innovator!We're a passionate team working on a Shopify app called OneClickSell, an application that empowers online businesses by offering advanced upselling, downselling, and post-checkout order bump opportunities.While we're pretty stoked about what we've built so far, we've got our sights set on the next level. We're planning to integrate AI and Machine Learning capabilities into our app to give it a competitive edge. And we're looking for someone like you - a genius in the realm of AI - to help us make that leap!Here's what we're imagining:AI-Optimized Sales Funnel Recommendations: With your AI mastery, we're hoping to create an algorithm that can analyze a store's sales data, customer behavior, and more to generate personalized recommendations on how to improve their sales funnel.Intelligent Product Bundling: We'd like to build an AI that can identify potential product combinations that would make killer bundles.Personalized Upsells/Downsells and Post-Checkout Order Bumps: The goal here is to use AI to tailor upsell/downsell offers and post-checkout order bumps based on each customer's purchase history and behavior.AI-Powered A/B Testing: We're hoping to automate the process of A/B testing different strategies, with an AI that can both set up and analyze the results.Predictive Analytics and Forecasting: Another interesting challenge is to create an algorithm that can forecast future sales performance based on current trends.Customer Churn Prediction: Let's build a system that identifies at-risk customers before they even know it themselves!Continuous Learning System: And finally, we want to make our AI smarter over time. We want it to learn from new sales data and customer behavior to ensure it continues to deliver value to our customers.Does this sound like something you'd love to work on? We're hoping it does!Here's what we're looking for in our ideal candidate:Extensive experience with AI/Machine Learning. (especially in a marketing/sales context)Proven track record with data analytics and predictive modeling.Experience with Shopify app development would be a bonus!If you're passionate about leveraging AI to empower businesses, thrive in a collaborative environment, and are ready to hit the ground running, we'd love to hear from you. Let's transform the e-commerce landscape together!Shoot us a proposal if you're interested, and let's start this exciting journey together!","['Python', 'Artificial Intelligence', 'Machine Learning', 'JavaScript', 'TensorFlow', 'Data Science', 'Web Development', 'Data Analysis', 'Graphic Design', 'HTML5', 'Machine Learning', 'JavaScript', 'TensorFlow', 'Data Science', 'Web Development', 'Data Analysis', 'Graphic Design', 'HTML5']",United States,352,32.12,1.2,"['Tech', 'IT']",,"['40.00', '70.00']",Remote Job,Expert
Tableau Desktop version upgrade,"I'm looking for the Tableau specialist who can plan, lead and upgrade Tableau Desktop version. The current Tableau Desktop version is 2020.3. We would like to upgrade to the latest available 2023.1.","['Tableau', 'SQL', 'Tableau server', 'Amazon Redshift', 'Amazon Redshift']",United Kingdom,5,,,"['Sales', 'Marketing']",,,Remote Job,Expert
Muhammad Ahmad R.,"I am writing on behalf of a company that is dedicated to accelerate R&D process for Pharma, Biotech, Chemical, Cosmetic and Nutraceutical companies minimizing risks through zebrafish services, adding value to clients R&D&i mainly in preclinical area. This company also develops and validates cost-effective Toxicity and Efficacy Assays.We need to write articles that contain approximately 1.000 words in english, focused on SEO, with a good scientific component and that are similar to these posts that I send you below:https://blog.biobide.com/oecd-guidelines-for-chronic-toxicity-studieshttps://www.zeclinics.com/blog/crispr-the-genetic-scissors/https://daniolab.com/five-best-management-practices-for-zebrafish-rooms/We would initially need 12 articles, 2/3 per month. Do you see it possible? If so, I would appreciate it if you could explain to us how we would work.I’ll be waiting for your response, thank you in advanceNaiara.","['Writing', 'Article Writing', 'SEO Content', 'English', 'Science', 'SEO Content', 'English', 'Science']",Spain,1,,,,,,Remote Job,Expert
Build a custom Google Data Studio reporting system,"The ultimate goal is to create data visualization of an entire marketing funnel.Our funnels are driven by FB and Google. Leads are automatically pushed into our CRM (Go High Level). Leads are then manually moved through the pipeline by appointment setters. Currently we have set up a UTM structure so we can track the source of each lead. We want to be able to quickly track the outcomes of different ads. For example filter by channel (Google or FB), filter by group (Ad Set or Keyword), and maybe even filter by individual ads....And once that filter is selected we can see:-Cost per Lead-Conversion Rate-Schedule Rate-ECTWe have already attempted to build this but ran into a skill gap internally and are looking for some expert help to either find a fix for our solution or offer an alternative. I believe tools like 'Super Metrics' can achieve this but the price point per account is not scalable for us. we would like to get 50+ clients on this eventually. Overview:https://www.loom.com/share/a66dcaf571224c0c9669dcb63e450eadI can provide any of the documents or logins as needed. thanks.","['Google Data Studio', 'API', 'Data Visualization', 'Data Analysis', 'Google Sheets', 'Zapier', 'HighLevel', 'Data Visualization', 'Data Analysis', 'Google Sheets', 'Zapier', 'HighLevel']",,1,,,,,"['60.00', '150.00']",Remote Job,Expert
MFA for Tableau Server,"As a part of Cyber security Essential Certification, we should setup Two-Factor Authentication to the Tableau Server. In the company we are use Microsoft Authentication.We are searching for the solution to setup MFA without the migration to the Tableau Cloud. We are open for the propositions.","['Tableau Server', 'MFA', 'AWS Cognito', 'Business Intelligence', 'Python', 'Microsoft Authentication', 'Business Intelligence', 'Python', 'Microsoft Authentication']",United Kingdom,5,,,"['Sales', 'Marketing']",,,Remote Job,Expert
Create river connection to Rivery itself,"I'm looking for a freelancer who knows how to work in Rivery. We want to create a river to the Rivery itself (https://api-docs.rivery.io/). We would like to load data to the Redshift about all the rivers in the development and production environments. We would like to have information about their schedules, status, RPU, target table name, etc. Data will be used to increase visibility of the Rivery account.","['ETL Pipeline', 'rivery', 'Data Processing']",United Kingdom,5,,,"['Sales', 'Marketing']",,,Remote Job,Expert
Data Engineer/Python developer,"We are looking for savvy Data Engineers to join our growing team. The ideal candidate is1. self-directed, proactive, and comfortable building complex data pipelines2. Have strong Python programming skills3. Have hands-on experience with SQL database design.4. Good exposure to working on ETL (Extract, transform, load) framework and API Pipelines.5. Have Implemented and Architected solutions on Google Cloud Platform using the components of GCP6. Is well versed with how to use Google BigQuery.","['Data Engineering', 'Python', 'ETL Pipeline', 'API', 'SQL', 'Python Script', 'RESTful API', 'SQL', 'Python Script', 'RESTful API']",India,60,10.67,41,"['Engineering', 'Architecture']",,"['15.00', '25.00']",Remote Job,Expert
Power bi map bubbles,I already have dashboard on power bi i have map with bubbles and filter by year i want you to show me solution when i click per exemole on year2020 all the bubbles keep showing regaldess the year i mean also the unflitred bubbles keep showing in red color and the filtred color keep showing in red color you will give the solution on team viewer,"['Microsoft Power BI', 'Data Visualization', 'Business Intelligence', 'Microsoft Power BI Data Visualization', 'Business Intelligence', 'Microsoft Power BI Data Visualization']",Tunisia,2,,,,10.00,,Remote Job,Entry level
Google Analytics and Google Tag Manager Expert for Website GA4 Migration Project,"We are seeking a highly skilled professional to join our team for a project involving the migration of our clients websites (B2B & B2C) to Google Analytics 4 (GA4) and troubleshooting issues related to Gtag event setup. The ideal candidate will possess extensive experience and expertise in Google Analytics and Google Tag Manager, enabling them to provide exceptional support and guidance throughout the project. The expected duration of the project is 1-3 months.Key Responsibilities:Troubleshoot Gtag event setup: Our previous expansion of event tracking in Universal Analytics (UA) resulted in significant issues. We require an expert in Gtag event tracking setup who can thoroughly investigate and resolve any issues.Migrate old UA data to GA4: We have already initiated the process of migrating our clients data to GA4; however, our Gtag events are not properly reporting. The successful candidate will be responsible for identifying the most suitable migration strategy for our websites and implementing the necessary tracking codes to ensure accurate data collection in GA4.Essential Qualifications and Skills:Extensive experience in Google Analytics and Google Tag Manager for B2B and B2C (ecommerce) GA4 Migration, including advanced knowledge of data layers & event tracking setup.Proven ability to troubleshoot and resolve issues related to Gtag event tracking.Strong understanding of website analytics and data migration principles.Excellent communication skills and the ability to collaborate effectively with our team to fulfill project requirements.Application Instructions:To be considered for this position, please submit a detailed proposal outlining your relevant experience and approach to completing this project. Additionally, we kindly request that you provide links to any completed projects that demonstrate your expertise in Google Analytics and Google Tag Manager.We eagerly await your application and look forward to working with a qualified professional to achieve a successful website migration to GA4 while ensuring accurate data analysis.","['Google Analytics', 'Google Tag Manager', 'Analytics', 'Analytics']",India,1,,,,,,Remote Job,Intermediate
Data Scraping and Lead Generation Expert,"We are seeking a skilled freelancer to assist our company with data scraping and lead generation tasks. As we expand our business and explore new opportunities, we need accurate and reliable data to drive our growth strategies. This is a remote freelance position with flexible hours and the potential for long-term collaboration.","['Data Scraping', 'Data Mining', 'Lead Generation']",United Arab Emirates,7,,,"['Finance', 'Accounting']",,"['3.00', '5.00']",Remote Job,Intermediate
Database Developer & Site Maintenance Engineer,"About Comms8:Comms8 is a full-service marketing agency specialising in cross-cultural marketing solutions, bridging the gap between the UK and Chinese markets. With a strong focus on creativity, innovation, and data-driven strategies, we are committed to helping our clients succeed in today's ever-changing global landscape. We pride ourselves on our dedication to understanding different cultures and delivering tailored marketing solutions that resonate with diverse audiences.The Opportunity:The Database Developer & Site Maintenance Engineer will be responsible for the development, integration, and maintenance of our various databases and online platforms. This role involves working with a vast amount of data from different sources, maintaining the integrity and performance of our databases, and ensuring all aspects of our platforms remain functional and user-friendly.Key Responsibilities:•	Developing, managing, and testing back-end database systems to improve our client's user experience.•	Integrating databases from various sources to create a robust, cohesive data environment.•	Building and maintaining SaaS platforms to facilitate data accessibility and usage.•	Monitoring and improving system performance, including optimizing and tuning for performance.•	Regular maintenance and updates of our website and other online platforms to ensure optimal performance and UX/UI.•	Assisting in troubleshooting and resolving database problems.•	Working closely with the development team to design and implement data strategies, build data flows and develop conceptual data models.•	Creating and managing data reports, tools, and dashboards.•	Ensuring the security and integrity of our database systems.Candidate Requirements:•	A degree in Computer Science, Information Technology, or a related field.•	Proven work experience as a Database Developer or a similar role.•	Familiarity with modern database technologies and SaaS platform development.•	A strong understanding of SQL or other database languages.•	Proficiency in UX/UI design principles and website maintenance.•	Excellent problem-solving and analytical skills.•	Strong communication skills to effectively collaborate with team members.•	A keen eye for detail and a commitment to excellence.•	Familiarity with data privacy regulations and best practices.","['Database Maintenance', 'SaaS', 'UX & UI']",United Kingdom,5,,,,,,Remote Job,Expert
Setting up GA4 and Lead Gen tracking for Google Ads,"I have a new client and we need to set up some easy tracking - we are going to work on Google search for generating leads for consultations. Basically, what I need is:- creating conversions/events inside the ads account (leads are looking like this- booking an online consultation - this is the main goal; phone call and contact via email)- connecting ads account with GTM and making proper tags- making sure that G-ads are following lead gen event- setting up basic GA4","['Google Analytics', 'Google Tag Manager']",Serbia,3,,140,,50.00,,Remote Job,Intermediate
Conversational AI Developer with Webhook Integration Experience,"Seeking a Conversational AI Developer with expertise in integrating webhooks and AI models. The project involves developing a chatbot, setting up webhook integrations, and seamlessly integrating an AI model like ChatGPT. Clear expectations and deliverables will be provided.Skills Required:Conversational AI developmentWebhook integrationAI model integration (e.g., ChatGPT)Backend developmentNLP knowledgeStrong problem-solving skillsGood Communication:Effective communication is essential for clear requirements understanding, progress updates, and addressing any project-related queries. Prompt and open communication is highly valued.Work Preferences: Regular updates, progress reports, and a willingness to incorporate feedback are important for successful project completion.","['Machine Learning', 'Natural Language Processing (NLP)', 'Backend Development', 'Conversational AI Development', 'Webhook Integratio', 'API', 'Backend Development', 'Conversational AI Development', 'Webhook Integratio', 'API']",United Arab Emirates,2,,,"['Health', 'Fitness']",1000.00,,Remote Job,Expert
Data Science PPT Content Creator,"We need a Data Science Expert who can create PPT Slides within a reasonable timeframe of 30 days and at reasonable price point. The ideal profile of this type of SME would be a Data Scientist having 10 years of experience in the IT domain and at least 6+ years of hands-on experience in the field.Workscope: PPT Slides creation.Closure Steps:Here are the next stages of the process:1. If you are interested, please, share your latest resume for us to put through our Editorial Board for approval.2. Once approved, we will schedule a quick 15 mints call on Upwork and finalize on the schedule and compensation. We will then have a final call with the content team to ensure that the scope of work is clear.That's it. Once the above 2 steps are done and approved by our Editorial Board, we will quickly move to the contracting stage on Upwork and start with the project.","['Data Science', 'Presentation Slide']",India,197,575.00,58,,800.00,,Remote Job,Expert
Chatbot developer,"Prove your skills.Please bid if you can modify this code to make it work.Please attach the modified code and execution process.If you can do the work above, you will have time to work with talented developers.If you have read this far, please use 'chat' as the password.","['Chatbot Development', 'Bot Development', 'API', 'Artificial Intelligence', 'Natural Language Processing', 'Chat & Messaging Software', 'JavaScript', 'API', 'Artificial Intelligence', 'Natural Language Processing', 'Chat & Messaging Software', 'JavaScript']",United States,3,,,,,"['40.00', '70.00']",Remote Job,Expert
Data analyst and research assistance,"Please read carefully the project description:We are a data provider company. At the moment, we are searching for new data sources, in order to improve our capabilities. More details will be provided in pm.We are looking for an expert, who can help to improve our data basis. The task includes research of new data sources, setting up workflows for including those data sources within our business, finding new data providers.The expert must have in-depth understanding how data mining, enrichment and analysis works. All in all, it is an interesting and non-trivial task.This job ISN'T about data scrapping or manual data input!","['Marketing Analytics', 'Product Analytics', 'Operations Analytics', 'Report', 'Business Intelligence', 'Data Analytics', 'Data Interpretation', 'Big Data', 'Data Analysis', 'Market Research']",Switzerland,33,12.76,11,"['Sales', 'Marketing']",,"['40.00', '75.00']",Remote Job,Expert
Reorganisation/Split of a MATLAB Project,"Looking for an experienced MATLAB professional. You will work in collabaration with a engineer along the project. This first milestone is one stage in a project. Experience of porting MATLAB to cloud and C++ is a plus for the following stages.We currently have a project running completely on MATLAB, in the development phase, with different types of algorithms implemented, data acquisition via USB devices or via UDP/TCP and computing ressources. The scope is to reorganise/split the current project to make it more modular, build its architecture, and separate it into several blocks (GUI part, computing, data acquisition, to define).We also want to analyse the system's performance by setting up a profiler for various measurements.Expected duration of the project is 40 hours. To be considered for this project, please submit a proposal outlining your experience with reorganizing/splitting the Matlab project.We'll be happy to discuss our project in more detail and provide you with the scopes and terms of our project.","['C++', 'C', 'Algorithm Development', 'MATLAB', 'MATLAB Script', 'Architectural Design']",Switzerland,5,4.50,381,,,"['20.00', '50.00']",Remote Job,Expert
Power Bi developers,We need a resource who can understand the need related to the job & deliver the same on time,"['Microsoft Power BI', 'Data Analysis', 'Microsoft Power BI Development', 'Data Visualization', 'Business Intelligence', 'Data Modeling', 'Python', 'ETL', 'Data Mining', 'Data Science', 'Microsoft Power BI Development', 'Data Visualization', 'Business Intelligence', 'Data Modeling', 'Python', 'ETL', 'Data Mining', 'Data Science']",India,1,,,,,"['20.00', '50.00']",Remote Job,Intermediate
Data-Intensive Edge-Computing: Computation offloading for object detection service,"The goal of the assignment is to develop a data processing application using Docker, Python, and TensorFlow and understand the mechanisms behind computation and data offloading. The assignment will be deployed and tested via AWS, utilizing its cloud infrastructure for seamless scalability and efficient computation. The assignment consists of four parts:1.Implementation of data processing application:The application should be implemented inside the detection_loop function of the app.py provided in the attached .zip archive. Students should develop one application with the following functionality: Object detection: the application takes as input an image and returns the objects that have been detected on the image. It should also work for multiple images. Images are sent to theapplication via Post request as an array of base64 encoded Strings. Results should be returned as JSON Response.The dataset with images datasets is provided. As a reference for theirimplementation, students can use official TensorFlow documentation. More precisely, Object detection: https://www.tensorflow.org/hub/tutorials/object_detectionThe application should be at least commented on the main parts. We want to be sure that you understand what you are doing.2. Dockerization of application:The developed application should be dockerized, i.e., deployed inside a Docker container. Students are encouraged to use the Dockerfile attached, which sets up the basic service needed for the execution of Docker. Please note that you might need to include more Python packages according to the design of your implementation. To add new packages, it is recommended to add them in the requirements.txt file.Additional resources can be found in the official Docker documentation.3. Local and remote execution:Once you deploy your container with your application running, execute your application on the provided datasets and collect data about the average inference time of your implementation. By Inference time, we mean the time it takes for the application to perform the required object recognition. If not already provided by TensorFlow methods, you can obtain this value for a single image by using additional Python modules, i.e., time or time it. The average should be calculated onthe whole images on the provided datasets.-Local execution:Local execution can be done with docker clients for the operation system of your choice. A Docker container must be built and afterward can be started. As it is required to send images to Dockercontainer via Post request, you either prepare a client script or use any other tool which allows you to send multiple images to your Docker container. Images should be sent as Base64 encoded Strings toavoid any problems and can be decoded according to your needs on the server.-Remote ExecutionFor remote execution, the containerized app should be deployed on Amazon Web Services. Once it is deployed, you should collect data about (1)4. Report:Students are expected to provide a report on the developed application and on local and remote execution. Produce a report.pdf that contains a detailed report including at least five sections, 1. Introduction, 2. Problem Overview, 3. Methodology and Approach, 4. Results, and 5. Conclusions.The Methodology and Approach section should have an architecture diagram explaining your offloading solution, including a short description of how your setup on AWS was built. Results should comment on these data, i.e., explaining whether it is worth offloading data to the remote AWS or not and in which conditions it makes sense to execute locally or to offload. The conclusion should be supported by the data you collected. The overall report should not exceed more than 8 pages (A4 size).-EvaluationEvaluation will be mainly performed based on the quality of the provided report. The report should contain the following:1. Information on how the application has been developed, explaining the most important design choices and any modification to the Docker file or requirements.txt needed to make your implementation work.2. Commands needed to deploy your container.3. Explanation of how you calculate inference and transfer time.4. Information on your experimental setup. i.e., CPU power, network bandwidth, and any additional hardware (GPU) that you use to run your experiments.5. Data about local/remote inference time and transfer time.6. Comments on your execution: is it worth offloading execution on the remote cluster? If not, why? What would be needed to improve the performance of remote and local execution? Can you think of a scenario where offloading improves performance?If someone solves the assignment objectives using elastic services other than EC2. For instance, ECR+ Lambda services for remote execution. Deadline: 25.6.2023.","['Python', 'TensorFlow', 'Data Science', 'Docker', 'offloading', 'data-offloading', 'Docker', 'offloading', 'data-offloading']",Austria,6,,401,,250.00,,Remote Job,Intermediate
Research project data modelling needed PLS-SEM,"Hello, I need help for a research project for analysing the data in SPSS or Excel and creating a model with Smart PLS-SEM for the different research topics Example attached. Preferably people who recently developed a research project or master/doctorate thesis","['Data Analysis', 'PLS-SEM', 'Smart PLS', 'Quantitative Analysis', 'Statistics', 'Quantitative Analysis', 'Statistics']",Spain,1,,,"['Sales', 'Marketing']",100.00,,Remote Job,Intermediate
Cohort analysis in Power BI,"We have deals from CRM, and we need to see weekly cohorts, what is the conversion of cohorts from sales calls scheduled to calls conducted from a certain period.","['Data Analysis', 'Data Visualization', 'Microsoft Power BI', 'Business Intelligence', 'Microsoft Power BI', 'Business Intelligence']",Serbia,1,,,,,"['18.00', '30.00']",Remote Job,Intermediate
GA4 expert for Shopify / GTM setup,Need an expert to review our current GA4 setup with our Shopify store and GTM. Setup is done but still showing large discrepencies in data vs UA and a few issues that need to be sorted out (e.g. product coupon code being confused with order coupon in reports). Need it setup properly in time before forced migration.,"['Data Analytics', 'Google Tag Manager', 'Google Analytics', 'Shopify', 'Shopify']",France,23,15.00,6.5,,,"['40.00', '150.00']",Remote Job,Expert
Migration of GA to GA4,"Hello, I'm looking for someone to migrate Google analytics to the g4 version as requested by Google. Thank you! My site: www.marilynheraud.com a 9 pages built in html/css.","['Google Analytics', 'Google Tag Manager', 'Web Development', 'Web Development']",Canada,1073,2.66,54,"['HR', 'Business Services']",10.00,,Remote Job,Expert
Fullstack/Drupal Developer (Only EU Based),"We are seeking an experienced Drupal Developer based in EU to join our client’s team. The successful candidate will play a key role in developing our client’s platform.Mandatory: At least two years of specific expertise in Drupal 9 (min. competence level [4].Responsibilities:Development of front-end website architecture.Design of user interactions on web pages.Development of back-end website applications.Implement core business logic.Creation of servers and databases for functionality.Understanding and implementation of security and data protection.Cross-platform optimization.Design responsive applications.Design and develop APIs.Participating in the design and creation of scalable software.Taking lead on projects, as needed.Maintenance of code integrity and organization.Writing clean, functional code on the front and back-end.Compile and analyze data, processes, and codes to troubleshoot problems and identify areas for improvement.Testing and fixing bugs or other coding issues.Meet both technical and consumer needs.Write technical documentation.Requirements & Skills:Proficiency with fundamental front-end languages such as JavaScript, HTML and CSS.Good knowledge with JavaScript frameworks and libraries such as Bootstrap.Proficiency with back-end languages and frameworks such as Drupal and PHP.Familiarity with database technology such as MySQL.Knowledge of code versioning tools such as Git or SVN.Knowledge of software development methodologies (e.g. AGILE)Location: RemoteExperience: 6+ yearsDuration: 6+monthsUtilization: 40hrs/ weekLanguages and level1) Fluent in English2) Bachelor’s degree in computer science, information technology, or a similar field.3) Available on a Full-time basis4) A relaxed and reliable team member that enjoys working with others","['HTML', 'Bootstrap', 'Git', 'MySQL', 'drupal 9', 'PHP', 'CSS', 'JavaScript', 'Tortoise SVN', 'Agile Software Development', 'Tortoise SVN', 'Agile Software Development']",Sweden,122,11.95,208,,,"['15.00', '25.00']",Remote Job,Expert
AI generated song,I basically have a cartoom character (the character has sung songs) i basically need you use an AI app to generate a happy birthday song from this character.Simple task i dont have time to find an app that can do this,"['Neural Network', 'Artificial Intelligence', 'Deep Learning', 'Deep Learning']",Singapore,156,,1.8,,10.00,,Remote Job,Expert
Data scientist specialized in Time series,"At MiriaData, we're leveraging the power of data to redefine our business landscape. We're seeking a skilled Data Scientist with a strong focus on time series analysis to join our dynamic team.The Data Scientist - Time Series Specialist will be responsible for designing and implementing models based on time series analysis. They will work closely with various teams to understand and forecast trends, analyze sequential data, and provide actionable insights to inform strategic decision-making.1. Design, develop, and implement statistical models for time series - analysis.2. Analyze historical data to identify trends, seasonal variations, and other patterns.3. Predict future trends and patterns using sophisticated statistical techniques.4. Implement machine learning algorithms tailored to time series data.5. Collaborate with cross-functional teams to implement models and drive business results.6. Communicate complex quantitative analysis in a clear, precise, and actionable manner to non-technical stakeholders.7. Keep abreast with the latest developments in time series analysis and machine learning methodologies.Please provide Portfolio and attach resume.","['Python', 'Data Science', 'Data Analysis', 'Machine Learning', 'Deep Learning', 'TensorFlow', 'Statistics', 'R', 'Neural Network', 'Machine Learning', 'Deep Learning', 'TensorFlow', 'Statistics', 'R', 'Neural Network']",Tunisia,3,,0,,1500.00,,Remote Job,Expert
Data and System Analyst,"Data and System Analyst / Technical SupportEssential duties and responsibilities:• Assist with and independently conduct data analysis in support of Yetta’s business activities. Theseinclude, but are not limited to:• Customer support• Customer projects• Data quality• Product development• Engage extensively with the Product and R&amp;D teams, and work with the Sales and Marketing teams toensure customer success is achieved and that service delivery expectations are met and exceeded.• Perform root cause analysis for production errors and support queries.• Perform for end-to-end data testing, i.e., making sure the right data is ingested, processed, and madeavailable for consumption.Who we are looking for:• BS/MS in Computer Science or equivalent experience, with the ideal candidate having 4-6 years of overallexperience.• Highly independent, self-starter who can work on individual assignments, as well as lead specific projectswith the team.• In-depth understanding of OLAP, OLTP schemas and ETL frameworks.• Familiarity with BI technologies (e.g., Microsoft Power BI).• Knowledge of SQL and data APIs.• Hands on experience with pricing &amp; retail data.Nice to have:• Skills and experience in Git, AWS, Azure.• Ability to communicate within operational and business teams in English.• Excellent analytical and design skills at product level.• Experience with Agile software development processes.• Demonstrated initiative and client success.","['Microsoft Power BI', 'Data Analysis', 'SQL', 'ETL', 'olap', 'Microsoft Excel', 'Microsoft Excel']",India,4,,,,10000.00,,Remote Job,Expert
Experienced Data Miners Needed for Children's Stories Research Project,"We are seeking skilled Data Miners for an exciting short-term project focused on the research and extraction of specific types of children's stories from the internet.Your role will involve:1) Identifying online sources of children's short stories, making sure to avoid any copyrighted or paid content.2) Extracting text from the identified stories, ensuring the quality and integrity of the data remain intact.3) Compiling and organizing the data in a structured format in an Airtable.4) Providing the source of the story (URL/Image/PDF) for each entry.5) Recording metadata for each story, including the age appropriateness and any other relevant information that can be derived from the source.Key Qualifications:- Proven experience in data mining and web research.- Experience working with Airtable or similar data management platforms.- Ability to determine age appropriateness of children's stories.- Excellent attention to detail and data accuracy.- Proficiency in English.Deliverables:- A minimum of 400 unique children's short stories sourced, extracted, and logged into our Airtable.- Clear attribution to source links for each story.- Detailed metadata for each story.Please note: For this project, we're specifically looking for children's stories available on the internet. We are not interested in content generated by AI models like ChatGPT or any similar services.How to Apply:Please submit your proposal detailing your relevant experience, your approach to this project, and your availability. Proposals with examples of similar projects you've undertaken will be highly regarded.Looking forward to your applications!Thank you.","['Data Mining', 'English', 'Critical Thinking Skills', 'Data Entry', 'Data Entry']",Israel,14,7.80,1.5,,200.00,,Remote Job,Intermediate
Strong AI engineer,"I am looking for strong AI engineer.We have to make chatGpt can work locally. You should have experience in AI,especially chatbot.If u have work,experiecn, send me.Free for Applying~~","['Artificial Intelligence', 'Machine Learning', 'Python', 'Data Analysis', 'Deep Neural Network', 'Deep Learning', 'Automatic Speech Recognition', 'Machine Learning', 'Python', 'Data Analysis', 'Deep Neural Network', 'Deep Learning', 'Automatic Speech Recognition']",Germany,1,,,,1800.00,,Remote Job,Expert
Excel template for trouble ticket,"I am looking for someone to create an Excel template for trouble ticket tracking from predefine site database with various asset configuration and multi customer information. I need to track maintenance requests, so it needs to include priority levels in the template. It should able to the capture the trouble ticket duration for next level escalation and with root cause and ETA for resolution. This project needs to be completed as soon as possible and shall contain at least the following1. Trouble Ticket identifier, for internal and external.2. Day/Week/Month Reporting Dashboard (# of TT (Open vs Closed), performance, prolong issue)3. Uptime calculation (gross or net after exclusion)4. Site wise and customer wise performanceIm looking to establish the template for tracking the Trouble ticketthis maybe for initial stage, 7 days is MAX. further to extend the functionality to more features.Now I want to focus for more like data entry things, where I can have a visibility on a daily entry","['Microsoft Power BI', 'Microsoft Excel', 'Visual Basic for Applications', 'Microsoft Access', 'Microsoft Windows Powershell', 'Microsoft Access', 'Microsoft Windows Powershell']",United Kingdom,305,5.00,2.9,,,"['10.00', '15.00']",Remote Job,Expert
AI engineer job,"HelloWe are seeking an experienced Al Engineer to join our team and help us develop and implement advanced Al algorithms for our trading platform. In this role you will use your expertise in Python, machine learning and deep learning to design and implement models that analyze market data and make predictions about cryptocurrency China StocksNotes: i have some problems to reply of some messages so i will send you the reply on your Email account","['Artificial Intelligence', 'Python', 'Machine Learning', 'Data Science', 'Python', 'Machine Learning', 'Data Science']",China,3,,,"['Sales', 'Marketing']",2500.00,,Remote Job,Expert
IoT Gateway and data collection,"We are working with Vehicle Gateways on the field in buses, cars and other vehicles. We collect data from the vehicles and runs services on-board the units and send to servers for further business enhancing.","['Internet of Things', 'Enhanced Interior Gateway Routing Protocol']",Norway,6,25.00,2.6,,,"['15.00', '40.00']",Remote Job,Expert
Full Stack developer  typescript openAI RVC ChatGPT Next.js React node.js python vercel strapi,"We are currently seeking a skilled team or individual to develop a web application for our platform, which will allow users to utilize pre-existing voice models or create their own. The application will offer TTS (Text-to-Speech) functionality as well as a Retrieval-based Voice Conversion.To support AI image generation, we will be utilizing AWS S3 bucket and the stable diffusion.For the backend Node.js Python and Docker as our primary technologies. As a headless CMS solution, we are considering implementing StrapiIn terms of text processing and prompts, we will be leveraging the OpenAI ChatGPT.On the frontend Next.js, React.js Tailwind CSS. Integration of payment gateways, particularly PayPal, will be facilitated through Stripe.Deployment docker hub, runpod. Vercel for deploying the Next.js application.Prior experience with AWS and expertise in data science are highly desired qualifications for this role.If you are an experienced data scientist with proficiency in AWS and a passion for working on AI-driven projects, we encourage you to apply. Please include examples of your previous work and relevant experience in your application.","['Amazon Web Services', 'Next.js', 'ChatGPT', 'TypeScript', 'React', 'Node.js', 'Strapi', 'Stripe', 'AI Text-to-Speech', 'AI Model Integration', 'AI Text-to-Speech', 'AI Model Integration']",Ukraine,7,,,,,"['40.00', '70.00']",Remote Job,Expert
Senior Data Engineer,"Looking for a Senior Data engineerProject: global leader in labor market / Job marketFull remote, full-time, long-term project, Kyiv time zoneRequirements:1. Analytical mind, personality and aptitude for working with data2. Ability to look at the numbers, trends, and data to derive conclusions based on findings3. Work closely with management to prioritize business and information needs4. Proven ability to work effectively to meet goals and deadlines with minimal supervision5. Highly creative problem-solving skills and an ability to tailor efforts based on the importance of the issue being addressed.6. A hands-on, detail-oriented mindset with the ability to look beyond the box7. Expert knowledge of object-oriented design, data structures, and algorithms8. Demonstrated experience with agile or other rapid application development methods, object-oriented design, coding, testing patterns with a variety of languages9. Significant knowledge of data structures, algorithms, data modeling and disaster recovery of data systems.Major responsibilities:1. Architect software applications, and test and build automated tools.2. Select data solution software and define hardware requirements3. Develop standards and processes for integration projects and initiatives.4. Lead the design/development of software applications, testing, and building tools5. Ensure database changes are reviewed and approved to standards6. Lead and communicate to leadership on solution design7. Provide technical assistance to junior members and to colleagues across the company",['Data Engineering'],Estonia,104,52.28,42,"['Tech', 'IT']",,"['18.00', '27.00']",Remote Job,Expert
Join the exciting world of VeilFans: Web Developer Position at a Cutting-Edge Start-up,"Transform the NSFW Industry: Web Developer Internship at VeilFansInvitation: Are you an emerging technological pioneer, committed to harnessing your skills for innovation and impact? VeilFans, an avant-garde start-up backed by industry-leading corporations.VeilFans is poised to disrupt the NSFW industry with a novel subscription-based platform that marries groundbreaking AI technology with respect for content creators' privacy. This transformative application empowers individuals to creatively express their uniqueness while preserving their anonymity. As an intern Web Developer, you will collaborate with a team of world-renowned professionals in leveraging state-of-the-art technology to sculpt a new era in a rapidly evolving industry.Responsibilities:1. Front-end Development: Craft aesthetically appealing and intuitive user interfaces that create immersive experiences. Work in tandem with our design team to metamorphose wireframes and prototypes into refined web pages.2. Back-end Development: Engineer robust, scalable web applications employing cutting-edge frameworks and languages. Craft efficient server-side components, APIs, and integrations for optimal performance and seamless data transmission.3. Collaborative Problem Solving: Actively engage with cross-functional teams to comprehend and address technical challenges. Participate in brainstorming sessions, contributing fresh perspectives to enhance platform functionality and security.4. Performance Optimization: Proactively monitor and enhance the website's speed, responsiveness, and overall performance. Implement industry best practices and optimization techniques to ensure an exceptional user journey.Qualifications:- Pursuing or completing a Bachelor's or Master's degree in Computer Science, Software Engineering, or related disciplines.- Proficiency in HTML, CSS, JavaScript, and front-end frameworks such as React or Angular.- Proficiency in back-end development using languages like Python, Node.js, or Ruby on Rails.- Familiarity with database systems (e.g., MySQL, MongoDB) and RESTful API development.- Robust problem-solving abilities, and adept at working in a high-octane, collaborative milieu.- Zeal for lifelong learning and staying abreast with the evolving web development trends and technologies.Additional Perks:- Opportunity to work closely with esteemed professionals and learn from industry titans.- Flexible working hours and remote work options.- Networking opportunities within the fintech, crypto, and adult entertainment industries.- Potential for future full-time employment.- Leverage your skills to create a positive social impact by empowering content creators to preserve their privacy and enhance artistic freedom.VeilFans is a staunch believer in diversity and inclusion. We welcome applicants from all backgrounds and experiences. All applications will be treated with strict confidentiality.","['HTML', 'CSS', 'JavaScript', 'Python', 'MySQL', 'API', 'Node.js', 'Ruby on Rails', 'Web Design', 'Web Development', 'MySQL', 'API', 'Node.js', 'Ruby on Rails', 'Web Design', 'Web Development']",United States,1,,,"['Media', 'Entertainment']",5.00,,Remote Job,Expert
Digital Analytics & Reporting - Transforming Paper-Based Enrolment System,"The project involves digitizing a paper-based enrolment system, which is a well-defined project. While it may require a significant amount of work and coordination, it is not a long-term or highly complex initiative like developing and executing a brand strategy. The focus is on transforming the enrolment system to an online platform and implementing analytics and reporting capabilities.Main Skills required:    Google Tag Manager/Google Analytics 4: The candidate should have experience in implementing and managing Google Tag Manager and Google Analytics 4 for tracking and analyzing digital data.    Basic Java Script/Python: Basic knowledge of JavaScript and Python would be beneficial for custom tracking implementations and data manipulation.    Personalization and Testing Programs: Experience with designing and implementing personalized customer experiences using tools like Salesforce Interaction Studio or equivalent would be advantageous.    Google Marketing Platform: Familiarity with the Google Marketing Platform, especially Google Analytics 360, Google Analytics 4, and Data Studio, is necessary for reporting and data analysis.    Digital Performance Media Programs: Expertise in managing and implementing digital performance media programs such as SEM (Search Engine Marketing), Display, and Social media advertising.    Communication Skills: Ability to effectively communicate complex information in a simple and concise manner.    Compliance and Privacy Policy Management: Understanding of compliance requirements and privacy policies related to digital marketing activities.","['Data Analytics', 'ETL', 'JavaScript', 'Python', 'Google Analytics', 'Python', 'Google Analytics']",Australia,1,,,"['Tech', 'IT']",,"['10.00', '20.00']",Remote Job,Intermediate
Auto ML,"Looking for an ML AI expert who can work closely with my team for achieving following goals - 1. Look at our entire AI ML process and suggest ways to to ensure we are following industry standards to have efficiency, scalability and precision. 2. Make Auto ML standard in our entire ML and AI process. 3. Implement Optuna.org and MLFlow to their full potential.4. Work with our data scientists on complex requirements.","['MLflow', 'Python', 'Machine Learning', 'optuna', 'optuna']",United States,275,43.71,242,"['Tech', 'IT']",,"['40.00', '70.00']",Remote Job,Expert
Chat GPT - Auto GPT Assistant,"Assistance with Chat GBT and Auto GBT to integrate with other subscriptions such as Office, Panda Doc, Outlook etc. The idea is to be able to easy set tasks in text window and the Ai should access subscriptions it is granted to create the Document, Send Email, add Credit etc depending on the task","['ChatGPT', 'Machine Learning', 'Deep Learning', 'AI Model Integration', 'AI Model Integration']",Saudi Arabia,56,15.88,14,"['Tech', 'IT']",,"['10.00', '20.00']",Remote Job,Expert
"Python Streamlit App Developer - Cloud Deployment (GCP, AWS, Azure)","We are seeking a skilled and experienced Python Streamlit App Developer who specializes in deploying applications to cloud platforms such as Google Cloud Platform (GCP), Amazon Web Services (AWS), and Microsoft Azure. As a Python Streamlit App Developer, you will play a crucial role in developing and deploying interactive and data-driven web applications while ensuring seamless integration with cloud environments.Responsibilities:Collaborate with cross-functional teams to understand application requirements and translate them into functional Python Streamlit applications.Design and develop user-friendly, responsive, and visually appealing web applications using Python and the Streamlit framework.Implement data processing, analysis, and visualization features within the applications to present complex information in an intuitive and interactive manner.Utilize cloud services and resources, such as GCP, AWS, and Azure, to deploy and host Streamlit applications securely and efficiently.Configure and optimize cloud infrastructure to ensure high availability, scalability, and performance of the deployed applications.Collaborate with DevOps teams to establish continuous integration and continuous deployment (CI/CD) pipelines for automated application deployment and updates.Monitor application performance, troubleshoot issues, and implement optimizations to enhance user experience and application efficiency.Stay up to date with the latest trends and best practices in Python, Streamlit, cloud platforms, and application deployment techniques.Qualifications:Bachelor's degree in Computer Science, - Engineering, or a related field. Relevant certifications are a plus.- 3+ years of professional experience as a Python developer, with a focus on web application development.- Strong proficiency in Python programming and experience with frameworks such as Streamlit, Flask, or Django.- Experience deploying applications to cloud platforms, such as GCP, AWS, or Azure, utilizing platform-specific services and resources.- Solid understanding of cloud infrastructure, containerization, and deployment concepts (e.g., Docker, Kubernetes).- Familiarity with database systems, data modeling, and integration within web applications.- Knowledge of front-end technologies, including HTML, CSS, and JavaScript, to enhance user interfaces.- Strong problem-solving skills and ability to troubleshoot and debug applications in cloud environments.- Experience with CI/CD pipelines and version control systems (e.g., Git) for collaborative development.- Excellent communication and collaboration skills to work effectively within a team environment.- Self-motivated and able to manage multiple projects and priorities effectively.To apply, please submit your resume, a cover letter detailing your relevant experience and achievements as a Python Streamlit App Developer, and any examples or links to your deployed applications on cloud platforms (GCP, AWS, Azure).","['Website Redesign', 'API Integration', 'HTML', 'CSS', 'SQL', 'Azure Cosmos DB', 'Amazon DynamoDB', 'Python']",United States,57,15.43,11,,,"['15.00', '32.00']",Remote Job,Intermediate
Generating report and Tracking everything,We want to see report of our every move on FB Email Calandly so that we can track essentials and focus on that,"['Campaign Reporting', 'Google Analytics', 'Facebook', 'Google Ads', 'Facebook', 'Google Ads']",United Kingdom,5,,100,,75.00,,Remote Job,Intermediate
Question setter for English comprehension with AI tool,We are looking for talents with strong English education background to help us set some english comprehension questions with our AI tool.,"['English', 'Artificial Intelligence', 'Editing & Proofreading', 'Editing & Proofreading']",Hong Kong,1,,,,,"['5.00', '6.00']",Remote Job,Intermediate
Looking for Google Looker Studio/MS Excel/Google Sheets and other Business Intelligence Tools,"Hi, I am looking for an expert to partner with me in fulfilling the client deliverables. The work would be day to day basis with set deadlines and timelines of the deliverables taking into consideration quality. The ideal candidate should have expertise in Google Looker Studio (Mandate), MS Excel (Mandate), and Google Sheets (Mandate). I would guide the whole framework along with step-by-step directions for each task. Knowledge of Financial Reporting is a must. Kindly apply with your portfolio and write the phrase ""I am in"" in the beginning of your portfolio to make sure you have read the whole job description. More information shall be given on the interview call with the shortlisted candidates. Best,Shash!","['Dashboard', 'Query Development', 'Google Data Studio', 'Data Visualization', 'Microsoft Excel', 'Google Sheets', 'Data Analysis', 'Data Modeling', 'Spreadsheet Software', 'Tableau', 'Microsoft Excel', 'Google Sheets', 'Data Analysis', 'Data Modeling', 'Spreadsheet Software', 'Tableau']",India,28,10.02,329,,50.00,,Remote Job,Intermediate
Review Python code for algotrading,"I have Python code for algo trading which I want to get it review and ensure it is working without any issue. Also do minor update as per the requirements. This work requires knowledge of algo trading, so please don’t apply if you don’t have this skill.","['Python', 'Machine Learning', 'Trading Automation', 'Trading Automation']",United States,10,,2.1,,50.00,,Remote Job,Intermediate
Looking for AI engineer,"Near is seeking a Data Engineer to join our team. In this role, you will have the opportunity to work on a huge scale of data, a cutting-edge tech stack, and leverage your skills and toolset to help us build a high-value and scalable product. You will be responsible for developing techniques to enhance data. You will also work with our data scientists, data analysts and product stakeholders to implement processes and infrastructure in order to support our data driven reports and analytics. These systems process billions of location data points per day.You will be part of one of the fastest growing Enterprise SaaS companies – a great opportunity for people who can work independently and are self-driven.A Day in the Life: Design, build and maintain the data pipeline for ingress and egress of location-based data Build and optimize the data warehouse to allow for report generation and analytics Assemble large, complex data sets that meet business requirementsWhat you bring to the role: Moderate experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases. Moderate knowledge of AWS cloud services: EC2, EMR, RDS, Redshift, S3, Athena Experience with object-oriented/object function scripting languages (Python)  Experience with Airflow or other orchestration tool Experience with Docker Experience with big data technologies: Spark, Hive, Mad/Reduce, Hadoop  Experience with UNIX/Linux including basic commands and shell scripting  Experience breaking down complex problems into manageable steps to solve  Must be a team player with strong attention to detail, and also able to work independently Proven track record at delivering timely and accurate information in a fast-paced environment Ability to build rapport with product, project, and QA teams Excellent critical thinking, problem solving, and mathematical skills, and sound judgment Experience building and optimizing AWS data pipelines, architectures and data sets Familiarity with mobile location data intelligence infrastructure and industry  GIS background is nice to have Able to work independentlyCompensation:$160,000 - 175,000 base salary + bonus + RSUsComprehensive benefits packagehttps://remotive.com/remote-jobs/data/data-engineer-1686841?ref=opentoworkremote.com&utm_source=opentoworkremote.comContact recruit.near@gmail.comApply with your work experience.","['Artificial Intelligence', 'Python', 'Machine Learning', 'Adobe Illustrator', 'Data Science', 'Artificial Neural Network', 'TensorFlow', 'Deep Learning', 'Natural Language Processing', 'Python', 'Machine Learning', 'Adobe Illustrator', 'Data Science', 'Artificial Neural Network', 'TensorFlow', 'Deep Learning', 'Natural Language Processing']",United States,4,,,,,"['40.00', '70.00']",Remote Job,Expert
Project Manager (Agile) - Banking Project,"Job Summary: We are seeking a talented and detail-oriented Business Analyst to join our team for a data consultancy project with a consumer bank. As a Business Analyst, you will be responsible for gathering, analyzing, and translating business requirements into data requirements. You will work closely with stakeholders, including business users, data analysts, and technical teams, to ensure that the project delivers valuable insights and solutions that align with the client's goals.Job Responsibilities:•	Collaborate with business stakeholders to understand their needs, goals, and challenges related to data analytics and reporting.•	Elicit, document, and analyze business requirements and translate them into detailed data requirements.•	Work closely with data analysts and data scientists to ensure that data requirements are well-defined and feasible.•	Conduct data analysis to identify trends, patterns, and insights that can drive business decision-making and improve processes.•	Define and document data flows, data mappings, and data transformation rules to support the development of data solutions.•	Assist in the design and development of data models, databases, and data integration processes.•	Work with technical teams to validate and verify data quality, ensuring that data is accurate, complete, and consistent.•	Collaborate with UX/UI designers to ensure that data visualizations and reports are intuitive, user-friendly, and aligned with business requirements.•	Participate in user acceptance testing (UAT) and provide feedback to ensure that the developed solutions meet business requirements and usability standards.•	Support the implementation and rollout of data solutions, providing guidance and training to end-users as needed.•	Proactively identify opportunities for process improvements and data-driven initiatives that can enhance business performance and customer experience.•	Stay up to date with industry trends, emerging technologies, and best practices in data analytics and business intelligence.Job requirements:•	Bachelor's degree in a relevant field (e.g., Business Administration, Information Systems, Economics) is preferred.•	3 + years of proven experience as a Business Analyst, preferably in data-related projects within the banking or financial services industry.•	Strong analytical and problem-solving skills, with the ability to extract insights from complex data sets and translate them into actionable recommendations.•	Proficiency in data analysis tools and techniques, such as SQL, Excel, or data visualization tools (e.g., Tableau, Power BI).•	Familiarity with data modelling concepts and techniques, including data warehouses, data marts, and dimensional modelling.•	Excellent communication and interpersonal skills, with the ability to effectively collaborate with stakeholders at all levels of the organization.•	Detail-oriented mindset with strong documentation and requirements gathering skills.•	Knowledge of banking processes, products, and regulatory requirements is desirable.•	Experience with agile methodologies, such as Scrum or Kanban, is a plus.•	Relevant certifications, such as Certified Business Analyst Professional (CBAP), are advantageous but not mandatory.project period 6 months","['Data Science', 'Apache Spark', 'Data Entry', 'Data Entry']",Singapore,6,,,"['Finance', 'Accounting']",9000.00,,Remote Job,Intermediate
Experienced AI Engineer / Chatbot Developer / Prompt Engineer,"Greetings,We are an innovative digital agency in search of an experienced AI Engineer or Chatbot Developer to join our dynamic remote team. As our portfolio expands, we are in need of an individual with expertise in AI, Natural Language Processing (NLP), and Machine Learning to help us build and refine intelligent Ai and chatbot solutions for our diverse range of clientsResponsibilities:- Design, develop, and deploy AI-driven chatbots and conversational interfaces- Create, test and improve prompts for use internally and for our clients- Leverage machine learning, NLP, and AI to improve the understanding and responsiveness of our chatbots- Collaborate with our developers to integrate chatbots with our existing systems and infrastructure- Implement rigorous testing processes to ensure chatbot accuracy and efficacy- Monitor and evaluate chatbot performance and make improvements as necessary- Stay current with the latest AI and chatbot trends and technologies, proactively suggesting improvements and new featuresThis is a remote, project-based role with the potential to evolve into a long-term position. If you are passionate about AI, enjoy working with cutting-edge technology, and thrive in a fast-paced, innovative environment, we would love to hear from you.","['Artificial Intelligence', 'Chatbot Development', 'Natural Language Processing', 'Machine Learning', 'Chatbot Development', 'Natural Language Processing', 'Machine Learning']",United Kingdom,28,6.30,8.6,,,"['10.00', '30.00']",Remote Job,Expert
Build a Radiomic library,"I need a Radiomic library to be built for PET imaging. The library should be able to extract features such as shape-based, intensity-based, and texture-based features. It should be compatible with Python programming language. The ideal candidate should have experience/good knowledge in medical imaging and knowledge of Radiomics. Proficiency in Python programming language is a must.The main goal is to create a radiomic library using pyradiomicsi have a csv file with DICOM metadata which should be used to train the modelthe library should include all the steps like segmentation of the PET images , feature extraction and feature selection.https://wiki.cancerimagingarchive.net/display/Public/NaF+PROSTATEthis link has the PET images and DICOM meta data filesPlease go through the files and let me know if the images and dataset are enough to come up with the required outputif you believe i have provide you with all the input resources please explain me the path forward that you will be takingcan you please study the dataset and PET images from the link that I have sharedand provide me an explanation in writing like a typed messagewhich contains the approach you will be taking to complete this task","['Machine Learning', 'Data Science', 'Software Architecture', '3D Design', 'Software Architecture', '3D Design']",United Kingdom,305,5.00,2.9,,,"['10.00', '15.00']",Remote Job,Expert
Coin Recognition Software with AI,"Given a coin's image (both sides) analyze and identify the coin.1. Coin Identification:a. The app should be able to analyze images of coins and identify the readable text, including language, denomination, country, and any other relevant information.b. It should have the capability to recognize and classify non-textual features of coins, such as images of historical figures, symbols, or artwork. c.The app should be able to determine if a coin has any errors or anomalies, such as mint errors or variations from the standard design.2. User Interface and Experience:a. UI will be developed by us, but you need to provide basic UI to allow you test the software.  b. The app should provide an intuitive and user-friendly interface for capturing and uploading coin images. You can look at Numista.com as an example of coin data; or coinscope.com.   We will provide you a large set of data and image for testing.Technical Requirements1. Image Preprocessing:   - Prior to applying AI algorithms, the app should preprocess coin images to enhance their quality and reduce noise. This may involve techniques like resizing, cropping, and adjusting lighting conditions.  (3rd Party libraries)2. Convolutional Neural Networks (CNNs):   - CNNs are commonly used for image recognition tasks. You can train a CNN model on a large dataset of coin images to learn features and patterns specific to different coins.   - The model can have multiple layers of convolutional and pooling operations to extract visual features from the images.3. Transfer Learning:   - Transfer learning can be employed to leverage pre-trained models, such as popular architectures like VGG, ResNet, or Inception. These models are trained on large image datasets and can be fine-tuned to recognize coins with relatively smaller datasets.4. Text Recognition:   - Optical Character Recognition (OCR) techniques can be used to identify and extract readable text from coin images. This can include detecting and recognizing languages, denominations, and other textual information on the coins.   - Example: Using OCR to identify the country name, denomination, or minting year imprinted on a coin.5. Feature Extraction:   - Along with text recognition, the app should be able to extract non-textual features from coin images. This can involve identifying symbols, historical figures, or unique artwork.   - Example: Detecting and classifying portraits of historical figures like presidents, monarchs, or national heroes on coins.6. Error Detection:   - AI algorithms can be trained to identify errors or anomalies in coin designs. This can include mint errors, variations from standard designs, misalignments, or double strikes.   - Example: Detecting a misaligned image of a coin where the front and back designs are not properly aligned or are partially overlapping.7. Confidence Scoring and Voting:   - AI algorithms can provide a confidence score or probability for each identification. If the confidence is below a certain threshold, the app can prompt users to verify or vote on the identification.   - Implementing a voting system where multiple users can provide their input on the identification can help increase accuracy and build consensus.   - Example: If the AI identifies a coin with 80% confidence, the app can ask users to vote on its identification to increase confidence or provide alternative suggestions.8. Model Training and Iteration:   - Continuous model training and iteration are necessary to improve the accuracy and performance of the image recognition algorithms.   - Collecting user feedback, incorporating user-provided corrections, and periodically retraining the models will help enhance the app's identification capabilities over time.We have several other similar projects. Please apply only if you have high level of expertise to provide a highly effective solution.  Please provide information on your related background and experience, your approach, tools you will use (must be royalty free), time-frame to complete the project, and a fixed price.  We can only follow up with those that provide the above information.Michael","['Transfer Learning', 'Feature Extraction', 'Artificial Intelligence', 'Machine Learning', 'Computer Vision', 'Deep Learning', 'Image Processing', 'Convolutional Neural Networks ', 'Confidence Scoring and Voting', 'Model Training and Iteration', 'Machine Learning', 'Computer Vision', 'Deep Learning', 'Image Processing', 'Convolutional Neural Networks ', 'Confidence Scoring and Voting', 'Model Training and Iteration']",United States,1,,,,,,Remote Job,Expert
Web scrapping,It is a quick project which can be done in one day as the elements that we are looking for do not exceed 400 elements.We are looking for a list of appliances:- ACs- Refrigerator- Washing machine......,"['Data Scraping', 'Python', 'Data Mining', 'Web Crawling', 'Data Extraction', 'Web Crawling', 'Data Extraction']",Germany,32,27.37,24,"['Energy', 'Utilities']",80.00,,Remote Job,Intermediate
Conduct a Workshop on ChatGPT &  its application in business,I am looking to hire a professional who can conduct workshops for my employees sitting at different locations. The workshop should be conducted in person.Preferred Location : Delhi/Gurgaon/Noida,"['ChatGPT', 'GPT-3', 'GPT-4']",India,2,,,,,,Remote Job,Expert
Japanese speakers needed for a long term web research and data entry job,"Become a long-term top data curator – 100% Remote Job!Join us to become a long-term top data curator for one of the biggest cloud computing companies in the life science industry. What’s in it for you? - Learn how to capture online available data by following specific rules within a 1-month intensive training  with full pay - Advance in your ability to gather data by significantly increasing your web research skills - Follow clear Key Performance Indicators (KPIs) based on error rates and time spent on each task - Become comfortable with medical terms, degrees, specialties & workplaces - Join and integrate into an international curator base of +1200 peopleJob requirements:  - Personal computer/laptop  - Good to great internet (10 mbs +) (https://www.speedtest.net/) - Fluent English, focus on reading and speaking skills   - Communicate actively to gain understanding of the tasks at hand - 40 hours/week availability - Motivation to acquire new skill by learning set of rules and guidelines provided in the  training book  - Be able to deliver high-quality data within each week in accordance with set KPIs - High attention to details  - Fluent reading ability in the Japanese language. Can read Japanese without using any translation application or dictionaries(At least JLPT N2 or above)Nice to have:  - Education or work experience in the life science (education or professional experience)/ healthcare industry - Experience as a web researcher Benefits: - Flexible working hours & work from anywhere - Growth-path opportunity within the company  - Long-term collaboration after a successful probation period of one month - Internal transfers within the company","['Online Research', 'Microsoft Excel', 'Data Entry', 'Google Docs', 'Data Entry', 'Google Docs']",Germany,511,,,,8.00,,Remote Job,Entry level
Broker Statement Parser - PDF,"1) The file to be parsed can only be in PDF format.2) Data to be stored in DATABASE Table accordingly. SQL Table schema shared in guideline sheet.3) Code should be in the form of ""Node.js"" or ""Python.""4) Time taken should be less than 1 seconds.5) Only the correct files should be parsed; the remaining files should be rejected with relevant errors.6) Keys in code should be appropriate.7) The maximum file size allowed is 20 MB.8) It should be a serverless application which ideally should be deployed on AWS lambda.9) We do not want any additional paid service(AWS Textract, etc)Do check the rules and list of brokers attached below.","['Python', 'Data Extraction', 'Node.js', 'PDF Conversion', 'Microsoft Excel', 'A-Parser', 'Data Scraping', 'AWS Lambda', 'JSON', 'PDF Conversion', 'Microsoft Excel', 'A-Parser', 'Data Scraping', 'AWS Lambda', 'JSON']",India,14,,0,"['Finance', 'Accounting']",3000.00,,Remote Job,Intermediate
Image to Text Converter (Captcha Solver),"We are looking for a skilled developer to help us with a project that involves converting images to text. The candidate should be able to integrate the system with AWS Lambda and have experience with Node.js or Python.Important points:-1)The file should be converted into text format with at least 99% accuracy.2)Code should be in the form of ""Node.js"" or ""Python"" in the latest version.3)The parsing time should be less than 0.5 seconds.4)Keys in code should be appropriate.5)We do not want any additional paid service(AWS Textract, etc)6)Open Source version and LTS are preferable7)The maximum file size allowed is 1 MB.","['Data Extraction', 'API Integration', 'Python', 'Image Processing', 'Node.js', 'AWS Lambda', 'Image Processing Software', 'AWS Lambda', 'Image Processing Software']",India,14,,0,"['Finance', 'Accounting']",300.00,,Remote Job,Intermediate
Survey data calculation with specific steps,"Urgent completion for a relatively easy but time consuming (for a non expert) task. I have a Data sheet  where you will find survey data from August to October. I have identified the NPS (net promoter score) per market per month. Considering the targets per market and Domain and based on these I have identified the markets where :(1)the target was not met for last month (October), (2)the target was not met for the last 2/3 months (3) the trend is decreasing in last 2 months.The Task: I need CPK diagrams including VSF calculation and findings, for each market/domain. Perform Box Plot analysis per Domain (Care/Online Shop) with Market data, for general overview and market comparison per Channel.If you can help me accurately and promptly I will prefer you for future tasks on a regular basis.","['Six Sigma', 'vsf calculation', 'Box Plot', 'Microsoft Excel', 'Box Plot', 'Microsoft Excel']",Greece,1,,,,,,Remote Job,Expert
Software Engineer / Software Developer / Theme Developer / Liquid Shopify / Automation / AI,"Immediate Start ProjectProject:We are seeking a productive professional that is interested in building one of the most important infrastructures and to assist in the day to day operations. Candidate will assist in designing and developing new concept of website, including architecting features, and scripting, and website theme development.Minimum Requirements:Experience in Developing FeaturesExperience in e-commerce / shopify FrameworkExperience in C#/Java/Python/JavaScriptExperience in Full-Stack Mode (Plus)On-Site Office :Plus: If you are based in Bay Area, CaliforniaPlease reply if you are interestedkeywords: software engineer, developer, software engineer, founder, ecommerce, e-commerce, markets, new, ai, software engineer, hardware engineer, 3d modeling, 3d, architecture, AI, VR, AR, applications, AI, ML, machine learning, data scientist, data, data science, software engineer, quant, research, engineer, machine learning, trading, investing, developer, e-commerce","['Ecommerce Website', 'API Integration', 'Artificial Intelligence', 'Web Development', 'Shopify Apps', 'Amazon Web Services', 'Architectural Design', 'Java', 'API', 'JavaScript', 'Web Development', 'Shopify Apps', 'Amazon Web Services', 'Architectural Design', 'Java', 'API', 'JavaScript']",United States,1,,,,2000.00,,Remote Job,Intermediate
Web Scraper Needed - Extracting Information From Careers Pages,"Hi! I'm looking for someone that can help me extract a tonne of information from companies career pages. I'm looking to gather information on parental benefits from employers globally, starting with Aus, Singapore, UK and USA. I'd like a tool that I can use again when moving to focus on other markets too. The information I want to extract includes whether they offer parental leave, maternity leave, fertility support, childcare leave, flexible working etc (I will provide you a sheet with specific fields). I'd also like the data to sit alongside the careers page link. I will then take this information and publish it. Please reach out if you can help! I'm a working mum so evenings Singapore time work best for me if we need calls. Looking to get this data asap to be honest. Thanks!","['Data Scraping', 'Python', 'Data Entry', 'Scrapy', 'Data Extraction', 'Scrapy', 'Data Extraction']",Singapore,4,,,,,"['25.00', '40.00']",Remote Job,Expert
Stock Recommendation Algorithm,"Goal - build an algorithm that based of a few inputs would recommend if a stock is worth buying, selling or holding more of Inputs:- Investors Risk appetite---- High---- Medium ---- LowSectors of Interest---- All---- Energy and transportation---- Finance---- Life sciences---- Manufacturing---- Real Estate and Construction---- Tech---- Trade and ServicesSymbol: ---- Ticker---- Price---- Target price(s)---- RSI---- MACD---- Support levels---- Resistance levels---- Sectors---- Recent ratings upgrades or downgrades ---- Recent price targets from ratings User Story 1) As a user, I would like to go through app onboarding where I select my risk tolerance and sector(s) of interest. Upon noting my risk tolerance and sectors of interest, I am recommended three stocks to follow by the algorithm.User story 2) As a user, I would like to know if I should buy hold or  sell a stock. I would tell the algorithm which stock I would like to assess and the algorithm would return a buy sell or hold recommendation The algorithm when back tested should have a win rate of 80%","['Python', 'Algorithm Development']",United States,5,46.96,27,,,"['40.00', '70.00']",Remote Job,Expert
Scraping data from Web of Science,"I want to scrape the Web of Science dataset to derive the citation data of each journal.For example, I want to get the number of new citations in 2019 for articles published between 2017-07-01 and 2018-06-30 on Nature. From the document I attached, you can see the publication titles (Nature), publication date (2017-07-01 to 2018-06-30) and from below you can get the total number of citations in 2019 is 41,597.I want to do the same process for every journal in the past 20 years. The total number of scrapings is about 250,000. The list of journals for every year is also attached.","['Python', 'Scrapy', 'Web Crawling', 'Data Scraping', 'API', 'Data Scraping', 'API']",China,1,,,,300.00,,Remote Job,Intermediate
Scheduling and EHR/EMR Software Developer,"I am seeking a highly skilled and experienced Software Developer to join our team. Experience in healthcare EHR/EMR development is strongly preferred, but experience in scheduling development is also applicable. In this role, you will be responsible for creating a robust Electronic Health Records (EHR) and Electronic Medical Records (EMR) system. Your primary focus will be developing a comprehensive solution that includes scheduling and appointment management, billing platform (invoice, integrate with 3rd party payment processing), HIPAA compliance, form creation, integration with eRX systems, Microsoft Cloud services, other relevant integrations, and seamless integration with clearinghouses for insurance claims and management.Responsibilities:- Design and develop a state-of-the-art EHR/EMR system that meets the needs of healthcare providers, patients, and regulatory requirements.- Build secure and scalable backend infrastructure for data storage, retrieval, and processing.- Develop intuitive and user-friendly front-end interfaces for healthcare professionals to interact with the system.- Implement robust scheduling features that optimize appointment management and resource allocation.- Integrate billing functionalities, ensuring accurate and efficient reimbursement processes, including seamless integration with clearinghouses for insurance claims and management.- Ensure HIPAA compliance throughout the system, including data privacy and security measures.- Create dynamic forms and templates for healthcare documentation, allowing for customizable and standardized data entry.- Collaborate with eRX providers to establish seamless integration for electronic prescription management.- Utilize Microsoft Cloud services to ensure scalability, reliability, and data redundancy.- Explore and integrate AI software, such as ChatGPT, to enhance clinical decision support and automate routine tasks.- Research and evaluate additional third-party integrations to expand the system's capabilities and interoperability.Requirements:Bachelor's or Master's degree in Computer Science, Software Engineering, or a related field.Proven experience in developing EHR/EMR systems or similar healthcare software.Strong proficiency in programming languages such as Java, C#, or Python.In-depth knowledge of healthcare industry standards, regulations, and best practices, including HIPAA.Familiarity with Microsoft Cloud services, database management, and data security.Experience integrating third-party APIs and systems, including eRX, clearinghouses for insurance claims and management, and AI software.Ability to work collaboratively in cross-functional teams and effectively communicate complex technical concepts to non-technical stakeholders.Strong problem-solving skills and the ability to handle and prioritize multiple tasks in a dynamic environment.","['C#', 'Ruby', '.NET Framework', 'Web Design', 'API Integration', 'Web Application', 'Microsoft SQL Server', 'JavaScript', 'Python', 'Java', 'Web Application', 'Microsoft SQL Server', 'JavaScript', 'Python', 'Java']",United States,2,,,,,,Remote Job,Expert
Webscrape auto parts website,need someone to scrape the rockauto.com website for auto parts which are compatible with each other  and save a database in sql and excel,"['Data Scraping', 'Python', 'Data Mining']",Canada,2,,75,,10.00,,Remote Job,Entry level
Data replication tool for heterogeneous databases,All the project information is mentioned in the attached file.,"['Python', 'SQL', 'MySQL', 'BINLOG', 'Database', 'MySQL Programming', 'MySQL Programming']",Saudi Arabia,4,,101,,35.00,,Remote Job,Intermediate
Ruby Engineer (Snowflake),"We are seeking a highly skilled Ruby Engineer with strong experience in data processing and management. As a Ruby Engineer, you will be responsible for developing and maintaining efficient and scalable data solutions, leveraging your knowledge of Ruby programming language and data technologies.Key Responsibilities:•	Develop, test and maintain data processing applications using Ruby and related technologies•	Collaborate with cross-functional teams to design and implement scalable data solutions•	Design and optimize data storage, retrieval, and processing systems•	Write efficient SQL queries and optimize database performance•	Develop ETL pipelines to extract, transform, and load data from various sources into our data warehouse•	Work with Snowflake, Postgres, and other database tooling to manage and maintain data stores•	Continuously monitor and improve the performance of data solutions•	Ensure data security, accuracy, and integrity throughout the data processing and storage lifecycleQualifications:•	Strong experience in Ruby programming language•	Strong experience with data processing and management•	Experience working with Snowflake, Postgres, and other database tooling•	Experience with ETL-like processes and data pipelines•	Strong SQL skills, with the ability to write complex queries and optimize database performance•	Excellent problem-solving and analytical skills•	Strong communication and collaboration skills","['Ruby', 'PostgreSQL', 'SQL', 'Snowflake']",India,10,,,"['Tech', 'IT']",,"['25.00', '42.00']",Remote Job,Expert
Build a Radiomic library,"I need a Radiomic library to be built for PET imaging. The library should be able to extract features such as shape-based, intensity-based, and texture-based features. It should be compatible with Python programming language. The ideal candidate should have experience/good knowledge in medical imaging and knowledge of Radiomics. Proficiency in Python programming language is a must.The main goal is to create a radiomic library using pyradiomicsi have a csv file with DICOM metadata which should be used to train the modelthe library should include all the steps like segmentation of the PET images , feature extraction and feature selection.https://wiki.cancerimagingarchive.net/display/Public/NaF+PROSTATEthis link has the PET images and DICOM meta data filesPlease go through the files and let me know if the images and dataset are enough to come up with the required outputif you believe i have provide you with all the input resources please explain me the path forward that you will be takingcan you please study the dataset and PET images from the link that I have sharedand provide me an explanation in writing like a typed messagewhich contains the approach you will be taking to complete this task","['Machine Learning', 'Data Science', 'Software Architecture', '3D Design', 'Software Architecture', '3D Design']",United Kingdom,305,5.00,2.9,,,"['10.00', '15.00']",Remote Job,Expert
Power BI Dashboard for Sales Analysis,"The objective of this Power BI project is to create a comprehensive sales analysis dashboard for our organization. The dashboard will provide insightful visualizations and data-driven insights to help us monitor and analyze sales performance, identify trends, and make informed business decisions.Scope:The scope of this project includes the following:Data Integration: Connect and integrate relevant data sources, such as our CRM system, sales database, and other relevant sources, to gather the necessary data for analysis.Data Modeling: Design and implement a robust data model that aligns with our business requirements, ensuring data accuracy and efficient data retrieval.Dashboard Design: Develop an intuitive and visually appealing dashboard interface using Power BI, incorporating charts, graphs, tables, and other visualizations to present sales data effectively.Key Metrics and KPIs: Identify and display key sales metrics and KPIs, such as revenue, units sold, average order value, sales growth, customer acquisition, and retention rates.Sales Performance Analysis: Provide interactive and drill-down capabilities to analyze sales performance across various dimensions, such as time periods, product categories, regions, and sales representatives.Trend Analysis: Include trend analysis features to identify patterns, seasonality, and emerging trends in sales data, enabling proactive decision-making.Sales Funnel Analysis: Visualize the sales funnel, from lead generation to conversions, to analyze and optimize the sales process.Geographic Analysis: Incorporate geospatial visualizations to analyze sales performance across different regions and territories, identifying opportunities and potential challenges.User-Friendly Filters and Parameters: Implement user-friendly filters and parameters to allow users to customize the dashboard based on their specific requirements and drill deeper into the data.Mobile Compatibility: Ensure the dashboard is optimized for mobile devices, allowing users to access and analyze sales data on-the-go.Documentation and Training: Provide documentation and user training materials to ensure the effective utilization of the Power BI dashboard within our organization.Deliverables:The deliverables for this project include:Power BI dashboard with interactive visualizations and data-driven insightsData integration and modeling documentationUser training materials and documentationOngoing support and maintenance as requiredTimeline:The project timeline will be determined based on the complexity of the data sources and the specific requirements. A detailed project plan and timeline will be established upon agreement.Please note that this is a general outline, and further discussions will be needed to finalize the specific requirements and details of the project.If you have any questions or need further information, please feel free to reach out.","['Data Visualization', 'Microsoft Power BI', 'Tableau', 'Tableau']",United States,1,,,,,"['20.00', '25.00']",Remote Job,Expert
Power BI Specialist,We are conducting a refresh of their Business Intelligence Dashboard and need a Microsoft Power BI Consultant to build the reports. All reports and display types will be provided and our tech team will handle the data views from sql server.You will be responsible for building the reporting pages of the BI Dashboard in line with the requested platform design of the client. Client workshops will provide the additional information you need for the design and build.The scope of work is to build 4-5 reporting pages each with multiple data reports to create a professional BI Dashboard. There will be approximately 30 reports across the pages. The current BI Dashboard will be provided to show how it has been done in the past.,"['Microsoft Power BI', 'Data Analysis', 'Data Visualization', 'SQL', 'Data Modeling', 'Microsoft Power BI Data Visualization', 'Microsoft Power BI Development', 'Microsoft Azure SQL Database', 'Azure Cosmos DB', 'Data Visualization', 'SQL', 'Data Modeling', 'Microsoft Power BI Data Visualization', 'Microsoft Power BI Development', 'Microsoft Azure SQL Database', 'Azure Cosmos DB']",Australia,1,,,,,"['20.00', '70.00']",Remote Job,Intermediate
ChatGPT -need data extracted at scale,"Hi,I'm looking for someone to run thousands of queries in ChatGPT and export the answers into an Excel spreadsheet.Please let me know if you're able to do this and the delivery date.Thanks!","['Data Entry', 'Microsoft Excel', 'Data Mining', 'Data Scraping', 'Python', 'Lead Generation', 'Data Analysis', 'Data Mining', 'Data Scraping', 'Python', 'Lead Generation', 'Data Analysis']",United Kingdom,71,5.00,1.1,,10.00,,Remote Job,Entry level
Wicked Report Setup Expert,Need a wicked report expert. who can setup our account to get proper conversion tracking.,"['Customer Service Analytics', 'Product Analytics', 'Marketing Analytics']",United Kingdom,30,12.00,2.3,,50.00,,Remote Job,Expert
Grafana dashboard for InfluxDB dada,"Description:We are looking for an experienced Grafana dashboard builder who can integrate data from InfluxDB and create visually appealing and interactive dashboards in Grafana. The dashboards will be used to monitor and analyze real-time data from various sources.Data is coming from our event logging system. Each event is is logged to InfluxDB as: time stamp, event type, event name, event data Responsibilities:Connect Grafana with InfluxDB and configure the necessary data sources.Design and develop custom dashboards in Grafana based on specific requirements.Create visualizations and panels to display real-time data from InfluxDB.Implement interactive features such as drill-downs, filters, and alerts.Optimize dashboards for performance and scalability.Collaborate with stakeholders to understand their data visualization needs and provide recommendations.Ensure data accuracy and integrity by validating queries and data transformations.Document the dashboard creation process and provide training to end-users if required. Requirements:Strong experience in building Grafana dashboards with InfluxDB integration.Proficient in writing InfluxQL queries to retrieve data from InfluxDB.Deep understanding of Grafana features and visualization options.Familiarity with data transformation techniques and data modeling in InfluxDB.Ability to create dynamic and interactive dashboards using Grafana templates, variables, and annotations.Experience with Grafana plugins and customizations is a plus.Strong problem-solving skills and attention to detail.Excellent communication and collaboration skills.Ability to work independently and meet project deadlines.","['Dashboard', 'Grafana', 'SQL', 'Python', 'Data Visualization', 'Logstash', 'Logstash']",United States,46,9.96,21,,,"['20.00', '45.00']",Remote Job,Expert
Help me fix my classification project,"I am working on lending data. I'm trying to predict lendees who are likely to take another loan. There was some sort of target leakage in the models which led me to preprocess the data in a way that now makes the training data and testing data distributions different. I don't think the predictions on unseen data are very good.This is primarily a preprocessing task. I need someone to decide if the target leakage is properly handled and if the only issue is the distributions not matching. Also, to suggest how to fix the determined issue.","['Python', 'Machine Learning', 'Data Science', 'Data Science']",United States,13,12.00,15,,,,Remote Job,Expert
PDF to text conversion,"Hello!I am looking for help in converting image scans of a manuscript into a text based format. Not exactly sure what this specific process is call but essentially...I have/will have:Hard copy of the book/manuscriptImage scans of the books in a PDF format. (Pending)The book is approximately 425 pagesI need:The image scans converted to a text document, ideally with page numbers and chapter headers removedBonus points if you can format for KDP/Kindle releaseI've tried Acrobat's OCR processing and it contains too many errors to be efficiently used. I'm aware of products like ABBYY FineReader or Tesseract OCR but don't have the time to learn them or go through the error checking process. I think FineReader is likely the ideal software for the task because of the error correction but open to suggestions.In your proposal if you could give me an estimated total cost of the project based on a page count of 425 it would be greatly appreciated.Thanks in advance!","['Tesseract OCR', 'OCR Software', 'PDF Conversion', 'Ebook', 'ABBYY FineReader', 'PDF Conversion', 'Ebook', 'ABBYY FineReader']",United States,5,28.23,763,,,,Remote Job,Intermediate
Looking for Data Scientists & Programmers,"Hey! This might not be your usual job pitch, but hear me out :)I’m looking for data scientists and programmers to test out a new AI software I built to help you automate the whole job search process. I know it might sound crazy but I’ve figured out a way to let AI find job posts for you and actually submit a proposal as well.I recorded a video to show you how it works because it's difficult to explain through messages.Please make sure to watch it as it has important information that you need to know before you apply.https://www.loom.com/share/39269eaa6b6c48edad839fe4a3bf96f6: The AI tool is new so I need some freelancers willing to give it a test. If you’re interested, let me know!Talk soon,AdamThe AI tool is new so I need some freelancers willing to give it a test. If you’re interested, let me know!Talk soon,Adam","['Data Analysis', 'Data Analysis Expressions', 'Data Analytics & Visualization Software', 'Data Analytics Framework', 'Data Access Layer', 'Data Analytics', 'Data Annotation', 'Data Backup', 'Python', 'Statistics', 'Machine Learning', 'Data Science', 'Content Writing', 'Microsoft Excel', 'Data Entry', 'Lead Generation', 'CNC Programming', 'PIC Programming', 'PLC Programming', 'PHP', 'R', 'WordPress', 'TensorFlow', 'Android', 'Java', 'JavaScript', 'Data Analytics & Visualization Software', 'Data Analytics Framework', 'Data Access Layer', 'Data Analytics', 'Data Annotation', 'Data Backup', 'Python', 'Statistics', 'Machine Learning', 'Data Science', 'Content Writing', 'Microsoft Excel', 'Data Entry', 'Lead Generation', 'CNC Programming', 'PIC Programming', 'PLC Programming', 'PHP', 'R', 'WordPress', 'TensorFlow', 'Android', 'Java', 'JavaScript']",United States,421,8.72,33,,,"['50.00', '900.00']",Remote Job,Expert
Prompt Engineering Developer - Auto-GPT and Embedding Specialist,"Job Description:We are seeking a skilled and experienced Chat Module Developer who specializes in utilizing Auto-GPT and embedding techniques such as langchain and openai, with expertise in prompt engineering. As our company aims to enhance our chat module's capabilities to understand user requirements and intents more effectively, we need an expert in natural language processing, machine learning, and crafting effective prompts.Responsibilities:Develop and integrate Auto-GPT models into our existing chat module framework.Utilize embedding techniques like langchain and openai to improve the understanding of user requirements and intents.Implement prompt engineering techniques to fine-tune the model's responses and guide its behavior.Train and fine-tune the Auto-GPT models using relevant data to improve the accuracy and performance of the chat module.Collaborate with the software development team to integrate the chat module with existing systems and platforms.Conduct thorough testing and debugging to ensure the chat module performs reliably and efficiently.Stay up-to-date with the latest advancements in natural language processing, Auto-GPT, embedding techniques, and prompt engineering to continually improve the chat module's capabilities.Requirements:Proven experience in developing chat modules or conversational AI applications using Auto-GPT and embedding techniques.Strong understanding and hands-on experience with natural language processing and machine learning algorithms.Expertise in prompt engineering, including crafting effective prompts, refining outputs, and managing biases.Proficiency in programming languages such as Python, JavaScript, or similar languages commonly used in chat module development.Familiarity with Auto-GPT frameworks like OpenAI's GPT-3.5 or similar models.Experience with embedding techniques, including langchain and openai, to enhance language understanding and intent recognition.Knowledge of relevant libraries and tools in the NLP and machine learning ecosystem.Excellent problem-solving skills and the ability to optimize and fine-tune models for improved performance.Strong communication and collaboration skills to work effectively within a team.Nice to have:Experience with deploying and maintaining chat modules in production environments.Familiarity with cloud platforms such as AWS, Azure, or Google Cloud for deploying and scaling chat applications.Knowledge of chatbot development frameworks or platforms such as Dialogflow, Rasa, or Microsoft Bot Framework.If you possess the required expertise in Auto-GPT, embedding techniques like langchain and openai, and have a strong understanding of prompt engineering, along with a passion for building intelligent chat modules, we would love to hear from you. Please provide examples of your previous work and projects demonstrating your expertise in chat module development.Note: This job description is intended to provide a general overview of the responsibilities and requirements for this position. The specific duties, skills, and qualifications may vary depending on the project and the organization.","['ChatGPT', 'Machine Learning', 'Prompt Engineering', 'Azure OpenAI', 'Azure OpenAI']",United States,9,,438,,,"['5.00', '25.00']",Remote Job,Intermediate
Software Engineer / Software Developer / Theme Developer / Liquid Shopify / Automation / AI,"Immediate Start ProjectProject:We are seeking a productive professional that is interested in building one of the most important infrastructures and to assist in the day to day operations. Candidate will assist in designing and developing new concept of website, including architecting features, and scripting, and website theme development.Minimum Requirements:Experience in Developing FeaturesExperience in e-commerce / shopify FrameworkExperience in C#/Java/PythonExperience in Full-Stack Mode (Plus)On-Site Office :Plus: If you are based in Bay Area, California Please reply if you are interestedkeywords: software engineer, developer, software engineer, founder, ecommerce, e-commerce, markets, new, ai, software engineer, hardware engineer, 3d modeling, 3d, architecture, AI, VR, AR, applications, AI, ML, machine learning, data scientist, data, data science, software engineer, quant, research, engineer, machine learning, trading, investing, developer, e-commerce","['Python', 'Ecommerce Website', 'API Integration', 'API', 'Data Science', 'Java', 'Desktop Application', 'JavaScript', 'Ecommerce Platform Development', 'Script', 'JavaScript', 'Ecommerce Platform Development', 'Script']",United States,12,,,,2000.00,,Remote Job,Intermediate
automated car design and convservation using AI,"We are looking for an expert in Artificial Intelligence to assist us with a project involving the automated design and conservation of cars. The ideal candidate should have experience in applying AI to the automotive industry, with a particular focus on car design and conservation.The project will last between 1 to 3 months and will involve developing an AI-powered system that can automatically create and optimize car designs while also considering conservation factors. The system should be able to generate designs that are both aesthetically pleasing and environmentally sustainable.To apply for this job, please submit a detailed proposal outlining your experience in AI, specifically in the automotive industry. Please include links to past completed projects that demonstrate your ability to develop AI-powered systems for car design and conservation.We are excited to work with a talented individual who can help us achieve our goals in this project. Thank you for your interest in working with us.Note: Some of the content in this job post may have been auto-generated using advanced AI.",['Artificial Intelligence'],Mexico,3,,,,12.00,,Remote Job,Intermediate
Product Manager,"Our company is looking for product managers and platform testers that can test  and use our software based solutions, in our case SaaS web based solutions for our clients;As an expert in representing similar platforms, online or software based, ideally, you have already tested similar platforms in the past, and you also have strong business development skills including client prospecting and engagement as well as international payment systems experience. Our online based solutions are low cost, and you understand the value in representing a platform with low cost solutions for our subscribers;Another asset would be previous experience in the following industries and/or roles:•                    Portfolio construction•                    Investment strategy•                    Private wealth•                    Investment banking•                    Commercial banking•                    Hedge funds•                    Corporate finance•                    Data science•                    Quantitative investing•                    Regulatory entities or standard setters","['Software Testing', 'Functional Testing', 'Bug Reports', 'Automated Testing', 'Software QA', 'Usability Testing', 'Web Testing', 'Test Case Design', 'Bug Reports', 'Automated Testing', 'Software QA', 'Usability Testing', 'Web Testing', 'Test Case Design']",Canada,22,,,"['Finance', 'Accounting']",,,Remote Job,Intermediate
Product Manager,"Our company is looking for product managers and platform testers that can test  and use our software based solutions, in our case SaaS web based solutions for our clients;As an expert in representing similar platforms, online or software based, ideally, you have already tested similar platforms in the past, and you also have strong business development skills including client prospecting and engagement as well as international payment systems experience. Our online based solutions are low cost, and you understand the value in representing a platform with low cost solutions for our subscribers;Another asset would be previous experience in the following industries and/or roles:•                    Portfolio construction•                    Investment strategy•                    Private wealth•                    Investment banking•                    Commercial banking•                    Hedge funds•                    Corporate finance•                    Data science•                    Quantitative investing•                    Regulatory entities or standard setters","['Software Testing', 'Functional Testing', 'Bug Reports', 'Automated Testing', 'Software QA', 'Usability Testing', 'Web Testing', 'Test Case Design', 'Bug Reports', 'Automated Testing', 'Software QA', 'Usability Testing', 'Web Testing', 'Test Case Design']",Canada,22,,,"['Finance', 'Accounting']",,,Remote Job,Intermediate
German TTS Model Voice cloning and setup on server,"This is for German language, please only apply if you can speak German or have successfully finished related german projects. I'm looking to record my own voice in german  and use it to train a Text-To-Speech (TTS) model. I need someone to help set this up on my server. After some research it seem that coqui is the way to go. Tasks include:1.) Setting up COQUI TTS on the server in the German language. You'll find a complete guide on GitHub, and there's a YouTube playlist available that illustrates how it works: https://www.youtube.com/watch?v=jZrsz_3j16c&list=PL19C7uchWZeo-j9mUmYeVfgzbP3vHSHU-Refer to this link: https://github.com/coqui-ai/TTS/2.) Creating a guide/description: How do I create and train a German language model? Please refer to the corresponding video: https://www.youtube.com/watch?v=-ojEpHO729o&list=PL19C7uchWZeo-j9mUmYeVfgzbP3vHSHU-&index=6The entire system should run online. Ideally, I should be able to input text and receive a WAV file of the spoken text.Requirements:- Deep understanding of TTS models and experience with the COQUI TTS system.- Familiarity with server setup - Strong problem-solving skills and the ability to troubleshoot any issues that arise.- Excellent communication skills in German While not required, experience with audio processing and knowledge of the German language will be a plus. This is a remote job and can be done from any location. You will be in direct communication with me during the process to ensure the project is on track. If you feel you can take on this task and help me achieve my goal, I look forward to your application.","['AI Text-to-Speech', 'Python', 'coqui']",Malaysia,115,5.27,58,"['Sales', 'Marketing']",,"['36.00', '70.00']",Remote Job,Expert
Data Analyst,"We're looking for a data analyst - someone that can gather and interprets company data to help employees and leadership better understand it. Some of their duties include putting complex data sets into understandable charts and reports, finding significant trends to help make better business decisions and building effective statistical testing procedures.","['Business Intelligence', 'Data Visualization', 'Data Entry', 'Business Modeling', 'Statistics', 'Data Analysis', 'Data Visualization', 'Data Entry', 'Business Modeling', 'Statistics', 'Data Analysis']",United States,1,,,,,"['75.00', '95.00']",Remote Job,Entry level
"Data Analytics, Engineer & Google Sheets Expert","Hello,Job Description:We are seeking an Excel Data Analyst & Comparison Specialist for a project involving the comparison of two extensive excel spreadsheets. These spreadsheets contain different providers' pricing data for a variety of products. Your task will be to identify common products between the two datasets, even in cases where the product names are not exactly the same.Key Responsibilities:Review, analyze, and interpret the data sets, identifying correlations between differently named but identical products.Perform manual and/or AI-based comparison of the two excel spreadsheets.Identify commonalities and differences in the pricing of the same product between different providers.Generate comprehensive reports detailing the findings from the comparison.Develop and implement efficient data management strategies.I am looking for someone who can help pull reports from our phone system and do data analysis. They must be extremely proficient in excel. Experience in billing is a plus!","['Microsoft Excel', 'Data Visualization', 'Google Analytics', 'Data Analysis', 'Google Data Studio', 'ETL Pipeline', 'JavaScript', 'Data Science', 'Tableau', 'Visual Basic for Applications', 'Google Analytics', 'Data Analysis', 'Google Data Studio', 'ETL Pipeline', 'JavaScript', 'Data Science', 'Tableau', 'Visual Basic for Applications']",United States,1,,,"['Retail', 'Consumer Goods']",,,Remote Job,Expert
Conversion of S19 Encrypted file to a text files,We have files with the extension of .S19 that we need to convert to a readable text.,"['Data Extraction', 'Encryption']",United States,41,19.62,136,"['Tech', 'IT']",,"['15.00', '100.00']",Remote Job,Expert
Confirm Google Analytics 4 Migration,"We are a small family-run business. We believe we have done all that's needed to have GA4 working, but Google keeps emailing us that we have not. Need someone to confirm we are all set, as well as set up new features that GA4 offers, and otherwise optimize GA4.",['Google Analytics'],United States,19,11.16,22,,,"['45.00', '75.00']",Remote Job,Intermediate
Data Specialist for AI Models | Greek and English,"Data Specialist for AI Models | Greek and English | Remote, Part Time, Work from HomeWork Location: remote, work from homeWork Schedule: part time, flexible scheduleCompensation: competitive rateExperience: no prior experience requiredLanguage Requirements: fluent in EnglishStart Date: immediatelyProject Duration: intermittentDoes this sound like you?Are you a stay-at-home mom or dad, student, gig worker, or professional looking for freelance, part-time, remote, work-from-home jobs where you can set your own schedule? Are you interested in helping to improve the reliability of today’s AI models? If yes, then this opportunity is for you!What we’re looking forRWS Group is looking for Data Specialists including Online Raters, Data Collectors, Data Annotators, Search Engine Evaluators and Ad Evaluators, to help train a broad range of AI applications. These applications consist of large language models (LLMs), virtual assistants, chatbots, security / authentication systems, search engines and more. Typical tasks for the Data Specialist include:[Online Rater] Providing feedback or performing assessments in accordance with specific criteria on text, audio, image, or video data found online.[Data Collector] Collecting, creating, or generating text, image, audio, or video data. For example: acquiring data from the public domain, filming, taking pictures of objects, or recording speech.[Data Annotator] Annotating, labeling, or tagging text, audio, image, or video data based on specific guidelines or instructions.[Search Engine Evaluator] Assessing and providing feedback on text, audio, image, or video search results based on specific search queries.[Ad Evaluator] Reviewing and providing feedback on online ads in search engines, social media platforms and other websites based on specific criteria.Work benefitsWork from home part time and when you want with a flexible work scheduleWork-life balance - maintain your lifestyle while you workEarn extra money on the sideTimely payments made directly to your PayPal or bank accountAccess more opportunities when you join our SmartSource AI communityEquipment you’ll needHigh-speed internet access (cable modem, DSL, etc.) A personal computer running the latest version of Google ChromeWindows or Mac OS X operating system Email service: Outlook, Gmail, or any otherJob requirementsFluent in English to be able to follow instructions and guidelinesNative-level fluency of GreekDetail-oriented with the ability to understand and follow instructionsAbility to meet deadlinesResponsible, reliable and communicative Apply now using the link below  to get startedTo get started, you will need to join our SmartSource AI community. You’ll be asked to:Choose the option which best describes you – private individual, sole proprietor / freelancer, or company / corporationComplete a sign-up form based on your previous selectionComplete an assessment test (optional)You will then start receiving email notifications of specific tasks. Training may be required to complete tasks. Apply Here:https://locpartners.moravia.com/registrationtype/?cc=AI&brand=SmartSourceAICommunityAccess more opportunities through our SmartSource AI communityBy becoming a Data Specialist in our SmartSource AI community, you'll gain access to additional freelance, remote, part-time, or work-from-home opportunities related to training AI models.About RWSRWS Holdings plc is a unique, world-leading provider of technology-enabled language, content and intellectual property services. Through content transformation and multilingual data analysis, our unique combination of technology and cultural expertise helps our clients to grow by ensuring they are understood anywhere, in any language.Our purpose is unlocking global understanding. By combining cultural understanding, client understanding and technical understanding, our services and technology assist our clients to acquire and retain customers, deliver engaging user experiences, maintain compliance and gain actionable insights into their data and content.We work with over 80% of the world’s top 100 brands, more than three-quarters of Fortune’s 20 ‘Most Admired Companies’ and almost all of the top pharmaceutical companies, investment banks, law firms and patent filers. Our client base spans Europe, Asia Pacific and North and South America. Our 65+ global locations across five continents service clients in the automotive, chemical, financial, legal, medical, pharmaceutical, technology and telecommunications sectors.Founded in 1958, RWS is headquartered in the UK and publicly listed on AIM, the London Stock Exchange regulated market (RWS.L).For further information, please visit: www.rws.com.",['English'],Japan,3,,,,,,Remote Job,Entry level
AI ChatGPT Prompt Engineer for Websites,"I am looking for someone to work closely with me to develop a specific set of prompts that will produce website copy for my clients.I want to go deep into this so no beginners, please.Your English must be great!More details once you apply for the job","['ChatGPT', 'Python', 'JavaScript', 'Web Development', 'AI Content Creation', 'AI Content Creation']",Australia,109,11.20,8.8,,,"['5.00', '25.00']",Remote Job,Expert
Machine Learning LLM Artificial Intelligence with custom Dataset in Arabic text. Similar to LLaMA,"I need a chat bot that behaves like Chat GPT, it will be in Arabic language only.The goal of this project is to be able to give the AI a database in Arabic text and the AI should be able to analyze and answer questions about it. Also to retrieve info from the data base.This is a prototype so it can be very basic and it does not need to be 100% perfect. And it needs to run locally (CPU or GPU and no cloud).The Database Dataset is not available at this point so we can use dummy datasets off of HuggingFace.The deliverable will be the source code and a build along with a documentation on describing how the model/data were created and processed. Windows OS is preferred.","['Natural Language Generation', 'Machine Learning', 'Artificial Intelligence', 'Deep Learning', 'Natural Language Processing', 'Neural Network', 'Natural Language Understanding', 'Data Model', 'Deep Learning', 'Natural Language Processing', 'Neural Network', 'Natural Language Understanding', 'Data Model']",United States,1,,,,600.00,,Remote Job,Expert
Data Engineer (25 hrs/week for 3 months) on US work hours,"Hello,Looking for Data Engineer Contract (3 months) US remote.Design, develop and implement real time data ingestion pipelines from multiple sources using Data bricks.Develop high-quality, scalable, and re-usable frameworks for ingesting high volume and large data sets.Apply best practices to Integrate and ingest various big data formats like Protobuf, Parquet, AVRO, and JSONWork with event based / streaming technologies like Kafka, or Kinesis, to ingest and transform the data using Kafka Streams or KSQLSkills Required:- Strong experience with Python for data engineering tasks- In-depth knowledge of AWS services, including EC2, S3, RDS, and Kinesis- Hands-on experience with Apache Kafka for real-time data streaming and processing- Proficiency in using Snowflake as a cloud-based data warehouse solution- Familiarity with data modeling, ETL processes, and data warehousing concepts- Excellent problem-solving skills and the ability to work in a fast-paced, dynamic environment- Strong communication skills and the ability to collaborate effectively with team members- A minimum of 5-6 years of experience in a data engineering roleIf you have the skills and experience we're looking for, we'd love to hear from you! Please reach out to us with your CV and experience information. We are looking forward to working with you to help our IT company continue to thrive and innovate in the world of data engineering.","['Data Entry', 'Microsoft Excel', 'Administrative Support', 'Customer Service', 'JavaScript', 'Python', 'Email Communication', 'Tableau', 'Data Analysis', 'CSS', 'Administrative Support', 'Customer Service', 'JavaScript', 'Python', 'Email Communication', 'Tableau', 'Data Analysis', 'CSS']",United Kingdom,1,,,"['Tech', 'IT']",,,Remote Job,Expert
Data Specialist for AI Models | Ukrainian and English,"Data Specialist for AI Models | Ukrainian and English | Remote, Part Time, Work from HomeWork Location: remote, work from homeWork Schedule: part time, flexible scheduleCompensation: competitive rateExperience: no prior experience requiredLanguage Requirements: fluent in EnglishStart Date: immediatelyProject Duration: intermittentDoes this sound like you?Are you a stay-at-home mom or dad, student, gig worker, or professional looking for freelance, part-time, remote, work-from-home jobs where you can set your own schedule? Are you interested in helping to improve the reliability of today’s AI models? If yes, then this opportunity is for you!What we’re looking forRWS Group is looking for Data Specialists including Online Raters, Data Collectors, Data Annotators, Search Engine Evaluators and Ad Evaluators, to help train a broad range of AI applications. These applications consist of large language models (LLMs), virtual assistants, chatbots, security / authentication systems, search engines and more. Typical tasks for the Data Specialist include:[Online Rater] Providing feedback or performing assessments in accordance with specific criteria on text, audio, image, or video data found online.[Data Collector] Collecting, creating, or generating text, image, audio, or video data. For example: acquiring data from the public domain, filming, taking pictures of objects, or recording speech.[Data Annotator] Annotating, labeling, or tagging text, audio, image, or video data based on specific guidelines or instructions.[Search Engine Evaluator] Assessing and providing feedback on text, audio, image, or video search results based on specific search queries.[Ad Evaluator] Reviewing and providing feedback on online ads in search engines, social media platforms and other websites based on specific criteria.Work benefitsWork from home part time and when you want with a flexible work scheduleWork-life balance - maintain your lifestyle while you workEarn extra money on the sideTimely payments made directly to your PayPal or bank accountAccess more opportunities when you join our SmartSource AI communityEquipment you’ll needHigh-speed internet access (cable modem, DSL, etc.) A personal computer running the latest version of Google ChromeWindows or Mac OS X operating system Email service: Outlook, Gmail, or any otherJob requirementsFluent in English to be able to follow instructions and guidelinesNative-level fluency of Ukrainian Detail-oriented with the ability to understand and follow instructionsAbility to meet deadlinesResponsible, reliable and communicative Apply now using the link below  to get startedTo get started, you will need to join our SmartSource AI community. You’ll be asked to:Choose the option which best describes you – private individual, sole proprietor / freelancer, or company / corporationComplete a sign-up form based on your previous selectionComplete an assessment test (optional)You will then start receiving email notifications of specific tasks. Training may be required to complete tasks. Apply Here:https://locpartners.moravia.com/registrationtype/?cc=AI&brand=SmartSourceAICommunityAccess more opportunities through our SmartSource AI communityBy becoming a Data Specialist in our SmartSource AI community, you'll gain access to additional freelance, remote, part-time, or work-from-home opportunities related to training AI models.About RWSRWS Holdings plc is a unique, world-leading provider of technology-enabled language, content and intellectual property services. Through content transformation and multilingual data analysis, our unique combination of technology and cultural expertise helps our clients to grow by ensuring they are understood anywhere, in any language.Our purpose is unlocking global understanding. By combining cultural understanding, client understanding and technical understanding, our services and technology assist our clients to acquire and retain customers, deliver engaging user experiences, maintain compliance and gain actionable insights into their data and content.We work with over 80% of the world’s top 100 brands, more than three-quarters of Fortune’s 20 ‘Most Admired Companies’ and almost all of the top pharmaceutical companies, investment banks, law firms and patent filers. Our client base spans Europe, Asia Pacific and North and South America. Our 65+ global locations across five continents service clients in the automotive, chemical, financial, legal, medical, pharmaceutical, technology and telecommunications sectors.Founded in 1958, RWS is headquartered in the UK and publicly listed on AIM, the London Stock Exchange regulated market (RWS.L).For further information, please visit: www.rws.com.",['English'],Japan,3,,,,,,Remote Job,Entry level
Senior Data Engineer,"The company creates solutions covering all types of pricing use cases in online, offline, omnichannel, mono- or multi-brand retail. Whether you need to get a 360 maker view, reduce repricing time & efforts, or set prices based on demand patterns and sales cross-impacts. Tasks:·     Design, build, extend, and maintain data pipelines and unified integration ETL·     Scale the data pipeline throughput using applicable instruments·     Introduce and adopt new instruments, technologies and their combinations that will allow the company to scale the data processing speed and performance in a cost-efficient way  Requirements:·     Proven experience in building data processing pipelines·      Experience with workflow automation tools (AirFlow, Prefect, Luigi, etc.)- RDBMS, Column-oriented DBMS (writing queries, db architecture building, administration, etc.)·     Apache Spark-·     Strong core Python knowledgePleasant extras: ·     ClickHouse·     Apache Kafka·     CDC (e.g. WAL, Debezium, Kafka)·     ksqlDB·     Spark SQL·     Argo Workflows·     GCP: BigQuery, Dataproc, Data Fusion, DataFlowBenefits:·     Meaningful work in an agile team of engineers, who turn business ideas into software solutions·     Freedom to choose the best suitable technologies to deliver the solution (even if it’s not in the product yet)·     Want to learn? Competera loves that and is eager to cover 60% of your training/courses fee·     Fair payout with regular performance-based reviews and stock options plan for top performers-·     Remote-first ideology even after the pandemic and the war·     Working hours that adapt to your biorhythm·     Paid vacation & sick leaves (20 business days each) + 15 days off·     Partial medical insurance coverage","['Apache Kafka', 'Database Design', 'apeche kafka', 'DWH', 'Big Data', 'ETL', 'CDC', 'ClickHouse', 'Spark SQL', 'ETL', 'CDC', 'ClickHouse', 'Spark SQL']",Ukraine,23,,,,6500.00,,Remote Job,Expert
Data Specialist for AI Models | Hebrew and English,"Data Specialist for AI Models | Ukrainian and English | Remote, Part Time, Work from HomeWork Location: remote, work from homeWork Schedule: part time, flexible scheduleCompensation: competitive rateExperience: no prior experience requiredLanguage Requirements: fluent in EnglishStart Date: immediatelyProject Duration: intermittentDoes this sound like you?Are you a stay-at-home mom or dad, student, gig worker, or professional looking for freelance, part-time, remote, work-from-home jobs where you can set your own schedule? Are you interested in helping to improve the reliability of today’s AI models? If yes, then this opportunity is for you!What we’re looking forRWS Group is looking for Data Specialists including Online Raters, Data Collectors, Data Annotators, Search Engine Evaluators and Ad Evaluators, to help train a broad range of AI applications. These applications consist of large language models (LLMs), virtual assistants, chatbots, security / authentication systems, search engines and more. Typical tasks for the Data Specialist include:[Online Rater] Providing feedback or performing assessments in accordance with specific criteria on text, audio, image, or video data found online.[Data Collector] Collecting, creating, or generating text, image, audio, or video data. For example: acquiring data from the public domain, filming, taking pictures of objects, or recording speech.[Data Annotator] Annotating, labeling, or tagging text, audio, image, or video data based on specific guidelines or instructions.[Search Engine Evaluator] Assessing and providing feedback on text, audio, image, or video search results based on specific search queries.[Ad Evaluator] Reviewing and providing feedback on online ads in search engines, social media platforms and other websites based on specific criteria.Work benefitsWork from home part time and when you want with a flexible work scheduleWork-life balance - maintain your lifestyle while you workEarn extra money on the sideTimely payments made directly to your PayPal or bank accountAccess more opportunities when you join our SmartSource AI communityEquipment you’ll needHigh-speed internet access (cable modem, DSL, etc.) A personal computer running the latest version of Google ChromeWindows or Mac OS X operating system Email service: Outlook, Gmail, or any otherJob requirementsFluent in English to be able to follow instructions and guidelinesNative-level fluency of HebrewDetail-oriented with the ability to understand and follow instructionsAbility to meet deadlinesResponsible, reliable and communicative Apply now using the link below  to get startedTo get started, you will need to join our SmartSource AI community. You’ll be asked to:Choose the option which best describes you – private individual, sole proprietor / freelancer, or company / corporationComplete a sign-up form based on your previous selectionComplete an assessment test (optional)You will then start receiving email notifications of specific tasks. Training may be required to complete tasks. Apply Here:https://locpartners.moravia.com/registrationtype/?cc=AI&brand=SmartSourceAICommunityAccess more opportunities through our SmartSource AI communityBy becoming a Data Specialist in our SmartSource AI community, you'll gain access to additional freelance, remote, part-time, or work-from-home opportunities related to training AI models.About RWSRWS Holdings plc is a unique, world-leading provider of technology-enabled language, content and intellectual property services. Through content transformation and multilingual data analysis, our unique combination of technology and cultural expertise helps our clients to grow by ensuring they are understood anywhere, in any language.Our purpose is unlocking global understanding. By combining cultural understanding, client understanding and technical understanding, our services and technology assist our clients to acquire and retain customers, deliver engaging user experiences, maintain compliance and gain actionable insights into their data and content.We work with over 80% of the world’s top 100 brands, more than three-quarters of Fortune’s 20 ‘Most Admired Companies’ and almost all of the top pharmaceutical companies, investment banks, law firms and patent filers. Our client base spans Europe, Asia Pacific and North and South America. Our 65+ global locations across five continents service clients in the automotive, chemical, financial, legal, medical, pharmaceutical, technology and telecommunications sectors.Founded in 1958, RWS is headquartered in the UK and publicly listed on AIM, the London Stock Exchange regulated market (RWS.L).For further information, please visit: www.rws.com.",['English'],Japan,3,,,,,,Remote Job,Entry level
Website Developer Needed,"Our company is at the forefront of revolutionizing the real estate industry with 3D camera technology. We are embarking on an ambitious project that will allow us to fully scan homes and create immersive, virtual walk-through experiences as if the users were actually present in the house.We are hiring a professional, talented, and experienced Full Stack Developer to join our team and lead the development of the website that will host these 3D experiences.Job Description:As a Full Stack Developer, you will be tasked with the design, development, and deployment of our new website. Your primary focus will be to create an interactive platform that can seamlessly integrate with our innovative 3D camera technology and provide a smooth, immersive user experience.Responsibilities:Collaborate with a team of developers, designers, and stakeholders to define, design, and ship new features.Develop front-end website architecture and back-end website applications.Ensure the website can handle large data sets including 3D models and imaging data.Implement user interface components for maximum speed and scalability.Write clean, readable, and testable code.Design and implementation of low-latency, high-availability, and performant applications.Implementation of security and data protection measures.Troubleshoot, debug and upgrade existing systems.Participate in code reviews to maintain high-quality code.Ensure website functionality and stability across devices and browsers.Qualifications:Proven experience as a Full Stack Developer or similar role.Fluent in English, both spoken and written.Proficient in front-end languages (HTML5, CSS3, JavaScript, etc.), back-end languages (e.g., Python, Java, .NET), and JavaScript frameworks (e.g., Angular, React, Node.js).Familiarity with database technologies, such as MySQL, MongoDB, and Elasticsearch.Knowledge of user interface design principles and standards.Experience with 3D data visualization or a similar field is a plus.Ability to work in a fast-paced, deadline-driven environment.Excellent communication and teamwork skills.Degree in Computer Science or a related field is preferred.Note: As we are developing new camera software and lens, we operate on a strict budget. Therefore, we are looking for a professional who can deliver high-quality work while effectively managing resources.To apply for this position, please provide a cover letter, resume, and examples of previous work or portfolio. We are looking forward to meeting you!","['WordPress', 'PHP', 'CSS', 'HTML5', 'CSS 3', 'HTML', 'Web Design', 'Web Development', 'Website', 'Prototyping', 'HTML', 'Web Design', 'Web Development', 'Website', 'Prototyping']",United States,1,,,,22750.00,,Remote Job,Expert
"Single cell genomics, proteomics and spatial analysis","Molecular and spatial analysis of single-cell genomics and spatial transcriptomics (including preprocessing, clustering, characterization of molecular programs and cellular communication patterns, and appropriate visualizations).","['Data Analysis', 'Bioinformatics', 'computational biology', 'Deep Learning', 'Machine Learning', 'R', 'Python', 'Data Modeling', 'Data Visualization', 'computational biology', 'Deep Learning', 'Machine Learning', 'R', 'Python', 'Data Modeling', 'Data Visualization']",United States,1,,,,,"['10.00', '45.00']",Remote Job,Expert
Google Analytics 4 (GA4) Expert Wanted,"Looking for someone who can install GA4 using Google Tag Manager and setup advanced goals such as clicks on specific links and segmenting between new & returning traffic, etc... in order to track conversions from various channels and provide month over month reporting for each of my web properties.","['Google Analytics', 'Google Tag Manager', 'ga4', 'analytics 4', 'ga4', 'analytics 4']",United States,10,12.08,2.3,,,,Remote Job,Intermediate
Florida Commercial Construction List BuildData Mining,"I have a list of currently 250 companies in Florida. I need them to be verified that they do commercial construction projects, then if they are I need the name of the director/ceo, their email address, LinkedIn profile, and company address and phone number.I may add more to the list but the initial list is 250","['Microsoft Excel', 'Data Scraping', 'Data Entry', 'Data Mining', 'Data Entry', 'Data Mining']",Turkey,2,,,"['Media', 'Entertainment']",5.00,,Remote Job,Expert
Business Intelligence Data Developer,"We are looking for a skilled Business Intelligence Database Developer to join our team on a short-term contract basis. As a Business Intelligence Developer and Analyst, you will be responsible for integrating customer database into Metabase, analyzing customer database profiles, developing KPIs and data visualizations, extracting specific information, and organizing your findings . Your role will play a crucial part in providing valuable insights to support our business decisions.Responsibilities:Thoroughly analyze Excel spreadsheets and other document types from the insurance company's customer profilesExtract and organize the required information via MetabaseAdhere to privacy policies and ensure the security of customer dataDevelop and code the KPIs needed for real-time business intelligence for creating customer profiles for target marketingRequirements:Prior experience with Metabase is requiredProven experience in similar projects or rolesStrong analytical skills and attention to detailEffective communication skills, including the ability to participate in calls or video callsBudget: NegotiableDuration: The initial project will last 2-4 weeks, with the possibility of repeat work if the initial job is completed successfully.If you meet the requirements mentioned above and are interested in this position, please submit the following:1. Your updated resume highlighting your relevant experience2. Examples or a portfolio showcasing your work in similar projects","['Metabase', 'Data Analysis', 'Business Intelligence', 'Microsoft Excel', 'Business Intelligence', 'Microsoft Excel']",United States,19,34.70,1.2,,,"['18.00', '25.00']",Remote Job,Intermediate
"Scrape Data, Organize, and deliver on a Spreadsheet","I want you to create a spreadsheet that lists each US office location of 7 law firms, broken down by location - practice area (i.e. Corporate, etc) - Attorney/Partner/Associate - Paralegal/law clerk (if available). The end product will be a spreadsheet that would look something like the attached spreadsheet example. You can exclude the litigation practice from this list. All of this information exists on the 7 law firm websites with the exception of the paralegal/law clerk information (some law firms list this, some do not). If you can scrape LinkedIn as well for the Paralegal/Law Clerk data that would be great. I will provide links to all 7 law firm websites that I want to have this data for. Happy to answer any questions you might have. I am looking to get this data as soon as possible.Thank you.","['Data Scraping', 'Data Mining', 'Google Sheets', 'List Building', 'Lead Generation', 'Data Extraction', 'Scrapy', 'Google Sheets', 'List Building', 'Lead Generation', 'Data Extraction', 'Scrapy']",United States,1,,0,"['Tech', 'IT']",100.00,,Remote Job,Intermediate
FREELANCER WhatsApp GPT integration for Sleep Suggestions Project AI,We're looking for a LONG TERM commitment and NOT agencies. This will require a full time engagement to make it. Experienced GPT and whatsapp integration is a MUST.,"['Python', 'Artificial Intelligence', 'Machine Learning', 'JavaScript', 'WordPress', 'Machine Learning', 'JavaScript', 'WordPress']",United States,1,,,"['Tech', 'IT']",,"['40.00', '70.00']",Remote Job,Expert
Scrape web site,"1. https://www.actrsl.org.au/sub-branchesAddress, phones, emailsAll phones in 1 column separate by a comma, emails too2. https://www.rslsa.org.au/subbranch-detailsScrape all details","['Data Scraping', 'Data Mining', 'Web Crawling', 'Web Crawling']",Indonesia,36,,333,,5.00,,Remote Job,Intermediate
Retail IT with data SQL knowlege,Individual who has access to cloud data and can convert retail data in order to create reports on customer data,"['Converting data', 'SQL']",United States,2,,,,,"['45.00', '75.00']",Remote Job,Intermediate
Data Analyst for Digital Marketing,"Hello, We are looking for someone who has deep understanding of both the Google Ads and Analytics platform, as well as Meta Ads platform. The goal is to generate a report for each platform on a month to month basis to determine the changes in trends, traffic, conversions, etc. Someone detail oriented, experienced with excel, is highly valued. Thank you.","['Data Visualization', 'Google Ads', 'Google Analytics', 'meta ads', 'Data Analysis', 'Microsoft Excel', 'meta ads', 'Data Analysis', 'Microsoft Excel']",United States,5,,,,200.00,,Remote Job,Expert
Google Analytics & Google Optimize Expert,We are a health and wellness brand that helps people recover from surgeries faster and more comfortably. We are looking for an expert in Google Analytics & Google Optimize to optimize our GA account and work with our Shopify web developer to create our first A/B split tests.Our website is https://healfastproducts.com/,"['Marketing Analytics', 'Google Analytics', 'Google Optimize', 'Google Tag Manager', 'Google Tag Manager']",United States,43,11.86,32,,,"['25.00', '60.00']",Remote Job,Expert
Looker Studio Report Generator,Need help building basic reports in Looker Studio.  We have connected Shopify to BigQuery so the source data is all in BigQuery.,"['Looker', 'Google Data Studio', 'Data Visualization']",United States,32,12.00,10,,,"['5.00', '12.00']",Remote Job,Entry level
Scrape fast people search information to Excel or google spreadsheet,"I have a list of people i need to search the phone numbers and their emails, I saw an advertisement for a skiptracing bot but it feels suspicious. I have limited budget due other invesmtents but i want to hear your offers for this job, I am open to other options, i found another guy offering monthly subs for the bot or software but i dont trust them. shoot your msg lets talk .Not looking to pay hourly. flat price monthly or sold price for the app.",['Data Scraping'],Nicaragua,12,,100,['Real Estate'],,,Remote Job,Entry level
Urgent : Need Data Analyst to analyze a small dataset and visualize data,"Check the files attached, two excel sheets and an explainatory pdf. Analysis needed done before MONDAY.","['Dashboard', 'Presentations', 'Data Analytics', 'Data Interpretation', 'Microsoft Power BI', 'Data Analysis', 'Tableau', 'Python', 'Data Visualization', 'Microsoft Excel', 'Data Visualization', 'Microsoft Excel']",France,3,,45,['Education'],15.00,,Remote Job,Intermediate
Excel Expert,Expert Excel Programmer required to set up a project book for recording timesheets and total revenue generated.,"['Dashboard', 'Presentations', 'Data Visualization', 'Microsoft Excel', 'Data Analysis', 'Visual Basic for Applications', 'Spreadsheet Software', 'Visual Basic for Applications', 'Spreadsheet Software']",New Zealand,6,,127,"['Engineering', 'Architecture']",,"['5.00', '10.00']",Remote Job,Expert
Redshift Partner with Teradata migration experience,"We are looking for a skilled Redshift Partner with Teradata migration experience to assist with a project that will last more than 6 months. The ideal candidate should have experience in Amazon Redshift, Database Architecture, SQL, and Teradata.The primary responsibility of the candidate will be to assist with the migration of our data from Teradata to Amazon Redshift. They should be able to analyze our current database architecture, identify potential issues, and develop a plan to optimize the migration process. Additionally, the candidate should be able to provide support for our team during the migration process and ensure that the migration is successful.To be considered for this position, the candidate must have extensive experience in database migration, specifically between Teradata and Amazon Redshift. They should have a solid understanding of SQL and be able to troubleshoot any issues that may arise during the migration process.This effort includes some pre-sales work.  Our client is investigating the pros and cons of performing this migration and the complexities associated with it.Interested candidates should submit a proposal outlining their experience and how they can help with this project. Additionally, candidates should include links to past completed projects that demonstrate their expertise in this area.","['Teradata', 'Database Architecture', 'Amazon Redshift', 'SQL']",United States,70,48.23,31,"['Tech', 'IT']",,,Remote Job,Expert
Automated Data Mining Framework Developer (Excel/eClinicalWorks),"We are looking for a skilled and experienced developer to create an automated data mining framework capable of extracting and analyzing data from Excel files and the eClinical Works platform. The successful candidate will possess expertise in data mining, Excel manipulation, and familiarity with eClinical Works to design and develop a robust framework that can efficiently retrieve and process data.Responsibilities:- Collaborate with our team to understand the project requirements and objectives.- Design and develop an automated data mining framework capable of extracting data from Excel files and the eClinical Works platform.- Implement data extraction algorithms and techniques to efficiently retrieve and organize relevant information.- Develop scripts or code snippets to manipulate and clean data extracted from various sources.- Create mechanisms to validate and verify the accuracy of the extracted data.- Integrate the framework with existing data analysis tools or develop new analysis functionalities as needed.- Ensure the framework is scalable, efficient, and capable of handling large volumes of data.- Conduct rigorous testing to validate the framework's functionality and performance.- Provide documentation and instructions for the client to understand and effectively use the data mining framework.Requirements:- Proven experience in developing automated data mining frameworks or similar solutions.- Expertise in data extraction techniques from Excel files and familiarity with eClinical Works.- Proficiency in programming languages such as Python, R, or other relevant languages for data manipulation and analysis.- Strong understanding of data structures, algorithms, and data cleaning methodologies.- Familiarity with data analysis and visualization tools such as Excel, Tableau, or Power BI.- Ability to design and implement scalable and efficient solutions for handling large volumes of data.- Excellent problem-solving skills and attention to detail to ensure accurate data extraction.- Strong communication skills to collaborate effectively with the team and understand client requirements.- Ability to work independently, meet project deadlines, and provide timely updates on progress.- Prior experience working on healthcare or clinical data mining projects is a plus.To apply for this position, please provide examples of previous data mining frameworks or projects you have developed, highlighting your experience with Excel and eClinical Works integration. Additionally, include your proposed timeline and cost estimate for completing the project.Note: The selected candidate will be required to sign a confidentiality agreement to protect the client's data privacy and comply with all relevant data protection regulations.","['Data Mining', 'Microsoft Power BI', 'Python', 'Microsoft Excel', 'eClinicalWorks', 'Data Analysis', 'eClinicalWorks', 'Data Analysis']",United States,2,,,"['Science', 'Medicine']",,,Remote Job,Expert
Setup My Google Analytics 4,"I am looking for someone to setup our Google Analytics 4. I tried myself, but it was far too confusing. We primarily use GA to monitor website traffic and track our advertising campaigns with UTM codes and Conversion Goals. That is all we are looking to do in GA4. I am looking for someone to set up GA4 and then provide me with a brief demo of how we can accomplish the same things we use GA for.","['Google Analytics', 'Analytics']",United States,4,,,,,"['75.00', '120.00']",Remote Job,Expert
Data Analytics and Google Sheets Expert,"We are looking for an analytical and numbers-focused data analyst to produce a complex spreadsheet for our ecommerce business.Your role will be to help us store and organise all of our cost of goods for all products we sell, across a range of suppliers and countries. All suppliers offer the same products, but some suppliers are cheaper for some products/SKUs, and some are cheaper when shipping to certain countries.The information you will be provided will include:• Supplier name• Product / SKU name• Cost per unit• Shipping cost per unit to a range of countriesWe have multiple suppliers and add more quite often. We are now struggling to compare pricing across suppliers and countries to understand which supplier we should use for each product, depending on the country we are shipping to.We need the hired candidate to complete the following tasks:• Creation and maintenance of a complex spreadsheet detailing the costs of all SKUs across all suppliers, with shipping costs to multiple countries• Using conditional logic to highlight the most cost effective supplier for each SKU in each country we operate.• Adding new SKUs to the spreadsheet in coordination with the CEO and new product development manager.• Advise CEO on changing suppliers in order to achieve lower cost of goods if spreadsheet reveals new opportunities in this areaThere may be opportunity for further work to make the spreadsheet even more complex, as sometimes suppliers can ship multiple products together in one shipment, and therefore charge a 'bundled' shipping cost. Here are some scenarios for example:A Poster costs $5 and the shipping cost is $5.A Greetings Card costs $1 and the shipping cost is $3.But if shipped together, the shipping cost is $5.A Poster costs $5 and the shipping cost is $5.But if we ship 2 posters to the same location, the shipping cost is only $6, not $10.If you are highly analytical and skilled in creating complex spreadsheets with a range of variables and conditional logic, please apply.We want the spreadsheet to be formatted with a tab for each supplier. On this tab will be the full price lists for all SKUs and shipping costs for each SKU.We then want a summary/dashboard tab which shows the best supplier for each SKU when shipped to a range of different countries.I would be happy to provide a walkthrough of our current spreadsheet to the hired candidate.Thank you","['Operations Analytics', 'Sales Analytics', 'Product Analytics', 'Dashboard', 'Google Sheets', 'Data Visualization', 'Data Analysis', 'Analytics', 'Excel Formula', 'Microsoft Excel', 'Data Analysis', 'Analytics', 'Excel Formula', 'Microsoft Excel']",United Kingdom,351,15.38,401,"['Retail', 'Consumer Goods']",,"['40.00', '75.00']",Remote Job,Expert
Yolo v8 vehicle detection and tracking model improvement,"Need a skilled computer vision and deep learning expert to improve our Yolo v8 vehicle detection and tracking model. Project uses OpenCV, Python, and PyTorch.Detection model was moved from Yolo v3 over to v8. Detection is working  but need ways to benchmark the results and suggestions to improve results.Current model uses sort tracking method to track vehicle movements. See attachment.","['PyTorch', 'Python', 'Computer Vision', 'Machine Learning', 'OpenCV', 'Deep Learning', 'Neural Network', 'OpenCV', 'Deep Learning', 'Neural Network']",United States,244,16.72,54,,,"['30.00', '80.00']",Remote Job,Expert
Data Engineer for Cloud-Based Data Repository,"We seek an experienced Data Engineer to build and maintain a cloud-based data repository and lead management system using Google Cloud Platform (GCP) or Amazon Web Services (AWS). The ideal candidate will have expertise in data warehousing, data processing, and data analytics using cloud services and a strong background in Python and integration with external APIs.Design and develop a cloud-based data repository and lead management system using GCP or AWS based on the provided project overview and product requirementsImplement data extraction, transformation, and loading (ETL/ELT) processes to integrate various data sources and data-appending services seamlessly.Utilize Google BigQuery or a similar data warehousing solution to manage large datasets and perform complex analytics.Develop data processing and filtering features for lead generation based on specific rules.Integrate the system with external APIs and webhooks for data import.Ensure the system complies with relevant data protection regulations (e.g., GDPR, CCPA)Collaborate with our team to conduct testing and QA processesProvide ongoing support and maintenance for the system after deploymentRequirements:At least 5 years of experience in data engineering, with a focus on cloud-based solutions (GCP or AWS)Strong proficiency in Python programming and web frameworks such as Django or FlaskExtensive experience with data warehousing solutions, such as Google BigQuery, Amazon Redshift, or SnowflakeKnowledge of ELT and ETL processes and experience with popular ETL/ELT tools and frameworks (e.g., Apache NiFi, Talend, Microsoft SSIS)Experience with API integration, webhooks, and Python libraries for handling data (e.g., Pandas, NumPy)Understanding of data security and compliance best practicesExcellent problem-solving and critical thinking skillsStrong communication and collaboration abilitiesNice-to-Have:Experience with data processing and analytics tools or libraries in PythonFamiliarity with lead management or CRM systemsBackground in working with large datasets and complex analyticsTo apply for this position, please submit a proposal detailing your relevant experience and how you can assist with this project. Please also include links to past completed projects that demonstrate your skills in this area. We look forward to hearing from you.","['Data Engineering', 'Database Design', 'Data Preprocessing', 'Data Integration', 'Microsoft Excel', 'Amazon Web Services', 'Python', 'MySQL', 'ETL Pipeline', 'MySQL', 'ETL Pipeline']",United States,31,13.35,140,,1500.00,,Remote Job,Intermediate
Archiving Google Analytics 3 Data,"I would like someone to login to our Google Analytics 3 account and archive the following data (in spreadsheets) for the last 4 years:Source/Medium, Top Pages, Channel, DeviceI am also to any recommendations that the contractor recommends too. Someone well versed in Google Analytics is preferential","['Data Analysis', 'Report', 'Google Analytics', 'Microsoft Excel', 'Data Entry', 'Data Entry']",United States,15,200.00,15,,200.00,,Remote Job,Intermediate
"Data Analyst, Engineer, Excel & Google Sheets Expert", Automate repetitive tasksInsurance Agency The goal is to organize and analyze the data and generate an output file—an experienced Data Analyst who can provide automation to data cleansing. I want to automate the manual process to include a data entry form that automatically populates a table - and then creates the charts. These tables must be updated as data is entered over time—everything from our CRM exports in CSV format.,"['Microsoft Excel', 'Google Sheets', 'Data Analysis', 'Data Analysis']",United States,31,13.35,140,,,"['45.00', '75.00']",Remote Job,Intermediate
"Data Analyst - Excel Power Query, Power Pivot & Power BI","I'm seeking a skilled tutor in Power Query, Power Pivot, and Power BI to help me analyze a lot of complex sales data. I'm about to buy a business with a large but messy sales data set. I need to slice and dice it to identify key trends over time. The initial focus will be tutoring me so I can understand the tools, analyze data, transform it, and make dashboards independently. Once I understand the system, you'll transition to doing more complicated analysis independently and then providing weekly reports on an ongoing basis based on our updated weekly sales numbers.   After the acquisition, the analysis will become more challenging as we will be switching accounting systems. You'll need to merge both data sets so I can see sales trends over time without that data getting interrupted.","['Microsoft Power BI', 'Microsoft Excel PowerPivot', 'Data Analysis', 'Microsoft Excel', 'Power Query', 'Microsoft Power BI Development', 'Data Analysis', 'Microsoft Excel', 'Power Query', 'Microsoft Power BI Development']",United States,32,40.64,62,,,"['40.00', '150.00']",Remote Job,Expert
"Data Analyst, Engineer, Excel & Google Sheets Expert", Automate repetitive tasksInsurance Agency The goal is to organize and analyze the data and generate an output file—an experienced Data Analyst who can provide automation to data cleansing. I want to automate the manual process to include a data entry form that automatically populates a table - and then creates the charts. These tables must be updated as data is entered over time—everything from our CRM exports in CSV format.,"['Microsoft Excel', 'Google Sheets', 'Data Analysis', 'Data Analysis']",United States,31,13.35,140,,,"['45.00', '75.00']",Remote Job,Intermediate
"Data Analyst - Excel Power Query, Power Pivot & Power BI","I'm seeking a skilled tutor in Power Query, Power Pivot, and Power BI to help me analyze a lot of complex sales data. I'm about to buy a business with a large but messy sales data set. I need to slice and dice it to identify key trends over time. The initial focus will be tutoring me so I can understand the tools, analyze data, transform it, and make dashboards independently. Once I understand the system, you'll transition to doing more complicated analysis independently and then providing weekly reports on an ongoing basis based on our updated weekly sales numbers.   After the acquisition, the analysis will become more challenging as we will be switching accounting systems. You'll need to merge both data sets so I can see sales trends over time without that data getting interrupted.","['Microsoft Power BI', 'Microsoft Excel PowerPivot', 'Data Analysis', 'Microsoft Excel', 'Power Query', 'Microsoft Power BI Development', 'Data Analysis', 'Microsoft Excel', 'Power Query', 'Microsoft Power BI Development']",United States,32,40.64,62,,,"['40.00', '150.00']",Remote Job,Expert
"Looking for a Google Sheets and Excel expert to build various models, filters and functions","Looking for an experienced Google Sheets and Excel expert with advanced data analysis and modeling abilities. My preference is to use Google Sheets for projects.What we are doing:I have various datasets and models that need to be further developed. Sometimes these are relatively simple tasks, other times I need more complex modeling and functions. The first project involves filtering data from a large dataset with thousands of rows across multiple sheets. The dataset is attached. I will need you to do the following:- Filter rows by key words- Remove any duplicate rows - Perform any necessary data cleaningRows should be kept that have any of the below keywords:""Fest""""Festival""""Convention""""Con""""Food & Wine""""Jamboree""""Music & Arts""""Music""""Open""If a row has any of the below keywords, then the row should be removed:""Theater"" (remove)""Amphitheatre"" (remove)""Arena"" (remove)""Ballroom"" (remove)""Tour"" (remove)""Club"" (remove)""Stadium"" (remove)This will be the first of many projects. To be a best fit for this project you need:- Ability to communicate clearly- Dedication to meet project deadlines in a timely manner- Experience in modeling, excel, google sheets, formulas, data analysis - Write “I am a human” at the top of your proposal- Attention to detailsIf my team likes the deliverable, we will consider you for similar future projects.","['Microsoft Excel', 'Google Sheets', 'Data Analysis', 'Spreadsheet Software', 'Data Cleansing', 'Data Analysis', 'Spreadsheet Software', 'Data Cleansing']",United States,24,17.13,112,,,,Remote Job,Expert
"Excel data cleaning , merging , data split , highlighting data.","Good at excel data cleaning, merge, split ,highlighting data ,converting pdf to excel","['Microsoft Excel', 'Data Entry', 'Spreadsheet Software', 'Google Sheets', 'Data Visualization', 'Spreadsheet Software', 'Google Sheets', 'Data Visualization']",United Arab Emirates,1,,,,,"['10.00', '30.00']",Remote Job,Intermediate
Google Analytics Consultation,"1. Looking for guidance on GA4 migration/setup and Google Tag Manager setup. 2. I would like the freelancer to walk me through the various aspects of setup, troubleshooting and provide oversight into the best approach.3. Availability to do an over-the-shoulder instruction via screen share is ideal.  Here are a list of topics I'd like to cover (or as many of these topics  as possible):1.1 Tracking Code Implementation 1.2 Placement of Tracking Code 1.3 Missing Code 1.4 Migration from UA 1.5 Connected Site Tags 1.6 Consent aware tracking 2.0 GA4 Configuration 2.1 User Permissions / Roles 2.2 Reporting Time Zone 2.3 Data Streams 2.4 Enhanced Measurement 2.5 Filters 2.6 Internal Traffic 2.7 Referral Exclusions 2.8 Cross-Domain Tracking 2.9 Data Collection 2.10 Google Signals 2.11 Data Retention Period 3.0 Data Quality 3.1 Discrepancy in User Count (with UA) 3.2 Engagement Rate 3.3 Query Parameter Exclusion 3.4 (not set) in Reports 3.5 Default Reporting Identity 3.6 Attribution Model 3.7 Lookback window 3.8 PII (Personally Identifiable Information) 4.0 Measurement 4.1 Campaign Data with UTM usage 4.2 Custom Event Tracking 4.3 Event Parameters 4.4 Custom Dimensions/Variables 4.5 Naming Convention (Snake case) 4.6 Custom Metrics 4.7 Data Imports 4.8 User-ID 4.9 Remarketing 4.10 Audiences 4.11 Site Search 4.12 Content Grouping 4.13 Measurement Protocol 5.0 Conversions 5.1 Macro Conversions 5.2 Micro Conversions 5.3 Ecommerce Tracking 5.4 Conversion Migration from UA 5.5 Goal Funnels (Funnel Viz) 5.6 Path Exploration 5.7 Predictive audiences 6.0 Account Linking 6.1 Google Ads","['Google Analytics', 'Google Tag Manager', 'BigQuery', 'BigQuery']",United States,1,,,,,"['30.00', '75.00']",Remote Job,Expert
Data Engineer (40 hrs/week for 6 months) on US work hours,"Looking for Data Engineer Contract (6 months) US remote. Design, develop and implement real time data ingestion pipelines from multiple sources using Data bricks.Develop high-quality, scalable, and re-usable frameworks for ingesting high volume and large data sets.Apply best practices to Integrate and ingest various big data formats like Protobuf, Parquet, AVRO, and JSONWork with event based / streaming technologies like Kafka, or Kinesis, to ingest and transform the data using Kafka Streams or KSQL","['Apache Kafka', 'Data brick']",United States,35,20.28,14,,,"['55.00', '65.00']",Remote Job,Intermediate
Lightspeed Analytics Database Manager,"Our existing Lightspeed database needs to be exported and housed in an Excel spreadsheet.  The database needs to be wiped clean and start from scratch.  We have approximately 400 unique items that we sell.  These items need to be recreated in Lightspeed with proper matrix.  Age (Youth or Teen), Size (XS, S, M, L, XL, XXL), Color (Pink, Purple, Blue, Green, White, Tan, Gray, etc.), Category (Bottoms, Tops) Sub Category (Shorts, Sweats, TShirts, Sweatshirts, Crop Tops, Hoodies, Tank Top, Bras, etc.) .  All reports must be able to export with a column header that matches all of these classifications (Age, Size, Color, Category, Sub Category).  This project will require that the inventory quantities are entered accurately by item,  and that our supplier site is connected via SAP in the back end (S&S Apparel) and that PO's can be input and tracked as new inventory arrives.  This project will essentially be to create an entirely new database for our 6 stores plus our ECommerce store.  Only individuals with previous experience should apply.  We will provide an excel file with the proper Item Name and classification as indicated above for every item.  This individual will then take that information and input it into Lightspeed so that we are able to track and manage our inventory.  We also have non-inventory items to sell as well, that will also need to be set up in the system.  We will just be tracking sales and not inventory on the non-inventory items.","['Microsoft Excel', 'Data Entry', 'Database', 'Data Mining', 'Analytics', 'Database', 'Data Mining', 'Analytics']",United States,1,,,,1500.00,,Remote Job,Expert
Reinforcement Learning Freelancer Needed for Double Inverted Pendulum Project,"I am seeking an experienced and knowledgeable reinforcement learning freelancer to work on an project involving the implementation of reinforcement learning algorithms, specifically SAC (Soft Actor-Critic) or PPO (Proximal Policy Optimization). The goal of the project is to develop a control system for a double inverted pendulum.Responsibilities:* Design and implement a reinforcement learning framework using SAC or PPO algorithms to control a double inverted pendulum.* Develop and optimize the RL agent's policies and value functions to achieve stable and efficient control of the pendulum system.* Customize the RL algorithms and hyperparameters to suit the dynamics and requirements of the double inverted pendulum.* Fine-tune the agent's performance through iterative experimentation and evaluation.* Collaborate with me to understand project requirements and provide regular updates on progress.* Document the project, including the implemented algorithms, methodologies, and key findings.Requirements:* Proven experience in reinforcement learning and deep learning algorithms.* Strong understanding of SAC or PPO algorithms and their application to control systems.* Proficiency in Python and experience with popular RL libraries/frameworks (e.g., Stable Baselines, OpenAI Gym).* Solid understanding of control systems and dynamics.* Familiarity with physics-based simulations and robotic control.* Ability to work independently and deliver high-quality results within agreed-upon timelines.* Excellent communication skills to effectively collaborate and provide project updates.Nice to have:* Experience with other RL algorithms such as DDPG, TRPO, or A2C.* Knowledge of advanced deep learning techniques (e.g., neural networks, policy gradients).* Prior experience with inverted pendulum or similar control problems.If you are passionate about reinforcement learning and have the skills and expertise required to tackle this challenging project, I would love to hear from you. Please provide examples of your previous work in reinforcement learning, specifically highlighting projects involving SAC or PPO algorithms.Duration: The project is estimated to take approximately 2 months.Budget: Please provide your proposed budget for this project.I look forward to receiving your applications and working together to achieve remarkable results with the double inverted pendulum project.","['Reinforcement Learning', 'Python', 'TensorFlow', 'Deep Learning', 'Algorithm Development', 'Algorithm Development']",Germany,1,,,,1000.00,,Remote Job,Expert
Implementing AI to make our company much more productive operationally and much more user friendly,"We are seeking a skilled and experienced AI expert to implement AI technology to make our company more productive operationally and user-friendly. The project will last for 1 to 3 months.The successful candidate will be responsible for implementing AI that will provide our clients with seamless and personalized communication as well as increase our employees’ productivity. You will be required to implement an AI system that can help us achieve these goals.To be considered for this role, you must have a strong background in AI technology and implementation, with demonstrable experience in creating chatbots that can effectively communicate with users. You should be familiar with the latest advancements in AI technologies and have a strong working knowledge.To apply for this role, please submit a proposal detailing your experience with AI implemnetation and how you can help with this project. Please include links to past completed projects and any relevant work samples.",['AI Chatbot'],Kuwait,74,,889,,,,Remote Job,Expert
Write R Code for our baRcodeR package,"We are looking for a (paid) collaborator to help update our baRcodeR R package, which is widely used to generate barcode labels for biological samples. For more information, see:https://github.com/ropensci/baRcodeRhttps://docs.ropensci.org/baRcodeR/The package currently produces QR barcodes using the qrcode package:https://github.com/ThierryO/qrcodeWe would like to add an option to produce Data Matrix barcodes of different sizes. To do this, we are looking to hire a programmer/collaborator to write an R function that will take a string as input and output a Data Matrix barcode following standards of ISO/ICEC:16022:2006The output must be capable of producing a ggplot2 using the functions in createPDF.R and hidden_createPDF.R code in baRcodeR. For more information, see: https://github.com/ropensci/baRcodeR/tree/master/RThe final code will be similar to qr_code.R but for the Data Matrix standard. For more information, see:https://github.com/ThierryO/qrcode/blob/main/R/qr_code.R","['R', 'ggplot2', 'R Shiny']",Canada,12,14.86,2.9,,250.00,,Remote Job,Intermediate
Data Mining,"Looking for a complete list of Lawyers in the State of Texas. Preferably around the Dallas-Ft. Worth areas.  We need their Name, Company Name, Type of Law Practiced, Phone Number, Email,  and Location.","['Online Research', 'Data Mining', 'Data Scraping', 'Google Spreadsheets API', 'Data Entry', 'Google Spreadsheets API', 'Data Entry']",United States,2,,,,275.00,,Remote Job,Intermediate
Setting up and troubleshooting complex cross-domain Google Analytics + GTM triggers,"We are looking for someone with vast analytics experience to help us troubleshoot and set up UTM tracking within a single-page app using Flutter in a cross-domain setup. This individual needs to have not only analytics setup and troubleshooting capabilities, but they should have the ability to work with developers and product leads to get the appropriate triggers and event code implemented. * Must have extensive experience with Google Analytics and Google Tag Manager setup and tracking. Users should also be well-versed in the G4. * Cross-domain tracking experience is a must.* Prior experience operating between marketing and product teams.* Very helpful to have dev background experience or enough experience working with teams of developers to clearly communicate and discuss workarounds.We would have someone look at our GA/GTM setup to optimize (perhaps also ensure things are set up in the most optimal way for our marketing efforts, current and future) as well as work our tech partner to get UTM tracking set up/troubleshoot in their single page app environment. An NDA will need to be signed. Project length depends on what we find as a solution. It could take place over the next couple weeks - let's discuss!","['Marketing Analytics', 'Google Analytics', 'Google Tag Manager', 'Web Development', 'Google Analytics API', 'Analytics', 'Analytics & Tracking Setup', 'Flutter', 'Cross Domain Tracking', 'Web Development', 'Google Analytics API', 'Analytics', 'Analytics & Tracking Setup', 'Flutter', 'Cross Domain Tracking']",United States,10,41.44,4.2,,,,Remote Job,Expert
Open Source AI LLaMA Model Training Tuning Developer,"We are an eCommerce agency that's serving large enterprises as well as small startups. We're looking for an AI consultant to help implement and train an open source AI model with relevant data to deliver human like results faster and more efficiently.Some non confidential tasks we're looking to automate:- Responding to emails- Create job posts- Review resumes- Optimizing product information- Lead generation- Implement chatbotsYou will be a part of teams of back and / front end developers, DevOps, and data integration experts that will work in collaboration to make these projects successful.Thank you and happy UpWorking ","['Model Tuning', 'Machine Learning Model', 'ChatGPT', 'Artificial Intelligence', 'Machine Learning', 'Deep Learning', 'Neural Network', 'Machine Learning', 'Deep Learning', 'Neural Network']",United States,333,10.81,456,"['Tech', 'IT']",,"['18.00', '40.00']",Remote Job,Intermediate
Help me develop charts to visualize data,"I am looking for an expert chart developer to help me visualize some data points in a compelling manner. Specifically, I have some tables I'd like to show as graphs. It's not a lot of work, but if it goes well we'll have more to do in the future. I am more concerned about the quality of the graph than the design elements: I can do that on my own.",['Data Visualization'],United States,17,24.46,6.9,"['Tech', 'IT']",,"['70.00', '100.00']",Remote Job,Expert
Programming Tutor - Python/Pandas & DBT,"We are seeking a highly skilled and passionate  Programming Tutor to work as a freelancer and help a single developer who already has some knowledge of Python and Pandas to expand their skills and knowledge in these areas. As a Programming Tutor, you will be responsible for creating lesson plans and exercises that are tailored to the specific needs of the developer. The ideal candidate should be familiar with technologies such as machine learning, DBT or other areas of expertise that might useful to learn for a data professional.Responsibilities:Create customized lesson plans and exercises that are tailored to the developer's needsHelp the developer understand complex concepts in Python and PandasProvide guidance and feedback on code quality and best practicesEncourage and motivate the developer to continue learning and expanding their knowledgeStay up-to-date with the latest trends and advancements in Python and Pandas, as well as related technologies such as machine learning and DBTEvaluate the effectiveness of the lesson plans and adjust them as necessaryCollaborate with the developer to ensure the best possible learning experienceRequirements:Strong proficiency in Python and PandasExcellent communication and teaching skillsExperience with creating lesson plans and exercisesFamiliarity with machine learning and DBT technologiesAbility to work independently and as part of a teamStrong problem-solving skills and attention to detailFlexibility to adapt to changing priorities and requirementsAvailability to work on a freelance basis with a single developer.","['Python', 'pandas', 'NumPy', 'Data Science']",Sweden,2,,0,"['Tech', 'IT']",,"['10.00', '32.00']",Remote Job,Intermediate
Business Analytics,"Buenas tardes, busco un analista de negocios que me ayude a analizar mi emprendimiento en cuanto al desarrollo del mismo y me ayude a mejorar el branding, me gustaría que sea una persona con experiencia en administración y también con experiencia en marketing, redes sociales y diseño digital. El trabajo es 100% en españolQue herramientas utilizara?actualmente estoy usando figma y  balsamiq para diseñaren lo administrativo estoy con sql, power point, power bi, tableau, data studio, excel algunos script de automatización para conciliaciones en PythonSi consideras que me podes ayudar, estare agradecido de recibir tu propuesta.","['Google Analytics', 'Business Intelligence', 'Marketing Strategy', 'Microsoft Excel', 'Business Analysis', 'Data Analysis', 'Business Modeling', 'Facebook', 'Business Plan', 'Social Media Marketing', 'Marketing Strategy', 'Microsoft Excel', 'Business Analysis', 'Data Analysis', 'Business Modeling', 'Facebook', 'Business Plan', 'Social Media Marketing']",Argentina,1,,,,,"['40.00', '75.00']",Remote Job,Expert
Need Google Sheet Pro to Double Check Existing Formulas,"Looking for an ongoing google sheets expert. Few hours here and there, more hours long term.First task will be double checking how we are doing some things currently.If interested, reply with your favorite data visualization project (see - dashboard), and then also include your favorite food in the first line of our application.Gracias",['Google Sheets'],United States,12,12.88,5,"['Finance', 'Accounting']",,"['10.00', '30.00']",Remote Job,Intermediate
Seeking Ecommerce Data analytics expert.,"Looking for someone to provide analysis on our current Amazon Attribution strategy. Create a data analytics dashboard to measure inflowing traffic to Amazon from multiple channels. Provide us with insight as to which marketing channels are providing best conversions.Familiarity with TikTok, Twitter, and Facebook Ad Buying preferred but not required.","['Amazon Attribution', 'Facebook Ads Manager', 'TikTok Ad', 'Google Analytics', 'TikTok Ad', 'Google Analytics']",United States,11,12.37,1,,1200.00,,Remote Job,Intermediate
Google Analytics Specialist,Migration from Universal Analytics to Google Analytics,"['Google Analytics', 'universal analytics', 'Web Development', 'Web Development']",United States,1,,,"['Tech', 'IT']",,"['18.00', '45.00']",Remote Job,Intermediate
Urgent Power BI Report Development Project,"Our organization urgently needs a proficient Power BI developer with immediate availability. We require the development of two custom reports that will draw upon our Microsoft Dynamics and SharePoint data. If you can begin this project quickly, we would love to hear from you.Project Overview:Our company currently leverages the Microsoft Power BI environment (https://app.powerbi.com/) to manage a myriad of reports and datasets, which integrate data from our Dynamics environment (OData feed Data Source) and Excel files housed in SharePoint (Excel Workbook Data Source).Here are the two reports that we require:Inventory Forecast Report: This report will consolidate data from our Dynamics system and a SharePoint sales forecast Excel file. The aim is to visualize future weeks' inventory per item, considering the current quantity on hand, sales forecasts (presently stored in Excel on SharePoint), and a production forecast derived from our Dynamics system.Production Planning Guide: The second report will utilize the same data sources as the first one, with an additional feature - for each item, we'll establish minimum and maximum weeks on hand. The report should then calculate the quantity required to add to each week's production forecast to meet the minimum and maximum targets.Sample: Please refer to 'Forecast report mock_ups v2.xlsx' for a rough outline of our requirements.Given the time-sensitive nature of this project, we are prepared to proceed quickly with the right candidate. Please provide us with a quotation for your services, including a proposed timeline for completion.","['Query Development', 'Microsoft Power BI', 'SQL', 'Data Analysis', 'Business Intelligence', 'Data Analysis', 'Business Intelligence']",United States,3,,,,,"['70.00', '100.00']",Remote Job,Expert
Google Analytics Specialist,Migration from Universal Analytics to Google Analytics,"['Google Analytics', 'universal analytics', 'Web Development', 'Web Development']",United States,1,,,"['Tech', 'IT']",,"['18.00', '45.00']",Remote Job,Intermediate
Urgent Power BI Report Development Project,"Our organization urgently needs a proficient Power BI developer with immediate availability. We require the development of two custom reports that will draw upon our Microsoft Dynamics and SharePoint data. If you can begin this project quickly, we would love to hear from you.Project Overview:Our company currently leverages the Microsoft Power BI environment (https://app.powerbi.com/) to manage a myriad of reports and datasets, which integrate data from our Dynamics environment (OData feed Data Source) and Excel files housed in SharePoint (Excel Workbook Data Source).Here are the two reports that we require:Inventory Forecast Report: This report will consolidate data from our Dynamics system and a SharePoint sales forecast Excel file. The aim is to visualize future weeks' inventory per item, considering the current quantity on hand, sales forecasts (presently stored in Excel on SharePoint), and a production forecast derived from our Dynamics system.Production Planning Guide: The second report will utilize the same data sources as the first one, with an additional feature - for each item, we'll establish minimum and maximum weeks on hand. The report should then calculate the quantity required to add to each week's production forecast to meet the minimum and maximum targets.Sample: Please refer to 'Forecast report mock_ups v2.xlsx' for a rough outline of our requirements.Given the time-sensitive nature of this project, we are prepared to proceed quickly with the right candidate. Please provide us with a quotation for your services, including a proposed timeline for completion.","['Query Development', 'Microsoft Power BI', 'SQL', 'Data Analysis', 'Business Intelligence', 'Data Analysis', 'Business Intelligence']",United States,3,,,,,"['70.00', '100.00']",Remote Job,Expert
AI Data Scrapper,I am looking for software developed to allow me to scrape amazon and other e-commerce sites and extract real-life testimonials and categorize pain points for supplement and health buyers.,"['Online Research', 'Data Scraping', 'Data Mining', 'Machine Learning', 'Data Extraction', 'Artificial Intelligence', 'Machine Learning', 'Data Extraction', 'Artificial Intelligence']",United States,162,4.82,24,"['Sales', 'Marketing']",,"['7.00', '21.00']",Remote Job,Expert
Scrape a small online directory,"I need to scrape this online directory for 3 types of users. https://red.prod.secure.nv.gov/Lookup/LicenseLookup.aspxI need all ACTIVE records for license pre-fixes S, BS and B.Site has some basic human verifications, and I've had freelancers work with it in the past.Please run a quick check and include an attachment of 10 records. I'll respond to every inquiry with this attachment and looking to select a partner today.","['Data Scraping', 'Python']",United States,2,34.16,0,['Automotive'],,"['8.00', '25.00']",Remote Job,Intermediate
Need WebScraper.io Expert for Linkedin Sales Navigator,"We are looking for a skilled web scraping expert who has experience with webscraper.io and can help us extract data from LinkedIn Sales Navigator.As our ideal candidate, you should have a strong background in data scraping and have in-depth knowledge of webscraper.io or another comparable parser. You should be able to extract data from LinkedIn Sales Navigator efficiently and accurately. Your main responsibilities will be to create a webscraper.io project that can extract data from LinkedIn Sales Navigator based on specific criteria and deliver the data in a usable format. You will work closely with our team to understand the requirements and ensure that the final deliverable meets our expectations.To apply for this job, please submit a proposal that details your experience with webscraper.io and data scraping. Please include links to past completed projects that demonstrate your expertise in this area. We look forward to hearing from you and working with you on this project.Deliverable = a crawling sequence that I can run on my browser","['webscraper.io', 'Data Scraping']",United States,88,6.66,15,,,"['8.00', '25.00']",Remote Job,Intermediate
NLP developer to help develop Bulgarian Grammar Error Correction model,"I am looking for a person with machine learning experience, preferably Bulgarian. The goal is to create a Web-based AI model, that can correct grammatical mistakes for the Bulgarian Language. I am a novice in NLP, so I need someone to either help me create the model or someone to outright do it.  The project is not time-sensitive.","['Natural Language Processing', 'Python', 'Machine Learning', 'Python', 'Machine Learning']",Bulgaria,1,,,,,,Remote Job,Intermediate
Traffic Data Collection Tool,"Traffic Data Collection Tool(c) 2023 Sampson Engineering LLCCollecting traffic data at signalized intersections.44 buttons for data incrementing by movement.4 data fields for coding Unmet values by period.Buttons to include appropriate labels and arrows.Pressing most buttons increases the value by 1.Timer set to flag and open Unmet at 12 minutes.Timer to reset all values to 0 at 15 minutes.Data stored to CSV file by 15-minute period.Format will be provided for analysis importing.Built to work on iPhones, Androids and Windows.See attached file for the preliminary design.","['Mobile App Development', 'CSV Format', 'Mobile App', 'CSV Format', 'Mobile App']",United States,3,,0,"['Engineering', 'Architecture']",,,Remote Job,Intermediate
Generative AI Video Creator,"We need to submit a short trailer for a sci fi movie project. We have the text and the images and the story plot. We need excellent English language skills, responsive and creative. Prior work with a sci fi assignment would be preferred.","['Adobe Premiere Pro', 'Video Production']",United States,1,,,,,"['36.00', '70.00']",Remote Job,Expert
Build Custom Stripe App that only shows dashboard with revenue but no customer data,Stripe's native user permission sets do not allow me to add a user who can see the revenue (on the dashboard specifically) without also having access to customer data like email and phone number.I am looking for someone to create a solution for me to have a user see the dashboard and the revenue reported there but not have the ability to access customer information.,"['Stripe', 'Stripe API', 'Stripe SDK']",United States,1,,,,,"['18.00', '45.00']",Remote Job,Intermediate
Python Data Connectors,"Connections are of 2 kinds: data source and alert channel. Data sources retrieve either historical or live data from various sources, typically REST APIs, and send it to either Elastic or Kafka. Alert channels listen to Kafka topics, apply certain criteria to the data, and if the criteria are met, send an event to a data sink (also typically a REST API).The framework code and examples of other connectors are already available.We are looking for a mid-level or senior developer who can write clean, well-documented and tested code that is robust to edge cases such as missing data, and who can work with a degree of independence. We can provide an introduction to our existing code base and show where the connectors should be implemented.","['Python', 'Data Scraping', 'Data Mining', 'API', 'API']",Saudi Arabia,1,,,,,"['25.00', '35.00']",Remote Job,Intermediate
Google Analytics set up,"I have google analytics set up, but i need someone to go in an make sure that everything is perfectly connected and set up the best it can be","['Google Analytics', 'Analytics']",United States,121,7.97,20,"['Sales', 'Marketing']",20.00,,Remote Job,Intermediate
Excel Expert with Accounting Experience Needed Immediately,"We have an urgent need for immediate assistance and are seeking a talented and experienced individual who is an Expert in Spreadsheet and Excel Dashboard Development, with experience in accounting. In this project, you will effectively analyze a complex spreadsheet and utilize your accounting expertise to populate it with the company’s data. Your expertise in advanced formulas and data visualization will be crucial.This is a one-time project, that includes the following tasks:•Analyze and understand the structure and formulas of a complex spreadsheet.•Identify and organize the company’s data into the spreadsheet.•Apply accounting principles and practices to ensure the accuracy and integrity of the data.Requirements:•Proven experience as a Spreadsheet and Dashboard Excel Expert, preferably in an accounting or finance role.•In-depth knowledge of Microsoft Excel including advanced functions, formulas, and data visualization techniques.•Strong analytical skills and the ability to interpret complex data sets. •Solid understanding of accounting principles and financial concepts. •Excellent attention to detail and accuracy in data handling.Note: Please only apply if you are a native or bilingual English speaker.To apply for this job, please submit a detailed proposal outlining your experience and how you can help us with this project.We look forward to receiving your application.Thanks.","['Data Analytics', 'Data Visualization', 'Dashboard', 'Microsoft Excel', 'Accounting', 'Financial Accounting', 'Excel Formula', 'Spreadsheet Skills', 'Financial Accounting', 'Excel Formula', 'Spreadsheet Skills']",United States,15,9.15,17,,250.00,,Remote Job,Expert
Data Mining Specialist for Real Estate Project,"We are seeking an experienced data mining specialist with a solid understanding of the real estate market to compile a database of specific properties according to our criteria.The task at hand requires data of houses that meet these requirements:- Properties that haven't sold in the last 5 years.- Houses with 3 or less bedrooms and 3 or less bathrooms.- Homes located in the following zip codes: 75205, 75209, 75219, 75283, 75284, 75391, 75225, 75275.Deliverables:The successful candidate will provide us with an Excel database that includes the following:Address of the propertyNumber of bedroomsNumber of bathroomsThe year the house was last sold (if available)The house's square footagePlease note that accuracy and completeness of the information are paramount.","['Microsoft Excel', 'Online Research', 'Data Mining', 'Web Scraping', 'MLS Consulting', 'Data Scraping', 'MLS Consulting', 'Data Scraping']",United States,3,22.00,164,,50.00,,Remote Job,Entry level
AI Engineer,"AI Engineer needed to show small company how to use AI to create voice and ( Avatars?) using existing, non technical tools. Immediate start. About  5-10 hours of consulting needed.",['Artificial Intelligence'],United States,105,7.25,168,,,"['55.00', '200.00']",Remote Job,Intermediate
Web Scraper Training Support (webscraper.io and/or Python),"I'm looking for someone to train me in the use of the Chrome Web Scraper extension (webscraper.io). I have an immediate need, which is to scrape job postings. I'm also interested in learning how to build my own scraper with Python. I'm tech savvy (am an advanced Excel / Sheets user) and a fast learner. If we establish an effective working relationship I would like you to be my coach for occasional, ongoing work learning to code in Python. I'm particularly interested in working with someone in Australia or Melbourne but that's not essential, as long as our time zones work.","['Beautiful Soup', 'Data Scraping', 'Data Mining', 'Python', 'Selenium', 'Training', 'Python', 'Selenium', 'Training']",Australia,3,,20,,,"['8.00', '65.00']",Remote Job,Intermediate
Behavior Technician Panel,We are trying to put together a panel of Behavior technicians to discuss ABA topics.  We work with ABA practices all over the country and we would love to get feedback about the work environment from BTs to help our owners with turn over and creating a better place to work.,"['RBT', 'Applied Behavior Analysis']",United States,317,17.33,82,,,"['20.00', '30.00']",Remote Job,Expert
RxG Unit Troubleshooting and Performance Analysis Specialist,"We are currently seeking an experienced and knowledgeable RxG Unit Troubleshooting and Performance Analysis Specialist to help us address ongoing ping and packet loss issues. We recently decommissioned one of our old RxG units due to intermittent connectivity problems, and now we are experiencing similar symptoms with two other deployed units. We need someone who can thoroughly investigate and identify the root cause of these issues.Responsibilities:Conduct a comprehensive analysis of the problematic RxG units to understand the intermittent ping and packet loss issues.Access the units remotely or on-site, depending on the situation, to gather detailed information and perform diagnostic tests.Collaborate with internal stakeholders to gather additional information about the network infrastructure and any recent changes or updates that might have affected the units.Utilize your expertise to identify potential causes of the connectivity problems, such as hardware malfunctions, software conflicts, or network configuration issues.Perform in-depth troubleshooting and diagnostic procedures to isolate the root cause of the ping and packet loss issues.Provide detailed reports and documentation on your findings, including a clear explanation of the problem, possible causes, and recommended solutions.Collaborate with the relevant teams to implement the necessary fixes and enhancements to address the identified issues.Monitor and test the performance of the fixed units to ensure the problems are resolved and the connectivity is stable.Provide knowledge transfer and training to the internal teams, enabling them to troubleshoot similar issues in the future.Requirements:Strong experience in troubleshooting and performance analysis of RxG units or similar networking devices.In-depth knowledge of networking protocols, configurations, and diagnostic tools.Familiarity with remote access technologies and techniques.Proficiency in diagnosing and resolving connectivity issues, such as intermittent ping and packet loss.Excellent problem-solving skills and ability to handle complex network problems.Strong communication skills to effectively collaborate with internal teams and stakeholders.Detail-oriented mindset with a commitment to delivering accurate and thorough analysis reports.Ability to work independently and efficiently, managing time and resources effectively.This is a contract-based position, and the duration of the project will be determined based on the complexity of the troubleshooting and analysis required.  Please provide your estimated timeline and proposed budget when applying.If you are a highly skilled RxG Unit Troubleshooting and Performance Analysis Specialist with a proven track record in resolving connectivity issues, we encourage you to apply. Help us identify and resolve the intermittent ping and packet loss issues, ensuring the stability and reliability of our deployed RxG units.","['RxG unit', 'Network Troubleshooting', 'Performance Analysis', 'Networking Protocols', 'Diagnostic Tools', 'Remote Access', 'Problem Solving', 'Communication Skills', 'Analytical Thinking ', 'Performance Analysis', 'Networking Protocols', 'Diagnostic Tools', 'Remote Access', 'Problem Solving', 'Communication Skills', 'Analytical Thinking ']",United States,7,44.62,6.5,,,"['18.00', '45.00']",Remote Job,Intermediate
Seeking an AI developer to create an AI-based proposal compliance scoring plug-in,"Initial requirement is to create a plug in to ChatGPT/OpenAI or similar that can be used to upload compliance criteria associated with a customer's requirement to then be used to evaluate a proposal document and score its level of compliance to said criteria.  The AI tool would be required to analyze objective data, but more importantly, be able to assess/score subjective text/language data based on more nuanced requirements.  The final result would be the ability to refine a proposal to be 100% compliant with a customer's requirements, thus increasing the odds of customer selection and award.","['ChatGPT Plug-ins', 'Artificial Intelligence', 'Natural Language Processing', 'Machine Learning', 'Natural Language Processing', 'Machine Learning']",United States,1,,,,,"['25.00', '27.50']",Remote Job,Intermediate
Extract all followers of the specific company from LinkedIn Sales Navigator using Python API,The candidate should have prior experience in building APIs using Python. They will be responsible for extracting all the followers of the specified company from LinkedIn Sales Navigator. It is required that the candidate possesses their own LinkedIn Sales Navigator account or is able to create a trial account.,"['Data Scraping', 'Python', 'LinkedIn Sales Navigator']",Pakistan,1,,,,60.00,,Remote Job,Intermediate
Satellite Image Analysis Expert for Change Detection Project,"We are seeking a skilled and experienced Satellite Image Analysis Expert to implement an exciting project involving the detection of changes in satellite images for a specific location at different points in time. This project aims to analyze satellite imagery data to identify and quantify changes occurring in the target area.Purpose is to automatically detect building construction over an area. Example photos attached for reference.Responsibilities:Conduct comprehensive analysis of satellite images for a specific location.Develop and implement algorithms or techniques to detect and quantify changes in the target area.Evaluate and select suitable satellite imagery datasets for the analysis.Preprocess and prepare satellite images for analysis, including data cleaning and calibration.Apply image processing and computer vision techniques to extract meaningful information from satellite images.Develop automated change detection methodologies and optimize their performance.Perform statistical analysis and validation of the results to ensure accuracy.Generate visualizations, reports, and summaries of the detected changes.Communicate project progress, findings, and recommendations.Requirements:Experience in satellite image analysis and change detection projects.Proficiency in remote sensing, geospatial analysis, and image processing.Strong programming skills in languages such as Python, R, or MATLAB.Knowledge of satellite image processing techniques, including image registration, normalization, and enhancement.Familiarity with popular remote sensing software and libraries, such as ENVI, ArcGIS, or QGIS.Ability to develop and implement algorithms for change detection and feature extraction.Strong analytical and problem-solving skills.Excellent communication and collaboration abilities.Knowledge and experience in a relevant field (e.g., Remote Sensing, Geographic Information Systems, Computer Science, or a related discipline).Additional Information:Project Duration: Approximately 1-3 months (may vary based on the complexity of the project)Hours: Part-time or full-time (to be discussed with the selected candidate)Remote work: The position is fully remote.Language: English proficiency is required.Project Budget: To be discussed based on qualifications and experience.If you are passionate about satellite image analysis, change detection, and have a strong track record in similar projects, we would love to hear from you. Please provide your portfolio, including previous relevant work samples and a detailed explanation of your approach to satellite image analysis for change detection.To apply, please submit your proposal outlining your relevant experience, methodology, estimated timeline, and your expected rate. We look forward to reviewing your application and discussing the project further.Note: Only shortlisted candidates will be contacted.","['Web Development', 'GIS', 'Python', 'Image Processing', 'Image Processing']",India,1,,,,,,Remote Job,Intermediate
Google Data Studio Teacher,"I am looking for google data studio teacher that can teach me how to use it and connect it to Google Search Console, GA4 datas to create useful reporting that can save time and accurate.","['Google Data Studio', 'Google Analytics', 'Google Docs', 'Google Sheets', 'Data Visualization', 'Google Docs', 'Google Sheets', 'Data Visualization']",Indonesia,28,7.64,6.9,"['Tech', 'IT']",,"['7.00', '12.00']",Remote Job,Expert
Phd Social Science - 1 Hour Consultation,"!!!GENERIC APPLICATION WILL BE IGNORED!!!Are you a PhD holder with extensive knowledge and experience in social sciences? Are you passionate about mentoring and guiding aspiring researchers on their PhD journey? I am currently seeking a highly qualified and experienced person to provide consultation to a Phd candidate.Responsibilities:- Provide expert guidance and consultation to individuals pursuing a PhD program in social sciences.- Assist in identifying and evaluating potential PhD programs that align with the candidate's research interests and career goals.- Advise on the preparation and execution of the PhD scholarship application process, including crafting research proposals and preparing for interviews.Requirements:- Hold a PhD degree in social sciences or a related field.- Extensive understanding of different PhD programs in social sciences.- Excellent communication and interpersonal skills.- Ability to provide constructive feedback and guidance to supportTo apply provide evidence of your credentials and experience.","['Social Science', 'Sociology', 'Phd ', 'Phd ']",Australia,15,11.77,989,"['Tech', 'IT']",50.00,,Remote Job,Expert
Google Analytics GA4 Ecommerce Implementation,"Project Title: Google Analytics GA4 Ecommerce Implementation for Marketplace Conversions Tracking on Sugarwod.comOverview:Sugarwod.com is an online fitness platform that offers a marketplace for coaches and athletes to connect and purchase workout programs and other fitness-related products. The website is looking to implement Google Analytics GA4 ecommerce tracking to better understand user behavior and track marketplace conversions.Objectives:The objectives of this project are to:Implement GA4 ecommerce tracking on Sugarwod.com to accurately track user behavior and marketplace conversions.Develop a custom event tracking strategy to track key user actions, such as product views, add to cart, checkout, and purchase.Create a dashboard in GA4 to visualize the data and generate insights into user behavior and marketplace performance.Provide documentation on the implementation process and custom event tracking strategy for future reference.Scope of Work:The scope of work for this project includes:Conducting an audit of the current Google Analytics implementation on Sugarwod.com and identifying any potential issues or gaps in tracking.Implementing GA4 ecommerce tracking code on Sugarwod.com and configuring the necessary settings to track marketplace conversions.Developing a custom event tracking strategy to track key user actions, such as product views, add to cart, checkout, and purchase.Creating a dashboard in GA4 to visualize the data and generate insights into user behavior and marketplace performance.Providing documentation on the implementation process and custom event tracking strategy for future reference.Deliverables:The deliverables for this project include:A GA4 ecommerce implementation plan detailing the steps required to implement GA4 ecommerce tracking on Sugarwod.com.A custom event tracking strategy document outlining the events to track, the triggers, and the parameters to be captured for each event.A GA4 dashboard configured to display key performance indicators and provide insights into user behavior and marketplace performance.Documentation on the implementation process and custom event tracking strategy for future reference.",['Web Analytics'],United States,2,,,"['Sales', 'Marketing']",750.00,,Remote Job,Intermediate
3D synthetic face image generation,"I'd like to develop a model that would generate new people based on the following input values:-gender-race-agefor each person, I want a variety of faces generated - with/without glasses, different pose orientation (from 0 to +/- 30 degrees yaw and pitch), different lighting (indoor/outdoor, shadows, side, overhead), different expressions (neutral, smile, frown).  perhaps up to 20 images per person.The result should be 3D face image.For 3D the result is a JPG or PNG plus a depth channel.Thanks","['Python', 'Deep Learning', 'Machine Learning']",United States,7,,1.1,"['Engineering', 'Architecture']",2000.00,,Remote Job,Intermediate
Fullstack Python Developer,"About the job Currently, we’re looking for a Python Developer to join our team!.What You Will be DoingSolve complex technical problems and collaborate with other team members on solving them.Develop new product features by writing efficient and testable code.Build and maintain automated CI/CD pipelines.Building web services/RESTful APIs.Collaborate in code reviews and help maintain excellent code bases.Perform code versioning management.Other specific project tasks.What Will Help You Succeed Having passion for what you do and a natural hands on tendency.Being an energetic, high performing and results oriented individual.Being able to look at the bigger picture.Intermediate - Advanced english skills.3+ years of experience on an agile development team, working with other developers as well as QA analysts, designers and technical and project leaders.Experience in Python using Django and/or Flask and mastery of computer science fundamentals such as OOP, Data structures, Design patterns and problem solving.Object Oriented analysis and design using common design patterns.Knowledge of Relational Databases and SQL.Knowledge of code versioning tools (e.g. git, github).Experience building web services and/or RESTful APIs.Experience working with JSON and XML.Familiarity with cloud technologies and services.Having an analytical and problem solving mindset, be able to work on complex technical problems and figure out the easiest solution to them.Being a team player, being able to mentor others as well as learning from others.Nice to HaveKnowledge of NoSQL Databases.Knowledge/experience working on Data science and/or AI/Machine learning projects.","['Python', 'API', 'Backend', 'Front-End Development', 'Cloud Computing', 'Software Architecture & Design', 'Cloud Computing', 'Software Architecture & Design']",Colombia,3,,,"['Tech', 'IT']",,"['30.00', '40.00']",Remote Job,Expert
FOrecasting sales using AI,I have a store operating in a city. we divide the city into regions. at the end of the day I get all the orders aggregated and I pack the items in the trucks to go to each regionI need a predictor to tell me how much quantity of each item will be made for each region,"['Python', 'Machine Learning', 'Artificial Intelligence', 'Data Analysis', 'Artificial Intelligence', 'Data Analysis']",Lebanon,263,12.63,34,"['Engineering', 'Architecture']",300.00,,Remote Job,Expert
iframe pardot form connect GTM/GA,I need someone to help me set up GTM/GA for my iframe forms hosted in pardot,"['Google Analytics', 'Google Tag Manager', 'Pardot']",United Kingdom,21,,130,,100.00,,Remote Job,Intermediate
Experienced Power BI Developer for Map Visualization Development,"We are seeking an experienced Power BI Developer to create a visually appealing and interactive map that will help us analyze and monitor our HVAC technician's job performance across our various locations.The scope of work for this project includes, but is not limited to:- Gathering requirements and understanding the performance indicators to be displayed on the map.- Designing the map visualization layout and incorporating branding elements as per our company guidelines.- Extracting, transforming, and loading (ETL) the necessary data from our existing Databricks warehouse- Developing the interactive map visualization using Power BI, including appropriate data visualizations (e.g., color-coded markers, heat maps).- Implementing filtering and drill-down capabilities to allow users to focus on specific locations, time periods, or performance metrics.- Integrating tooltips or pop-ups to provide additional details on each location's performance.- Testing the map visualization to ensure data accuracy, performance, and responsiveness.- Providing documentation and user instructions on how to use and maintain the map visualization.Candidates should have a solid understanding of PowerBI Development, and Data Engineering best practices","['Dashboard', 'Microsoft Power BI', 'Data Visualization', 'Data Analysis', 'SQL', 'Microsoft Power BI Data Visualization', 'Business Intelligence', 'Data Analysis', 'SQL', 'Microsoft Power BI Data Visualization', 'Business Intelligence']",United States,2,,,,2500.00,,Remote Job,Intermediate
Salesforce and Tableau Integration Specialist,"We're looking for a skilled Freelance Salesforce and Tableau Integration Specialist to connect a Salesforce org with Tableau Cloud. Your primary responsibility will be building best-practice sales reports and dashboards focused on general sales, profit and loss, and forecasting.Responsibilities:- Connect Salesforce org with Tableau Cloud for seamless data integration.- Design and develop insightful sales reports and dashboards.- Transform complex data into visually appealing visualizations.- Provide documentation, training, and support to an internal team member.Requirements:- Proficiency in Tableau Desktop and Tableau Server/Online.- Strong data analysis and visualization skills.- Experience with Salesforce data architecture and APIs.- Excellent communication and collaboration abilities.- Strong problem-solving and time-management skills.If you have the expertise to integrate Salesforce with Tableau and create impactful sales reports and dashboards, we want to hear from you.","['Salesforce CRM', 'Tableau', 'Data Visualization', 'Data Analysis', 'Data Visualization', 'Data Analysis']",United States,1,,,,,"['70.00', '150.00']",Remote Job,Expert
Social Media Marketing Expert - Increasing followers & engagement for a grant writing company,"I've been in business for 6 years helping science and tech start-ups secure grants from federal programs. I recently launched my social medias and my YT channel January 2023 to help teach start-ups how to go about these processes. Currently there is no one talking about this or teaching founders how to prepare these grants. My goal for launching this is to attract other founders to work with me and I have some consulting work and people who have found me through YT that have purchased my products and templates (https://www.keepyourequity.co/templates).I’m looking for an expert to learn how I can increase my following, especially on YouTube. I am in a very niche topic so I’m sure if I should be improving the content, style of video, etc. to grow. Socialshttps://www.tiktok.com/@keepyourequityco?lang=enhttps://www.youtube.com/channel/UCWjTpIQBTI-UqDqKjiAk22Ahttps://www.instagram.com/keepyourequity.co/reels/About KeepYourEquity.coKeepYourEquity.co supports scientists, engineers, and clinicians throughout their start-up journey. Our mission is to empower technical and clinical founders in the commercialization of innovative technologies. Former founders, entrepreneurs, and start-up executives with PhD-level technical backgrounds, we are well-equipped to guide you from research and development (R&D) to successful commercialization. We also served as former SBIR/STTR reviewers in study sections for various agencies including the NIH and NSF.Grants & RFPs we work on:- NIH SBIR / STTR: Phase I / II, Fast Track, Direct to Phase II, Commercialization Plans- NSF SBIR / STTR: Pitch Application, Phase I / II- DOD SBIR: Phase I / II / III, Direct to Phase II, AFWERX- DOE, DHS, USDA: Phase I / II- GHERI, PCORI, ARPA-E, ARPA-H, CDMRP, R01, and othersTechnical Areas- Biomedical Technologies: Medical Devices, Diagnostics, Digital Health Technologies, Therapeutics, Orthopedics, Implants- Pharmaceuticals: Research, Assay Development, Cancer Therapeutics, Clinical Trials- Biomaterials: Chemistry, polymer chemistry, coatings, ionic liquids, formulations- Technology: AI / ML / NP, Big data processing, Drones, Blockchain, Hardware, Mobile AppsSoftware, Hardware, 3D Printing, Space, Drones, Sensors, Communication, Supply Chain, Manufacturing- Environmental Sciences: Energy, AgTech/farming, Batteries, Renewable, Oil / Gas / Solar, Green Energy","['YouTube', 'TikTok', 'Instagram']",United States,4,27.37,2.3,,,"['100.00', '200.00']",Remote Job,Expert
Build a Radiomic library,"I need a Radiomic library to be built for PET imaging. The library should be able to extract features such as shape-based, intensity-based, and texture-based features. It should be compatible with Python programming language. The ideal candidate should have experience/good knowledge in medical imaging and knowledge of Radiomics. Proficiency in Python programming language is a must.The main goal is to create a radiomic library using pyradiomicsi have a csv file with DICOM metadata which should be used to train the modelthe library should include all the steps like segmentation of the PET images , feature extraction and feature selectionThe main goal is to create a radiomic library using pyradiomicsi have a csv file with DICOM metadata which should be used to train the modelthe library should include all the steps like segmentation of the PET images , feature extraction and feature selectionhttps://wiki.cancerimagingarchive.net/display/Public/NaF+PROSTATEthis link has the PET images and DICOM meta data filePlease go through the files and let me know if the images and dataset are enough to come up with the required outputif you believe i have provide you with all the input resources please explain me the path forward that you will be taking","['Machine Learning', 'Data Science', 'Software Architecture', 'Software Architecture']",United Kingdom,305,5.00,2.9,,,"['10.00', '15.00']",Remote Job,Expert
Scrape Twitter bot,"Hi,Need an automated bot that runs 24/7 to scrape Twitter data based on the information and input I will give you.Bot should find new and freshly created accounts that meet certain criteria. I will explain more in DM's. Do not apply if you have no expertise in this field.Thank you.","['Data Scraping', 'Python', 'Bot Development', 'Scrapy', 'Twitter API', 'Automation', 'Scrapy', 'Twitter API', 'Automation']",Belgium,8,28.00,113,"['Finance', 'Accounting']",200.00,,Remote Job,Expert
Google Analytics/Marketing Manager,"Need support transferring our analytics from Universal Analytics to Google Analytics 4.  Need support in tags for website.Support with Google Ads and ad performance.Prefer someone with google ad experience, particularly in the sports retail industry.","['Google Analytics', 'Google Ads', 'Google Tag Manager', 'Search Engine Marketing', 'Campaign Reporting', 'Search Engine Optimization', 'Google Tag Manager', 'Search Engine Marketing', 'Campaign Reporting', 'Search Engine Optimization']",United States,10,,9.1,,,,Remote Job,Intermediate
Looking for GPT-4 Open-Source Developer,"This is research project. I am looking for alternate GPT-4 Open-Source which is hosted internally.If you have experience with Open AI, ChatGPT, Open Source, Language model and Chatbots, etc.Please apply and lets discuss the details.","['Python', 'API', 'LAMP Stack']",United States,752,9.74,306,,,,Remote Job,Expert
Looking for AI Team,"Looking for a team who can work on AI projects.Need skilled level in Machine learning, data science and artificial intelligence.Should be a team of people who can take up projects and work like a team.","['Artificial Neural Network', 'Machine Learning', 'Data Science']",India,56,,,,,"['10.00', '20.00']",Remote Job,Expert
ChatGPT (Prompt Creation),"Looking to write an EPIC prompt to be used in CHatGPT to create an employee Policy for my company's USE of ChatGPT. To restrict and direct the use of ChatGPT within my organization.I need to the prompt to be usable by other companies as well. So including industry, appropriate sections on privacy, ownership, etc.. This prompt should create the perfect policy for any company's usage of ChatGPT by simply changing a few words.This will require knowledge of ChatGPT as well as HR policies for employees.","['ChatGPT', 'HR & Business Services']",Canada,31,27.90,13,,100.00,,Remote Job,Expert
SQL and Data analysis,"We are seeking a skilled data analyst with strong SQL programming skills to assist us with data analysis for a project that will last more than 6 months. The ideal candidate should be proficient in data analysis, data visualization, Microsoft Excel, and Python. Responsibilities include data cleaning, data analysis, and data visualization of large datasets using SQL programming. The candidate will work closely with our team to identify trends, patterns and insights that will help us make data-driven decisions. To be considered for this role, please submit a detailed proposal outlining your experience in data analysis, your proficiency in SQL programming, and how you can contribute to the success of this project. Please also include links to past completed projects that demonstrate your expertise in data analysis and visualization. We look forward to hearing from you and working together to achieve our project goals.Note: Some of the content in this job post may have been auto-generated using advanced AI.","['Data Analysis', 'SQL', 'Microsoft Excel', 'Data Visualization', 'Python', 'SQL Programming', 'Data Visualization', 'Python', 'SQL Programming']",United States,38,20.83,30,,,"['15.00', '50.00']",Remote Job,Expert
Complete G4 setup for website currently in Google universal analytics that needs to be converted,Need to upgrade current website AtlantaParent.com from universal analytics to G4 including new tags.  Need complete set up for analytics. Not serving ads through google anymore.,"['Google Analytics', 'WordPress']",United States,3,,,,,,Remote Job,Expert
Complete a Power BI build to calculate date differences,Complete a Power Build - Last step - Date difference calculations.,"['Microsoft Power BI', 'Data Analysis']",United States,3,24.44,625,"['Sales', 'Marketing']",,"['18.00', '45.00']",Remote Job,Intermediate
DataMiner Expert - Need Custom Recipes  Build-out,I need Custom Recipes built out in our DataMiner to scrape on a few sources. Bluebook Contractors page Glassdoor Linkedin Etc. We have a short list and this would be ongoing when we need one will hire to have it done!,"['Data Mining', 'Data Scraping']",United States,54,31.31,4.5,,,,Remote Job,Intermediate
Product Owner for New AI Tech Stacking Firm,"Job Title: Product Owner, WealthStack.aiLocation: RemoteType: Temporary, with potential for part-timeAbout WealthStack.ai:WealthStack.ai is a tech stack enablement service for financial advisors. Our mission is to reduce overhead expenses for advisors and elevate service standards for their clients. We aim to streamline communication and business processes, making it easier for advisors to deliver top-tier services.Job Description:We are seeking a Product Owner to join our team on a temporary basis, with the potential to transition into a part-time role. The Product Owner will be responsible for guiding the development of our service capabilities, working closely with our founders and stakeholders to ensure our product meets the needs of our users.Responsibilities:Define and prioritize product backlog, creating actionable user stories for the development team.Work closely with stakeholders to understand their needs and translate them into product requirements.Collaborate with the development team to ensure product features are delivered on time and meet quality standards.Facilitate Scrum ceremonies, including sprint planning, daily stand-ups, sprint reviews, and retrospectives.Monitor product performance and gather feedback from users to inform product enhancements.Ensure the product aligns with the company's strategic goals and vision.Requirements:Bachelor's degree in Business, Computer Science, or a related field.Proven experience as a Product Owner, Product Manager, or similar role in a tech company.Strong understanding of the financial advisory industry and the challenges advisors face.Familiarity with Agile methodologies and Scrum framework.Exceptional communication and presentation skills.Ability to work effectively with cross-functional teams.Strong problem-solving skills and the ability to make decisions under pressure.Experience with product management tools such as Jira or Trello.Nice to Have:Certified Scrum Product Owner (CSPO) or similar certification.Experience in a startup environment.Knowledge of fintech industry trends and emerging technologies.WealthStack.ai is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees.How to Apply:Interested candidates are invited to submit their resume, along with a cover letter detailing their interest and qualifications for this role. We thank all applicants for their interest; however, only those candidates selected for an interview will be contacted.","['Data Analysis', 'Market Research', 'Product Development', 'Product Strategy', 'Project Management', 'Go-to-Market Strategy', 'Implementation Plan', 'Product Roadmap', 'Product Management', 'Product Design']",Canada,48,9.85,42,,,"['8.00', '25.00']",Remote Job,Intermediate
Automate ocr pdf data extraction into pre set excel sheet,"Case description: Our client is a producer of foam concentrates for fire (https://www.sthamer.com/en/). When potential customers approach him and send a request for the foam concentrates, he receives data sheets of the customer’s products (including their characteristics regarding flammability etc.), which are unfortunately very often and not normed. These data sheets of the products need to be compared to the data sheets of the foam concentrates of our client in order to evaluate which foam concentrates are a good fit for which customer’s product. Currently, this work is done by our client entirely by hand. In the following way:Step 1: Extract (relevant) data from the product’s data sheets of the customer’s substances into an excel table - this is the first project scopeStep 2: Analysis: go through excel sheet manually and for each of the substances, mark either distinguishable or not distinguishable - this could be resulting from a successful first step.  (Step 3: Write report to the customer) - this is not really relevant for youRegarding step 1(first project scope): This is the most time-consuming step because some of the product data sheets are not compliant with the standards or are outdated. If this is done by AI, it would help a lot already! So here we need something like a OCR to Excel crawler.Regarding step 2: The alignment is currently done in the head/on the basis of the knowledge of an employee. There is no (source/knowledge) database, although we might be able to use the data sheets of the form concentrates for this.In the attachment of the job you find the (translated) Excel file where currently the information is extracted (step 1, black) and then evaluated (step 2, green) by hand. Also, there is a translated example of data fields of a product data sheet. Note however as stated, that these data sheets are not necessarily normed. We would want to setup a very easy to use micro service for this Step 1 Extract (relevant) data from the product’s data sheets of the customer’s substances into an excel table. Which interface could be used? How could the microservice be executed and run? Would it be able to have an upload of pdfs and download of the excel with the input data then? Please let us know a rough idea about a project plan and your way to solve this Step 1 problem and make it easy accessible Kind Regards from Hamburg, GermanyHauke","['Data Extraction', 'PDF Conversion', 'Spreadsheet Software', 'Data Entry', 'Scripting', 'OCR Algorithm', 'Automation', 'Spreadsheet Software', 'Data Entry', 'Scripting', 'OCR Algorithm', 'Automation']",Germany,1,,,,,"['15.00', '40.00']",Remote Job,Expert
"Excel, Data sort and Telegram Bot Integration","We have an ongoing data sorting, processing and integration project started by another freelancer that we need help completing. The details of the work left to finish are:We have customer name and address data in a text file with one customer per line. The data has been partially sorted by location by the previous freelancer. We need you to finish sorting and cleaning the remaining data.For each remaining customer, find the closest ""Store X"" location from a list of store addresses and assign the customer to that store. If multiple customers are within close proximity, assign them to different stores to distribute customers evenly. For example, if we have remaining customer data for Springfield, assign each customer to a different ""Store X"" location.In some cases, remaining customers may need to be assigned to a store that is not the absolute closest in order to distribute customers among locations. For example, move the customer down 10-20 positions on the sorted list so they are not called at the exact same time.Clean up any remaining data by removing any extra characters or correcting typos.Use Excel formulas and macros to automate any remaining parts of the sorting, assigning and integration process with the click of a button.Ensure an inexperienced user would be able to easily add or modify any new data added and the changes would update appropriately in the Excel sheet, CSV, calling script, and bot.The previous freelancer has exported most of the sorted and cleaned data into a CSV file and populated the data into a calling script. You will need to finish exporting any remaining data into the CSV and populate it into the script. When a customer is selected in the CSV, the data for that customer should automatically populate the necessary fields in the script.Integrate the Excel data with a Telegram bot that can generate temporary phone numbers and email addresses. The bot should be able to access the customer data in the Excel sheet and generate the contacts, which then need to be populated into the CSV, calling script, and Excel sheet. The generated contacts will allow conducting SMS and email campaigns through the bot.The data contains contact info for customers who have opted-in to receive promotional calls about store events and offers. We want to ensure that customers within a close proximity are not all assigned to the exact same store.The ideal candidate will have advanced Excel skills, experience with data processing and integration, basic Python/coding skills to integrate with the Telegram Bot API, and the ability to automate repetitive tasks through Excel to complete the work started by our previous freelancer. Please let me know if you have any questions or need any clarification. We are looking to resume and finish this project as soon as possible.","['API Integration', 'Selenium', 'pandas', 'Python', 'Automation', 'Data Scraping', 'API', 'Microsoft Excel', 'Visual Basic for Applications', 'Data Mining', 'API', 'Microsoft Excel', 'Visual Basic for Applications', 'Data Mining']",United States,2,8.38,0,,,"['5.00', '20.00']",Remote Job,Expert
Google Analytics Specialist and Shopify App Integration Expert,"We are seeking a highly skilled and experienced Google Analytics Specialist with expertise in connecting Shopify apps with Google Analytics. The ideal candidate will have a deep understanding of Google Analytics implementation, configuration, and data analysis, specifically focusing on full funnel tracking for marketing campaigns. You will play a crucial role in helping us measure the success of our marketing efforts by ensuring accurate and comprehensive tracking of our advertising campaigns from the traffic source to landing pages and app installations in the Shopify App Store.Responsibilities:- Collaborate with our marketing team to understand campaign objectives and tracking requirements.- Set up and configure Google Analytics to accurately track and measure campaign performance.- Connect Shopify apps with Google Analytics to capture relevant data for app installs.- Troubleshoot and resolve any tracking issues or discrepancies.- Generate comprehensive reports and dashboards to present campaign performance metrics.Qualifications:- Extensive experience working with Google Analytics and implementing tracking codes.- Proven track record of successfully integrating Shopify apps with Google Analytics.- Strong understanding of full funnel tracking and attribution modeling.- Familiarity with Shopify platform and app development.- Solid knowledge of digital marketing channels and advertising platforms.Application Questions:1. How many years of experience do you have working with Google Analytics and implementing tracking codes?2. Describe your experience connecting Shopify apps with Google Analytics. What challenges did you face, and how did you overcome them?3. Have you worked with full funnel tracking before? If so, please provide an example of a campaign you tracked and the key metrics you measured.","['Google Analytics', 'Google Tag Manager', 'Shopify', 'Shopify Apps', 'Marketing Analytics', 'Analytics', 'Shopify', 'Shopify Apps', 'Marketing Analytics', 'Analytics']",Germany,2,,,,,"['18.00', '45.00']",Remote Job,Intermediate
Google Sheet Graphs for Reporting,"I'm looking for a professional that can take an existing Google sheet, pull monthly numbers to create visible charts on Google sheets for reporting.Basically, the Google sheet is populated straightforward with numbers needing graphs, visual charts, a one-time quick project.  Project needs to be completed by end of business day.","['Google Sheets', 'Data Visualization', 'Visual Basic for Applications', 'Visual Basic for Applications']",United States,1,,,,,"['25.00', '75.00']",Remote Job,Intermediate
Power BI Teacher,I have existing PowerBI files that someone else created for my clients. I want to learn how Power BI works so that I can make minor changes to these existing reports myself. I also want to set up new reporting and create a standard set of reports that I can use across all of my clients.,"['Microsoft Power BI', 'Data Analysis', 'Data Visualization', 'Data Visualization']",United States,4,25.00,1.5,,,"['15.00', '25.00']",Remote Job,Expert
HubSpot Expert Needed to Build out Reporting,"UFS is a FinTech company specializing in lending to clients seeking capital to start or buy a business. We have used HubSpot successfully for over 2 years. However, our use of native HubSpot reporting capabilities is basic and needs to be enhanced with outside expertise. Note: we need help with basic sales and operational metrics / KPI reporting. At this time, we do not need (and would prefer not to use) a third-party data visualization tool or API. A laundry list of HS reporting we need includes:(Wow/MoM/QoQ/YoY for each)- Total leads assigned to COMPANY overall- Total leads assigned to each Loan Advisor (LA)- Total # of deals created in SALES Pipeline Company overall- Total # of deals created in SALES Pipeline each LA- Ratio of Leads to Deals created as a %- Number of Leads needed to create a deal- Total # of Deals moved Past “Agreement Signed” - # of deals moved past agreement signed each LA- Ratio of Leads to deals signed as a percentage.- Number of deals moved into “Funded” as company- Number of deals moved into funded as LA- # of deals moved to “Closed/Dead” Total- # of deals moved to Closed dead each LA- Time to first contact. - Time in each Lifecycle Stage- Time in each Deal Stage- Dropout % after each stage- List of every deal moved to closed/dead (for post-mortem)- Total amount we can expect to close by EoMWe're a fun, collaborative group of people to work with, and need additional expertise to better optimize our CRM processes. We would also prefer to work with a freelancer vs. an agency/dev shop.","['Sales Analytics', 'Operations Analytics', 'Data Analysis', 'Report', 'HubSpot']",United States,9,43.25,7.5,,,,Remote Job,Expert
Data analyst/BI expert to help bring intelligence to our data,"Looking for someone who can help us take our data to the next level. Build specific dashboards and automate reports using sales, inventory, and pricing data from a number of different data sources. Should be experienced in Power BI and understanding the challenges associated with disparate datasets. Work closely with remote sales and operations teams to scope needs and translate to meaningful insights.Ability to onboard & train new users to show the value of BI over spreadsheets.","['Microsoft Power BI', 'Data Analysis', 'Data Visualization', 'Business Intelligence', 'Data Visualization', 'Business Intelligence']",United States,1,,,,,"['45.00', '75.00']",Remote Job,Intermediate
Generative AI Developer for Subreddit-Powered Chatbot with Google Sheets Integration,"We are currently seeking a talented Generative AI Developer to work on a project involving the development of a chatbot that utilizes a subreddit as a data source. The chatbot's primary goal is to provide helpful answers on the subject of the subreddit, drawing upon the questions and answers found within the subreddit.Required Skills:Proficiency in PythonStrong background in Natural Language ProcessingExperience in Chatbot DevelopmentKnowledge of Machine Learning and API integrationThe selected freelancer will work independently, but effective communication throughout the project is essential.If this project is successful, there may be potential for future collaboration to further develop the initial product, including the addition of features and enhancements. However, please note that this initial engagement is for a single project only.We are eager to collaborate with a skilled Generative AI Developer who can transform our vision into a functional chatbot utilizing subreddit data. If you possess the required skills and experience, we encourage you to submit your proposal and share relevant work samples that highlight your expertise in generative AI development and chatbot projects.Please include any additional information about your preferred way of working and any specific requirements or questions you may have regarding the project. We look forward to reviewing your proposals and discussing the project details further.","['Python', 'Natural Language Processing', 'Chatbot Development', 'Machine Learning', 'API Integration', 'Chatbot Development', 'Machine Learning', 'API Integration']",Israel,1,,,,,"['25.00', '40.00']",Remote Job,Intermediate
Python/Django Backend Developer with Machine Learning Experience,"Project Description:We developed a mobile micro-learning platform using Flutterflow with Airtable and Firebase as our databases. Our existing codebase for an algorithm determines what question to answer next to each learner based on their accuracy, speed, and confidence in answering previous questions. This algorithm is written in Python and uses machine-learning techniques. We are looking for an experienced Python/Django Backend Developer with a solid understanding of machine learning to integrate this algorithm into our existing platform.Responsibilities:Understand and navigate our existing Python codebase, which includes Django, Django Rest Framework, and machine learning algorithms.Work with our existing databases (Airtable and Firebase) to fetch and manipulate the necessary data.Integrate our existing machine learning algorithm into the platform to determine what question to answer next to each learner.Develop APIs using Django Rest Framework.Collaborate closely with our frontend team to ensure proper integration of the backend functionality.Debug and optimize the performance of the backend application.Requirements:Strong Python programming skills with a deep understanding of Django and Django Rest Framework.Proficiency with machine learning algorithms, specifically in Python.Experience with Airtable and Firebase databases.Knowledge of the CSV and JSON data formats.Familiarity with version control systems, preferably Git.Experience with AWS for deployment and scaling purposes.Ability to write efficient, reusable, and reliable code.Strong problem-solving skills and attention to detail.Excellent communication skills and the ability to work as part of a team.Nice-to-Haves:Experience with Flutterflow would be a plus.Prior experience in EdTech or microlearning platforms.How to Apply:Please apply with your resume, briefly introducing yourself and why you're interested in this project, and examples of relevant work you've done. Applicants who do not provide this information will not be considered.  This project needs to be done quickly, and cost is the strong determination of who will be awarded the project.  Anyone who provides a Flat Rate will be preferred.  We look forward to hearing from you and potentially working together to improve our microlearning platform!attached is the codebase, and below is the link to the beginning of the API that is not done http://ec2-54-160-76-27.compute-1.amazonaws.com:6969/api/v1/","['Python', 'Django', 'Machine Learning', 'Python Script', 'API', 'RESTful API', 'Python Script', 'API', 'RESTful API']",Canada,23,36.32,17,,,"['20.00', '30.00']",Remote Job,Intermediate
Generative AI Engineer,"Your main responsibilities will include:- Design, develop, and implement generative AI models and algorithms, utilizing state-of-the-art techniques such as GPT, VAE, and GANs.- Collaborate with cross-functional teams to define AI project requirements and objectives, ensuring alignment with overall business goals.- Conduct research to stay up-to-date with the latest advancements in generative AI, machine learning, and deep learning techniques, and identify opportunities to integrate them into our products and services.- Optimize existing generative AI models for improved performance, scalability, and efficiency.- Develop and maintain AI pipelines, including data preprocessing, feature extraction, model training, and evaluation.- Develop clear and concise documentation, including technical specifications, user guides, and presentations, to communicate complex AI concepts to both technical and non-technical stakeholders.- Contribute to the establishment of best practices and standards for generative AI development within the organization.- Provide technical mentorship and guidance to junior team members.","['Neural Network', 'Artificial Intelligence', 'TensorFlow', 'Machine Learning', 'Artificial Neural Network', 'Deep Learning', 'TensorFlow', 'Machine Learning', 'Artificial Neural Network', 'Deep Learning']",India,27,,,"['Engineering', 'Architecture']",,"['16.00', '40.00']",Remote Job,Intermediate
Évaluateur de données en ligne,"Rejoignez-nous en tant qu’Évaluateur de données en ligne afin d’améliorer les résultats de requêtes de recherche en les rendant plus pertinents, précis et fiables. Dans le cadre de ce projet, vous vérifierez, évaluerez et réaliserez un rapport sur la précision de différentes requêtes de recherche.Grâce à votre contribution à ce projet, vous aurez un impact précieux sur le futur de la technologie IA. Si vous être prêt à relever le défi et à participer à des projets passionnants pour les plus grandes marques mondiales de la technologie – ça pourrait être votre chance !Nos prérequis:· Doit être actuellement basé en France et y avoir résidé au minimum ces 5 dernières années · Français courant et bonne maîtrise de l’anglais· Sens du détail, engagement sur les objectifs et la qualité, capacité à suivre des lignes directrices de projet· Capacité à comprendre un feedback et à ajuster en conséquence· Ordinateur portable ou de bureau avec connexion internet et logiciel anti-virus fiablesAfin d’être présélectionné pour le poste, vous devrez étudier des directives de travail détaillées en anglais et passer un examen en ligne à livre ouvert afin de garantir la bonne compréhension de celles-ci (le temps d’étude ne sera pas rémunéré).Ce que nous offrons:· Travail à domicile, indépendant et gratifiant n’incluant pas de service client· Autonomie horaire. Vous choisissez les heures de travail qui correspondent le mieux à votre routine quotidienne· Télétravail jusqu’à 20 heures par semaine· Travail passionnant à l’avant-garde de la technologie IA moderneEnvoyez-nous votre CV à ratercommunity@transperfect.com","['French', 'English', 'Accuracy Verification', 'Data Analysis', 'Data Analysis']",France,1,,,"['Tech', 'IT']",,"['12.00', '15.00']",Remote Job,Entry level
Solve neural network task,"I want this task solved:Translated:Task 1. Consider a neural network with initialized weights as indicated in the figure:The desired network score (target) is t1 = 0.5, t2 = 0.5. If x1 =1and x2 =1:- calculate ""by hand"" and with PyTorch the straight move in the grid- calculate ""by hand"" and with PyTorch the derivatives ∂L/∂w(2) and∂L/∂w(2) , where L e an evaluation function of the type mean sum of 12squared errors (MSE).Submit your solutions as images (pdf or otherwise) and as ipynb.Original:Задача 1. Разглеждаме невронна мрежа с инициализирани тегла, както е указано на фигурата:Исканият резултат от мрежата (target) е t1 = 0.5, t2 = 0.5. Ако x1 =1иx2 =1:- изчислете “на ръка” и с PyTorch правия ход в мрежата- изчислете “на ръка” и с PyTorch производните ∂L/∂w(2) и∂L/∂w(2) , където L e оценъчна функция от типа средна сума от 12квадратите на грешките (MSE).Изпратете решенията си като изображения (в pdf или по друг начин) и като ipynb.","['Python', 'Neural Network', 'Mathematics']",Bulgaria,1,,10,,10.00,,Remote Job,Entry level
"Bioinformatics,  microbiome data analysis, manipulating phyloseq objects, machine learning","It is a  bioinformatics, NGS sequencing, project that requires upstream processes of a phyloseq object by applying various ML methods in Python.  The project has to be performed in approximately 1 month.","['Machine Learning', 'Statistics', 'R', 'Python', 'Python Scikit-Learn', 'R', 'Python', 'Python Scikit-Learn']",Romania,4,26.17,356,,,"['10.00', '35.00']",Remote Job,Expert
Perform GA4 and GTM Education and Preparation Checklist,"We are looking for a Google Analytics and Tag Manager expert to create and deliver a presentation to our Marketing and IT teams to ready our teams and businesses for Google Analytics 4. In addition, prepare a post-education checklist for the steps to ensure proper setup for both GA4 and GTM success. Additional opportunities for audits, dashboard development, etc. could also become available.","['Marketing Analytics', 'Dashboard', 'Presentations', 'Business Intelligence', 'Google Tag Manager', 'Google Analytics', 'Search Engine Optimization']",United States,2,,3.6,"['Travel', 'Hospitality']",1500.00,,Remote Job,Expert
Tableau Dashboard Specialist,"We are seeking an experienced Tableau Dashboard Specialist to help troubleshoot and fix a problem with our Tableau dashboard. There may be potential for additional tasks in the future depending on performance and business needs.Responsibilities:- Understand the current problem with our Tableau dashboard and provide solutions to fix it- Apply best practices in data visualization to enhance readability and interpretability- Collaborate with our team to understand data and dashboard requirements- Ensure that the fixed dashboard will not require additional work in future- Provide explanation about the issues fixed and any improvements implementedQualifications:- Proven experience as a Tableau Dashboard Developer or similar role- Proficiency in Tableau software, including troubleshooting and problem-solving capabilities- Understanding of data visualization best practices- Strong analytical and problem-solving skills- Knowledge of BigQuery- Knowledge of other data analysis tools (e.g., Python) is a plusHow to Apply:Interested candidates should submit their resume, a brief cover letter outlining their relevant experience, and examples of previous work with Tableau dashboards.We look forward to hearing from you!","['Dashboard', 'Tableau', 'Data Visualization', 'Data Analysis', 'BigQuery', 'Data Analysis', 'BigQuery']",Ukraine,19,13.23,2.6,,,,Remote Job,Intermediate
Data Scraping Expert for ITPrice_com,"We are seeking a skilled and experienced data scraping expert to extract data from the website https://itprice.com. The goal is to collect comprehensive information about IT products, including their product#, description, list price, and our price. Please check the attached screenshot for the required data details.","['Beautiful Soup', 'Selenium', 'Scrapy', 'pandas', 'Python', 'PHP', 'Data Scraping', 'Data Mining']",Pakistan,3,,,,,"['8.00', '25.00']",Remote Job,Intermediate
I am hiring for Python Developer for one of the Projects,"Project for BFSI Domain with expertise in Kafka and Python, SQL in Software development","['Python', 'Apache Kafka', 'API', 'Amazon Web Services', 'SQL Programming', 'Data Science', 'Apache NiFi', 'Java', 'Python Script', 'Amazon Web Services', 'SQL Programming', 'Data Science', 'Apache NiFi', 'Java', 'Python Script']",India,1,,,"['Tech', 'IT']",,"['10.00', '20.00']",Remote Job,Intermediate
Scrapping a Webpage,"Looking for someone to extract data from a website. All the information we are looking for is on the front of the page, but it spread across 100 different pages. I have created a video showing how I would do this manually with copy and paste, but looking for someone who can write a script an automate the extraction and help with organization. Here is a link to a video discription: https://www.loom.com/share/8c16c57ca7fc474e8db0b107d03311f4Here is the website with the target data:https://www.knowde.com/b/markets-personal-care/products","['Data Extraction', 'Data Scraping', 'Data Mining']",United States,61,27.41,1.2,,,"['15.00', '40.00']",Remote Job,Entry level
Data Scientist for a model/machine learning and visualization solution,"We are seeking a Medior/Senior Data Scientist to solve the problem. You will be responsible for two essential tasks: Data Processing and Production Optimization. You will work on provided datasets to analyze and solve business cases related to manufacturing processes.Task 1: Data ProcessingYour goal is to transform raw sensor data into a processed format. This includes aggregating data into specific intervals and calculating the count of different event types. You must ensure the code is production-ready, utilize popular scientific Python libraries, and provide visualizations when necessary.Task 2: Production OptimizationYou will work on a business case related to optimizing products while minimizing costs. Using machine learning and modeling techniques, you will analyze the process parameters and characteristics of the final product. Your findings and recommendations will be presented to the product lead.Requirements:1. Strong data processing and analysis skills using scientific Python libraries.2. Proficiency in machine learning and modeling techniques.3. Excellent communication skills to convey findings and present solutions effectively.4. Experience with visualizations and creating reports.The project is expected to finish in 2 days after starting. ( no worries, if you are an expert, you will be able to nail it mush sooner)We invite you to apply if you are a skilled data scientist passionate about optimizing production processes and solving complex problems.","['Python', 'Data Science', 'Machine Learning', 'Statistics', 'TensorFlow', 'Python Scikit-Learn', 'Predictive Analytics', 'Data Mining', 'Algorithm Development', 'Statistics', 'TensorFlow', 'Python Scikit-Learn', 'Predictive Analytics', 'Data Mining', 'Algorithm Development']",Belgium,1,25.00,0,,,"['20.00', '70.00']",Remote Job,Expert
Alabs - Phase 0 / Initial Infrastructure Design,"Objective: Develop a robust infrastructure for monitoring, identifying, executing, and covering transaction steps in the DeFi space, while discovering new opportunities, creating passive income streams, and incorporating transaction obfuscation techniques.Design and implement a DeFi monitoring infrastructure:•	Set up a real-time data pipeline to collect and analyze on-chain data from various DeFi protocols, including swaps, liquidity pools, and lending platforms.•	Integrate with APIs and WebSockets from blockchain data providers like Alchemy, Infura, and QuickNode to access real-time data, including pending transactions, gas prices, and network congestion.•	Monitor smart contract events, price oracles, and other data sources to identify relevant transaction events, arbitrage opportunities, and liquidation alerts.In-depth study and analysis of DeFi transactions:•	Conduct a thorough analysis of successful and unsuccessful transactions on various DeFi platforms, including front-running and back-running attempts.•	Identify patterns, trends, and strategies that can be used to generate alpha in the market, such as transaction timing, gas price optimization, and multi-step transactions.•	Research novel techniques and methods for discovering new trading opportunities in the DeFi ecosystem, including cross-chain and layer-2 solutions.Develop algorithms and scripts for passive income generation:•	Use data science, machine learning, and statistical analysis to identify opportunities with consistent returns, such as yield farming, liquidity provision, and automated market making.•	Build automated trading strategies and scripts that can capitalize on these opportunities, incorporating transaction obfuscation methods to protect against front-runners and other malicious actors.•	Implement risk management techniques to ensure the sustainability of the passive income streams, including portfolio diversification, position sizing, and stop-loss mechanisms.Utilize DeFi research tools and platforms to stay ahead of the competition:•	Leverage research tools like Eigenphi, DexScreener, Dune Analytics, and other MEV research platforms to identify new opportunities, monitor market trends, and analyze competitors' strategies.•	Stay up-to-date with the latest developments in the DeFi space, including new protocols, token launches, and regulatory changes, to adapt trading strategies accordingly.•	Collaborate with other data scientists, quants, and DeFi experts to share insights, improve trading strategies, and develop novel transaction obfuscation techniques.Apply quantitative and trade engineering skills to develop trading strategies:•	Use advanced quantitative techniques, such as time series analysis, Monte Carlo simulations, and optimization algorithms, to model the DeFi market and identify profitable trading opportunities.•	Design both simple and complex transactions based on market conditions, liquidity, and other factors, while incorporating transaction obfuscation techniques to minimize the risk of being frontrun.•	Optimize transaction execution strategies to minimize slippage, gas fees, and other costs, leveraging layer-2 solutions and off-chain computation when appropriate.","['Blockchain Architecture', 'Python', 'solidity ', 'Machine Learning', 'Rust', 'Smart Contract Development', 'Python', 'solidity ', 'Machine Learning', 'Rust', 'Smart Contract Development']",United Kingdom,4,96.26,3.9,"['Tech', 'IT']",,,Remote Job,Expert
Big data Architect,"We are looking for Big Data Architect Requirements:Strong experience in integrating data from multiple sourcesProficiency in various ETL techniques and frameworks, such as FlumeFamiliarity with messaging systems like Kafka or RabbitMQ and SparkMLSolid understanding of Lambda Architecture, including its advantages and disadvantagesExperience with at least one Hadoop distributionAbility to select and integrate relevant Big Data tools and frameworksMonitoring performance and recommending necessary infrastructure changesEstablishing data retention policiesManaging Hadoop clusters and associated servicesProficiency with Hadoop v3, Spark, Kafka, and HDFSExperience in building stream-processing systems using Storm or Spark StreamingGood knowledge of Big Data querying tools like Pig, Hive, and ImpalaFamiliarity with NoSQL databases, including HBase, Cassandra, and MongoDBIf you meet these qualifications and are interested in the position, please submit your application.","['Apache Hadoop', 'Big Data', 'Apache Spark', 'Python', 'Data Modeling', 'ETL Pipeline', 'Scala', 'Apache Kafka', 'Apache Cassandra', 'Apache Hive', 'Apache Spark', 'Python', 'Data Modeling', 'ETL Pipeline', 'Scala', 'Apache Kafka', 'Apache Cassandra', 'Apache Hive']",Tunisia,1,,,,,,Remote Job,Expert
AI machine learning to learn a programing language and analyse the logic,"We are looking for an experienced AI and Machine Learning expert to help us with a project that involves learning a programming language and analyzing the logic. The ideal candidate should have a deep understanding of Apache MXNet, PyTorch, TensorFlow, and other AI tools. Additionally, knowledge of Artificial Intelligence Ethics, Reinforcement Learning, and Supervised Learning will be an added advantage.The project is expected to run for 3 to 6 months, and the selected candidate will work closely with our team to develop and implement a program that will learn and analyze the programming language. We are looking for someone who can come up with innovative solutions to complex problems. The candidate must also have excellent communication skills and be able to work independently.To apply for this position, please submit a proposal that outlines your experience and how you can help with the project. Please include links to any relevant past completed projects that demonstrate your expertise in the field. We look forward to hearing from you!Note: Some of the content in this job post may have been auto-generated using advanced AI.","['Artificial Intelligence Ethics', 'Reinforcement Learning', 'Supervised Learning', 'TensorFlow', 'PyTorch', 'Apache MXNet']",Turkey,13,17.00,834,"['Tech', 'IT']",,"['30.00', '45.00']",Remote Job,Expert
Generative AI video Expert,"We are looking for an experienced AI expert to work with us on a generative video project. The ideal candidate should have a strong knowledge of CycleGAN, Convolutional Neural Network, Deep Belief Network, and Python. The project length will be 1 to 3 months.Project is to change content of some videos based on some arguments.The candidate will be responsible for developing a generative video model that can create realistic videos based on a given set of input data. The model should be able to learn and adapt to the input data, creating unique and diverse outputs. The candidate should have experience working with generative models and be able to apply this knowledge to the project.To apply, please submit a proposal that includes your relevant experience and skills, as well as a plan for how you will approach the project. Please provide links to past completed projects that demonstrate your expertise in this area.We look forward to hearing from qualified candidates who can help us bring this exciting project to life.Note: Some of the content in this job post may have been auto-generated using advanced AI.","['Python', 'CycleGAN', 'Deep Belief Network', 'Convolutional Neural Network']",Turkey,13,17.00,834,"['Tech', 'IT']",,"['36.00', '70.00']",Remote Job,Expert
AI Manager,Analyse all business processes and offer AI solutions for business process optimization.,"['Machine Learning Model', 'Machine Learning', 'Data Science', 'Artificial Neural Network']",Romania,99,12.65,8,,,"['10.00', '15.00']",Remote Job,Entry level
Generative AI python developer to develop Floorplan software (oprnsources available),"Hi All!I want to develop a tool that will get a naked 2d floorplan and will generate by a free text field and a few dropdowns for a 2d, 3d and virtual tour colorful and furnished.I found tons of open sources we can rely on and develop it quick, you will need to make the adaptations and take it into my github. You should make sure there are no limitations on top of this repository. When you approach please talk about it as well.you can see an example video attached.I dont have the dataset etc then it should be included.I attach here a reference which is different but they do something interesting on top of the architecture softwares such as Cad, Revitt etc. https://www.evolvelab.io/verasThanks in advanceJob Description:We are seeking a skilled and creative developer to join our team and take on the exciting challenge of developing a tool that can transform black and white floorplans into vibrant, visually appealing representations. This tool aims to add furniture, grass, swimming pools, and other elements to the floorplan, providing a realistic and colorful depiction of the space.Responsibilities:Design and develop a software tool that can process black and white floorplans and convert them into colorful representations.Implement image processing techniques, computer vision algorithms, and graphic design principles to identify different elements within the floorplan and add colors, textures, and other details.Collaborate with architects, interior designers, and potential users to understand their requirements and preferences, and incorporate their feedback into the tool's development.Research and explore cutting-edge technologies, libraries, and frameworks in the fields of image processing, computer vision, and graphics to enhance the tool's capabilities.Conduct thorough testing and debugging to ensure the accuracy and reliability of the tool's output.Stay up-to-date with the latest trends and advancements in floorplan representation, computer graphics, and design to continually improve the tool's functionality and user experience.Document the development process, including algorithms, methodologies, and technical specifications, for reference and future enhancements.Qualifications:Bachelor's or Master's degree in Computer Science, Software Engineering, or a related field.Strong programming skills in languages such as Python, Java, or C++, with experience in image processing, computer vision, or graphics-related projects.Proficiency in image processing libraries or frameworks, such as OpenCV.Knowledge of graphic design principles, color theory, and composition.Familiarity with architectural drawings, 2D floorplans, and interior design concepts.Excellent problem-solving and analytical skills, with attention to detail.Effective collaboration and communication abilities to work with cross-functional teams and gather feedback from stakeholders.Self-motivated and able to work independently while adhering to project deadlines.Experience in testing and debugging software applications is a plus.Join our dynamic team and contribute your skills to create an innovative floorplan conversion tool that revolutionizes the way spaces are visualized. Apply now with your resume, portfolio, and any relevant project samples.","['Generative AI', 'Artificial Intelligence', 'Image Processing', 'Computer Vision', 'Graphic Design', 'GitHub', 'Python', 'Machine Learning', 'three.js', 'Image Processing', 'Computer Vision', 'Graphic Design', 'GitHub', 'Python', 'Machine Learning', 'three.js']",Israel,55,,100,['Real Estate'],1000.00,,Remote Job,Expert
PowerBI with Microsoft Dataverse,Seeking resource with experience in PowerBI. Ideal candidate has used Dataverse and PowerBI together to create line based reports and graphs as well.  Please provide some samples of some PowerBI reports as well.,"['Microsoft Power BI', 'Data Visualization', 'Data Analysis', 'Data Analysis']",United States,624,23.22,656,,,,Remote Job,Intermediate
Company Data Scraper,"Hello Freelancers, I’m looking for an individual to scrape companies for me. I’m looking for thousands of companies within specific guidelines to be put into a google sheets document. These companies need to be FinTech/ Web 3.0/ Crypto-based and I want to capture any companies that are targeting people age 16-35. So ONLY Business to Consumer Companies. Are you aware of the platforms TikTok and Instagram? Any companies that are suitable to be marketed there within the FinTech/ Web 3.0/ Crypto Space. If you think you can do this using software/ Ai/ or not I don’t mind as long as you can make sure they are suitable! I’m looking forward to hearing back from you!Reyan","['Data Scraping', 'Data Mining', 'Lead Generation', 'Data Extraction', 'Influencer Marketing', 'Instagram', 'TikTok', 'Lead Generation', 'Data Extraction', 'Influencer Marketing', 'Instagram', 'TikTok']",India,1,,,"['Sales', 'Marketing']",,,Remote Job,Intermediate
Selenium and Python Script to Download Remote Sitemap - Extract Data and Post to Web Service,"PLEASE READ THIS BEFORE APPLYING TO THIS JOB:I appreciate your interest in this project, but I want to be clear about my expectations upfront. This is not a multi-day project, and I require it to be created and delivered within a couple of hours. If you estimate that it will take you 2-3+ days to complete, I kindly request that you do not proceed with your application.  DON'T WASTE MY TIME OR YOURS APPLYING.As a fellow developer, I understand the technologies involved, including Selenium, PHP, bash, curl, and more. Based on my experience, I have a general idea of the time required for this task, and it should not extend beyond a few hours.I hope this clarifies the time frame I'm expecting for the project. Thank you for understanding.------------------------------------------------------------------------------Looking for a web scrapping expert to develop a Selenium, Python,  Bash script that will perform the following:- Download and extract a remote sitemap to local directory.- Loop thru entries of the sitemap file and read the url (loc) tag.- Create new ""target"" url string from the ""loc"" tag .- Open target url and extract data.- Post extracted data to a webform (already created)- LoopHere is the url of the sitemap that you will need to download:  https://s3.amazonaws.com/kunversion-frontend-sitemaps/sellwithduran.com/sitemap-listings-1.xml.gzHere is an example of a page (url) in the sitemap.  This's the ""loc"" that you will be reading to create the target url string:https://www.sellwithduran.com/property/129-3483489-18-Greenbrush-Court-Greenlawn-NY-11740Create string split function that will read the url and create a new one that will look like this:  https://www.sellwithduran.com/property/3483489/18-Greenbrush-CourtOpen that url, extract the following data:- Address- City- State- Zip Code- Price- Status- Description- Bedrooms- Baths- Annual Taxes- Year Built- TypeNext, post extracted data to a form which is already created.The script will be running on a windows desktop (Windows 11)  currently running the latest version of chrome.I'm available to discuss and start as soon as possible.I will provide TeamViewer for you to install and run the script. Project will not be consider completed until the script is successfully  executed on my desktop. ------------------------------------------------------------------------------AGAIN, PLEASE READ THIS BEFORE APPLYING:I appreciate your interest in this project, but I want to be clear about my expectations upfront. This is not a multi-day project, and I require it to be created and delivered within a couple of hours. If you estimate that it will take you 2-3+ days to complete, I kindly request that you do not proceed with your application.  DON'T WASTE MY TIME OR YOURS APPLYING.As a fellow developer, I understand the technologies involved, including Selenium, PHP, bash, curl, and more. Based on my experience, I have a general idea of the time required for this task, and it should not extend beyond a few hours.I hope this clarifies the time frame I'm expecting for the project. Thank you for understanding.","['PHP', 'Data Scraping', 'Python', 'Scripting', 'Selenium', 'Data Extraction', 'Selenium WebDriver', 'Automation', 'Selenium', 'Data Extraction', 'Selenium WebDriver', 'Automation']",United States,32,,1.6,['Real Estate'],,"['3.00', '50.00']",Remote Job,Intermediate
"Google Analytics, Set Up, GA4","Someone who can do Google Analytics, maybe as well Google tag manager tracking and also a SetUp cross domain tracking.We are a startup, so we have to put our two websites in one google analytics if it is possible.","['Google Analytics', 'Google Tag Manager', 'Google Ads', 'Google Ads']",Switzerland,2,,0,"['Retail', 'Consumer Goods']",50.00,,Remote Job,Expert
Optimize my Python code,"I have 2 Python files that I wrote which are running very slow. The involve Pandas and dataframes and text processing. I would like you to work on these to make them run faster. I'm looking to get a 5x to 10x improvement in execution and output.I am also including the input data file and output file, along with the 2 Python files. Your output must match my output exactly. It has to be the same.The budget is fixed. I would like this to be done ASAP 3 days max. Looking forward to working with you!Input file = 2023 Mens Tour - Test.xlsxOutput file = PointsData.csv","['Data Extraction', 'Data Mining', 'Python', 'Data Science']",United States,50,,2.4,,16.00,,Remote Job,Intermediate
Digital Marketing Data Analysis & Report Creation,"We are looking for someone who can create YTD stat reports for our clients based off print / digital marketing campaigns completed from January - present.Reports will be formatted in excel and will be stat reports pulled from various social platforms.This project will consist of multiple client reports completed prior to August 1 with drafts and updates needed.  Approx. 20-30 reports but this project can be ongoing with the right candidate. Self-starter, detail oriented, must have knowledge in digital analytics and strong knowledge of excel.","['Marketing Analytics', 'Report', 'Google Analytics', 'Market Analysis', 'Microsoft Excel', 'Data Analysis', 'Analytics', 'Microsoft Excel', 'Data Analysis', 'Analytics']",United States,152,27.28,293,,,"['30.00', '55.00']",Remote Job,Intermediate
Help With Capturing and Passing GCLID Data via Webform,"We are looking for someone to help us with our webform that should capture the GCLID from google ads for each customer via a hidden field and pass that value into our CRM and Thankyou email. .We are also looking for help to capture other UTM data in campaign id, device and keyword used via hidden fields.We have had a go at adding the code provided by google but cannot get it to pass through the GCLID.We require someone who has had previous experience setting up the GCLID.","['CRM Development', 'Compaign', 'Google Ads', 'Web Development', 'GCLID', 'webform', 'Google Ads', 'Web Development', 'GCLID', 'webform']",Pakistan,67,,,,,"['10.00', '15.00']",Remote Job,Expert
Scrap Linkedin Search URLs at Scale,Hi there! I have a list of LinkedIn search URLs. I need to scrap all the profiles and get their emails.I do not provide any LinkedIn cookie or Email finder API key.I'm currently using PhantomBuster with Hunter.io but it does not scale.Thanks!,"['Data Scraping', 'Lead Generation', 'Data Mining', 'Prospect List', 'Data Mining', 'Prospect List']",Morocco,78,7.00,14,,,"['3.00', '50.00']",Remote Job,Expert
Build a Radiomic library,"I need a Radiomic library to be built for PET imaging. The library should be able to extract features such as shape-based, intensity-based, and texture-based features. It should be compatible with Python programming language. The ideal candidate should have experience/good knowledge in medical imaging and knowledge of Radiomics. Proficiency in Python programming language is a must.The main goal is to create a radiomic library using pyradiomicsi have a csv file with DICOM metadata which should be used to train the modelthe library should include all the steps like segmentation of the PET images , feature extraction and feature selection","['Python', 'Machine Learning', 'Data Science', 'Software Architecture', 'Software Architecture']",United Kingdom,305,5.00,2.9,,,"['10.00', '15.00']",Remote Job,Expert
Python script to determine Best Fit (ML or Statistics),"I have two CSV files for input.Each CSV file contains columns with the output of algorithms ran on some data.One CSV file contains the output of the alogirthms from unmodified data.The other CSV file contains the output of the algorithms from modified data.I need a script that is able to take in the input from both CSV files, then determine and output the values each algorithm should be set to in order to predict if certain data is ""unmodified"" or ""modified"".","['Python', 'Data Science', 'Machine Learning', 'Python Scikit-Learn', 'Python Scikit-Learn']",United States,33,46.21,14,"['Tech', 'IT']",,"['40.00', '75.00']",Remote Job,Expert
Youtube lecture search,A list of 1000 Youtube lectures on maths is required  for exam identical to the links below:(Before submitting proposals watch each vdu upto end so to find said exactness)https://www.youtube.com/watch?v=Wk4Lj8mJx8Ahttps://www.youtube.com/watch?v=0D8OBNc6Oyohttps://www.youtube.com/watch?v=pNBwHuLe7Rchttps://www.youtube.com/watch?v=JjIbZY-iGIshttps://www.youtube.com/watch?v=wKiazbE2EhUhttps://www.youtube.com/watch?v=uDUNYbyyO_4https://www.youtube.com/watch?v=jXyEIJ11n2M,"['Presentations', 'Data Visualization', 'JavaScript', 'Python', 'Education', 'Data Entry']",Pakistan,5,,,,,"['5.00', '7.00']",Remote Job,Entry level
Phocas Software Report & Dashboard Developer,"We have recently implemented a reporting tool called Phocas that draws data from multiple sources.  Some through API and some through a data parsing process from excel exports.  We would like to have someone build dashboards and reporting in the tool for us, ideally they would be familiar with the software, however not necessary as it seems to be fairly straight forward work.  Attention to detail, ability to speak good English and understand relatively large data sets.","['Microsoft Excel', 'Phocas Software', 'API Integration', 'API Integration']",United States,1,,,,5000.00,,Remote Job,Intermediate
"Using LLM, Match user tone while drafting the content | Langchain |Generative AI","We are seeking an experienced professional to assist with content drafting using LLM and generative AI for our Langchain. The ideal candidate should have a strong background in Generative AI, Large Language Model, and Natural Language Processing.This is 4-5 hour job, and the chosen candidate will be responsible for matching the user's tone while drafting the content using LLM. Interested candidates should submit a proposal detailing their experience and how they can help with the project. Please include links to past completed projects that showcase your skills in Generative AI, Large Language Model, and Natural Language Processing.We look forward to reviewing your proposal and selecting the best candidate for the job.","['Natural Language Processing', 'Generative AI', 'Large Language Model']",India,11,,240,,40.00,,Remote Job,Expert
PowerBI Expert Needed for Long Term Dashboard Management,"Looking for an experienced data analytics professional to work with our agency, creating dashboards for multiple clients. Each client's dashboard will look similar to this:• Google Analytics Visitor Data• Google Analytics Conversion Data• Lead Data from MSSQL• Lead Data from Call Rail• Possibly an additional connector (some client's use salesforce, hubspot, etc)What we require from our partner:• You must be an expert in PowerBI or LookerStudio• You must be able to collect data from multiple sources and present in a dashboard similar to the 4 screens shared below.• You must be flexible and willing to solve problems or challenges our client's may ask for (eg.  Can you show a chart with 'xyz').I repeat that last bullet, we are looking for someone who can self manage and solve problems.This is long term project.  We anticipate the individual we hire managing these dashboards for us into the future.We have an urgent need to create 1 new dashboard ASAP (next 2-3 days).  We will be looking to hire someone quickly.   Please let us know if you are available to work this weekend.","['Dashboard', 'Digital Mapping', 'Looker', 'Microsoft Power BI', 'Data Visualization', 'Data Analysis', 'Business Intelligence', 'Data Modeling', 'Google Data Studio', 'Tableau', 'Data Analysis', 'Business Intelligence', 'Data Modeling', 'Google Data Studio', 'Tableau']",United States,70,7.61,6.1,"['Sales', 'Marketing']",,"['15.00', '25.00']",Remote Job,Expert
Economist to help develop system can see Aerospace Raw Material pricing every week for newsletter,"We are building a newsletter for aerospace supply chain professionals. In part of the newsletter, we want to display a dashboard which shows the pricing of most common raw materials. Pricing to be in USD. Unsure how to display this, assuming it will be something like USD/mt (price per metric ton). There are several indexes that might be best to reference such as Metals exchange, Carbon Fiber pricing index, composites index, etc. Our goal is to show if our readers can expect the pricing of these materials to go up or down from the week prior. We're less worried on how the data will be displayed, really focused on someone developing a system where we can get the data every week for each of these materials. So maybe build a dashboard for this that we can reference and use the data for our newsletter.  Materials to include: - Aluminum- Stainless Steel- Steel- Titanium - Inconel - Carbon Fiber - Composites - Advanced Plastics / Polymers - Composite Honeycomb (lower priority)","['Operations Analytics', 'Product Analytics', 'Dashboard', 'Query Development', 'Data Visualization', 'Data Analysis', 'Python']",United States,23,56.37,35,['Aerospace'],,"['18.00', '80.00']",Remote Job,Intermediate
Integrating GPT 4 or other LLM into Vessel,"We are looking for a skilled professional to integrate GPT 4 or other LLM into our Vessel platform. The ideal candidate should have experience in ChatGPT, Bard, Deep Learning, Live Chat Software, Machine Learning, and TensorFlow. The project will last anywhere from 1 to 3 months, depending on the complexity of the integration.As the candidate, we would like to see how you can help us achieve our goals. Please submit a proposal outlining your experience with these technologies and how you plan to integrate them into our platform. We would also appreciate links to any past completed projects that demonstrate your expertise.The successful candidate will be responsible for integrating GPT 4 or other LLM into our Vessel platform, ensuring that it is fully functional and meets our business requirements. You will work closely with our team to identify any potential issues and ensure that the integration is seamless.If you have the required skills and experience, we would love to hear from you. Please submit your proposal along with links to any relevant past projects. We look forward to hearing from you soon.","['ChatGPT', 'Machine Learning', 'Deep Learning', 'TensorFlow', 'Bard', 'Live Chat Software', 'TensorFlow', 'Bard', 'Live Chat Software']",United States,4,,,,,"['35.00', '55.00']",Remote Job,Expert
Seeking a solid SQL server developer with knowledge of Azure Data Factory Dataflows,Seeking a solid MS SQL Server Developer with excellent scripting skills and sound knowledge of Azure Data Factory Dataflows. Should be able to interpret existing SQL scripts and transfer it to Azure Data Factory/Synapse Dataflow.Good communications skills in English is a must.,"['Microsoft Azure', 'Azure data factory', 'Microsoft SQL Server Programming', 'ETL', 'Microsoft SQL Server Programming', 'ETL']",Canada,1,,,,15.00,,Remote Job,Expert
GA4 Migration,"We are seeking a skilled and experienced freelancer to assist us with migrating our existing Google Analytics setup to Google Analytics 4 (GA4) while ensuring the conservation of Google Tag Tracking and Conversions. This project requires strong knowledge of both Google Analytics and Google Tag Manager, as well as expertise in data migration and tracking implementation.Responsibilities:- Analyze and assess our current Google Analytics setup, including tracking tags and conversion events, to identify potential challenges and dependencies for the migration process.- Develop a comprehensive migration plan that outlines the steps, timelines, and required resources for migrating from the current Universal Analytics to Google Analytics 4.- Implement the necessary changes in Google Tag Manager to ensure a seamless transition to GA4, including updating existing tracking tags and configuring new event tracking for conversions.- Collaborate with our development team to ensure proper data layer implementation and data integrity throughout the migration process.- Perform rigorous testing and quality assurance to verify the accuracy and completeness of the migrated data in GA4.- Provide documentation and training materials to enable our internal team to understand and utilize the new GA4 features and reporting capabilities effectively.Requirements:- Demonstrable experience in Google Analytics and Google Tag Manager, with a proven track record of successful migration projects.- Strong knowledge of Google Analytics 4, including its features, event tracking, and data layer implementation.- Familiarity with conversion tracking and implementation using Google Tag Manager.- Proficiency in JavaScript, HTML, and CSS for troubleshooting and custom tracking implementation, if required.- Excellent analytical and problem-solving skills, with a keen eye for detail.- Effective communication and collaboration skills, able to work with cross-functional teams.- Ability to work independently, prioritize tasks, and meet project deadlines.","['Google Analytics', 'Google Tag Manager']",United Kingdom,54,31.26,113,,,"['20.00', '75.00']",Remote Job,Expert
"roperty maintenance contractor email, phone, country  in NY usa","provide property maintenance contractor email, phone, country  in NY usa. contractor such as landskeeping, grass cut, pool securing, property interior and exterior maintenance, tree triming","['Database Management', 'LinkedIn', 'Data Science', 'Google Sheets', 'Data Cleansing', 'Data Mining', 'Data Entry', 'Lead Generation', 'List Building', 'Online Research', 'Data Science', 'Google Sheets', 'Data Cleansing', 'Data Mining', 'Data Entry', 'Lead Generation', 'List Building', 'Online Research']",United States,1,,,,50.00,,Remote Job,Intermediate
Scraping from Arabic (Algerian) forums,We are looking for a freelancer who can scraping from Arabic (Algerian) forums. We have 2 forums to scrape from. Top candidates will be given more information about the task.,"['Data Scraping', 'Data Mining']",Hong Kong,38,,6.5,,100.00,,Remote Job,Intermediate
Importing CCDA files into eClinicalWorks,looking for subject matter expert in file integration around EMR/EHR systems. Looking for someone with experience working with multiple EMR/EHR systems . the goal is to import CCDA files from one EMR system into 2nd EMR system eClinicalWorks.,"['Data Processing', 'eClinicalWorks', 'XML', 'intergration', 'ccda', 'ccda']",United States,20,99.24,27,,,"['150.00', '200.00']",Remote Job,Expert
Route planning (script needed - no need for any UI) - Ops research,Need a route planning program whereThere would be inputs such as:1. Client location2. Kitchen location3. Vehicle capacity4. Pickup time5. Delivery timeOutput needed:In what sequence should the deliveries be done? (The orders should be batched wherever applicable) - e.g. a driver can pick up multiple orders (constrained to the capacity),"['Python', 'Data Science', 'Operations Research']",India,1,,,,,"['20.00', '40.00']",Remote Job,Intermediate
Power BI Financial Report Development,Develop Power BI visualizations for monthly financial sales reporting. This is a rewrite of several SSRS reports. Primary data source is SQL. Output will include a report with various pre-defined filters/slicersDedicated Project Manager will interface. Project Team will engage in QA process.Supplementary documents will be provided for full scope of work.Anticipated timeline:• Development: June 2023 - September 2023• Quality Assurance Testing: October 2023 - January 2024• Production: February 2024,"['Dashboard', 'SQL', 'Microsoft Power BI', 'Microsoft Excel', 'Business Intelligence', 'Data Visualization', 'SQL Server Reporting Services', 'Microsoft Power BI Data Visualization', 'Data Analysis', 'Business Intelligence', 'Data Visualization', 'SQL Server Reporting Services', 'Microsoft Power BI Data Visualization', 'Data Analysis']",United States,20,36.94,114,,,,Remote Job,Intermediate
Multi-tennacy DB Lambda Multi-continental Data Distribution Expert,"We are seeking a cutting edge technologist that can work in consulting and architecture design to support a 1M+ userbase that spans the globe.There are legal considerations, technical considerations that need to be considered before deploying worldwide.We need someone who has already engineered a similar system that can answer our questions about designing around the constraints of worldwide distribution and handle any of the planning that is required in the nuance of each deployment.We need an individual that can plan around 2 layers of tenancy and micro-service deployments with different configurations provided for each of the deployment to handle differentiation in pricing/language/display/ etc.Our stack is:LaravelLambdaNginxNodePythonRDBWe are looking for a specialist in the data layer that can help us design a system to segment based on the traffic to the site and deliver a seamless system for CI/CD data integrity, security.","['Database Design', 'Data Preprocessing', 'PHP', 'AWS Lambda']",United States,154,27.20,235,"['Tech', 'IT']",1000.00,,Remote Job,Expert
Artificial Intelligence Consultant,"I need of a consultant to guide organization through the use and incorporation of artificial intelligence to augment, support and develop a professional ecosystem.  The candidate should have knowledge of the current AI landscape, current capabilities of AI,  and future of AI. Ultimately, will need support and assist in deploying those AI capabilities into a professional ecosystem.","['Artificial Intelligence', 'Machine Learning', 'Data Science', 'Data Analysis', 'Deep Learning', 'Machine Learning', 'Data Science', 'Data Analysis', 'Deep Learning']",United States,5,,,,,"['30.00', '60.00']",Remote Job,Intermediate
German Side By Side Project,"BackgroundIn this project, 2 different search results will be put on the same page, then you need to determine which one is better according to the rules and experience, and better meet the user's demands. So that optimizes the performance of search engines.Responsibilities1.	Determine the demand of the query and judge if it needs to be dropped2.	Compare the full page experience of both sides3.	Score the full page search experience of both sides4.	Achieve the daily quality and quantity targets set by the PMRequirements1.	Native speakers of German2.	Good command of English (minimum B2 English level)3.	Available to work 4 hours (PTE) per day (during the training might need to work 8 hours per day)5.   Available to be online every weekday from 13-14pm4.	TikTok users and young people (20 - 40 years old) will be preferred5.	Similar working experience in the data annotation industry will be preferred6.	 Up-to-date PC (Windows 10 or later) or Mac (Big Sur or later) with stable utility and internet connectionStart date: on going project Project duration: Long-term project (about 12 months)","['German', 'English']",China,3,,,"['Tech', 'IT']",9.00,,Remote Job,Entry level
Web Crawler/Scraper/Data Mining for YC Startup,"Santé is a modern POS for liquor stores. We are going through the YC program this summer.We are looking for an expert software engineer to help us create a crawler/scraper that extracts data from a few websites, structures it, and stores it on our own backend.Thanks,","['Python', 'Data Scraping', 'Data Mining', 'Data Extraction', 'Web Crawling', 'TypeScript', 'Data Extraction', 'Web Crawling', 'TypeScript']",United States,20,50.00,6.2,"['Finance', 'Accounting']",,"['20.00', '60.00']",Remote Job,Expert
LSTM task,Need to apply LSTM on multiple intercorrelated timeseries to predict multiple timeseries,"['Deep Learning Modeling', 'Neural Network', 'Deep Learning']",Estonia,18,23.75,120,,,"['13.00', '40.00']",Remote Job,Intermediate
Native Kazakh Speakers Based in the Kazakhstan Needed for Automatic Speech Recognition,"BackgroundThis project is related to ASR (Automatic Speech Recognition), which to make it simple, is to transcribe what you hear from the provided audio. The purpose is to transcribe the audios as correctly as possible, to help improve AI technology. Those audios are mainly in your native languages. This way we can develop strong and independent AI technologies together!Responsibilities1. Transcribe the audios following the policy2. Achieve the daily quality and quantity targets set by the PMRequirements1. Native speakers of Kazakh, good command of English is preferred2. Available to work at least 8h/day with an up-to-date PC and stable Internet connection3. Have a good sense of language4. Similar working experience in the data annotation industry will be preferredAdditional Notes1. A qualification test will be provided by the end of the training. Your training fee will be added to the nearest payment once you pass the test2. Planned leaves (including public holidays) need to be claimed a week in advance3. A two-week notice by email is required for resignation*Start date: 2023/06/12*Project Duration:  About 3 months*Please attach your CV if you would like to join.","['English', 'Kazakh']",China,3,,,"['Tech', 'IT']",,"['3.00', '4.00']",Remote Job,Entry level
Live videos with AI avatars platform,"We're a Live video AI avatar platform startup! We want to create a platform where people can speak 1-1 on live video with an AI avatar that responds back, looks real, remember conversations and ask questions  We're looking for experts with deep expertise in artificial intelligence who wants to join us on this huge opportunity journey! We're looking for our CTO role and AI experts who knows everything about API's, development, machine learning, integrations etc.We are only looking for the best of the best talent around the world! We are currently 6 people on the team with deep expertise in marketing, branding & sales. Best regards August ","['AI Model Integration', 'Conversational AI', 'Generative AI', 'ChatGPT', 'AI Chatbot', 'AI-Generated Video', 'Automatic Speech Recognition']",Denmark,99,,1.4,,,,Remote Job,Expert
Database trading manager,"Hi, we are looking for someone who will be responsible from 6PM to 00AM UTC+2 ,  timezone for our trading database (monday to sunday work).It's required to be a very precise person.Google sheet and Google form knowledge also required.Nice to have: trading language and Tradingview knowledge.Looking for someone to build a lasting partnership with.","['Google Sheets', 'Google Forms', 'Tradingview', 'Trading Language', 'Telegram', 'Trading Language', 'Telegram']",Italy,6,,1.6,"['Finance', 'Accounting']",300.00,,Remote Job,Intermediate
Analysis of the provided database using sql,"We are looking for an experienced SQL expert to help us analyze a provided database. The successful candidate will be responsible for conducting a thorough analysis of the database and creating visualizations to help us better understand the data. The project is expected to take less than one month to complete.As a SQL expert, you should have experience in data analysis, database management, database programming, data visualization, and SQL programming. You will need to be able to analyze large datasets quickly and efficiently to provide insights that can be used to improve business decisions.To apply for this job, please submit a detailed proposal outlining your experience and how you can help us with this project. Please include links to past completed projects that demonstrate your experience in SQL and data analysis.We are looking for someone who is self-motivated, detail-oriented, and able to work independently. If you meet these qualifications and are interested in working with us on this project, please submit your proposal.Note: Some of the content in this job post may have been auto-generated using advanced AI.","['Data Analysis', 'Data Visualization', 'SQL', 'SQL Programming', 'Database Programming', 'Database Management', 'Database Management']",China,40,40.00,3.1,,,,Remote Job,Intermediate
Basketball Analysis to tag basketball games,Looking for a person who know how to identify basketball stats and has a windows computer.  Attention to detail is critical.,['basketball'],United States,4,6.66,694,,,"['3.00', '6.00']",Remote Job,Entry level
Fine tune a Vall-e Speech Synthesis Model,"We want to fine tune a model based on https://arxiv.org/abs/2301.02111 and one of the open source implementations https://github.com/topics/vall-eWe need someone who has experience working with Speech Synthesis, Neural Codecs and has experience setting up hyperparameters for these problems The ML Engineer will work on data preparation using lhotse or other equivalent tools, will train a model / fine tune it / and deliver the model weights and the inference logic","['PyTorch', 'Deep Learning']",United States,9,95.00,450,,,"['13.00', '40.00']",Remote Job,Intermediate
Python hardware testing project,I need to assistance with a project that requires hardware testing with python to show the difference in parallel and sequencial testing for 2 different computers. I will also require a short write-up on the progress and work that was done for this project as well.,"['Python', 'Software QA', 'Software Testing']",Singapore,71,,1.4,,20.00,,Remote Job,Intermediate
Email Database scraper needed,We have 3 websites we need you to scrape and get us the email addresses. You should format them in Excel so I have the company name in 1 column and email address in another column.,"['Data Scraping', 'Data Mining', 'List Building', 'Data Extraction', 'List Building', 'Data Extraction']",United States,1,,,,100.00,,Remote Job,Intermediate
Power bi,"Hi, I am looking for a power BI tutor who can teach me from the basics to advanced and also using live projects. And in future, matbe Python and SQL as well. Do you also teach? If yes, what's your hourly rate for coaching and how much duration it will require usually. Please let me know. Thanks.","['Microsoft Power BI', 'Microsoft Power BI Data Visualization', 'Microsoft Power BI Development', 'Microsoft Power BI Development']",India,4,,,,,"['3.00', '4.00']",Remote Job,Expert
"Search, copy and paste email addresses from a website to excel.","Need to search, copy and paste 1300 email records from a website to excel format. I will  provide the website link. More work opportunity will be provided upon successful completion of the task.","['Data Extraction', 'Data Integration', 'ETL', 'SQL', 'PHP', 'Python', 'Web Scraping Plugin', 'Data Mining', 'Data Scraping', 'Microsoft Excel', 'Microsoft Excel']",Pakistan,69,1.21,113,"['Sports', 'Recreation']",5.00,,Remote Job,Intermediate
Short Term AI Programming,Looking for someone who can program AI to go through about 100 old books and organize the information in those books into various categories with quotes. This is for the development of an app that would then allow this to be searchable and organized in various different ways. Second job could be creating the app.,"['Artificial Intelligence', 'Python', 'Python']",United States,46,12.71,7.7,['Education'],,,Remote Job,Intermediate
"Analysis + Data Cleaning, Assumption Testing, Preliminary Analyses and Inferential Statistics","I require a written analysis of 700 words. Must be completed within 24 hours.To complete this job, you will need to download the Data File (Excel spreadsheet, .xlsx) and import it into SPSS so that it can be saved as an SPSS file (.sav) for subsequent use. You will need to appropriately annotate your file by labeling your variables before conducting the required analyses.Data Cleaning, Assumption Testing, Preliminary Analyses (such as descriptive statistics and correlations), and Inferential Statistics (specifically, mediation or moderation analysis using Hayes' PROCESS macro in SPSS). Reporting the details of the assumption tests should be concise yet informative enough to demonstrate your understanding of the criteria, outcomes of each statistical assumption.","['Statistics', 'Data Analysis', 'IBM SPSS', 'Statistical Analysis', 'IBM SPSS', 'Statistical Analysis']",Australia,177,,10,,30.00,,Remote Job,Entry level
Data Miner based in El Salvador,We are looking for a freelancer based in El Salvador to test the sportsbook website.No previous experience is needed as we will prepare everything and the person who is given the job will simply check out the sportsbook website and fill in the data in our spreadsheets.Looking forward to hearing from you!,"['Online Research', 'Data Mining', 'Data Entry']",Denmark,316,18.84,83,,500.00,,Remote Job,Intermediate
Grafana - Percona Dashboards,"hi, I am looking to help create grafan dashboards. We are using grafana with percona to collect statistics from VM's in our system ( CPU load, memory etc ) , and I would ike to being on board soembody who is proficient in building dashboards, alerts etc. We have grafan/percona installed,  so that is done, but want to get someone on board who can bring real value from the data we are gathering and make it useful.regards,manu","['Grafana', 'percona', 'Performance Optimization']",United Kingdom,90,6.95,14,"['Tech', 'IT']",,"['10.00', '20.00']",Remote Job,Intermediate
Spoof Checker Dapp and Bot,"Project OverviewThe objective of this project is to develop an intelligent bot for Telegram and a decentralized application (DApp) on the Ethereum blockchain that can identify and eliminate spoofing transactions. The solution will have self-learning capabilities and a knowledge base that gathers and saves spoof data from various blockchain explorers such as Etherscan.Detailed RequirementsTelegram BotUser Interaction: The bot should support interaction with users in a user-friendly and intuitive manner.Notifications: The bot should be able to send notifications to users about potential spoofing transactions.Spoofing Detection: The bot should analyze transactions and identify potential spoofing behavior, such as rapid buying and selling, deceptive transaction volumes, etc.Knowledge Base Integration: The bot should access the DApp's knowledge base to improve its detection capabilities and update its understanding of spoofing patterns.Auto-learning Features: The bot should have machine learning capabilities to continuously improve its detection algorithms.Security: The bot must ensure user privacy and data security.DAppSmart Contract: The DApp will be built on Ethereum and will utilize smart contracts to identify and delete spoofing transactions.Integration with Blockchain Explorers: The DApp should pull data from blockchain explorers like Etherscan to update its knowledge base of spoofing transactions.Knowledge Base: The DApp should maintain a knowledge base of spoofing patterns and data, which can be used by the Telegram bot.Auto-learning Feature: The DApp should also have machine learning capabilities to improve its spoofing detection and mitigation measures.Security: The DApp must ensure the security of transactions and user data.Performance: The DApp should be optimized for high performance and low latency.Possible FeaturesUser Dashboard: An interface that allows users to monitor their transactions and alerts.Customization Options: Users can customize their notification preferences and the bot’s behavior.Reports: Detailed reports on detected spoofing transactions and actions taken.Integration with Other Messaging Platforms: The bot could be extended to other platforms beyond Telegram.Skills NeededTelegram Bot Development: Experience with developing bots for Telegram using their API.Blockchain Development: Proficiency in Ethereum smart contract development, preferably in Solidity.Data Analysis: Skills in data analysis to identify spoofing patterns.Machine Learning: Knowledge of machine learning algorithms to develop the auto-learning feature.Security: Understanding of cybersecurity principles and blockchain security.Backend Development: To build and manage the DApp's knowledge base and integration with blockchain explorers.UI/UX Design: For user dashboard and customization options.DevOps: For deployment, monitoring, and maintenance of the bot and DApp.Design Documents: Comprehensive documents detailing the architecture and design of the Telegram bot and DApp.Telegram Bot: The fully functional bot with all the described features.DApp: A secure, robust, and scalable DApp as per the requirements.Knowledge Base: A comprehensive knowledge base that stores and updates spoofing patterns and data.Testing Reports: Reports detailing the testing process and results.Deployment Guide: A guide outlining the deployment process and requirements.User Manual: A detailed manual instructing users on how to use the bot and DApp.Maintenance and Update Plan: A plan for regular maintenance and updates to the bot and DApp.Telegram BotSpoofing Checker: The bot should be equipped with a spoofing checker that verifies all incoming transactions. This checker should:a. Real-time Analysis: Analyze transactions in real-time to promptly identify any spoofing behavior.b. Pattern Recognition: Identify typical spoofing patterns (rapid buying and selling, fake volumes, etc.) using machine learning algorithms and the knowledge base from the DApp.c. Risk Assessment: Assign risk scores to transactions based on their likelihood of being spoofed.d. Notification System: Alert users immediately when a potential spoofing transaction is detected.DAppSpoofing Checker: The DApp should also include a spoofing checker to verify transactions within the blockchain. This checker should:a. Smart Contract Integration: Be integrated within the smart contract to automatically verify transactions.b. Pattern Recognition: Use machine learning and the knowledge base to identify spoofing patterns.c. Automatic Deletion: Have the capability to automatically reject or delete transactions identified as spoofing.d. Data Feed: Feed data on detected spoofing transactions back into the knowledge base for future reference.Skills Needed","['Chatbot', 'Deep Learning', 'Artificial Intelligence Ethics', 'Neural Network', 'C++', 'JavaScript', 'Node.js', 'Blockchain', 'C#', 'API', 'C#', 'API']",United States,67,6.31,3.7,"['Tech', 'IT']",,"['7.00', '25.00']",Remote Job,Intermediate
ArcGIS developer,We are seeking proposals for the delivery of an AI trained solution that can identify and map swimming pools and swimming pool enclosures in Europe and Australia using satellite imagery.We would like to know:How many pools there are by countryHow many retractable pool enclosures there are by countryWe also want a map with:All pools enclosures pinnedAll retractable pool enclosures pinnedA heatmap for swimming pools and retractable pool enclosures,"['ArcGIS', 'GIS', 'QGIS', 'Python', 'ArcGIS Online']",Australia,4,15.00,441,"['Manufacturing', 'Construction']",,,Remote Job,Intermediate
ArcGIS developer,We are seeking proposals for the delivery of an AI trained solution that can identify and map swimming pools and swimming pool enclosures in Europe and Australia using satellite imagery.We would like to know:How many pools there are by countryHow many retractable pool enclosures there are by countryWe also want a map with:All pools enclosures pinnedAll retractable pool enclosures pinnedA heatmap for swimming pools and retractable pool enclosures,"['ArcGIS', 'GIS', 'QGIS', 'Python', 'ArcGIS Online']",Australia,4,15.00,441,"['Manufacturing', 'Construction']",,,Remote Job,Intermediate
Experienced ETL developer for re-writing data transformation scripts,"Our SaaS products are built on MySQL DB (for daily transaction storage) and AWS Redshift (for data warehouse). We have established a data pipeline between MySQL DB and Redshift using AWS Glue (PySpark). PySpark scripts are responsible for extracting data from MySQL DB, performing transformations, and loading the result in Redshift. We are facing problems with regard to the performance of the scripts. Hence, we are looking for an experienced ETL developer who will work along with our ETL developers and will help in improving the performance of the jobs.This job opportunity requires a person to be involved in the performance tuning of existing ETL jobs or rewriting the complete job to achieve optimal performance.","['Apache Spark', 'Scala', 'PySpark', 'Python', 'SQL']",India,16,7.63,2.4,"['Tech', 'IT']",,,Remote Job,Intermediate
Create a calculator tool in excel with a scoring system,"Hi,Looking for someone who can help with creating a calculator tool in excel. The tool will calculate a score based on a number of questions and then allocate a recommendation accordingly. Details will be provided.Thanks","['Microsoft Excel', 'Visual Basic for Applications', 'Desktop Application', 'Desktop Application']",United Arab Emirates,73,23.47,16,,,"['18.00', '45.00']",Remote Job,Intermediate
AI based messenger,Need an App that combines AI for personalized messenger services for dating. Want to improve and simplify the communication. A combination between e.g. Chat GPT in connection with a nice App layout will be cool.,"['Artificial Intelligence', 'Graphic Design', 'Chatbot Development', 'Machine Learning', 'Chat & Messaging Software', 'Graphic Design', 'Chatbot Development', 'Machine Learning', 'Chat & Messaging Software']",Switzerland,1,,,,5000.00,,Remote Job,Intermediate
Typeform - UTM Tracking,We need to create a system that assigns a UTM parameter to a typeform submission within our google sheet storage of all of the submissions. Please find a detailed brief attached below.,"['Marketing Analytics', 'Typeform', 'Google Analytics', 'Google Tag Manager', 'Google Tag Manager']",United Kingdom,7,,3.4,"['Fashion', 'Beauty']",,"['9.00', '45.00']",Remote Job,Intermediate
Technical Writer - Data Flow Analysis Model Specialist,"Technical Writer - Data Flow Analysis Model SpecialistJob Description:We are seeking a skilled Technical Writer with expertise in creating data flow analysis models based on existing setups. As a Technical Writer specializing in data flow analysis, you will be responsible for documenting and communicating complex data flow processes and systems in a clear and concise manner. You will work closely with cross-functional teams to understand existing setups, gather information, and translate technical concepts into easily understandable content.Responsibilities:Conduct in-depth analysis of existing data flow setups and systems to understand their intricacies and dependencies.Collaborate with subject matter experts, developers, and other stakeholders to gather information and insights on data flow processes.Develop comprehensive and accurate data flow analysis models that represent the flow of data within complex systems.Create detailed documentation, including diagrams, flowcharts, and explanatory texts, that effectively communicate the data flow analysis models.Ensure that the documentation is consistent with established standards, style guides, and best practices.Collaborate with software engineers, architects, and other technical teams to validate and refine the accuracy of the data flow analysis models.Continuously update and maintain the data flow analysis documentation to reflect any changes or updates in the system.Work closely with project managers and technical teams to meet project deadlines and deliver high-quality documentation within defined timelines.Assist in the creation of user guides, manuals, and other technical documentation as needed.Stay updated with industry trends and best practices related to data flow analysis and technical writing.Requirements:Bachelor's degree in Computer Science, Information Technology, or a related field. Equivalent work experience will also be considered.Proven experience as a Technical Writer, preferably with a focus on data flow analysis models.Strong understanding of data flow concepts and processes within complex systems.Proficiency in creating clear and concise technical documentation, including diagrams, flowcharts, and explanatory texts.Excellent communication skills with the ability to collaborate effectively with cross-functional teams and subject matter experts.Attention to detail and ability to analyze complex technical information and present it in a user-friendly manner.Familiarity with data flow analysis tools and software.Knowledge of software development methodologies and experience working in an Agile environment is a plus.Strong organizational and time management skills to prioritize and meet deadlines.Ability to adapt quickly to changing requirements and work in a fast-paced environment.Join our dynamic team and contribute to the development of accurate and comprehensive data flow analysis models. Apply your technical writing skills to create valuable documentation that enables efficient understanding and optimization of complex systems.","['Specifications', 'Technical Case Study', 'Technical Documentation', 'Training Materials', 'English', 'Flowchart', 'Data Analytics']",Egypt,4,,,,,"['5.00', '40.00']",Remote Job,Intermediate
Web Traffic Analyst to Clean Our Network,"Hello Dear Candidate,We are seeking an experienced Web Traffic Analyst to join our team. As a Web Traffic Analyst, your primary responsibility will be to monitor and clean our programmatic advertising network from bots and invalid traffic using a global blacklist.We will provide you access to our platform, where you can create pop-under and push notification campaigns and send traffic to your URL, where you will be able to identify the bad traffic with your tools and report it.As you understand, this is a non-stop job, and we're looking for someone for a long-term partnership on a monthly fixed salary.Please let me know if you're interested in the job, including your background and your asked monthly salary.Thank you for your time. Feel free to ask me your questions.Kind regards,Michael","['Data Analytics', 'Big Data', 'Google Analytics', 'Network Security']",Bulgaria,80,6.66,13,"['Sales', 'Marketing']",,,Remote Job,Expert
Typeform - UTM Tracking,We need to create a system that assigns a UTM parameter to a typeform submission within our google sheet storage of all of the submissions. Please find a detailed brief attached below.,"['Marketing Analytics', 'Typeform', 'Google Analytics', 'Google Tag Manager', 'Google Tag Manager']",United Kingdom,7,,3.4,"['Fashion', 'Beauty']",,"['9.00', '45.00']",Remote Job,Intermediate
LinkedIn Data Crawler,I am looking for someone who can help me build database of people from Linkedin. I will offer you a set of filters and data that will be shown need to be extracted on excel,"['Data Scraping', 'Data Mining', 'LinkedIn', 'Data Extraction', 'LinkedIn', 'Data Extraction']",India,1,,,,1000.00,,Remote Job,Intermediate
Django Developer,"We are seeking a highly skilled and motivated Django Developer to join our dynamic team. As a Django Developer, you will be responsible for designing, developing, and maintaining web applications using the Django framework. Your primary focus will be on creating server-side logic, ensuring high performance and responsiveness of the applications, and collaborating with cross-functional teams to deliver exceptional user experiences.Responsibilities:1. Design, develop, and maintain robust, scalable, and secure web applications using the Django framework.2. Collaborate with product managers, designers, and other stakeholders to understand project requirements and translate them into technical solutions.3. Write clean, reusable, and efficient code while following best practices and coding standards.4. Implement and maintain database models, schema, and queries to support application features and functionality.5. Create and integrate RESTful APIs and third-party services to enhance application capabilities.6. Conduct thorough testing and debugging of applications to ensure high performance, reliability, and security.7. Optimize application performance and scalability by identifying and resolving bottlenecks.8. Collaborate with the front-end development team to integrate server-side logic with user interfaces.Requirements:1. Bachelor's degree in Computer Science, Engineering, or a related field (or equivalent experience).2. Proven experience as a Django Developer or a similar role, with a strong portfolio of completed projects.3. Proficiency in Python and Django framework, with a deep understanding of its internals.4. Strong knowledge of web development concepts, including RESTful APIs, MVC architecture, and version control systems (e.g., Git).5. Experience with front-end technologies such as HTML, CSS, JavaScript, and JavaScript frameworks (e.g., React, Angular, Vue.js) is a plus.6. Familiarity with database systems (e.g., PostgreSQL, MySQL) and proficiency in writing efficient SQL queries.7. Solid understanding of software engineering principles and best practices, including testing, debugging, and performance optimization.If you are passionate about web development, possess strong Django skills, and enjoy working in a collaborative environment, we would love to hear from you.","['Django', 'Python', 'API', 'PostgreSQL', 'Web Development', 'CSS', 'JavaScript', 'Web Development', 'CSS', 'JavaScript']",Pakistan,22,15.00,2.1,,,"['5.00', '20.00']",Remote Job,Intermediate
Microsoft power BI,"What will your role look likeAssist Business analysts in developing, maintaining and supporting operational / live reports, dashboards, and scorecards using Microsoft Power BI. • Implementation of Row Level Security by defining various constraints for each defined role. • Publish reports to app.powerbi.com and set up the necessary connection details and scheduling. • Create different visualizations using Slicers, Lines, Pies, Histograms, Maps, Scatter, Bullets, Heat Maps, Tree maps, etc. • Create calculated measures and columns with DAX in MS Power BI Desktop • Create dashboards, volume reports, operating summaries, and presentations and graph Why you will love this role •Besides a competitive package, an open workspace full of smart and pragmatic team members, with ever-growing opportunities for professional and personal growth • Be a part of a learning culture where teamwork and collaboration are encouraged, diversity is valued and excellence, compassion, openness and ownership",['Microsoft Power BI'],India,3,,,,,"['10.00', '25.00']",Remote Job,Expert
Computer Vision Project | Raspberry Pi and NoIR V2 Camera,"We are looking for a experienced Computer Vision expert having experience in multiple Computer Vision projects.The task is to detect a IR light in real time video feed from camera and detect the patterns. We want the candidate to do implementation of this available instructable article with some shapes that we will provide once we select the suitable candidate and then provide us the codes/firmware as deliverable.The work is similar to to what can be found here in the Instructable Web: https://www.instructables.com/Real-Working-Harry-Potter-Wand-Using-Computer-Visi/The only difference is the shapes. In the instructable they have used A and C. Our shapes will be different and the candidate must be able to train the model on that custom shape.Candidate should have a Raspberry Pi 4 Model B and a NoIR Camera. Pls only apply if you have the required hardware and have worked on computer vision projects in the past.** Avoid writing proposal using ChatGPT, we will not entertain such proposals :) ***","['Machine Learning', 'Machine Learning Model', 'Raspberry Pi', 'Computer Vision', 'Python', 'OpenCV', 'Raspberry Pi Firmware', 'Python', 'OpenCV', 'Raspberry Pi Firmware']",Pakistan,52,,504,"['Engineering', 'Architecture']",100.00,,Remote Job,Intermediate
Statistical expert,I need an expert in statistics. It is small task.,"['Statistics', 'IBM SPSS', 'Statistical Analysis']",Australia,52,50.08,4.4,,30.00,,Remote Job,Expert
Microsoft Certified Power BI Consultant,"Candidate must hold Microsoft Power BI Certification.Job Duties may include. Work closely with customers to understand their business requirements and challenges around data analyticsTranslate these requirements into a technical solution making use of Qlik and Power BIAnalyse and define tasks, data flows and dependencies necessary to scope and deliver complex technical projectsDevelop and maintain advanced analytics and other BI solutions using the different toolsDevelop and deliver knowledge transfer and training to the clientStrengthen our internal consultant network by helping solve challenges that other consultants present to the groupContribute to sales work by spotting opportunities for future work and building, modifying, and presenting demosWork on R&D side projects individually or as part of a team","['Qlik Sense', 'Microsoft Power BI', 'Business Intelligence', 'Data Analysis', 'Microsoft Power BI Data Visualization', 'Microsoft Power BI Development', 'Qlik View', 'Data Analysis', 'Microsoft Power BI Data Visualization', 'Microsoft Power BI Development', 'Qlik View']",United Arab Emirates,1,,,,2500.00,,Remote Job,Expert
Custom script or AI Tools Data Scraping for Leads,I am in search of an individual who can create a tailored script or leverage existing AI tools to extract targeted data from comments within Facebook groups. Further information will be provided to the candidates who make it to the shortlist.,"['Data Scraping', 'Data Mining', 'Data Extraction', 'Automation', 'Scrapy', 'Python', 'Microsoft Excel', 'Data Extraction', 'Automation', 'Scrapy', 'Python', 'Microsoft Excel']",India,142,13.36,3.8,,20.00,,Remote Job,Expert
Stylegan2 for RTX3090 on Linux,1. Our server is linux 20.04 ubuntu2. Our GPU is RTX30903. We are running in dockerI need- Stylegan2 working for RTX3090- I need the pytorch and cuda and python dependencies updated to latest for ubuntu 20.04- I need the repo run on a test image set and any images fixed---1. Submit what GPU locally you have for testing in job submission2. Submit number of hours you estimate3. Have you trained stylegan2 models before? Did you have trouble running them on modern hardware?,"['Machine Learning', 'Linux', 'Ubuntu']",China,213,15.62,206,"['Tech', 'IT']",,"['15.00', '25.00']",Remote Job,Entry level
Expert - Powerbi Visualization - Design skills,"We are looking for experts who can take data and put them into a more meaningful format, Someone who has a good design sense and has a good experience with powerbiTell me about 1. Your years of experience in this domain2. Give me links to your dashboard 3. explain to me the complexity you have worked on developing these dashboards","['Microsoft Power BI', 'Data Analysis', 'Data Visualization', 'Business Intelligence', 'Microsoft Power BI Data Visualization', 'Business Intelligence', 'Microsoft Power BI Data Visualization']",United Kingdom,224,14.36,75,"['Tech', 'IT']",,"['8.00', '14.00']",Remote Job,Intermediate
"Web Scraping expert to help teach me a scraping program (Octoparse, Outwit) or Python","I would like to hire an individual to help me set up simple web scrapers and macros  to help me pull data which I’d like to use to create databases. I am looking to pay hourly, and would like ideally to do his as affordable as possible. I would like to use octoparse or outwit hub to do this, so need someone familiar or willing to learn those. I would like to communicate over chat (zoom, teams) so that I can share my screen and get advice remotely My goal is to create simple databases from a variety to of websites. Some examples of sites I’d like to pull data from include: 1. (1000ish data pints) - https://www.55places.com/2. 40,000+ data points  - https://www.mhvillage.com/2. Unknown number of data points - https://www.newhomesource.com/I would like to set up macros to run and save links on various web pages- the goal is to get a list of all the URLs for various communities. Id then like some assistance setting up a scraper to scrape / export all available info from the property websites and the ideal output would be an excel file. Please contact me with your rate if interested! I expect this would take 5-10 hours of work.","['Microsoft Excel', 'Data Mining', 'Data Scraping', 'Administrative Support', 'Python', 'Data Scraping', 'Administrative Support', 'Python']",United States,1,,,,,"['8.00', '10.00']",Remote Job,Intermediate
Biostatistician to help calculate sample size,Urgent need (less than 72 hours) for one-off assistance from a statistician to help calculate the sample size for three different studies based on their main hypothesis. Context: Research proposals for cohort studies.Possibility of collaborating on future projects.,"['Statistics', 'sample size', 'Biostatistics', 'Epidemiology', 'Biostatistics', 'Epidemiology']",Belgium,2,,152,,,"['18.00', '50.00']",Remote Job,Intermediate
"Outbound (phone) Data Curator  - based in LATAM (GMT 5, 6 or 7) and a native US speaker","--- Outbound Data Curator (Phone) - Link Data Operations (Remote - Contractor) ---As a part of the Outbound Data Validation project, you will become the last step of the chain before data is released to our customers. Your main responsibility will be to phone specific locations to verify that the data that we have is correct and confirm or amend errors in our database.  Native English speaker  - Hiring in timezones: GMT 5, GMT 6, or GMT 7We are looking for one contractor for an Outbound Data Validation project with a duration of 6-8 weeks! Fully remote and paid in USD.What you will do- Learn how to capture online available data by following specific rules within a 1-month intensive training- You will Call specific locations to confirm the correctness of our data  - this might require being available during business hours - 9:00 AM to 5:00 PM. - Confirm correctness  or amend the errors in our database- Follow clear Key Performance Indicators (KPIs)- Become comfortable with medical terms, degrees, specialties & workplaces- Be part of  an international curator network of contractors for LinkRequirements - Personal computer/laptop with Operating Systems:     - Windows: Windows 10, version 22h2 (or newer versions, e.g. Windows 11)      - Mac OSX: Big Sur (or newer versions, e.g. Ventura, Monterey)- Internet connection of minimum 10 mbs -  (https://www.speedtest.net/)- Working environment designed to work from home - silent environment - Noise-blocking headphones- Experience in Inbound or Outbound Sales/Customer Service, public  speaking, delivering presentations;- Confident, articulate, and professional speaking abilities - Empathic listener and persuasive speaker- Ability to work independently and as part of a team- Excellent organizational and time-management skills- Ability to reference and compare database records from sources- Be able to deliver high-quality data in accordance with set KPIs- Native English with excellent communication skills (Focused on   speaking)- Monday to Friday - 9 AM to 5 PM in  one of the following timezones:       - GMT 5, GMT 6, or GMT 7- Proficient in Microsoft Office Suite and Google Documents &    spreadsheets- Fast learner- Excellent work ethics- Nice to Have- Education or work experience in life science (education or    professional experience)/ healthcare industry- Experience as a web researcher or Data Entry clerkOther information:- Flexible working hours & remote- Different contractor role  opportunities within the data operations   teamsVeeva Link delivers real-time customer intelligence to enable relevant engagement with medical and scientific experts. At Veeva Link, we gather permission-based data from multiple data touchpoints, creating the richest possible profiles. A key component of this customer intelligence is our high-quality profiles for specific disease areas. Those profiles are a direct result of Link's Data Operations team which engages with contractors to perform data curation and provide global coverage.Join one of the biggest cloud computing companies in the life science industry!","['Data Cleansing', 'Error Detection', 'Caption', 'Lecture Notes', 'Cold Calling', 'Data Entry', 'data validation ', 'Data Mining', 'native english', 'Outbound Call', 'data validation ', 'Data Mining', 'native english', 'Outbound Call']",Germany,511,,,,,"['4.00', '6.00']",Remote Job,Entry level
Data Miner based in Mexico,We are looking for a freelancer based in Mexico to test the sportsbook website.No previous experience is needed as we will prepare everything and the person who is given the job will simply check out the sportsbook website and fill in the data in our spreadsheets.Looking forward to hearing from you!,"['Online Research', 'Data Mining', 'Data Entry']",Denmark,316,18.84,83,,500.00,,Remote Job,Intermediate
Senior DevOps Engineer,"Senior DevOps EngineerEssential duties and responsibilities:• Develop and maintain secure new tools, high availability and high scalability infrastructure includingmission-critical information extraction, analysis, and management systems.• Develop integrations with internal and external systems.• Develop automated code to improve efficiency and reduce risk.• Develop platform environments to support auto-scaling for the business.• Perform root cause analysis for production errors.• Ensure that systems are safe and secure against cybersecurity threats.• Build frameworks for software and application deployment.• Monitor the organisation&#39;s digital architecture, checking for performance and compliance.• Monitor the infrastructure, identify, and investigate technical problems, develop, and deploy softwareupdates and fixes.• Contribute to and implement systems and data security and data governance activities.• Implement streaming data pipelines.• Work on ways to automate and improve development and release processes.• Participate in architecture and software development activities.• Use open-source technologies and tools to accomplish specific use cases encountered.• Use coding languages or scripting methodologies to solve a problem with a custom workflow.• Collaborate with others to brainstorm about the best way to tackle a complex technologicalinfrastructure, security, or development problem.• Perform incremental testing actions on code, processes, and deployments to identify ways to streamlineexecution and minimize errors encountered.• Design procedures for system troubleshooting and maintenance.• Work with development teams to build of websites, applications, and software pieces.• Management of internal databases.• Stay on top of industry best practices and trends, as well as changes to compliance requirements.Who we are looking for:• BS/MS in Computer Science or equivalent, with the ideal candidate having 8-10 years of overallexperience specialized in building world-class high availability and high scalability architecture.• Strong in server-side programming, API mindset, microservices-based concepts, and design patterns, PHP/ NodeJS / Serverless server-side frameworks.• Strong in Database Modelling and design, SQL, Data Caching, in-Memory Databases, Web Services, NoSQLand ETL (Extract, transform, load) frameworks.Excellent organizational and time management skills, and the ability to work on multiple projects at thesame time.• Extensive hands-on experience with monitoring and reporting tools like Zabbix.• Experience with large-scale and distributed software architectures.• Excellent hands-on experience with AWS and Azure.Nice to have:• Skills and experience in Unix administration, shell scripting, Git.• Experience with cloud-based data lake creation, cloud data mining and analytics.• Good to have working knowledge of emerging platform architectures around Serverless concept.• Ability to communicate within operational and business teams in English.• Excellent analytical and design skills at product level.• Experience with Agile software development processes.• Demonstrated initiative and client success.• Relevant AWS/Azure certifications.Keywords:• AWS / Lambda / Microservices• High Availability Infra Architecture / High Scalability Infra Architecture• DevOps / SysOps• Python / PHP• Cyber SecurityKeywords:• Python / NodeJS• Microservices / APIs• AWS / Lambda / DynamoDB / RDSEmail:  tharun.jose@fexle.comhttps://www.fexle.com/One year contract client is Australian and works starts at morning 7.00 Am",['DevOps'],India,2,,,"['Tech', 'IT']",,"['35.00', '60.00']",Remote Job,Expert
Looking for an Excel expert to compare files and create reports based on vlookups and comparisons,"We are currently seeking an experienced and highly skilled Data Analyst to join our team immediately. The ideal candidate will have a strong background in comparing and analyzing exported files from various source channels and creating detailed reports using VLOOKUPs and advanced Excel functions. This role requires an individual who can work independently and hit the ground running. Responsibilities:Conduct thorough comparisons of exported files from different channels, focusing on product data etc.Utilize advanced Excel functions, including VLOOKUPs and data comparisons, to identify similarities and differences in product data across multiple marketplaces.Generate comprehensive reports that highlight clear insights and actionable recommendations, emphasizing both similarities and differences in the data.Proactively identify and resolve data quality issues or inconsistencies to maintain reliable and accurate reporting.Requirements:Proven experience and expertise in comparing and analyzing data.Strong proficiency in Excel, including advanced functions such as VLOOKUPs, pivot tables, and data comparisons.In-depth understanding of ecommerce platforms, marketplace dynamics, and product data attributes.Exceptional analytical and problem-solving skills with acute attention to detail.Ability to work independently, prioritize tasks effectively, and meet deadlines without the need for handholding.Excellent communication skills to present complex data findings in a clear and concise manner.Demonstrated ability to work with large datasets and manipulate data efficiently.Immediate availability to start and contribute to the team without delay.Apply now and become an integral part of our dynamic and fast-paced organization.",['Microsoft Excel'],India,29,4.14,1.5,"['Sales', 'Marketing']",50.00,,Remote Job,Intermediate
Facebook Data mining,"We need an expert at Facebook Data Mining. What we need:FB profiles of Business owners DubaiAde 40+Interested in poker / gambling. For support, we have a list of pages relevant to poker and gambling interests as well as a list of public/private poker related groups in Dubai. We need someone who is an expert on how to mine data from Facebook and who can help us do this quickly.","['Data Mining', 'Data Scraping', 'Lead Generation', 'Facebook', 'Lead Generation', 'Facebook']",India,9,8.01,3.5,,1000.00,,Remote Job,Intermediate
"Programmer needed to build interactive, web-based map tool (data visualisation)","We are wanting to build an embeddable, interactive map tool based on city-wide data we have collected. We will host the tool on a landing page with supporting text.Within the tool, the user will be able to select options from two drop down menus; city and industry. Based on their input, the tool will update to display a in isometric map of the chosen city, with heig6ht bars overlaid that will indicate the volume of businesses in the selected industry, organised by the postcode region. This data is available in .csv format.I have added a draft design for reference, and can provide more information if needed. Initially I would like to enter into discussions to understand how long it would take to create a tool of this nature - this is a time-sensitive project.","['Data Visualization', 'Presentations', 'JavaScript', 'Python', 'HTML', 'Web Development', 'Web Application', 'Web Application']",United Kingdom,83,10.16,44,,,,Remote Job,Intermediate
AI expert to help with academic projects,"Salam everyone,I'm looking for an AI expert who has worked with MESA FRAMEWORK It's a very URGENT JOB and anyone who's interested and has done work on simulation on mesa framework before, feel free to apply RIGHT AWAYpotential for more work if this is delivered on time and with accuracy, also chance for bonusThank you","['Python', 'Machine Learning', 'Artificial Intelligence', 'Academic Writing', 'Data Analysis', 'Artificial Intelligence', 'Academic Writing', 'Data Analysis']",Pakistan,6,,80,"['Tech', 'IT']",70.00,,Remote Job,Expert
i want to create AI chatbot using python,"i want to create an AI Chatbot similar to this one :https://huggingface.co/spaces/justest/vicuna-ggmli have to be able to use ""System message"" + ""Prompt"" + ""Change the modal parameters""For create the AI chatbot u have to use :- Python- Langchain- Wizard-Vicuna-13B Modal (From huggingface.co)i need similar chatbot AI :https://huggingface.co/spaces/justest/vicuna-ggmlthank u","['Hugging Face', 'AI Chatbot', 'AI Model Integration', 'Langchain', 'AI Model Integration', 'Langchain']",Morocco,14,,70,"['Tech', 'IT']",,"['30.00', '50.00']",Remote Job,Expert
Synthetic data generation using SDV,"We would need help from expert in the SDV package to generate data for relational database. The expert should be familiar with all types like Single table, Multi table and Sequential.","['Python', 'Machine Learning']",Sweden,83,29.25,781,"['Tech', 'IT']",,"['40.00', '75.00']",Remote Job,Expert
Looker Studio Report Creation,"We are looking for a skilled freelancer who can help us in creating Looker Studio report for our business. The ideal candidate should have experience in data visualization, Google Ads, Google Analytics, and Google Data Studio. Proficiency in Looker Studio is also a must-have. The project is expected to last for 1 to 3 months, depending on the complexity of the reports. As the candidate, you will be responsible for developing reports that can help us analyze our business performance, identify trends, and evaluate the effectiveness of our marketing campaigns. To qualify for this job, please submit a proposal that outlines how you plan to approach the project. Please also include links to your past completed projects that are related to data visualization, Google Ads, Google Analytics, Google Data Studio, and Looker Studio.We look forward to working with a candidate who has excellent communication skills, attention to detail, and a passion for data analysis.Note: Some of the content in this job post may have been auto-generated using advanced AI.","['Google Data Studio', 'Data Visualization', 'Looker Studio', 'Google Analytics', 'Google Ads', 'Looker Studio', 'Google Analytics', 'Google Ads']",South Africa,23,24.25,5.5,,,"['10.00', '25.00']",Remote Job,Intermediate
AI Developer,"It’s simple. I need to create an A.I. investor presentation generator.The output should be in Google slides.Training sets should be from our google slides templates which we are increased one or two per day.The questions for the user are provided, like: Where do you intend to launch? As Multiple choice questions.Using GPT 4 if possible.Queries will also be provided.Most importantly, the final presentation can not be full of text and has to have google slides elements like icons or squares from the training sets and incorporating the user’s brand guidelines.This is an overview. There are multiple online tools but they are far from good, too wordy, and not diverse in terms of design.Can you work out such a tool? If so, tell me your experience in creating something similar, the average cost you’ll need, your timeframe, and any other questions. We’ll get on many calls I’m sure.Thanks,AL","['Artificial Intelligence', 'Machine Learning', 'Machine Learning']",Switzerland,134,10.69,37,,,,Remote Job,Expert
MindsDB,"Looking for a data scientist, who can effectively use MindsDB platform to provide us insights in our data. We would like to review the distribution data we receive on daily basis and analyze the lowest price and qty available for products. We would like to review our current sales data and other related data to review products in high demand. Finally I would like the model to make predictions on the products purchase, sale and profit margin.Currently all our data is stored in MariaDB","['Large Language Model', 'Python', 'ChatGPT', 'mindsdb', 'Inventory Management', 'Pricing predictions', 'Pricing predictions']",United States,3,25.00,4.8,,,"['15.00', '25.00']",Remote Job,Expert
Google Analytics Lead,"We are looking to hire a Google Analytics expert to lead our analytics and tracking efforts for a short-term project of less than 1 month. The ideal candidate should be proficient in Google Analytics and Google Tag Manager, with a proven track record of setting up and managing successful tracking campaigns. Our Goal: To set up google analytics on our website.Website: www.zipperminds.comThe successful candidate will be responsible for setting up tracking codes, So we can keep a track of the users visiting our website.  The candidate should have experience in setting up conversion tracking, goal tracking, and event tracking.To be considered for this role, candidates should submit a proposal outlining their experience, skills, and approach to this project. The proposal should also include links to past projects that demonstrate their expertise in Google Analytics and Tag Manager.We are looking for a candidate who can start immediately and work efficiently to deliver results within the specified timeframe. If you have the required skills and experience, we would like to hear from you.","['Google Analytics', 'Google Tag Manager']",India,5,,0,['Education'],50.00,,Remote Job,Expert
SEO Expert,"Why join us:T.A. Monroe is a B2B agency that prizes science-based frameworks, proof-driven solutions, and doing what works. We grow as a team, love to learn, and believe personal growth is as important as professional success.Even though T.A. Monroe is based in New York City, USA, this job is remote; hence we are accepting applications from candidates all over the world. We are looking for someone who will:- Execute tests, collect and analyze data and results, identify trends and insights in order to achieve maximum ROI in paid search campaigns- Track, report, and analyze website analytics and PPC initiatives and campaigns- Manage campaign expenses, staying on budget, estimating monthly costs and reconciling discrepancies.- Optimize copy and landing pages for search engine marketing- Perform ongoing keyword discovery, expansion and optimization- Research and implement search engine optimization recommendations- Research and analyze competitor advertising links- Develop and implement link building strategy- Work with the development team to ensure SEO best practices are properly implemented on newly developed code- Work with editorial and marketing teams to drive SEO in content creation and content programming- Recommend changes to website architecture, content, linking and other factors to improve SEO positions for target keywords.Required Qualifications:- Proven SEO experience- Proven SEM experience managing PPC campaigns across Google, Facebook and LinkedIn.- Solid understanding of performance marketing, conversion, and online customer acquisition- In-depth experience with website analytics tools (e.g, Google Analytics, NetInsight, Omniture, WebTrends)- Experience with A/B and multivariate experiments- Working knowledge of HTML, CSS, and JavaScript development and constraint - Up-to-date with the latest trends and best practices in SEO and SEMWhy You’ll Love Working At TA Monroe:- Fully Remote - Flexible schedule and time off- Performance based Bonus- Belief in the service - our offer solves a huge pain point in the marketplace, and we’re considered world-class at what we do- Culture is one of our top priorities. You will find a family at TA Monroe.About the company:We are strategists and thinkers in the digital space. We specialize in helping B2B companies build world-class revenue generation engines. We think of scalability. We’re scientific about profitability. We bring decades of highly specialized marketing, digital strategy, and advertising expertise to our clients.Our Philosophy:We believe creating sustainable demand delivers better ROI. When it comes to growth marketing, we let science guide us. Our systematic approach thrives on data and is driven by expert strategists. Test & Learn is in our DNA. We bring collective insights from 5,000+ experiments to our clients. We help brands build value.","['SEO Keyword Research', 'Search Engine Optimization', 'Organic Traffic Growth', 'SEO Backlinking', 'Google Analytics', 'SEO Audit', 'Off-Page SEO', 'On-Page SEO', 'Organic Traffic Growth', 'SEO Backlinking', 'Google Analytics', 'SEO Audit', 'Off-Page SEO', 'On-Page SEO']",United States,118,20.23,112,"['Sales', 'Marketing']",,,Remote Job,Intermediate
Kafka Expertise Needed,"We are currently facing an issue with our Kafka consumers in our software. The problem involves the consumers being dropped, resulting in a halt in event processing. The error message indicates a Kafka rebalancing issue, and the consumers are not reattached afterward. Can you provide assistance with this matter?",['Apache Kafka'],Bulgaria,1,,,,,"['10.00', '25.00']",Remote Job,Expert
Stable Diffusion webui + controlNet + mov2mov + topaz AI,Hey!So i want to create a service that takes an INPUT of a 10-15 second video and outputs an animated video like this. He is the gold standard at the moment.  https://www.youtube.com/@neilwong7760/videoshttps://www.reddit.com/user/neilwong2012/https://twitter.com/NeilWong2012I know that this person uses Stable diffusion webui + controlNet + mov2mov + Civit Lora models + topaz AI to make this video. I want to create a solution where everything can be done on the backened so people can just upload a video and it works.I want to start this project ASAP so let me know if anyone can do this within the budget I gave you. I will need proof that you understand this field very much indepth.Thank you,"['Machine Learning', 'Stable Diffusion', 'controlnet', 'Python', 'Artificial Intelligence', 'Deep Learning', 'Artificial Neural Network', 'controlnet', 'Python', 'Artificial Intelligence', 'Deep Learning', 'Artificial Neural Network']",South Korea,27,20.00,1.5,,7000.00,,Remote Job,Expert
Building Grafana Dashboards with InfluxDB Queries,We have influx db as storage we want to build a dashboard using grafana.,"['Python', 'Grafana', 'influxdb', 'Redis']",India,2,,,,,"['8.00', '10.00']",Remote Job,Expert
Microsoft Excel Dahsboard,Need interactive dashboard in Microsoft Excel format. The result shall be similar to datapine.com. The elements will be provided. We should be able to insert the data into one Sheet and have result in another.,"['Dashboard', 'Microsoft Excel', 'Visual Basic for Applications']",France,7,8.75,90,"['Finance', 'Accounting']",,,Remote Job,Expert
Scrapping LinkedIn & Other Data Sources,"We run a fine food, wine and hamper business bases in the UK. We are about to launch corporate gifts/hampers which will be sold to companies who will then in turn give as gifts to customer, staff etc. We need to create data sheets to allow us to email and contact decision makers in companies.LinkedIn will be Marketing Managers of larger companies and and we will want company name,  email and phone number if it exists. We will then give you some trade association sites for example all the accountants in the UK, Lawyers, etc. here we will want similar information. We will always want the marketing manager.We will want lots of scrapping done over a period of time. You need to be conversant in English, and ready for a zoom call.We have samples for you to follow","['Data Scraping', 'Data Mining', 'Data Extraction', 'Data Extraction']",United Kingdom,250,14.78,38,,,"['8.00', '25.00']",Remote Job,Intermediate
Supermetrics Locker Studio Export,"We are looking for a skilled professional to join our team as a data analyst for a project lasting 3 to 6 months. The ideal candidate must have extensive experience in data analysis, data visualization, Google Analytics, Google Data Studio, and Supermetrics. The project requires exporting data from a Supermetrics Locker Studio and transforming it into a format suitable for data visualization in Google Data Studio.The candidate should have excellent communication skills, be detail-oriented, and capable of working independently. The successful candidate will be responsible for providing data insights to the team, creating data visualizations, and ensuring the quality of the data. To apply, please submit a proposal outlining how you can help with this project. Please include links to past completed projects that demonstrate your skills in data analysis, data visualization, Google Analytics, Google Data Studio, and Supermetrics. We look forward to hearing from you!Note: Some of the content in this job post may have been auto-generated using advanced AI.","['Google Data Studio', 'Google Analytics', 'Data Analysis', 'Data Visualization', 'Supermetrics', 'Data Analysis', 'Data Visualization', 'Supermetrics']",Australia,8,50.00,1,"['Fashion', 'Beauty']",,"['10.00', '50.00']",Remote Job,Expert
Use artificial intelligence to tag images.,"I would like to classify images based on the concepts or themes found in them, through computer vision and machine learning. The idea would be to organize them into folders, where each folder represents these concepts, or through metadata / hashtags using a program like Lightroom.Those images are screenshots done while I was traveling through the world on a motorcycle, and would be used as a personal project that will became a book. This is not a comercial project.Here are some of my other artworks...www.rocherms.com","['Machine Learning', 'Computer Vision', 'Artificial Intelligence', 'Python', 'Deep Learning', 'Artificial Intelligence', 'Python', 'Deep Learning']",Spain,1,,,,,,Remote Job,Intermediate
Building a fintech app for an Adtech Company,"Engineering Manager for AdTech-Fintech Company (https://www.roninglobal.io/)We are looking for an experienced Engineering Manager to join our adtech company, focused on building its fintech product. The ideal candidate should have at least 7 years of experience in product development, preferably in a SAAS company. They should have expertise in Python and Reactjs.Responsibilities:- Develop product roadmaps and manage the entire product lifecycle, from ideation to launch and beyond- Work closely with cross-functional teams, including engineering, design, and sales to ensure successful product delivery- Define and track key performance metrics to measure product success and iterate based on data-driven insights- Continuously gather and incorporate customer feedback to improve the product and ensure customer satisfaction- Stay up-to-date with industry trends and emerging technologies to inform product development decisionsSkills and Qualifications:At least 7 years of experience in product development, preferably in a SAAS companyStrong knowledge of Python and Reactjs, and the ability to communicate technical concepts to non-technical stakeholdersExcellent communication skills and the ability to collaborate effectively with cross-functional teamsProven product management experience: A strong track record in product management, preferably in the AdTech and/or Fintech industries, demonstrating the ability to successfully develop and launch innovative products.Experience with fintech products is a plusAI integration expertise: Familiarity with AI technologies and their application in AdTech, along with a keen understanding of how to integrate AI into products to enhance features, user experience, and performance.Strategic and analytical thinking: The ability to think strategically and analyze complex data sets, customer feedback, and market trends to make informed decisions about product development and enhancements.Leadership and team-building: Proven experience in leading and managing cross-functional teams, as well as the ability to build, motivate, and mentor a high-performing product development team. User-centric approach: A focus on creating user-centric products, with a deep understanding of user needs, preferences, and pain points, to ensure the product delivers maximum value to the end-users.Bachelor's or Master's degree in Computer Science, Engineering, or a related fieldIf you meet these qualifications and are passionate about building innovative products in the fintech space, we would love to hear from you!","['Python', 'react.js']",India,1,,,,,"['25.00', '45.00']",Remote Job,Expert
Elctorinc reporting D365FO,"Need to bulid some report by Electorinc reporting fro Dynamics 365 Finance and opreation  , the data attached for vendor data",['Dyanmics 365 F&O'],Saudi Arabia,104,23.87,51,,,"['18.00', '25.00']",Remote Job,Intermediate
Solution to define building blocks with ChatGPT4 to write letters quickly.,"We are looking for a skilled professional to assist us with a project that involves defining building blocks with ChatGPT4 to write letters quickly. I'm looking for a personal tool (addition to browser ?) to write letters quickly with ChatGPT 4.0, the intention is to have the ability to learn the system - in a personal environment - to more easily collect building blocks for letters.Our ideal candidate should have extensive experience working with ChatGPT and be able to develop a solution that can quickly generate letters. The candidate should submit a proposal that outlines how they intend to approach the project, including the timeline, budget, and resources required.We are interested in seeing examples of past projects that the candidate has completed, particularly those that involved working with ChatGPT. The candidate should include links to their portfolio or relevant work samples to demonstrate their qualifications.In summary, we are seeking a highly skilled professional who can collaborate with our team and deliver a robust solution that meets our requirements. If you are up for the challenge, please submit your proposal and relevant work samples for our consideration.",['ChatGPT'],Netherlands,162,10.05,7.3,,100.00,,Remote Job,Intermediate
Scrape Linkedin posts from a search,I am currently looking to scrape all the posts for specific keywords inside Linkedin's post search feed.I have unique URLs for these post searches to make it easier.They should be delivered every 24 hours in a CSV/Google Sheets format.I have around 5-15 keywords that are unique.This will likely become a monthly recurring contract.,"['Data Scraping', 'LinkedIn', 'Data Mining', 'Python', 'Data Mining', 'Python']",Portugal,22,,2.4,"['Sales', 'Marketing']",100.00,,Remote Job,Intermediate
GA4 Expert,"We are looking for an expert in GA4 who can help us set up and optimize our Google Analytics account.We have GA Universal setup but need to setup an instance of GA4 that is effective for tracking conversions from Callrail, Typeform, and form fill contacts by URL. I'm also interested in landing page visits / conversions. Responsibilities will include setting up and configuring GA4, creating custom reports and dashboards, and analyzing data to identify areas for improvement. The candidate should be able to provide insights and recommendations based on the data to help us optimize our website and marketing campaigns.",['Google Analytics'],United States,94,26.35,112,,,"['40.00', '75.00']",Remote Job,Expert
Generative AI No Code Low Code - Make + Airtable etc,"Hi,I am looking for a consult and then execution around a No-Code / Low-Code solution to build a interim mid-tech prototype for a Generative AI tool. The tool will integrate with multiple Generative AI models and platforms such as Open AI Chat GPT, Mid Journey, Stable Diffusion, Eleven Labs, AIVA etc.I am thinking about using Make + AirTable but I am open to other suggestions.Please reply with MixedAI in your cover letter and be sure to tell me about what stack you might use, why you would use it and how long it would take you to setup a system to have an Airtable DB act as a Production Queue that collections a few pieces of initial data, then passes that into ChatGPT through Make and begins an Algorithm  using those tools and integrations to Generate a Composition of Outputs.I realize the scope of that is crucial to know,  so imagine the very most simple yet complete workflow to touch on the requirements noted above to Generate a result of value.You probably know how to use ChatGPT to create a cover letter based on my job post. You must tell me what you really think. Remember, I can personally detect AI generated cover letters, but my AI detector tools are even better than I am. These responses will be ignored.Cheers,Mike","['AI Content Creation', 'AI-Generated Art', 'AI-Generated Video', 'Image Processing', 'Natural Language Generation', 'Sentiment Analysis', 'GPT-4', 'Python', 'Artificial Intelligence', 'JavaScript', 'JavaScript']",Canada,271,10.29,95,,,"['5.00', '50.00']",Remote Job,Intermediate
AI/ML engineer,"Position - AI/ML EngineerShift - 3 pm -12 am ISTFull-Time RoleSkills required:AI/ML engine that will be trained with the data, algorithms, and flow. We have chosen AWS as the platform to do this in. Need the expertise of people who have worked on Sagemaker & Titan on Amazon.","['Amazon SageMaker', 'Machine Learning', 'Artificial Intelligence', 'Python', 'deeplearn.js', 'Algorithms', 'titan on amzon', 'amazon titan', 'Python', 'deeplearn.js', 'Algorithms', 'titan on amzon', 'amazon titan']",India,453,11.25,433,,,"['10.00', '11.00']",Remote Job,Intermediate
Senior DevOps Engineer,"Senior DevOps EngineerEssential duties and responsibilities:• Develop and maintain secure new tools, high availability and high scalability infrastructure includingmission-critical information extraction, analysis, and management systems.• Develop integrations with internal and external systems.• Develop automated code to improve efficiency and reduce risk.• Develop platform environments to support auto-scaling for the business.• Perform root cause analysis for production errors.• Ensure that systems are safe and secure against cybersecurity threats.• Build frameworks for software and application deployment.• Monitor the organisation&#39;s digital architecture, checking for performance and compliance.• Monitor the infrastructure, identify, and investigate technical problems, develop, and deploy softwareupdates and fixes.• Contribute to and implement systems and data security and data governance activities.• Implement streaming data pipelines.• Work on ways to automate and improve development and release processes.• Participate in architecture and software development activities.• Use open-source technologies and tools to accomplish specific use cases encountered.• Use coding languages or scripting methodologies to solve a problem with a custom workflow.• Collaborate with others to brainstorm about the best way to tackle a complex technologicalinfrastructure, security, or development problem.• Perform incremental testing actions on code, processes, and deployments to identify ways to streamlineexecution and minimize errors encountered.• Design procedures for system troubleshooting and maintenance.• Work with development teams to build of websites, applications, and software pieces.• Management of internal databases.• Stay on top of industry best practices and trends, as well as changes to compliance requirements.Who we are looking for:• BS/MS in Computer Science or equivalent, with the ideal candidate having 8-10 years of overallexperience specialized in building world-class high availability and high scalability architecture.• Strong in server-side programming, API mindset, microservices-based concepts, and design patterns, PHP/ NodeJS / Serverless server-side frameworks.• Strong in Database Modelling and design, SQL, Data Caching, in-Memory Databases, Web Services, NoSQLand ETL (Extract, transform, load) frameworks.Excellent organizational and time management skills, and the ability to work on multiple projects at thesame time.• Extensive hands-on experience with monitoring and reporting tools like Zabbix.• Experience with large-scale and distributed software architectures.• Excellent hands-on experience with AWS and Azure.Nice to have:• Skills and experience in Unix administration, shell scripting, Git.• Experience with cloud-based data lake creation, cloud data mining and analytics.• Good to have working knowledge of emerging platform architectures around Serverless concept.• Ability to communicate within operational and business teams in English.• Excellent analytical and design skills at product level.• Experience with Agile software development processes.• Demonstrated initiative and client success.• Relevant AWS/Azure certifications.Keywords:• AWS / Lambda / Microservices• High Availability Infra Architecture / High Scalability Infra Architecture• DevOps / SysOps• Python / PHP• Cyber SecurityKeywords:• Python / NodeJS• Microservices / APIs• AWS / Lambda / DynamoDB / RDS","['Python', 'DevOps', 'Docker', 'Amazon Web Services', 'NodeJS Framework', 'AWS Lambda', 'cyber security', 'NodeJS Framework', 'AWS Lambda', 'cyber security']",India,4,,,,10000.00,,Remote Job,Expert
GA4 Update,"GA3 register actually our sales and other values as product sold, categories, etc.We need to update events for GA4. GA4 now is registering the conversion sales number but not the total amount of these sales, products sold, etc.Our checkout page has events configured that has been working fine for GT3. We need to check config to let GA4 working as GA3","['osCommerce', 'Analitycs']",Spain,15,15.00,1.5,"['Food', 'Beverage']",25.00,,Remote Job,Expert
Looking for Freelance Blockchain Developer,"We are looking for a dynamic Freelance Blockchain Developer with a passion for creating meaningful impact through technology. The successful candidate will be primarily tasked with the development of STO Smart Contract for multiple fundraising rounds on the Avalanche Blockchain. The candidate should have a thorough understanding of blockchain applications, distributed blockchain-based networks, and cryptographic safeguards.Key Responsibilities:Develop STO Smart Contract for multiple fundraising rounds on the Avalanche Blockchain.Perform research, analysis, design, development, testing, and maintenance on Blockchain applications.Evaluate and integrate new tools and technologies to enhance and protect blockchain applications.Build and manage a distributed blockchain-based network.Support and maintain current and future distributed applications.Document and manage both new and current solutions.Provide safeguards against various cybercrimes.Engage with stakeholders, technical partners, and the developer community to explore new ideas.Work with cross-functional teams and management to identify blockchain technology needs.Required Skills & Experience:Passion for creating meaningful impact and sharing our values.Bachelor's degree/Master's degree in Computer Science, Information Technology, or equivalent.Proven experience in designing and developing blockchain applications.Hands-on experience with technologies such as Quorum, Hyperledger, Ethereum, and others.Experience with various PAAS solutions from Azure, AWS, and other cloud platforms.Solid understanding of data structures and standard methodologies.Expertise in one or more programming languages: C++, Java, JavaScript, NodeJs.Understanding of blockchains such as Bitcoin.Ability to develop efficient multithreaded programs.Understanding of basic cryptography and peer-to-peer networks.Excellent interpersonal and communication skills.Experience with API interaction with third-party applications.Previous experience with Python, Kafka, and Postgres will be a plus.Education:Bachelor's or Master's degree in Computer Science, Information Technology, or a related field.We welcome all who meet the requirements to apply. We value diversity and are committed to creating an inclusive environment for all team members.We look forward to receiving applications from candidates ready to contribute their expertise and innovative ideas to our team.",['Blockchain'],Vietnam,431,14.77,2,"['Tech', 'IT']",,"['5.00', '40.00']",Remote Job,Expert
MSC Marc Engineer,I am looking for a MSC Marc engineer.I will share the details over private chat.The candidate must be Full experience with Mechanical analysis on MSC Marc,"['CAD', '3D Modeling', 'Marc', 'Mechanical Engineering']",Germany,1,,,"['Manufacturing', 'Construction']",,"['40.00', '70.00']",Remote Job,Expert
Data extraction from text and web (AI/ML),"Our tech startup is seeking a software professional that is experienced in artificial intelligence (AI) and machine learning (ML) techniques to extract key data points from a dataset of renewable energy companies. The data will be sourced from either LinkedIn or the companies' websites. The required data points include company type (developer, investor, or lender), operating regions, operating countries, and technology focus (solar, wind, energy storage, other renewables, infrastructure). The project involves processing a dataset of 3,000 companies and requires a scalable and repeatable solution. We are looking for proposals that outline your approach, methodology, timeline, and cost estimates. An example company and data will be provided to interested applicants for demonstration purposes. Please get in touch with your proposal. Thanks","['Data Extraction', 'Machine Learning', 'Data Scraping', 'Data Scraping']",United Kingdom,32,14.57,101,,,,Remote Job,Expert
Tableau genius required to create dashboard using row data,"Our company has recently expanded into India and is looking forward to the growth of this market. In order to collect data, we gathered dealer names, their sales and profiles, as well as their primary market. We are seeking someone who can srot the data and create a dashboard so we can make decisions based on it.I need this project done incredibly urgently, so please only apply if you have the capability to complete it by EOD.","['Tableau', 'Data Visualization', 'Microsoft Excel', 'Minitab', 'Microsoft Excel', 'Minitab']",United States,2,,,"['Agriculture', 'Forestry']",300.00,,Remote Job,Intermediate
QGIS Coverage Map Creation,We're are looking to convert coverage maps from wireless internet service providers (WISPs) to geospatial data via QGIS and export those maps into a KML/KMZ.  Many providers just have a picture of their coverage area or coverage overlayed on Google maps and we're looking to create maps on QGIS those pictures and overlays.Examples:https://www.crowsnestbb.net/coverage-map.html  https://crescommwifi.com/coverageareas.htmhttps://next-leveltechnologypartners.com/,"['Data Visualization', 'QGIS', 'GIS', 'Digital Mapping', 'Geospatial Data', 'Geospatial Data']",United States,98,23.21,108,,,"['20.00', '50.00']",Remote Job,Intermediate
Survey Results Analysis,I need someone to take my Google forms survey with roughly 50 responses and pull together some statistics for me. Editable charts are also required if possible.,"['Data Analysis', 'Internet Survey', 'Survey', 'Survey']",Singapore,4,,,,300.00,,Remote Job,Intermediate
Data Scraping Expert Needed for Golf Courses Data Extraction from iOS Application,"Hello,We are in need of a highly skilled data scraping expert who has experience in extracting data from mobile applications, specifically iOS applications.Project Requirements:We require data to be extracted from an iOS application named SmartStat Golf.We are specifically interested in extracting data about golf courses in Ireland.The data we need to extract includes: golf course name,  number of holes with distance, tee/league.We need the data to be clean, well-structured, and formatted correctly.Here is a link to a Google Sheets document (https://docs.google.com/spreadsheets/d/132zEy_uYFBD2rkdZ2rG7TrApbUNWUabyvGA_KfAPjjU/edit#gid=0) that provides an example of the data structure we require.Key Skills Required:Proficient in data scraping from iOS applications.Experience working with Golf or sports-related data is a plus.Exceptional attention to detail and the ability to maintain a high level of accuracy.Strong experience in data structuring, cleaning, and formatting.Strong understanding of and respect for legal and ethical considerations related to data scraping.Please apply only if you have experience in similar projects and can ensure the data's accuracy and integrity. Be sure to provide samples of past projects that demonstrate your ability to successfully perform this kind of work.We look forward to receiving your applications.Thank you!","['Web Scraping Framework', 'Data Extraction', 'Data Scraping', 'Problem Solving', 'iOS Development', 'JavaScript', 'iOS Development', 'JavaScript']",India,6,,116,"['Tech', 'IT']",,,Remote Job,Expert
PowerBI dashboards (report templates) using data from Azure blob storage tables,"Looking to create 2-5 PowerBI dashboards using data from Azure. Must have experience in transforming data, connecting to Azure blob storage tables. Ideally the dashboards are templated so we can give them to our customers, which they can extend and change as they need. Documentation to support this will be required. The Azure data is slightly different for each customer (different date fields, spreadsheet data etc), so there is the likelihood of ongoing work. Should be collaborative and willing to ask questions and suggest the best possible solution. The dashboards are related to manufacturing Safety, EHS, Quality, but we will guide on the sorts of charts required.","['Microsoft Power BI', 'Data Visualization', 'Data Transformation', 'Microsoft Azure', 'Instruction Manual', 'Data Transformation', 'Microsoft Azure', 'Instruction Manual']",Australia,4,5.12,359,,,"['35.00', '70.00']",Remote Job,Expert
Data scrape products and variations,"We need product data scraped from 4 different websites. This task is just for the first website and if the work is done well we will offer the rest.We need the following data points:SKUPARENT SKU ( IF VARIATION)VARIATION TYPE (IF VARIATION)TITLEDESCRIPTIONIMAGESPRICECATEGORYADDITIONAL INFORMATIONThe tricky part is alot of the products have variation skus, which arent easy to grab using the normal do it yourself software. please apply for the task and we will release the website and category we need scraped to potential hires. If you can provide accurate data for one variation sku set, you will be hired.",['Data Scraping'],Australia,2,,,"['Retail', 'Consumer Goods']",10.00,,Remote Job,Intermediate
Developer of Advanced AI writer tools,I am looking for expect to develop complex AI writer tools for multiple tasks. Like app.shopia.ai or jasper,"['Machine Learning', 'Article Writing', 'Artificial Intelligence', 'Blog Writing', 'Python', 'Artificial Neural Network', 'Content Writing', 'Blog Content', 'Artificial Intelligence', 'Blog Writing', 'Python', 'Artificial Neural Network', 'Content Writing', 'Blog Content']",Mozambique,1,,,,,,Remote Job,Expert
Data visualization tableau expert,"We are looking for a skilled and experienced data visualization expert to work with us for a period of 3 to 6 months. The ideal candidate will have expertise in using Tableau, Google Data Studio, and Microsoft Power BI to analyze data, create data models, and develop visually appealing and intuitive charts and graphics to explain complex datasetse.The successful candidate will have a strong background in business intelligence, data analysis, and data visualization, and will be able to communicate complex data insights to non-technical stakeholders. They will work closely with our team to understand our business objectives and develop data visualization solutions that meet our needs.To apply for this position, please submit a proposal outlining your experience in data visualization, your expertise in Tableau and other data visualization tools, and how you can help us achieve our business goals. Please include links to past projects that showcase your data visualization skills.We look forward to hearing from you and potentially working together to create impactful and meaningful data visualizations.Note: Some of the content in this job post may have been auto-generated using advanced AI.","['Tableau', 'Data Visualization', 'Data Analysis', 'Microsoft Power BI', 'Google Data Studio', 'Business Intelligence', 'Data Modeling', 'Data Analysis', 'Microsoft Power BI', 'Google Data Studio', 'Business Intelligence', 'Data Modeling']",United States,25,8.28,2.6,"['Science', 'Medicine']",,"['20.00', '50.00']",Remote Job,Expert
[Tableau ] Build Tableau Reporting Dashboard,"I'm looking for a Tableau developer to help build a handful of polished client-facing reporting dashboards for my client's clients. We use Azure SQL DBs.Deliverables:* 1 ""Insights"" Dashboard - Pulling in and summarizing key metrics from our database.* 1 ""Metric Deep Dive"" Dashboard For Each Metric (5x) all using the same exact template - Histogram data, KPIs, 2x Top 10 lists ranked by different lists, and then a dump of all the raw data the user can download.Expectations:* You have the bandwidth to turn this work around in 2-3 weeks.* You've build client-facing dashboards in the past and have examples to prove it* You understand best practices to ensure the dashboards are quick to load.",['Tableau'],United States,5,,340,"['Sales', 'Marketing']",25.00,,Remote Job,Intermediate
Need Azure Python data engineer for Job support,"Your main responsibility would be to provide remote job support to candidate. You will develop python based data pipelines using Airflow, write custom logic for various ETL operations and participate in daily meetings and scrum calls.","['Apache Airflow', 'Apache Spark', 'Data Engineering', 'ETL Pipeline', 'Python', 'SQL', 'Microsoft Azure', 'Microsoft Azure']",India,2,12.00,0,"['Tech', 'IT']",,"['8.00', '12.00']",Remote Job,Expert
Senior Full Stack Software Engineer / With Experience Connecting Payment Systems Like Stripe,"**Must have at least a BS in Computer Science and at least 4 years of work experience after graduation from university.**Must have experience integrating a website with a payment system such as Stripe.**Must be an independent contractor, we can not work with firms due to regulatory reasons.**Please do not apply for this role if you do not fit these requirements.  About the role**Your first role is to add a payment solution such as Stripe to our SAAS platform.We are a rapidly growing silicon valley technology startup building the future of deepfake detection technology.  We are backed by Y-Combinator and Eric Schmidt.We are looking for a Senior Full Stack Software Engineer to help create an AI-first state-of-the-art scalable platform that supports multiple AI models processing thousands of user uploaded videos, images and audio files per day in real time. Responsibilities With your technical expertise you will help manage project priorities, deadlines, and deliverables.You will collaborate with a growing team, iterate on the architecture and technology, design and build the future of deepfake detection.You will build and operate at all levels of the tech stack.You will design, develop, test, deploy, maintain, and enhance our software solutions.Develop and improve the back-end API server to deliver data efficiently.Develop and improve the web portal by producing new components and pipelines.QualificationsYou are smart, driven, and passionate about helping change the world.You are excited in the opportunity to help us grow our team, lead projects, mentor engineers and take your skills to next level while having huge impact.You have experience in designing and implementing new end-to-end features and platforms through innovation and data-driven iterations.A strong technical background with experience developing with JavaScript, React, Python, Node.js, and using AWS services, especially Lambda, SQS, DynamoDB and RDS.Lines of communicationThe position reports to the CTO.","['Web Application', 'Amazon DynamoDB', 'Stripe', 'API Integration', 'JavaScript', 'React', 'Node.js', 'API', 'Web Development', 'Python', 'JavaScript', 'React', 'Node.js', 'API', 'Web Development', 'Python']",United States,9,15.00,41,"['Tech', 'IT']",,"['35.00', '75.00']",Remote Job,Expert
CLI Tool required to convert database files to CSV,"We have a backup of database files that need converting to csv format. The issue is that the files are in a non-standard format: .idx and .fs5. We need a tool that can interpret these index and data files and convert them into csv format. We have included one set of these files along with an already converted csv file of the data to compare against.When the provided index and data files can be interpreted and converted into the example csv file, additional files would be provided to ensure the tool can interpret and convert consistently. Successful completion of the project would see a tool that can read a folder of these files and convert them effectively.Final deliverables would be the source code including any scripts required to build the tool easily.","['Data Extraction', 'SQL']",Australia,4,37.53,1.7,,,"['15.00', '35.00']",Remote Job,Intermediate
Seeking AI Engineer/ML Expert for Social Networking Site,"We are a social networking site looking for an AI Engineer/ML Expert to work on our platform on a long-term, as-needed, freelance basis. The ideal candidate will have experience in Artificial Intelligence and Machine Learning. The main responsibility of the candidate will be to incorporate the use of AI and ML to improve user experience on our platform. The three main use cases for AI/ML that we have identified so far are:1. Prioritization of status updates in member feeds2. Detection of inappropriate content3. Detection of misinformationThe candidate should be able to work independently and possess excellent communication skills to collaborate with our team. The candidate should also have experience in data analysis and visualization. To apply for this job, please submit a proposal detailing how you can help improve our platform using your skills. Please include links to past projects that demonstrate your expertise in AI and ML. We are excited to work with a talented individual who can help take our platform to the next level.All other things being equal, strong preference will be given to candidates who are excited about our vision and goals.Thank you,Brent HunterChairman and CEOWorld Community Networkhttp://www.WorldCommunityNetwork.org","['Machine Learning', 'Artificial Intelligence']",United States,21,20.09,15,,,"['20.00', '70.00']",Remote Job,Expert
Build a Bot to Scrape Data from Partner Websites,"We are a moving company that provides moving services for moving in or out of self storage facilities. We are looking for a skilled and dedicated developer who can help us simplify a critical process in our workflow. Every day, we manually sift through the data from our partner self-storage companies, identify the new customers, and reach out to them directly via phone, email, or text. We believe this process can be automated, freeing up our team to focus more on customer service and less on administrative tasks.Your task, should you choose to accept it, will involve:Building a bot that can scrape our partner websites for new customer data.Automating the sending of an initial contact message (email/text) whenever a new customer is identified.Ensuring the bot operates at least once a day, with a preference for 24/7 operation if feasible.What you need to bring:Proven experience in web scraping and automation.Proficiency in Python, or a similar language, would be beneficial.Strong problem-solving skills.A can-do attitude and the ability to work to tight deadlines.","['Data Scraping', 'Data Extraction', 'Bot Development', 'Automation', 'Web Crawling', 'Bot Development', 'Automation', 'Web Crawling']",United States,14,,,,,"['8.00', '25.00']",Remote Job,Intermediate
Tealium and GTM Expert Needed to Analyze Configuration,Tealium expert needed to validate web tagging configurations across a web property. This involves a purchase event that needs to be validated based on a trigger upon order completion.This task will spillover to periodic analyses of configurations over time including implementation work within Google Tag Manager.,"['Google Tag Manager', 'JavaScript', 'Tealium', 'Tealium']",United States,171,25.56,108,"['Tech', 'IT']",,"['40.00', '75.00']",Remote Job,Expert
Make a d3 graph,Create a bar graph using D3. Must be responsive and have a tooltip on the legends/labels.,"['D3.js', 'Data Visualization', 'CSS', 'JavaScript', 'HTML', 'CSS', 'JavaScript', 'HTML']",United States,1,,45,,,"['10.00', '50.00']",Remote Job,Expert
Analyze and create report using Square Data,"We are seeking a talented individual to help us analyze and create a report using data from our Square account. Primary skills required are data analysis and data visualization.As a successful candidate, you will be responsible for analyzing our data regarding product movement from Square and creating visualizations that can be used to identify trends and insights. You should have experience in data analysis, with the ability to use tools such as Excel, SQL, or Python.To be considered for this project, please submit a proposal that details your experience with data analysis and visualization. Please include links to past projects you have completed that demonstrate your ability to work with large datasets and create visually appealing reports.We are looking for someone who can work independently and deliver high-quality work within the project's timeframe. If you are a detail-oriented individual with a passion for data analysis and visualization, we would love to hear from you.","['Data Analysis', 'Data Visualization']",Canada,15,33.14,1.7,"['Food', 'Beverage']",100.00,,Remote Job,Intermediate
Scrape LinkedIn,I am looking for someone who has the skills to scrape all of the data on Apollo.io (I know there are exploits to get the data for free),"['Data Mining', 'Data Scraping', 'LinkedIn', 'LinkedIn']",United States,23,,1.5,,500.00,,Remote Job,Expert
Create Python Script That Can Analyze Data And Output Data If Conditions Are Met,"I have a lot of data from years ago which is all in the same format, and a scraping script which updates the 2023 data daily. I also have a scraping script which scrapes future data rather than historic data.I need future data to be scraped with my script daily, then the future data to be analyzed, to see if any of the data meets a specific condition. If that condition is met then the specific data meeting the condition should be output.Once the application is functioning, I would like a nice GUI made, not with tkinter but rather something which looks and functions better.Please only apply to this job if you are a professional, can get the work done quickly and will make sure the code is up to par.",['Python'],United States,1,90.00,0,,,"['40.00', '120.00']",Remote Job,Expert
AI Computer Vision - Remove Logos from Images,"We are looking for a experienced Computer Vision AI expert who can help us use AI to remove logos from product images. The logos will keep changing, so supervised learning will not work.I've included samples of images that will require logo removal.Please share example of past work done in Computer Vision.","['Deep Learning', 'Computer Vision', 'Reinforcement Learning', 'Unsupervised Learning']",United States,176,14.74,192,"['Retail', 'Consumer Goods']",,"['40.00', '150.00']",Remote Job,Expert
Experienced Economist/Programmer to Review Julia Implementation of Economic Model Algorithm,"Description:I am looking for an experienced economist/programmer who can review my Julia implementation of an algorithm for solving an economic model. The implementation is approximately 500 lines of code. I suspect there might be bugs in the program or issues with the algebraic equations used. I need someone with expertise in mathematical modeling, specifically dynamic macro or spatial models in economics, to thoroughly review the implementation and identify any errors or areas for improvement.Responsibilities:1. Review the Julia implementation of the algorithm for solving the economic model2. Verify the correctness of the code and algebraic equations used3. Identify any bugs or errors in the implementation4. Propose solutions or modifications to ensure convergence of the program5. Provide recommendations for improving the efficiency or clarity of the codeRequirements:- Proficiency in programming with Julia or MATLAB- Experience implementing complex algorithms for economic models- Attention to detail and ability to identify errors in code and equations- Strong problem-solving skills- Strong background in economics, computer science, or math, particularly dynamic macro or spatial models, would be a plus.If you are confident in your ability to review the implementation and troubleshoot any issues, please apply with your relevant experience and qualifications. Please include the word ""ECONOMODEL"" at the beginning of your application to confirm that you have read the job description thoroughly. The selected candidate will receive the necessary code and additional documentation to perform the review. Payment will be based on an hourly rate, and the estimated time for completion is negotiable.","['Mathematics', 'Mathematical Modeling', 'Algorithm Development', 'Julia', 'MATLAB', 'Algorithm Development', 'Julia', 'MATLAB']",United States,3,250.00,463,['Education'],,"['40.00', '125.00']",Remote Job,Expert
Artificial Intelligence Film Script Analysis,"Project Description:We are seeking a talented individual with expertise in big data, machine learning, cloud computing, and web development to create a groundbreaking tool for the film and TV industry. This role involves developing an AI-based film script analysis tool that will use large scale data, predictive analytics, and machine learning to forecast potential revenue streams for film or TV series projects. The project will integrate multiple third-party data sources and offer a flexible user interface for modifying various variables such as cast or script elements.Key Responsibilities:Utilize big data technologies to aggregate, store, process, and analyze large datasets from multiple sources related to the film and TV industry.Design, develop and implement an AI model, possibly using large language models, that can predict potential box office revenues and other revenue streams for film or TV series projects.Develop a mechanism within the AI model to compare stats of new projects with similar ones to increase prediction accuracy.Incorporate a feature that allows for variables in the project to be altered, such as cast members or script details, and demonstrate the impact of these changes on revenue predictions.Create an automated evaluation system to assess various key factors of the script and cast.Design and develop a web interface for easy access and manipulation of the AI tool.Employ data visualization tools to effectively communicate analytical results.Qualifications:Proven experience in big data technologies, machine learning, predictive analytics, cloud computing, and web development.Proficiency in Node.js, JavaScript, SQL, and hands-on experience with machine learning libraries such as TensorFlow or PyTorch.Experience with large language models and their application in text analysis.Experience with cloud services like AWS, Azure, or Google Cloud.Proficiency in data visualization tools for effectively showcasing analytical results.Familiarity with the film and TV industry, understanding key drivers of success, and an appreciation for the creative process.Experience with third-party data sources and API integrations.Excellent problem-solving skills, the ability to think creatively, and strong communication and collaboration skills.This unique opportunity sits at the intersection of technology and creativity, offering the chance to make a significant impact on the film and TV industry. If you have the technical skills and a passion for film and TV, we would love to hear from you. Please apply with your resume and portfolio showcasing your relevant experience.","['Data Science', 'Node.js', 'Artificial Intelligence']",United States,1,,,,,,Remote Job,Expert
AI Sports & sports betting article generator,"We are looking for someone who can build us an AI content writer for wordpress blog. We want it to produce articles revolved around sportsbetting for upcoming games, predictions, etc It would need to be able to take in an API that gives the sportsbetting lines for upcoming games, produce an article around these linesThe ultimate goal is to have consistent content going out and convert organic users into our subscription service that offers sports betting pickssome example articles are here: https://www.covers.com/nhl/stanley-cup/panthers-vs-golden-knights-game-2-picks-predictions-june-5-2023https://www.pickswise.com/news/wise-n-shine-nhl-picks-mlb-predictions-and-nba-finals-odds-for-monday-june-5/https://www.actionnetwork.com/nhl/golden-knights-vs-panthers-odds-picks-prediction-stanley-cup-final-game-3-thursday-june-8https://www.cbssports.com/nhl/news/2023-stanley-cup-final-golden-knights-vs-panthers-odds-nhl-picks-game-3-predictions-from-hockey-model/","['Machine Learning Model', 'Chatbot', 'Blog Writing', 'Article Writing']",United States,20,,33,,,"['12.00', '30.00']",Remote Job,Intermediate
Looking for Freelance Python Developer,"Job Description:We are currently looking for a proficient Freelance Python Developer to join our dynamic team. The chosen candidate will be primarily tasked with the development of multiple data connectors inside our analytical software product. This position requires a candidate with an understanding of various data sources and alert channels. The developer should be capable of fetching historical or live data from different sources, mainly REST APIs, and sending them either to Elastic or Kafka.Key Responsibilities:Design, develop, and implement data connectors using Python.Fetch and manage data from various sources, predominantly REST APIs, and transport them either to Elastic or Kafka.Manage alert channels to listen to Kafka topics, apply certain criteria to the data, and send an event to a data sink when these criteria are met.Write clean, well-documented, and testable code.Troubleshoot and resolve potential issues related to the developed connectors.Maintain robustness against edge cases such as missing data.Collaborate effectively with the team and work with a certain level of independence.Required Skills & Experience:Proven experience as a Python Developer.Extensive knowledge of Python and its libraries.Strong understanding of REST APIs and Kafka.Experience with Elasticsearch is a plus.Familiarity with testing and debugging in Python.Excellent problem-solving skills and attention to detail.Demonstrated ability to write clean, well-documented, and testable code.Strong written and verbal communication skills.Ability to work independently and as part of a team.Education:Bachelor's degree in Computer Science, Information Systems, or related field is required. However, relevant experience will be considered in lieu of a degree.We encourage all who are interested and meet the requirements to apply. We value diversity and are committed to creating an inclusive environment for all employees.We look forward to welcoming a new member to our team who can contribute to enhancing our software product with their expertise and innovative ideas.",['Python'],Vietnam,431,14.77,2,"['Tech', 'IT']",,"['15.00', '40.00']",Remote Job,Expert
Regression and Classification Model Building using R and get best rMSE performance of the model,"Hello Data Scientists,I have a small task on building the Machine Learning Models i.e regression and classification model. Getting the desired and best  rMSE for the model is mandatoryPlease feel free to apply for this job. If you are well versed with this topic.Thank You!Ankita.","['Machine Learning Model', 'Regression Model', 'Classification Model', 'RMSE', 'Fit model', 'train data', 'test data', 'full model', 'R', 'RMSE', 'Fit model', 'train data', 'test data', 'full model', 'R']",Australia,14,,443,['Education'],20.00,,Remote Job,Expert
Generative AI developer with unreal and unity develop Floorplan software (oprnsources available),"Hi All!I want to develop a tool that will get a naked 2d floorplan and will generate by a free text field and a few dropdowns for a 2d, 3d and virtual tour colorful and furnished.I found tons of open sources we can rely on and develop it quick, you will need to make the adaptations and take it into my github. You should make sure there are no limitations on top of this repository. When you approach please talk about it as well.you can see an example video attached.I dont have the dataset etc then it should be included.I attach here a reference which is different but they do something interesting on top of the architecture softwares such as Cad, Revitt etc. https://www.evolvelab.io/verasThanks in advanceJob Description:We are seeking a skilled and creative developer to join our team and take on the exciting challenge of developing a tool that can transform black and white floorplans into vibrant, visually appealing representations. This tool aims to add furniture, grass, swimming pools, and other elements to the floorplan, providing a realistic and colorful depiction of the space.Responsibilities:Design and develop a software tool that can process black and white floorplans and convert them into colorful representations.Implement image processing techniques, computer vision algorithms, and graphic design principles to identify different elements within the floorplan and add colors, textures, and other details.Collaborate with architects, interior designers, and potential users to understand their requirements and preferences, and incorporate their feedback into the tool's development.Research and explore cutting-edge technologies, libraries, and frameworks in the fields of image processing, computer vision, and graphics to enhance the tool's capabilities.Conduct thorough testing and debugging to ensure the accuracy and reliability of the tool's output.Stay up-to-date with the latest trends and advancements in floorplan representation, computer graphics, and design to continually improve the tool's functionality and user experience.Document the development process, including algorithms, methodologies, and technical specifications, for reference and future enhancements.Qualifications:Bachelor's or Master's degree in Computer Science, Software Engineering, or a related field.Strong programming skills in languages such as Python, Java, or C++, with experience in image processing, computer vision, or graphics-related projects.Proficiency in image processing libraries or frameworks, such as OpenCV.Knowledge of graphic design principles, color theory, and composition.Familiarity with architectural drawings, 2D floorplans, and interior design concepts.Excellent problem-solving and analytical skills, with attention to detail.Effective collaboration and communication abilities to work with cross-functional teams and gather feedback from stakeholders.Self-motivated and able to work independently while adhering to project deadlines.Experience in testing and debugging software applications is a plus.Join our dynamic team and contribute your skills to create an innovative floorplan conversion tool that revolutionizes the way spaces are visualized. Apply now with your resume, portfolio, and any relevant project samples.","['Generative AI', 'Artificial Intelligence', 'Image Processing', 'Computer Vision', 'Graphic Design', 'Unreal Engine', 'Unity', 'GitHub', 'Image Processing', 'Computer Vision', 'Graphic Design', 'Unreal Engine', 'Unity', 'GitHub']",Israel,55,,100,['Real Estate'],1000.00,,Remote Job,Expert
Subject Matter Expert (SME) - AI Content Review,"OverviewWe are currently seeking a highly knowledgeable and experienced Subject Matter Expert (SME) specializing in Artificial Intelligence (AI) to join our team as a consultant. As an SME, you will be responsible for reviewing and providing expert feedback on the course structure, outline, and content of our AI training program. Your expertise will play a vital role in ensuring the accuracy, comprehensiveness, and relevance of our course materials.We are developing a learning program (comprises of 5 courses) for educators and trainers on the topic of Artificial Intelligence (AI), more specifically educators who are novice in the topic of AI yet expected to understand the ground frameworks of AI and its use in the education field to then share the knowledge to their students.Expected DeliverableReview Course Structure: Analyze the overall organization and flow of the proposed courses. Evaluate the appropriateness of the modules and lessons in relation to the target audience and learning objectives.Assess Course Outline: Examine the outline of each module and lesson, verifying that it covers relevant AI concepts, methodologies, and applications. Make recommendations for lesson topics (up to 3 for each lesson).Ensure Relevance and Currency: Keep up to date with the latest advancements and trends in AI. Evaluate the course content for relevance and currency, making recommendations for updates to reflect emerging technologies, research breakthroughs, or industry standards.Conduct Research to Support Content Development: Provide concrete research materials (articles, videos etc.), examples and case studies which can help to make abstract concepts more tangible and relatable to the audience. This can also help to demonstrate the real-world impact of the topic being discussed.Provide Expert Feedback: Using the template provided, provide inputs detailing your evaluations, recommendations, and suggested improvements for the course structure, outline, and content. Collaborate with our Instructional Design Team: Provide an hour of availability to meet with our team to ensure your feedback is implemented effectively.You may refer to the document attached for a high level overview of the course structure. Once you have been shortlisted, you will be provided a separate sheet where you will be able to provide the appropriate inputs (for reference, parts you will need to do is in the designated yellow columns within this document) adhering to the guidelines outlined below. Guidelines1. With regards to the selection of tools, it is recommended to prioritize the utilization of Bing Chat to a significant extent.2. It is advisable to contemplate generating content that revolves around the creation of easily accessible learning materials catering to diverse target audiences such as individuals with special needs, varying age groups and genders.3. It is highly recommended to refrain from producing content that is based on personal opinions, particularly in relation to the subject matter of AI responsibilities.Requirements1. Subject Matter Expertise: Extensive knowledge and expertise in Artificial Intelligence, including a deep understanding of AI concepts, algorithms, machine learning, neural networks, natural language processing, computer vision, and related areas.2. Experience in AI Content Review: Proven experience in reviewing and evaluating AI course materials, curriculum, or training programs. Previous work as an AI instructor, curriculum developer, or AI researcher would be highly advantageous.3. Education: A degree in Computer Science, Artificial Intelligence, Data Science, or a related field is strongly preferred. Advanced degrees or certifications in AI-related disciplines will be highly regarded.4. Industry Experience: Substantial practical experience working with AI technologies, either in academia or industry. Familiarity with real-world AI applications, challenges, and best practices is essential.5. Attention to Detail: Meticulous attention to detail with the ability to spot and correct errors, inaccuracies, or inconsistencies in course content.6. Communication Skills: Excellent written and verbal communication skills, with the ability to provide clear, constructive, and actionable feedback to improve the course materials.7. Time Management: Strong organizational skills and the ability to manage multiple tasks effectively within tight deadlines.If you are a subject matter expert with a passion for AI and possess the necessary qualifications and experience outlined above, please submit your proposal. Additionally, please include any previous AI course reviews or related work samples.We look forward to collaborating with you to enhance our AI training program.","['Article Writing', 'Education', 'Content Writing', 'Artificial Intelligence', 'Artificial Intelligence Consulting', 'Artificial Intelligence Ethics', 'Research Documentation', 'Artificial Intelligence Consulting', 'Artificial Intelligence Ethics', 'Research Documentation']",Malaysia,125,13.00,113,['Education'],,"['30.00', '100.00']",Remote Job,Expert
SAS statistical modeling,Help is needed to analyze large data sets using SAS,"['Statistics', 'Data Analysis', 'SAS', 'Statistical Analysis', 'Data Modeling', 'Data Science', 'Biostatistics', 'SAS', 'Statistical Analysis', 'Data Modeling', 'Data Science', 'Biostatistics']",United States,1,,,,,"['18.00', '45.00']",Remote Job,Intermediate
Python Developer for Logistic Regression,"1. Must write clean, documented, organized code2. Must have an GPU locally to run/test code. ---We need refactoring of a logistic regression pipeline in python.We need reports (confusion matrix, accuracy, precision and standard metrics) and graphs for each logistic classifier.","['Python', 'Machine Learning', 'Data Analysis', 'Statistics', 'R', 'Data Mining', 'Data Analysis', 'Statistics', 'R', 'Data Mining']",China,213,15.62,206,"['Tech', 'IT']",,"['15.00', '25.00']",Remote Job,Entry level
Python AI Data Scrap Expert,I'm looking for someone who is expertise in python AI web scrapping.You should get pharmaceutical  data from reddit.com and deepweb forums.Feel free to contact me.,"['Python', 'Data Scraping', 'Artificial Intelligence']",United Kingdom,2,,,"['Health', 'Fitness']",500.00,,Remote Job,Expert
SAAS Conversion Rate Expert - Help Dig Into the Data and Suggest Changes to Test,We have launched a new website and signup flow for our SAAS business. There are multiple ideas we are looking to test to help improve our conversion rate. Looking for someone to help suggest changes to make/experiments to run to improve our signup to paying customer conversion. We will provide you with...- Access to looker studio- MS ClarityLooking for suggestions on changes to make and potentially help with setting up our A/B testing tech & process.,"['A/B Testing', 'Funnel Testing', 'Hypothesis Testing', 'Google Analytics', 'Lead Generation', 'Google Ads', 'Conversion Rate Optimization', 'Web Design', 'Webflow', 'Google Ads', 'Conversion Rate Optimization', 'Web Design', 'Webflow']",Canada,2251,4.63,1.8,"['Tech', 'IT']",,"['10.00', '45.00']",Remote Job,Intermediate
Cross-Platform Data Extraction/Migration/Reporting,"I own a real estate team. Seeking help with cross-platform data extraction, migration & reporting. Example #1: extract data from various platforms, to produce a client-facing Marketing & Sales Report in Google Sheets. Example #2: extract data from web-based transaction software, to enable supporting reports in QuickBooks Online. Honestly not even 100% sure I am using the correct terminology above. :)","['Data Entry', 'Google Sheets', 'Google Docs', 'Microsoft Excel', 'Data Extraction', 'Data Scraping', 'Data Mining', 'Data Analysis', 'API', 'Accuracy Verification', 'Accounting Software', 'Database', 'Spreadsheet Software', 'Accounting Basics', 'Web Crawling', 'Intuit QuickBooks', 'Quickbooks', 'Cash Flow Statement', 'Data Migration', 'Scrapy', 'Scripting', 'Google Docs', 'Microsoft Excel', 'Data Extraction', 'Data Scraping', 'Data Mining', 'Data Analysis', 'API', 'Accuracy Verification', 'Accounting Software', 'Database', 'Spreadsheet Software', 'Accounting Basics', 'Web Crawling', 'Intuit QuickBooks', 'Quickbooks', 'Cash Flow Statement', 'Data Migration', 'Scrapy', 'Scripting']",United States,1,,,['Real Estate'],,"['25.00', '100.00']",Remote Job,Intermediate
AI Chatbot Developer(proof of concept),"We are seeking an experienced AI Chatbot Developer to join our team and implement a proof-of-concept chatbot.The successful candidate will be responsible for designing, developing, and testing the chatbot to ensure it meets the requirements of the project. Responsibilities: - Design and develop a chatbot using AI technologies such as natural language processing (NLP) and machine learning (ML) - Collaborate with project stakeholders to gather requirements and ensure the chatbot meets their needs - Test and debug the chatbot to ensure it functions correctly and meets performance requirements - Stay up-to-date with the latest AI technologies and trends in chatbot development Requirements: - Bachelor's degree in Computer Science, Software Engineering, or a related field - Proven experience developing chatbots using AI technologies such as NLP and ML - Strong programming skills in languages such as Python, Node, React - Familiarity with chatbot development frameworks such as Dialogflow, Botpress, or Rasa - Excellent problem-solving and analytical skills - Strong communication and collaboration skills If you are passionate about AI technologies and have experience developing chatbots, we encourage you to apply for this exciting opportunity to implement a POC chatbot","['ChatGPT', 'GPT-3', 'GPT-4', 'Artificial Intelligence', 'Chatbot Development', 'OpenAI Codex', 'Chatbot Development', 'OpenAI Codex']",Peru,1,,,"['HR', 'Business Services']",,"['18.00', '40.00']",Remote Job,Intermediate
AI/NLP Engineer to help build a personalised teaching system,"Hi, I am looking to develop a platform system that uses text-based interactions to assess a student's proficiency level, deliver personalized lessons, and evaluate the student's understanding through progressively challenging questions. I am looking for someone build a chatbot system on a website domain with pathways that I can lay out.I would first like to discuss what the best tools to do this would be (NLP, API, UI, etc). I expect you will have background on all appropriate tools that can be used so we can discuss which tools are most right for this application.","['Natural Language Processing', 'Machine Learning', 'Artificial Intelligence', 'Deep Learning', 'Chatbot Development', 'Machine Learning', 'Artificial Intelligence', 'Deep Learning', 'Chatbot Development']",Australia,3,5.00,125,,,"['13.00', '40.00']",Remote Job,Intermediate
ETL Specialist with Google Big Query and API Integration Experience,"We are looking for a specialist who can configure automated data collection from multiple sources (multiple Google Sheets spreadsheets, the https://keepa.com/ API, and CSVs retrieved via an unauthorized link) into Google Big Query.In addition, we expect you to- Understand ETL processes.- Be familiar with data warehousing concepts.- Experience with and knowledge of Google Cloud Console (project creation, user rights configuration) as well as cloud storage, cloud functions, cloud scheduler.- Experience with SQL.- Experience writing code in Python and JavaScript.- Experience optimizing code (whether it's your own or someone else's).Experience with Shopify and Amazon APIs is a plus.","['Python', 'SQL', 'API', 'JavaScript', 'BigQuery', 'Google Cloud Platform', 'API Integration', 'MySQL', 'ETL', 'BigQuery', 'Google Cloud Platform', 'API Integration', 'MySQL', 'ETL']",Ukraine,30,13.73,3.8,"['Tech', 'IT']",,"['10.00', '35.00']",Remote Job,Intermediate
Python + Word Document/ PDF + Auto generation + Machine Learning/Quantitative Research,"This project's goal is that data generated from an ML model is stored in the d.b as JSON artifacts. We want a Python script that can take the various parts from the database and generate quantitative parts of what would be a big chunk of a Ph.D. paper or a model review doc used in academics or industry. For example, you will read the JSON object stored for a ROC curve and be able to read that data and convert it to a proper image object in Word or read a confusion matrix stored as a JSON and create a well-formed table in Word and PDF.","['Machine Learning Model', 'Machine Learning', 'Python Scikit-Learn', 'Python Script', 'Python', 'Automation', 'PDF Conversion', 'Data Scraping', 'PDF Conversion', 'Data Scraping']",United States,21,,350,,300.00,,Remote Job,Expert
Automated PDF Data Extraction,I am seeking a professional with experience with PDF conversion into an automated ETL process for lead generation into Excel.I have BOL (bill of ladings) in PDF format that requires specific fields to be extracted as follows: For example: Shippers nameShippers addressContact (if available) Contact phone number (if available)Contact email (if available) Receiver info (same as above)commodity description/nmfc code/class from the BOLSpecial services (if listed) such as lift gate required; delivery appointment needed; residential or limited access),"['Data Extraction', 'Data Scraping', 'PDF Conversion', 'PDF Conversion']",United States,2,,,,300.00,,Remote Job,Expert
Excel Expert WANTED !!!!!,"We are looking for someone that is an EXPERT in excel. I need someone that is a 10 out of 10 when it comes to creating, editing , sifting and sorting data, in excel. You must be able to sift, clean and sort them according to specific criteria. So the end result will be a clean spreadsheet with accurate and organized records so that we can mail to our customers for marketing. You must be able to create formulated spreadsheets to be used within our business.I look forward to having you as part of our team.","['Spreadsheet Software', 'Data Entry', 'Data Mining', 'Data Mining']",United States,208,6.70,96,,,,Remote Job,Expert
Power BI Specialists,Assist with establishing data collected through online forms / excel / google sheets and display it in power BI,"['Dashboard', 'Microsoft Power BI', 'Data Analysis', 'Data Visualization', 'Microsoft Power BI Development', 'Microsoft Power BI Data Visualization', 'Data Visualization', 'Microsoft Power BI Development', 'Microsoft Power BI Data Visualization']",Hong Kong,73,19.03,80,"['HR', 'Business Services']",,,Remote Job,Intermediate
Product Manager,"Our company is looking for product managers and platform testers that can test  and use our software based solutions, in our case SaaS web based solutions for our clients;As an expert in representing similar platforms, online or software based, ideally, you have already tested similar platforms in the past, and you also have strong business development skills including client prospecting and engagement as well as international payment systems experience. Our online based solutions are low cost, and you understand the value in representing a platform with low cost solutions for our subscribers;Another asset would be previous experience in the following industries and/or roles:•                    Portfolio construction•                    Investment strategy•                    Private wealth•                    Investment banking•                    Commercial banking•                    Hedge funds•                    Corporate finance•                    Data science•                    Quantitative investing•                    Regulatory entities or standard setters","['Software Testing', 'Functional Testing', 'Bug Reports', 'Automated Testing', 'Software QA', 'Usability Testing', 'Web Testing', 'Test Case Design', 'Bug Reports', 'Automated Testing', 'Software QA', 'Usability Testing', 'Web Testing', 'Test Case Design']",Canada,22,,,"['Finance', 'Accounting']",,,Remote Job,Intermediate
Tableau Specialist,I need 4-5 graphs made for a presentation due tomorrow. Need help asap. Please do not commit unless you can start right away and can work 4 hours.,"['Tableau', 'Data Analysis', 'Data Visualization', 'Microsoft Excel', 'Microsoft Excel']",Canada,25,27.28,2.6,,,"['20.00', '30.00']",Remote Job,Expert
Need help organizing data on R Studio and conducting a non-parametric t test,"I have a raw data set that I need to input into R studio and analyze. Specifically, I am using a Signal Detection Theory approach, so I will need to calculate d', criterion, and a non-parametric estimate of bias.","['Data Analysis', 'R', 'Statistics', 'Microsoft Excel', 'Microsoft Excel']",United States,1,,,,,"['40.00', '75.00']",Remote Job,Expert
Need GA4 & conversion tracking specialist,"ScopeWe need an expert GA4 & Conversion Tracking Specialist to:1. Audit our current set up between GA4/GTM, Google Ads, LinkedIn Ads, Site and provide report on any issues with current setup2. Fix GA4 & conversion tracking (including conversion goals/events) so we are tracking/reporting to desired level of detail3. Provide documentation on setting up goals and events in GA4 (including video walk-throughs) to support team when adding new content to the site (ie. new pdf to download)4. Ongoing website analytics and optimization projects are likely for the selected freelancer who delivers on this initial project.OverviewWe worked with an agency for 2+ years who set up GA4, conversion tracking, however, we are finding discrepancies between GA4 and channels. For example, in May GA4 reported 5 conversions from LinkedIn, while we had implemented UTMs and manually tracked ~40 download conversions.Additionally, we have a lot of content that gets added to the site, we’d like to make sure that all channels and GA4 have goals and event tracking set up for all new gated content on the site so we can ensure we are accounting for all conversions. Right now, we don’t have that capability (only a few are tracked in GA4). Because we add content to the site frequently, we will need a how-to-video on how to set this up going forward so we have a set process to scale. LimitationsOur resources are not experts in conversion tracking or GA4, so working with an expert is crucial. We’re looking for an expert who can become a trusted extension of our team in this space.","['Google Analytics', 'Google Ads', 'Google Tag Manager', 'conversion tracking', 'Google Analytics 4', 'LinkedIn Analytics', 'Google Tag Manager', 'conversion tracking', 'Google Analytics 4', 'LinkedIn Analytics']",United States,1,,,,240.00,,Remote Job,Expert
Scrape data from opensyllabus.org,"We are looking for a skilled data extraction specialist who can scrape data from explorer.opensyllabus.org. The project is expected to last less than one month. The ideal candidate should have experience in scraping data from the web and delivering it in a structured format.The goal of this project is to collect data on academic books and their usage across various universities and institutions. Deliverables will the source code for running the scraping task, along with a CSV file containing the data with the following fields: school, field, country, title, author, and publisher (if available). To apply for this job, please submit a proposal outlining your relevant experience and your high-level approach to this project.","['Data Scraping', 'Data Extraction', 'Data Mining', 'Python', 'Data Mining', 'Python']",United States,5,,560,"['Tech', 'IT']",,,Remote Job,Intermediate
Data collection,collect various data and collate to a mailing list/call sheet,"['Data Collection', 'Data Entry', 'Data Mining', 'Data Mining']",Australia,43,10.72,32,,,"['3.00', '6.00']",Remote Job,Entry level
Looker studio dashboard,I need help creating a Google data studio dashboard from a Google sheet. I am setting it up but have questions and need some help completing the integrations,"['Google Data Studio', 'Data Visualization', 'Data Analysis', 'Data Analysis']",United States,59,12.93,3.2,,60.00,,Remote Job,Intermediate
Prepare an end to end solution for a real world data analytics problem statement,"We are looking for an end to end solution for a project, that we are designing for a training course. The project will be based on a real world problem statement, that then needs to be solved using various data analytics tools such as MS excel, SQL, python, power bi and PowerPoint for presentation. This is for one project, but we have a few more depending on the results of this one. Any questions, please ask.","['Presentations', 'Python', 'Microsoft Excel', 'SQL', 'visualisation', 'powerbi', 'SQL', 'visualisation', 'powerbi']",United Kingdom,14,,550,,350.00,,Remote Job,Intermediate
GA4 Event Set Up For Booking Widget Installed On Website,"We need help setting up GA4 events for a booking widget installed on a website. Previously, we've been able to see events for the booking widget show up in Google Analytics, which we could then import into Google ads to track conversions of bookings.However, now with GA4 taking over, we require assistance in identifying the event info and or setting it up so it's visible in GA4. The booking widget is called hotdoc. It Universal Analytics we can see event category, event action and event label data coming through from the widget, but in GA4 we can't see anything.Can you help?","['Google Analytics', 'Google Tag Manager', 'Growth Analytics', 'google analytics 4', 'website tracking']",Australia,32,19.14,9.2,,,"['18.00', '45.00']",Remote Job,Intermediate
Google analytics help,"Hi, I am looking for some help with my Google ads & Google Analytics.We have these accounts already set up looking for an Expert to review and to correct any mistakes we have madeThank you!Mark","['Google Analytics', 'Google Ads']",United States,1,,,,,"['75.00', '120.00']",Remote Job,Expert
Zoho Analytics SQL Expert,"Job Description:We're seeking a proficient SQL and Zoho Analytics freelancer who can assist us in rebuilding data tables and setting up custom reports and dashboards in Zoho Analytics. We recently migrated a SQL database to Zoho and are looking for help in refining our data visualization process. The primary tables that we are focusing on are Accounts, Contacts, Contract, Configuration Items, Tickets, and Time Entries/Notes.Key Responsibilities:Assist in the reconstruction of primary tables in our SQL database.Create custom reports and dashboards in Zoho Analytics.Collaborate with our team to optimize data visualization and reporting.Ensure the accuracy and integrity of data during the migration process.Provide recommendations on how to improve data management practices.Requirements:Proven experience in SQL and Zoho Analytics.Familiarity with data migration from SQL to Zoho.Strong understanding of data visualization techniques.Excellent problem-solving skills and attention to detail.Exceptional communication skills.","['Zoho Analytics', 'SQL', 'Data Analysis']",United States,8,,0,"['Tech', 'IT']",,"['45.00', '75.00']",Remote Job,Intermediate
UI Dashboard needed to display Google Doc Data,"We are looking for someone to take data from a google doc and create an attractive Dashboard.   We want someone creative that can also advise as to the look, feel and how the data is organized.  Below is a link to the current plain looking Dashboard.   We are an options trading company and we post every trade in a google doc/sheet. There are two tabs on the current dashboard.  The first is a list of every trade and the other tab is the compilation of all the data.   https://www.universityofoptions.com/pages/dashboardWe look forward to hearing from you!","['Google Docs', 'Google Sheets', 'Data Visualization', 'Graphic Design', 'HTML', 'Data Visualization', 'Graphic Design', 'HTML']",United States,1,,,,,"['40.00', '100.00']",Remote Job,Intermediate
NLP consultant,"I'm writing a parser to transform workout plans into a domain specific language and I need the advice and expertise of someone with experience in the field of NLP to consult on methods, toolset, and approach that would be reasonable.The DSL is written in Python and for that reason I'd like to use Python in my implementation.  I have a large corpus of workouts scraped and ready to process, I just need someone to show me the best approach!  Thanks for reading!","['Natural Language Processing', 'Python', 'Python']",United States,3,9.46,699,,,"['50.00', '95.00']",Remote Job,Expert
i want to create AI chat bot using Python,"Hi, i want to create python chat bot :- using google colab- Langchain- Wizard-Vicuna-13B Modal- GPU not CPUusing this type of prompt :(Role: system, assistant & user)something like this :""role"": ""system"", ""content"": ""You are a boy and your name is Alex, you are from Italy"", ""role"": ""user"", ""content"": ""Hi, what's your name ?""that's what i need.","['GPT-J', 'AI Model Integration', 'Conversational AI', 'Hugging Face', 'gpt4all', 'vicuna ai', 'Chatbot Development', 'Bot Development', 'lang chain', 'langchain', 'Bot Development', 'lang chain', 'langchain']",Morocco,14,,70,"['Tech', 'IT']",50.00,,Remote Job,Entry level
Scraping site,https://www.ibccoaching.com.br/ Need a parser for this site.  Save the result in csv,"['Data Scraping', 'Scrapy', 'Python']",Germany,2,,,['Aerospace'],,"['5.00', '15.00']",Remote Job,Entry level
Ml project and data scraping,It is a ml project which includes data scraping form websites and putting them in their respective category. I already have some code for it but I need you to revamp it with proper outputs,"['Data Science Consultation', 'Python', 'Data Scraping', 'Data Mining', 'Scrapy', 'Machine Learning', 'Data Science', 'Data Extraction', 'ETL Pipeline', 'Scrapy', 'Machine Learning', 'Data Science', 'Data Extraction', 'ETL Pipeline']",Spain,4,,175,,20.00,,Remote Job,Intermediate
Prompt Engineer for Silicon Valley AI Startup,"Hiring a prompt engineer with deep experience working with large language models, GPT, Anthropic etc. You must also have experience with chain of thought, chat prompting etc. We are a Silicon Valley AI startup that is founded by ex Stanford and Meta people. You will work with a A+ team and this is a long-term engagement opporutnity.","['Generative AI', 'Prompt Engineering', 'ChatGPT', 'Artificial Intelligence']",United States,143,11.60,46,"['Tech', 'IT']",,"['10.00', '40.00']",Remote Job,Expert
Prompt Engineer for Silicon Valley AI Startup,"Hiring a prompt engineer with deep experience working with large language models, GPT, Anthropic etc. You must also have experience with chain of thought, chat prompting etc. We are a Silicon Valley AI startup that is founded by ex Stanford and Meta people. You will work with a A+ team and this is a long-term engagement opporutnity.","['Generative AI', 'Prompt Engineering']",United States,143,11.60,46,"['Tech', 'IT']",,"['10.00', '40.00']",Remote Job,Expert
Prompt Engineer for Silicon Valley AI Startup,"Hiring a prompt engineer with deep experience working with large language models, GPT, Anthropic etc. You must also have experience with chain of thought, chat prompting etc. We are a Silicon Valley AI startup that is founded by ex Stanford and Meta people. You will work with a A+ team and this is a long-term engagement opporutnity.","['Prompt Engineering', 'Generative AI', 'Natural Language Generation', 'Artificial Intelligence', 'Machine Learning', 'Machine Learning']",United States,143,11.60,46,"['Tech', 'IT']",,"['10.00', '40.00']",Remote Job,Expert
Crystal Reports help using pervasive database,We need to develop a couple of Crystal Reports from the pervasive database. Globalshop experience is added advantage.,"['Data Visualization', 'pervasive database', 'Cystal Reports', 'Globalshop ', 'Globalshop ']",United States,277,7.38,4.7,,75.00,,Remote Job,Expert
GSI data management,"We are seeking a highly organized and detail-oriented individual to join our team as a Data Transfer Specialist. In this role, you will be responsible for transferring data from GSI mapping to an Excel sheet, ensuring accuracy and completeness of information. Your meticulousness and ability to work with large data sets will be crucial to the success of our organization. Also will need to skip trace name or address to obtain the phone numberResponsibilities:Extract data from GSI mapping software and transfer it to Excel spreadsheets.Review and verify the accuracy of data during the transfer process.Organize and categorize data in a systematic manner.Identify and resolve any discrepancies or errors in the data.Collaborate with other team members to ensure data integrity and consistency.Meet project deadlines and deliver high-quality results.Requirements:Proficient in using GSI mapping software and Excel.Strong attention to detail and ability to work with large data sets.Excellent organizational and time management skills.Analytical mindset with the ability to identify and resolve data discrepancies.Strong communication skills and ability to work collaboratively in a team environment.Prior experience in data entry, data management, or a similar role is preferred.","['Data Analytics', 'Business Intelligence', 'AnyLogic', 'Data Entry', 'Microsoft Excel', 'Data Mining', 'Big Data', 'Data Mining', 'Big Data']",United States,1,,,['Real Estate'],,"['3.00', '10.00']",Remote Job,Intermediate
Tableau Dashboard Development,Looking for an expert Tableau dashboard developer with advanced knowledge of calculations and a clean and tidy dashboard design.Needs to be familiarized with the latest Tableau functionalities. Please send relevant examples of previous work or your portfolio.Thanks!,"['Tableau', 'Data Visualization', 'Data Analysis', 'Business Intelligence', 'Data Analysis', 'Business Intelligence']",United States,2,,,,,"['20.00', '50.00']",Remote Job,Intermediate
Yardi - SQL Reporting,"I am pulling both financial and statistical data out of Yardi, a real estate accounting software.  We need to set up an FTP or similar process to copy the Yardi backup data(which is saved daily) into a SQL server.  We then need to create a stacked report that will update daily which I can load into Excel and build reports.  We need to be self-reliant so some training may be required.  I am data-savvy and teachable.  After the project,  if the work is good, we will likely have other work for you.","['SQL', 'MySQL', 'Yardi Software']",United States,2,,,['Real Estate'],3500.00,,Remote Job,Intermediate
Build a Cognos report that de-duplicates data into multiple tabs when exported into excel,Looking to build a cognos report that will deduplicate data into multiple taps when exported into excel,"['IBM Cognos TM1', 'framework manager']",United States,3,,35,,,"['15.00', '25.00']",Remote Job,Expert
Data Scraper,"Hi,I extracted all of my LinkedIn contacts and I'm looking for verified personal and business e-mails. The list has about 4,000 names.Thank you so much for your interest!","['Data Scraping', 'Data Extraction', 'Data Entry', 'Data Entry']",Canada,13,3.67,8.9,,50.00,,Remote Job,Intermediate
Looking for entry level power BI and analytics for agribusiness reporting,"Data is available, but I would like to build a dashboard that would respond in real-time response. I need someone to guide me how to turn raw data to market intelligence like","['Microsoft Power BI', 'Business Intelligence', 'Data Modeling', 'Data Visualization', 'Data Mining', 'Data Modeling', 'Data Visualization', 'Data Mining']",South Africa,1,,,,,"['18.00', '45.00']",Remote Job,Intermediate
SQL Developer / SQL query writer,"We are actively seeking an accomplished SQL Developer, specializing in query development, reverse engineering and performance optimization, to work on a contract basis and enhance our data analysis capabilities. This is a fully remote position, accepting candidates from anywhere in the world. The primary responsibility of this role is to decipher existing SQL queries, create new ones, and collaborate with our team to design and implement interactive dashboards.Responsibilities:Write, optimize, and reverse engineer complex SQL queries.Collaborate with our team to conceptualize, design, and implement dashboards using Metabase.Troubleshoot, debug, and rectify any issues that arise with the dashboards or queries.Provide insights and recommendations based on the analysis of the database structure and data.Maintain clear and comprehensive documentation for all developed queries and dashboards.Requirements:Significant experience with SQL, focusing on designing, optimizing, and reverse engineering queries.Demonstrable expertise in using Metabase for creating data visualizations and dashboards.Excellent analytical and problem-solving skills, with the capacity to translate data into actionable insights.Prior experience in a collaborative, team-oriented environment.Strong communication skills, able to articulate complex concepts to non-technical team members.","['SQL', 'SQL Programming', 'Metabase']",United States,24,22.08,22,,,"['30.00', '50.00']",Remote Job,Expert
Create a QBR / dashboard for a marketing agency,"We're a marketing agency that works with nonprofits to raise money through direct-response fundraising (email marketing, digital marketing, direct mail, etc.). We need to create a Quarterly Business Review (QBR) to use with each client. What the QBR needs to do: -Visualize key results for the last quarter-Easy to digest and analyze-Look great so the client can use it for board meetings-Easy for our in-house team to assemble -Be able to repeat over and over again with minimal effort-Final product will be a slide show, likely 5-10 slides Functionally, we need the QBR to: -be able for us to add some copy and context-be able to plug in a client data export and generate it easily You need to be able to: -work with us to find the best format-if possibly, build it in  g-suite (but we are open to other suggestions)-be available for the first few months to iterate and improve one we start using it","['Dashboard', 'Data Analysis', 'Presentations', 'Report', 'Data Visualization']",Canada,10,11.36,2.4,"['Sales', 'Marketing']",,"['15.00', '45.00']",Remote Job,Intermediate
Tableau and Funnels.io Expert (Data),"Hello,We are seeking a skilled Tableau expert to assist us in setting up a couple of dashboards. The primary task will involve pulling data from Funnel.io, so prior experience with Funnel.io would be highly beneficial.Requirements:Proven experience as a Tableau expert, with a strong portfolio showcasing your dashboard design and development skillsFamiliarity with Funnel.io or similar data extraction toolsExcellent understanding of data visualization principles and best practicesProficiency in extracting, transforming, and loading data from various sources into TableauStrong analytical and problem-solving skillsEffective communication and collaboration abilities to work with cross-functional teamsPlease comment AD128 at the beginning of your application to see if you read the job posting.Attention to detail and commitment to delivering high-quality work within agreed timelinesIf you possess the skills and expertise required for this job, we would love to hear from you. Please provide examples of your past Tableau dashboards, specifically highlighting any projects involving Funnel.io or similar tools.Thank you,","['Tableau', 'Data Visualization', 'Data Analysis', 'Data Analysis']",Canada,54,24.61,33,,,"['20.00', '60.00']",Remote Job,Expert
Tableau and Funnels.io Expert (Data),"Hello,We are seeking a skilled Tableau expert to assist us in setting up a couple of dashboards. The primary task will involve pulling data from Funnel.io, so prior experience with Funnel.io would be highly beneficial.Requirements:Proven experience as a Tableau expert, with a strong portfolio showcasing your dashboard design and development skillsFamiliarity with Funnel.io or similar data extraction toolsExcellent understanding of data visualization principles and best practicesProficiency in extracting, transforming, and loading data from various sources into TableauStrong analytical and problem-solving skillsEffective communication and collaboration abilities to work with cross-functional teamsPlease comment AD128 at the beginning of your application to see if you read the job posting.Attention to detail and commitment to delivering high-quality work within agreed timelinesIf you possess the skills and expertise required for this job, we would love to hear from you. Please provide examples of your past Tableau dashboards, specifically highlighting any projects involving Funnel.io or similar tools.Thank you,","['Tableau', 'Data Visualization', 'Data Analysis', 'Data Analysis']",Canada,54,24.61,33,,,"['20.00', '60.00']",Remote Job,Expert
Indeed job data retrieval,I'm looking to scrape jobs off indeed in the united states on a daily basis.What I expect from you:1) Build bot that will run consistently for months to come2) Recommend infrastructure needed to run bot3) Setup infrastructure to run bot4) Recommend database to store data from bot5) Build database to store data from botSample data I would like extracted: https://docs.google.com/spreadsheets/d/1x6mWbWYjJWK8Kt5HzatBRS1g9TZyfsO00h3Q74McC6I/edit?usp=sharing,"['Data Scraping', 'Data Mining']",United States,56,13.58,3.3,"['Retail', 'Consumer Goods']",40.00,,Remote Job,Expert
Looking for AI system architect / programmer to build 3 AI systems (clones of existing apps),"Are you an AI expert wishing there was a big project you could get paid to build?This is a serious and large project. I am looking for a very talented individual or a team that has experience working together. This is to build 3 different proof of concepts apps using local models and training / fine-tuning.There are three existing AI apps I want to recreate. Just basically clone capability and functionality.1. Video modification - dancer (as seen on tiktok)- take an existing video, and modify the video (every frame) in some way, so that the video as a whole is changed but still results in a smooth video- https://www.youtube.com/shorts/EcH-UTI8Njk- https://www.youtube.com/shorts/-aiq-5Q-QjA- https://www.youtube.com/shorts/gGb40e1zgmg2. Image generation - Image generation (as seen in the mobile app Imagine)- https://play.google.com/store/apps/details?id=com.vyroai.aiart&hl=en_US&gl=US3. Image modification of clothing- not this, but something like this: https://www.ai.fashion/- to get the idea, as an example, detect and replace someone's clothing- ask me for specific detailsThese are 3 different applications of AI. Each application will have its own interface and app. The interface is not important at this stage, it can be an extremely basic web API interface. The key factor here is that the AI generation works.Key requirements:- Basic API Interface (input of parameters / output of AI-generated result)- I must own the model (not using any AI api's or models e.g. OpenAI)- The model must be trainable with additional data- The engine must run on my own local server (not using cloud compute e.g. Azure)- It is a plus if you can write the code in C#, although not required. Let me know if you have experience with .NET and C#I will hire you full time if you do a good job.Milestones (delivery):- manual means that the system is obviously working, but may require manual (clunky) input of files and parameters. But if you gave me instructions on how to input the data (e.g. put file here, edit parameters in .txt file), I could generate the results.- API means that there is a system that can automatically generate and respond with the results - hundreds, thousands. Would need to be able to handle queueing. Also the system should be tidied and cleaned up to be fully operational as a quality proof of concept.- If you fail to meet the first milestone as a proof of concept of Project 2, for a working version that I can use, then you will not be paid for partial and unusable work. A working functional version that I can use is the minimum requirement.- Project 2, proof of concept- - $500 for first working version (manual)- - $750 for final proof of concept (API)- Project 3, proof of concept- - $500 for first working version (manual)- - $750 for final proof of concept (API)- Project 1, proof of concept- - $1000 for first working version (manual)- - $1,500 for final proof of concept (API)If you are interested in this project, please answer the following questions in your application.1. Your name, age, and geographic location2. What hours in California time are you available for discussion?3. Are you applying as an individual or a team? If a team, describe the team (# of members, roles, experience working together, etc.)4. What experience do you have building an AI product from scratch, such as the above?5. What do you need from me in order to be successful? E.g. server hardware requirements, etc.6. What else should I know about you?7. What questions do you have for me?Note, I intend to hire multiple individuals/teams, and will do the first part of a project with each team. Whichever team is best, I will continue with the rest of the job.NOTE - any applications that say ""let's have a call"" without answering the questions above will be immediately ignored. Answer the questions in your application!","['Machine Learning Model', 'Model Optimization', 'Model Tuning', 'Artificial Neural Network', 'Artificial Intelligence', 'Python', 'C#', 'Machine Learning', 'Python', 'C#', 'Machine Learning']",United States,385,6.74,166,,5000.00,,Remote Job,Expert
Develop Power BI Reports on Demand,"""Calling all Power BI Experts: Freelancer Needed for On-Demand Reports Creation!""**Spanish speakers are a plus**We are currently seeking a skilled freelancer to join our team for an exciting project. If you have experience in creating dynamic and visually appealing reports using Power BI, we would love to collaborate with you!Project description:We are looking for a reliable and efficient freelancer to work with us creating on-demand Power BI reports for our sales, manufacturing, and senior management teams in the cafe and restaurant industry.We need custom reports that present data in a clear and powerful way, providing valuable information for business decision making.Requirements:-Extensive experience in report creation using Power BI.-Ability to understand and translate business requirements into effective reports.-Solid knowledge of data visualizations and report design.-Ability to work independently and meet established deadlines.-Clear and effective communication skills to ensure smooth collaboration.-Ability to review the metadata report our system allow us to download in order to create the report needed feeded by the metadata reportResponsibilities:-Having meetings to gather requirements, criteria, and KPIs to be displayed.-Design and create customized Power BI reports based on established criteria.-Optimize data visualization to ensure clear understanding of information.-Present the preliminary versions of the developed reports in order to perform necessary testing and adjustments to ensure accuracy and quality of reports.-Meet agreed-upon deadlines and respond to any inquiries or change requests.What We Offer:-An exciting and challenging project with the opportunity to work on diverse industries and topics.-Flexible remote working environment that allows you to manage your time efficiently.-Fair compensation with a fixed cost per report created.-Potential future collaboration opportunities on additional projects.If you are a Power BI expert with demonstrated skills in creating effective reports and are ready for a new challenge, we want to hear from you! Please send us your resume and a few examples of your previous Power BI reports. We are excited to discover your talent and explore how we can work together on this project and beyond.We look forward to receiving your application as soon as possible.","['Dashboard', 'Business Intelligence', 'Microsoft Power BI', 'Data Analysis', 'Microsoft Excel', 'Data Visualization', 'Microsoft Power BI Development', 'Microsoft Power BI', 'Data Analysis', 'Microsoft Excel', 'Data Visualization', 'Microsoft Power BI Development']",Guatemala,3,,900,"['Transportation', 'Warehousing']",500.00,,Remote Job,Expert
Scrapping Bot Developer,"NNN Capital is seeking a backend developer to support our live websites and integrated bots. We are looking for someone who is passionate about building bots and improving process efficiency on our 4 websites. This role will primarily work on Python scripts and must be willing to support any other languages within our work environment.Over the years, NNN Capital has invested in its technology and online presence. A large piece of that has been in building out infrastructure and systems that pull in, transform, and manage data that is used to facilitate our agents to better serve our clients. We are looking for a passionate individual who is able to support this ecosystem.Responsibilities:•	Work with research team to maintain, develop, and enhance bots.•	Provide software development services in a fast-paced and innovative working environment.•	Build scraping tools for our backend web services compatible with our existing systems.","['Python', 'PHP', 'Bot Development', 'Data Scraping']",United States,4,13.78,90,,,"['8.00', '15.00']",Remote Job,Intermediate
Web Scraping application for key individuals,"We are looking for a skilled data scraper to write an application that is can scape data across all of the web. The ideal application can take a list of names and create alerts/notifications (emailed) whenever the name appears on the web. Also, to be able to run the application at any time.The main responsibilities will include writing the application and returning the data in a structured format to be reportable.To be considered for this project, please submit a detailed proposal outlining your experience in web scraping and how you will help achieve our project goal. Please include links to past completed projects and any relevant certification/training.We are looking for a candidate who is reliable, detail-oriented and able to work independently. We look forward to hearing from you.","['Web Scraping', 'Data Scraping', 'Data Entry', 'Microsoft Excel', 'Microsoft Excel']",United States,2,,,,,"['8.00', '25.00']",Remote Job,Intermediate
Klipfolio Dashboard using Veeam Backup API,"We're looking design a simple dashboard that will contain 2 tables using data from various Veeam Backup APIs.The data sources may use the Veaam Microsoft 365 API, the Veeam Backup & Replication API and/or the Veeam Service Provider Console API.  We have all 3 products installed and functional.The two tables required are:Veeam Backup for M365	• Company	• M365 Organization	• Licenced Users	• Object Storage UsageVeeam Backup & Replication	• Company	• VM Licenses	• Server Licenses	• Workstation Licenses	• VMs Backed Up	• Servers Backed Up	• Workstations Backed Up	• Object Storage UsageAPI reference materials can be found here:https://www.veeam.com/kb4311Successful completion of this job will likely lead to future Klipfolio design projects.","['Klipfolio', 'API', 'RESTful API', 'JSON', 'Veeam', 'JSON', 'Veeam']",Canada,3,,9.6,"['Tech', 'IT']",,"['30.00', '90.00']",Remote Job,Intermediate
"Data Analyst RStudio to help analyse, develop visuals, deliver insights and prepare a report","As a data-analyst with RStudio expertise, you will be responsible for analyzing data and providing valuable insights. You will work with a data set (excel).Responsibilities- Conduct data analysis using RStudio, leveraging its capabilities for statistical analysis.- Calculate and interpret descriptive statistics, including means, standard deviations, and other measures of central tendency and variability.-Perform t-tests to compare means between two groups and determine if the differences are statistically significant.- Conduct ANOVA to assess differences in means across multiple groups and identify significant variations.- Build regression models to examine relationships between variables, identify key predictors, and quantify their impact.- Validate and interpret statistical models, ensuring accuracy and reliability of results.- Prepare comprehensive reports and visualizations to communicate analysis findings effectively to stakeholdersDeadline: 23 june","['R', 'Data Visualization', 'Data Analysis', 'Quantitative Analysis', 'Report Writing', 'Insights Summary', 'Quantitative Analysis', 'Report Writing', 'Insights Summary']",Belgium,2,,,,,"['18.00', '45.00']",Remote Job,Intermediate
Data analyst with RStudio to help analyzing data and providing insights,"As a Data Analyst with RStudio expertise, you will be responsible for analyzing data and providing valuable insights. You will work with a data set (excel).- Conduct data analysis using RStudio, leveraging its capabilities for statistical analysis.- Calculate and interpret descriptive statistics, including means, standard deviations, and other measures of central tendency and variability.- Perform t-tests to compare means between two groups and determine if the differences are statistically significant.- Conduct ANOVA to assess differences in means across multiple groups and identify significant variations.- Build regression models to examine relationships between variables, identify key predictors, and quantify their impact.- Validate and interpret statistical models, ensuring accuracy and reliability of results.- Prepare comprehensive reports and visualizations to communicate analysis findings effectively to stakeholdersdeadline 23 of June","['R', 'Data Analysis', 'Data Visualization', 'Quantitative Analysis', 'Report Writing', 'Insights Summary', 'Quantitative Analysis', 'Report Writing', 'Insights Summary']",Belgium,2,,,,,"['18.00', '45.00']",Remote Job,Intermediate
WANTED: Chuck Norris of Google Analytics 4 & Tag Manager,"JOB DESCRIPTIONAre you a Google Analytics expert who loves to get elbow-deep in data and derive actionable insights? Do you know your way around Google Tag Manager like the back of your hand, and love setting up and simplifying configuring complex tracking setups? If you're a fan of analytics and tracking, can manage large-scale projects and aren't afraid to give a sh*#... then this project’s for you.WHO WE AREOur company is anything but ordinary. We create products and experiences that shake up industries and ignite the data-driven minds. We aren't afraid of challenges; we tackle them head on. We place a strong emphasis on company culture and focus on changing the world through meaningful innovation. Join our revolution.WHY WE’RE HEREWe're on a mission to optimize the analytics and tracking for over 2000 websites using our industry-leading website platform. We believe in the power of data, and we want to bring our platform to the next level with the help of an exceptional Google Analytics and Tag Manager expert.WHAT WE ARE LOOKING FORWe’re looking for a Google Analytics 4 and Google Tag Manager expert to implement analytics on our large suite of websites. If you are not a Google Analytics Bad A$$ - I’m sorry then… this job isn’t for you.We are only looking for the best, we don’t settle - and we are willing to pay for it.SCOPE OF WORK* Create and implement Google Analytics 4 (GA4) via Google Tag Manager (GTM) strategy across 2000 websites* Ensure the setup includes custom event tracking, custom conversion setup, and other customizations* Ensure cross-browser compatibility and performance optimizationWHAT WE WILL NEED FROM YOU* Develop a scaling strategy for the GA4 and GTM setup across all websites* Ensure proper tracking for custom events and conversionsImplement custom dimensions, metrics, audiences, funnels, and dashboards* Collaborate with our team to ensure seamless integrationREQUIREMENTS* Proven track record of success with Google Analytics and Google Tag Manager* Experience working on large-scale projects* Be brutally honest with no fluff* Most importantly - do the right thing* Excellent communication and teamwork abilitiesTO BE CONSIDEREDYou must provide work examples that will clearly demonstrate your expertise in Google Analytics and Google Tag Manager. Please clarify what your exact role was on each project.P.S.Bouncing around sucks - and it doesn’t have to end here (on this project). We are always looking for amazing people and never have a shortage of challenging problems that we are trying to solve. If you're looking for long-term work - we might be a match made in heaven.P.P.S.To make sure that you have read our requirements, please tell us your favorite color and share some examples of your work that will demonstrate your ability to accomplish this project. Otherwise, we will reject all generic applications.Cheers!","['Google Tag Manager', 'Google Analytics', 'Google Analytics API', 'Google Analytics API']",United States,515,38.31,231,"['Tech', 'IT']",,,Remote Job,Expert
Create image and data repository,"Need a freelancer to scrape 10,000 women's fashion listings, with HQ images and as much descriptor detail as possible (product name, description, pricing, sizes, colors, etc). Can be delivered in an Excel spreadsheet. Images will need to be downloaded to a matching S3 directory for product association and analysis.Quote price per 1000 products and/or price for 10k.","['Web Scraping', 'JavaScript', 'HTML', 'CSS', 'Python', 'HTML', 'CSS', 'Python']",United States,15,47.59,13,,,,Remote Job,Intermediate
"Fine-tune(or other method) 100 pdf books on the topic of ""mushrooms"" to an AI model","as stated in the headline, I am looking for somebody to ""load"" around 100 books, on the topic of mushrooms to an AI model. Idea idea is to have a mushroom expert AI, then I will give it data that I have gathered from my country, about forest types (the types of trees that live in certain coordinates, the type of soil) and a few other data points like: amount of rains, temperatures in the past few months. Hopefully this should be enough to give a somewhat accurate answer","['Machine Learning', 'Data Science']",Bulgaria,11,,150,"['Tech', 'IT']",50.00,,Remote Job,Entry level
Geospatial Database & Programming Contractor: Data Processing of AIS Shipping Data,"Clear Seas Centre for Responsible Marine Shipping (visit clearseas.org for more information) is looking for a technical services contractor to support data processing and database systems establishment for a large automatic identification system (AIS) geospatial dataset to support the characterization and analysis of shipping activity and risk.For more information please see the attached Request for Services.Clear Seas is seeking to hire a GIS and/or data consultant who can provide support to the Clear Seas Research team in establishing workflows to manage and process large datasets.Key tasks include:• Establish workflows to process large quantities of point data (in CSV form) into polylines.• Debug and troubleshoot existing Python scripts.• Automate data cleaning and geoprocessing tasks using Python, with ArcGIS Pro integration.• Conduct web scraping to fill dataset gaps.• Aid writing and integrating scripts within R and ArcGIS Pro to support automated and general data visualization.• Provide guidance and establishing best practices for managing large datasets and maintaining data integrity.• Document development methods and “how to” instructions to deploy and troubleshoot new processes and ensure replicability of systems.• Participate in meetings with Clear Seas team.• Contract reporting include to provide regular timesheets and progress reports at meaningful intervals.• Other related tasks as required.Completion of the contract activities are expected to be guided by the following considerations:• The contractor could be an individual operating as a sole proprietor or staff contracted out from a larger consultancy.• All work will be completed in a timely manner that ensures Clear Seas are able to maintain the systems and edit or run any code that is written.• Process(es) will be taught to members of the Clear Seas team once tasks are completed to ensure Clear Seas can maintain and run the systems independently.• The expected workload is estimated to be two to three hours of meetings with the Clear Seas research team per week, with one to five hours of additional data processing and workflow development tasks weekly.• The workload may vary each week, depending on the type of support required from the research team.• The contractor is expected to be available to meet with Clear Seas core working hours (9:00am to 5:00pm Pacific Standard Time). Work done independent of the Clear Seas team may be done outside the core hours at the contractor’s discretion.• The contract will cover an initial 3 months of work, with the possibility to extend to include additional scope of work.","['Data Processing', 'Microsoft Excel', 'R', 'SQL', 'Python', 'Database', 'GIS', 'Web Scraping', 'Spatial Analysis', 'Spatial Analysis']",Canada,8,35.00,815,,,"['30.00', '100.00']",Remote Job,Intermediate
ListReports / Highway.ai report generated,Looking for someone with a listreports account with full access (ListReports Elite + Agent Intel + Agent Intel Connect) to generate a full report on a particular location in NYC,"['Customer Service Analytics', 'Growth Analytics', 'Marketing Analytics']",United States,132,11.81,73,,50.00,,Remote Job,Expert
AI Prompt Engineer,"Hello!I'm wanting to find an A.I. prompt engineer that I can use and rely on, on a regular basis. Most of the prompts that we need will be for ChatGPT and will revolve around SEO & Content Marketing along with creating SOPs and helping with operations. Workload: 5 - 10 hours per week - it's more so going to be on a project by project basis.Please describe your experience with the specified tasks when applying.Thanks!","['Natural Language Processing', 'Machine Learning Model', 'deep understanding of AI', 'AI-generated content development', 'AI-generated content development']",United States,24,8.17,5.8,"['Sales', 'Marketing']",,"['18.00', '40.00']",Remote Job,Intermediate
Excel Data Population and Visualization,"Hello, I am working on an Excel spreadsheet to populate data for ease of use and entry. Please see the attached spreadsheet and let me know if you can help.Users will enter on the master sheet and it will update the dashboard. I am open to reformatting however is needed and best looking if you have ideas. The spreadsheet should also support addition of data that will need to be populated.Thank you.","['SQL', 'Microsoft Excel', 'Data Entry']",United States,8,,220,,25.00,,Remote Job,Entry level
Sports Tipping Competition Dataset (Internal Log),"The request is for a dataset that simulates a real sports tipping competition held by a company, involving real participants. The dataset will be used to examine the aggregate decision-making capability of participants in such competitions and compare it to individual forecasting.Dataset Details: The dataset should include the following information:Person ID: A unique identifier for each participant (name or anonymized ID).Event Prediction: The sporting events for which participants made predictions. This could include specific match-ups or event identifiers (e.g., ""Queensland vs NSW State of Origin I"").Prediction: The outcome predicted by each participant for the corresponding event (e.g., win, loss, or draw).Additionally, if available or included in the dataset: 4. True Results: The actual outcomes of the sporting events, indicating which team or player won.Sport-specific details:The specific sport for which the dataset is generated is not specified. The sport can be any popular public sport.If the true results are not included in the dataset, the requester can obtain them from publicly available sources.Purpose: The dataset will be utilized to test the hypothesis that the collective decision-making of a group outperforms individual decision-making in sports forecasting. The aim is to analyze whether the teams or outcomes predicted by the majority of participants align with the actual results, and to determine if no individual participant demonstrates the same level of accuracy as the group.Note: The focus of this request is not on the structure or format of the dataset but rather on evaluating the performance of aggregate decision-making in sports tipping competitions. The dataset can be anonymized if necessary to ensure privacy.","['Data Mining', 'Web Scraping', 'Microsoft Excel', 'Data Scraping', 'Data Entry', 'Market Research', 'Lead Generation', 'Microsoft Excel', 'Data Scraping', 'Data Entry', 'Market Research', 'Lead Generation']",United States,32,70.00,114,,,"['9.00', '50.00']",Remote Job,Intermediate
Power BI 360 support,"ongoing, long term support on diverse jobs: Power BI support, developing educational content, social posts, new examples, building datasets, building reports, dashboards.","['Dashboard', 'Report', 'Query Development', 'Microsoft Power BI', 'Data Visualization', 'Data Analysis', 'Microsoft Power BI Data Visualization', 'Data Modeling', 'Business Intelligence', 'Data Analysis', 'Microsoft Power BI Data Visualization', 'Data Modeling', 'Business Intelligence']",Germany,4,21.53,1.9,,,"['5.00', '35.00']",Remote Job,Intermediate
AI Expert - AI Development (Remote),"AI Expert - AI Development (Remote)A highly reputable mobile clinic specializing in primary and concierge care services for the geriatric population, is seeking an - AI Expert to join our team remotely. We are dedicated to delivering personalized and optimized healthcare solutions through the power of artificial intelligence. This is an exceptional opportunity for an experienced AI professional to make a significant impact on our organization's growth and innovation.Responsibilities:- Collaborate closely with cross-functional teams to understand the organization's data structure, requirements, and business model.- Develop and implement advanced AI models and algorithms to optimize various aspects of our business operations.- Utilize machine learning and natural language processing techniques to analyze and structure data inputs from multiple sources.- Design and build secure AI systems, ensuring confidentiality of internal conversations and protecting sensitive information.- Provide technical expertise and guidance on AI-related projects, leveraging existing language models and frameworks.Requirements:- Extensive experience as an AI Expert, with a focus on developing AI models and algorithms.- Strong proficiency in artificial intelligence, machine learning, and natural language processing.- Proficient programming skills in languages such as Python, Java, or C++.- Solid understanding of AI frameworks, libraries, and data manipulation techniques.- Knowledge of data privacy and security protocols to ensure confidentiality and compliance.- Excellent communication and collaboration skills, with the ability to work independently.Preferred Qualifications:- Previous experience in the healthcare industry or related domains.- Familiarity with electronic medical record (EMR) systems and healthcare data standards.- Demonstrated track record of successfully implementing AI solutions in a professional setting.To apply for this remote position, please submit your updated resume and a cover letter highlighting your relevant experience and contributions to AI projects. We highly value diversity and encourage applicants from all backgrounds to apply.We offer competitive compensation and a supportive work environment where innovation is encouraged. Join our team and play a key role in optimizing all aspects of our business through cutting-edge artificial intelligence.We appreciate all applicants' interest; however, only shortlisted candidates will be contacted for further evaluation.","['Artificial Intelligence', 'Neural Network', 'Artificial Neural Network', 'Machine Learning', 'Computer Vision', 'Adobe Illustrator', 'Neural Network', 'Artificial Neural Network', 'Machine Learning', 'Computer Vision', 'Adobe Illustrator']",United States,175,12.98,60,,,,Remote Job,Expert
Quantitative Analyst For Trading Algorithms,"We build trading algorithms for forex, commodities and crypto assets. I am looking for an analyst to backtest, potentially forward test on Metatrader 4 and make suggestions to change the algorithm to make it more profitable. This position needs to have prior experience with this type of work. If the first couple of projects go smoothly, the workload will go up from there. We are looking to hire full time.","['Algorithm Development', 'Quantitative Analysis', 'Data Analysis', 'Trading Automation', 'Forex Trading', 'Statistics', 'Data Science', 'Financial Analysis', 'Quantitative Analysis', 'Data Analysis', 'Trading Automation', 'Forex Trading', 'Statistics', 'Data Science', 'Financial Analysis']",United States,14,12.84,85,,,"['30.00', '200.00']",Remote Job,Expert
Immediate need for Board Certified Behavioral Analyst,"The BCBA or Behavior Therapist is responsible for evaluation, creation and implementation of a strength-based, staff supervision, positive approach behavior plan. They are also responsible for data collection and consultation and training with families and staff. The BCBA or Behavior Therapist collaborates with multidisciplinary teams to develop person-centered behavior plans to support the individual behavior and skill development needs of each person served.We will require that you apply to become an Illinois Department of Human Services  become an approved provider and a provider with other insurances.Remote Position.Essential Duties and ResponsibilitiesConduct functional behavior assessments (FBA) and develop evidenced based individual behavioral support plans (BSP)Train staff on data collection, providing ongoing supports as neededMonitor, collect and analyze behavior tracking, adjusting interventions as needed based on dataMaintain effective working relationships with program staff to ensure consistent approaches to behavior plan implementation and monitoring.Demonstrate flexibility of time in meeting each person’s support needs, as well as that of program staffMaintain weekly contact with people supported and staff in order to be able to quickly identify the need for behavioral support adjustments, staff training, and effective use of evidence based training proceduresCollaborate with families and collateral service providers as needed to ensure plans are developed in a manner that fully addresses a person’s needsAttend scheduled meetings to stay informed and provide information on each person supported.QualificationsActive BCBA certification requiredTwo or more years experience working with people who have behavioral health needs preferred, but not requiredExperience creating individualized behavior intervention plans with an emphasis on skill acquisitionExperience observing and analyzing inappropriate behavior and creating positive individualized intervention plans to support the reduction those types of behaviorsExperience with wide range of ages is preferred, but not requiredExperience with people served in community day or community living settings is preferred, but not requiredJob Knowledge, Skills, and Abilities:Skilled in strength-based behavior analysisAbility to effectively observe, analyze, and develop person-centered behavior plansAbility to remain calm and effective in challenging situationsGood written and interpersonal communication skillsDemonstrate respect for diversity of people supported, as well as for families and coworkers, including race, gender, and sexual orientation","['Supervision', 'Applied Behavior Analysis']",United States,2,,,,,"['30.00', '40.00']",Remote Job,Intermediate
Full Stack Developer with Machine Learning Experience,"Interested in working on a creative, innovative project for one of the leading experts in agility? Platinum Edge is looking for a full stack developer with machine learning experience to creating a custom web app that uses the GPT4 API that is  able to integrate a repository for new information to be ingested into the model.Requirements: - Machine Learning Experience - Experience with GPT-4 - Full Stack Developer - English Fluency - Creative, Innovative Thinker - Enthusiasm for New Ideas & Opportunities","['GPT-4', 'Full Stack Developer', 'Creative Strategy']",Puerto Rico,3,,,"['HR', 'Business Services']",,,Remote Job,Expert
Analyst programmer,"Hello, we want to create an online window store so that the client can choose the size and shape in 3D. I left an example of the site below","['3 D', 'Python', 'Database', 'Java', 'Business Logic Layer', 'Data Analysis', 'SQL', 'Ecommerce', 'Business Logic Layer', 'Data Analysis', 'SQL', 'Ecommerce']",Turkey,1,,,,,,Remote Job,Intermediate
Asia-based English-fluent AI specialist content aggregator,"We are looking for an Asia-based English-fluent AI specialist who can build a code and algorithm to aggregate Spanish language sports content for a US-based publication.    As our ideal candidate, you should possess in-depth knowledge of AI and be familiar with content creation, search engine optimization, AI model integration and article writing. Your primary responsibility will be to create and maintenance a code that aggregates and recreates 30 pieces of relevant content every day in real time using as a model existing Spanish language sports websites that cater to US-, Mexico- and Spain-based audiences.  To be considered for this position, you must speak fluent English and have a proven track record of using AI and machine learning as well as a ground floor understanding of search engine optimization. Please submit a proposal describing how you can help with this project. We look forward to hearing from you and learning more about how you can contribute to our team's success.","['AI Model Integration', 'AI Content Creation', 'Article Writing', 'Search Engine Optimization', 'Search Engine Optimization']",United States,5,50.00,300,"['Media', 'Entertainment']",2000.00,,Remote Job,Intermediate
Web scraping,"Hi, I need helping some data in multiple tables from some websites. Thank you,","['Selenium', 'Data Scraping', 'Python']",France,7,,50,,,"['15.00', '90.00']",Remote Job,Expert
Python - biopython project.,"Project Proposal - Understanding the evolutionary dynamics of SARS-CoV-2 strainsSARS-CoV-2 is the virus responsible for the COVID-19 pandemic that started at the end of 2019 and isstill affecting most of the world. Over three years after the start of the pandemic, several vaccines havebeen developed and rolled out. In this scenario, the major risk of new outbreaks arises from possiblemutations of the virus, which may potentially result in new strains against which existing vaccines are noteffective. Indeed, since the start of the pandemic, several strains have been identified and becomedominant at different points in time.ObjectiveThe objective of this project is to analyze the evolution of the most relevant strains of the SARS-CoV-2virus to date, and different aspects of the mutations associated with them.MethodologyThis project involves a combination of genomic sequence analysis (for example, with BioPython) withother types of statistical and/or network analyses and visualizations.Tasks1. Obtain sequences of the spike protein (or protein S) of SARS-CoV-2 from a selected country. Thesuggested SARS-CoV-2 database is EpiCoV from GISAID. To access it, you will need toregister in GISAID with your university email address (registration is free), access the EpiCoVdatabase, go to Downloads, and finally download the file spikeprotxxxx (where xxxx are fournumbers that identify the most current version of the database). This file contains the amino acidsequence for the spike protein of close to 10 million SARS-CoV-2 isolates. Although you areexpected to use this comprehensive database, you can also consider others. The NCBISARS-CoV-2 Resources web page is one possibility. In particular, you can use the list ofSARS-CoV-2 nucleotide sequence accession IDs, and then query these IDs in GenBank as we didin the lab (Session 2). You can also query, filter and download sequences directly from theSARS-CoV-2 Data Hub.2. You will find a FASTA file with the amino acid sequence of the spike protein in different variants of thevirus. These were obtained from the variants listed outbreak.info, and using the CoVizu tool in EpiCoV to obtain the IDs of a representative sample of each variant.3. Use pairwise sequence alignment to align each of the sequences in the selected country to eachvariant of the spike protein. After determining the variant of each sample in the dataset, build avisualization showing the percentage of each variant as a function of time. The visualization may look something like this:4. Based on the sequence alignments in 3, and perhaps other alignments (other proteins of the virus, other countries, etc.), study some interesting aspects of the relationship between mutations and strains, their evolution, the differences between viral proteins, their geographical distribution, or whatever other aspect of your choice. For inspiration, you can take a look at the Nextstrain narrative about the evolution of the virus in Arizona.","['Database Architecture', 'Data Preprocessing', 'Python', 'Anaconda', 'biopython', 'COVID-19', 'Data Analysis', 'programming python', 'COVID-19', 'Data Analysis', 'programming python']",Spain,3,,,,50.00,,Remote Job,Expert
Excel expert needed to create a few simple mathematical functions to apply to financial market data,"I am developing a financial market charting program with a few simple tools.  First, we will use Excel (unless there is a better option) to create a graph of financial market data provided by CSI Data, a stock and commodity market data provider.  I will provide this to you directly in the Excel format.  Last, I will need to add a few functions that will manipulate the data in ways that we can discuss over the phone.","['Microsoft Excel', 'Visual Basic for Applications', 'Data Entry', 'Financial Analysis', 'Financial Modeling', 'Data Analysis', 'Statistics', 'Data Entry', 'Financial Analysis', 'Financial Modeling', 'Data Analysis', 'Statistics']",United States,2,,0,,,"['50.00', '250.00']",Remote Job,Intermediate
Write a 'predict' function for Meta Robyn,"Meta Robyn is an open source Marketing Mix Modeling library in R, but it doesn't have a predict function.I need to use the result of a Robyn model to predict future values (withheld data to check accuracy).They have it internally obviously or they couldn't make the 'prediction vs actual' chart:https://github.com/facebookexperimental/Robyn/blob/7513935c6489c3b0092b919842e8da0d5ea2a402/R/R/plots.R#L1259However it looks like they haven't built it as a feature, I'm not sure why because it's standard in any MMM?https://github.com/facebookexperimental/Robyn/issues/351https://github.com/facebookexperimental/Robyn/issues/85https://github.com/facebookexperimental/Robyn/issues/79I just don't know enough about R to reverse engineer how to do this. Was hoping to figure it out in the next two weeks for a project I'm working on comparing the accuracy of different MMM approaches.I'll also give you credit in the blog post I'm writing which is for a popular marketing attribution blog going out to around 7,000 readers in the data science space.Here's the results of a recent robyn run:https://drive.google.com/drive/folders/1WY_yPPgSYvpdbyuPwLwUoN6CaaIwkZJV?usp=sharingHere's a saved model with coefs: https://drive.google.com/file/d/1pLt8oz5r5Uwc1I7YSoLZB8yNVW06N1GJ/view?usp=sharingYou could probably reconstruct it via the coefficients and hyperparams. I just wasn't sure how to do media transformation and seasonality...Or maybe you know where to look in the code base to piggyback of whatever function they already use for the predicted vs actual chart?Let me know your approach, experience, and availability. Having experience running Robyn before would be a plus.","['Statistics', 'R', 'Data Science']",United States,2,25.00,1.2,"['Sales', 'Marketing']",,"['40.00', '75.00']",Remote Job,Expert
Data Engineer - Operations Specialist,"Job Title: Data Engineer - Operations SpecialistCompany: DataFlikLocation: Fully RemoteType: Full-TimeAbout DataFlik:DataFlik is a fast-growing, data-driven company offering unique data solutions to our clients. We are expanding and looking for a highly skilled Data Engineer who specializes in Operations (Data Ops) to join our dynamic team.Job Description:We are seeking a detail-oriented and innovative Data Engineer - Operations Specialist to help us manage and optimize our data systems. The successful candidate will manage large-scale data processes, develop data architectures, create and maintain data ingestion and processing pipelines, and ensure data is readily available and of high quality for our Machine Learning Engineers.Key Responsibilities:Establish and maintain data pipelines, process data, and manage data storage.Transition our data storage to the Medallion Architecture.Efficiently and cost-effectively manage data storage, including the organization of expanding data (currently at 9.7 TB/year)Collaborate with ML and Software Engineering teams to optimize data systems.Implement and monitor data systems to ensure data availability, quality, and usability.Requirements:Degree in Computer Science, Engineering, or related fieldExperience with large-scale data processing and data storage systemsExperience with AWS S3, AuroraDB, and other cloud-based data solutionsFamiliarity with the Medallion Architecture and data ingestion pipelinesProven ability to collaborate with various teams and manage multiple tasks concurrentlyExcellent problem-solving skills and attention to detailPreferred Qualifications:Experience in a similar role focused on Data Operations.Proven track record of implementing efficient and cost-effective data organization systemsHow to Apply:Interested applicants are invited to submit a three-minute maximum Loom video answering the following questions:Why are you interested in this position?What do you know about our company?What is your ideal work environment?What are your strengths?Where do you see yourself in five years?Please also send any relevant project or work samples to our CEO Tyrus Garrett at ty@dataflik.com. Include ""Data Engineer - Operations Specialist Application"" in your email subject line.The monthly salary range is $4,000-$4,500","['AWS Glue', 'Data Engineering', 'SQL', 'ETL Pipeline', 'Python', 'Amazon Aurora', 'Amazon Aurora']",United States,61,32.47,211,"['Tech', 'IT']",,"['23.00', '25.00']",Remote Job,Expert
AI expert to consult us regarding building an HR AI assistant,"We are looking for an experienced AI expert to consult with us on building an HR AI assistant. The project will last between 1 to 3 months, and we are looking for someone with a strong background in Artificial Intelligence. As an AI consultant, you will be responsible for providing expert guidance on building an HR AI assistant. This will include analyzing  HR processes, identifying areas where AI can be beneficial, and helping us to design and build an AI assistant that can automate HR tasks. To be successful in this project, you should have a deep understanding of AI technologies.  You should also be able to communicate complex technical concepts to non-technical stakeholders and work collaboratively with our team.Please submit a proposal outlining your experience in AI.",['Artificial Intelligence'],United States,18,74.70,104,"['Tech', 'IT']",,"['100.00', '350.00']",Remote Job,Expert
Excel expert,"1. Have macro that submits a form to another worksheet in the same workbook, used as local database, using offset code. The macro works fine, but user message asks for a range to be entered each time. Need to work the macro code to automate that. 2. Trying to use that local log to perform calculations that feed other calculations and dashboard dynamically. Everything works fine, but cannot get two columns multiplied, and columns averaged. Data values come from dynamic formulas, so populate NA's and also won't multiply by 0s. I've tried every formula to ignore these values. It's the main information I need to make all the other calculations work. 3. locking and allowing user data entry in cells that have formula in them, without them being able to see or change the formula. It's on a ""user form"" that is basically a combo of xlookup return arrays. And another ""user form"" that is just one horizontal data row with a combo of drop down lists, date format, etc. 4. running calculations with values originating on worksheets that are hidden5. locking the workbook in full screen mode so that users do not see any menu or ribbons, can only open pivot tables on ""dashboard"". I imagine this would be very quick work for someone who knows the answers. I don't think anything is too complicated, I'm just not able to find the answers to those questions and running out of time with deadline. I need help immediately.","['Microsoft Excel', 'Visual Basic for Applications', 'Data Analysis', 'Data Analysis']",United States,1,,26,,,"['10.00', '30.00']",Remote Job,Expert
Process Automation & Data Visualization,"We are looking for someone extremely talented with the following: - Data Visualization (KPI Visualization, Pipeline Visualization, Team Visualization) - Process Automation (Automating & Systemizing Our Processes) This is sort of a fractional CTO role, where I'm going to give you a vision of what our back-end workflows should look like and you are going to bring it to life. Long-term employment opportunity as well if all goes well!","['Data Visualization', 'Business Intelligence']",United States,4,,,,,"['20.00', '50.00']",Remote Job,Intermediate
Data analysis/procession/mining project,"I have data sets from 4 different places. All four data sets list employee benefits for a ton of companies, but all in different formats. For example:One dataset says companies have a 4-day work week, unlimited PTO, and full health benefits.Another data set says ""4-day work week, yes"" and unlimited vacation.My ultimate goal is to build an Excel file (or database of some sort) with a list of thousands of companies and all of the employee benefits each company offers with structured data. The job requires taking data structured in 4 different ways and making it all make sense in one database.I'd like to show you the project and have you give me a quote on completing it.","['Microsoft Excel', 'Data Analysis', 'Data Mining', 'Unstructured Data', 'Data Mining', 'Unstructured Data']",United States,16,10.00,12,,,"['40.00', '150.00']",Remote Job,Expert
Deepface Labs Expert,"We are on the hunt for a highly skilled DeepFaceLabs specialist to join us in a freelance capacity. The ideal candidate should have a solid background in computer vision and deep learning, with a particular focus on facial recognition and deepfake technology using the DeepFaceLabs library.Responsibilities:- Work in close coordination with our team to design and develop DeepFaceLabs-based models for facial recognition and deepfake generation.- Improve and fine-tune the performance of existing DeepFaceLabs models.- Promptly identify and rectify any issues that arise.- Collaborate effectively with team members to ensure timely project delivery.- Remain current with the latest developments and advancements in DeepFaceLabs and Wave2Lip.Requirements:- Demonstrated proficiency in the DeepFaceLabs library, including model development and optimization.- Strong Python programming skills.- Familiarity with related libraries such as PyTorch, TensorFlow, and OpenCV.- Excellent problem-solving and troubleshooting abilities.- Strong communication and teamwork skills.If you are a driven individual with a love for computer vision and deep learning, and you meet the above qualifications, we would be excited to hear from you. To show that you have read the job post, please write ""Read Information"" at the start of your application. Failure to do so will result in your application being overlooked. We eagerly await your response!","['CycleGAN', 'JavaScript', 'wave2lip', 'deepface', 'Python', 'Python']",United States,162,15.55,82,,,,Remote Job,Expert
"ChatGPT(GPT-3.5, GPT-4) Developer","Job Description:We are looking for an experienced and highly skilled bot development to join our team. As an AI Doctor, you will be responsible for developing and implementing advanced AI algorithms and models to help diagnose and treat patients.Key Responsibilities:- Develop and implement advanced AI algorithms and models for patient diagnosis and treatment- Work collaboratively with cross-functional teams to design, develop, and implement new AI-based healthcare solutions- Evaluate and analyze large data sets to develop insights and identify areas for improvement- Work closely with medical professionals to ensure that all AI-based healthcare solutions are accurate and meet patients' needs- Keep up to date with latest AI trends and technologies to continuously improve our AI-based healthcare solutionsSkills and Qualifications:- Degree in Computer Science, Engineering, or related field- Strong experience with machine learning, natural language processing, and AI technologies- Excellent analytical and problem-solving skills- Strong communication and collaboration skills- Experience working in healthcare or related field is preferred[urgently]Please apply for me with times.","['Web Application', 'Chatbot', 'Chatbot Development', 'Prompt Engineering', 'Deep Learning', 'Prompt Engineering', 'Deep Learning']",Canada,1,,,,,"['25.00', '30.00']",Remote Job,Expert
Back End Developer (Language Models Specialist),"Our team is passionate about building products that not only solve complex problems, but also create an impact on businesses around the globe.We are currently seeking a talented and dedicated Freelance Back End Developer with expertise in language models. This individual will play a crucial role in scaling our enterprise products and enhancing our ability to deliver profound insights. The role will begin as a freelance position with the strong possibility to transition to a full-time role, which includes an equity stake.ResponsibilitiesDevelop, optimize, and maintain scalable server-side software.Work closely with our data science and product teams to implement language models into our product suite.Collaborate with front-end developers to integrate user-facing elements with server-side logic.Design and implement efficient, secure, and scalable APIs.Optimize application for speed, reliability, and scalability.Implement data protection and security measures.Collaborate on all phases of the development lifecycle, focusing on coding and debugging.Stay informed about emerging technologies and propose changes and updates as necessary.Required Skills & QualificationsProven experience as a Back End Developer, Software Developer, or similar role.Strong knowledge of and experience with AI and language models (like GPT-4).Strong programming skills in [preferred languages - such as Python, Java, etc.]Proficient understanding of code versioning tools, such as Git.Strong knowledge of data structures, system design, and algorithms.Experience with scalable cloud computing platforms like AWS, Google Cloud, or Azure.Experience with database technologies, both SQL and NoSQL.Strong problem-solving abilities, and a commitment to delivering quality code.Strong understanding of the entire web development process (design, development, and deployment).Excellent communication and teamwork skills, with a keen eye for detail.Preferred QualificationsA degree in Computer Science, Software Engineering, or a related field.Experience with enterprise software development.Experience with natural language processing (NLP) tools and libraries.Experience with big data tools and technologies.What We OfferCompetitive compensation.The possibility of transitioning into a full-time role, including an equity stake.Opportunities for professional development and career growth.","['Database Maintenance', 'Artificial Intelligence', 'Artificial Intelligence Consulting', 'Python', 'Ecommerce', 'JavaScript', 'Machine Learning', 'Web Development', 'API', 'Java', 'Artificial Intelligence Consulting', 'Python', 'Ecommerce', 'JavaScript', 'Machine Learning', 'Web Development', 'API', 'Java']",Canada,6,30.00,1.1,"['Science', 'Medicine']",,"['50.00', '100.00']",Remote Job,Expert
GIS Technician Needed for Digitizing Boundaries,"Dear Upwork Community,We are looking for an experienced GIS specialist to join our team on a contract basis. Our organization deals with extensive data pertaining to school attendance boundaries. Some of our data requires professional cleaning and digitizing to maintain its accuracy and usability.Key Responsibilities:-Cleaning and digitizing a large set of polygon data representing school attendance boundaries.-Ensuring all features of the data set, such as gaps, overlaps, and invalid geometries, are properly identified and rectified.-Entering and managing data about the features in the dataset.-Performing spatial data analysis and processing using GIS software and related tools.-Collaborating with our team to resolve any data inconsistencies and ensure high data quality.-Required Skills and Experience:-Proven experience in GIS data management, particularly in data cleaning, and digitizing.-Expertise in GIS software like ArcGIS, QGIS, and similar tools.Strong understanding of spatial data concepts and principles.Attention to detail, with a keen eye for identifying data inconsistencies and errors.-Strong problem-solving skills and the ability to think creatively to find solutions to complex issues.-Excellent communication skills, as you will be collaborating with team members across different areas of our organization.The ideal candidate will have a passion for data and a meticulous approach to their work. They should be a problem solver, who isn't afraid to take on a challenge and see it through to completion.To apply, please submit a cover letter detailing your experience with GIS, particularly in relation to data cleaning and digitizing. Please also provide details about any relevant projects you have worked on.We look forward to hearing from you and potentially working together to maintain the quality and accuracy of our essential dataset.Best regards,Nathaniel Liveby","['Data Processing', 'GIS', 'Data Entry', 'QGIS']",United States,194,32.65,162,['Real Estate'],600.00,,Remote Job,Intermediate
GPT prompt engineer,We're focussed on creating insights and reasoning from meeting transcripts from Zoom.  We need an expert in prompt engineering for GPT and ideally Anthropic to support us.  Please share examples of the work you have done.,"['GPT-3', 'GPT-4', 'Prompt Engineering']",United Kingdom,29,36.77,3,"['Tech', 'IT']",,"['13.00', '40.00']",Remote Job,Intermediate
Talend Developer,Develop Talend jobs for data transformations. Several hundred dependent data transformation jobs need to be changed with changes required for new architecture.  There will be new script development once this is completed.,"['Talend Open Studio', 'Data Transformation', 'ETL Pipeline', 'SQL', 'MySQL']",India,24,26.00,109,"['Tech', 'IT']",,,Remote Job,Intermediate
C++ Developer Needed for Quick Small Database Scraping Project Using Source Data API,"We're looking for a C++ programmer with experience in Web development technologies.This is for a quick, simple data extraction project using the C++ API or SDK of this website:  https://support.crea.ca/DDF#/categoriesHere is the programming guide of this site:  https://support.crea.ca/DDF#/categories/programmingEssentially, we want to have a cloned copy of the real estate listings database that they provide through their C++ API and SDK.And, we want this cloned copy to reside in our Web server. Plus, we want a cron job so as to:1)  Constantly check and extract updated data from the source site to populate and update the cloned database copy in our Web server; and2)  In a designated directory of our Web server, create and overwrite a CSV file containing the most up-to-date data after every 24 hours ...Note:  This CSV file should be downloadable through a CLI command where we supply secure credentials (username and password) ...Also, please include this line in the beginning of your cover letter so we know you've carefully read our description for this project:  ""C++ Programmer with Web Dev Experience Here"" ...Cheers!","['C++', 'Data Scraping', 'API', 'JavaScript', 'MySQL', 'MySQL']",Philippines,2,,,"['Sales', 'Marketing']",,"['5.00', '8.00']",Remote Job,Intermediate
Looking for an Artificial Intelligence Tutor,"Hello,I hope this message finds you well. I am currently studying artificial intelligence and seeking the assistance of a knowledgeable tutor to help me gain a deeper understanding of some key concepts. I am particularly interested in Neural Networks, Uninformed/Informed Search methods, Adversarial search, Logical Agents, First-Order Logic, Prolog, Genetic algorithms.I have attached my course notes to provide you with a better understanding of the topics covered in my curriculum. These notes serve as a reference for the concepts I would like to explore further with your guidance.If you possess expertise in any or all of these subjects and are available to assist me, I would be thrilled to collaborate with you. Please let me know about your experience in the field of Artificial Intelligence, your teaching approach, and your availability.Thank you for considering my request.Best regards.","['Artificial Intelligence', 'Artificial Neural Network', 'Deep Learning', 'Artificial Neural Network', 'Deep Learning']",Turkey,3,,30,,30.00,,Remote Job,Expert
Data analyst,"Qualifications3+ years of experience as a tableau developer, business analyst, data analyst, or similar roleExtensive experience in developing, maintaining, and managing Tableau-driven dashboardsBroad practical experience across the data and reporting spectrumAbility to manage multiple priorities and effectively meet deadlinesUnderstanding of SQL and relational databasesProficiency in the use of query and reporting analysis toolsCompetency in ExcelSelf-starter who can work both independently and with a team to come up with creative solutions to challenging problemsResponsibilitiesThe Data Analyst/Tableau Developer will perform analysis of multiple data sets to produce business insight and deliver innovative solutions to complex problemsThis position will be responsible for using industry best practices and techniques to cleanse and interpret first- and third-party data sets into meaningful informationThe culmination of analysis will be exposed via reports/visualizations in Tableau for both internal and external customersLeverage multiple data sources and tools to discover insights, answer questions, and deliver reports for business needsDevelop, maintain, and manage advanced reporting, analytics, dashboards, and other BI solutionsTell stories with data in a clear, concise, and informative mannerWrite and maintain complex queries potentially leveraging multiple joins, subqueries, CTEs, and window functionsPerform and document data analysis, data validation, and data mapping/designConduct unit tests and develop database queries to analyze and troubleshoot any issues that could impact reporting accuracyReview and improve existing systems and collaborate with teams to integrate new systemsOther projects and tasks as assigned","['Data Analysis', 'SQL', 'Tableau', 'Data Modeling', 'Analytics', 'Data Visualization', 'Data Modeling', 'Analytics', 'Data Visualization']",United States,1,,,,,"['15.00', '120.00']",Remote Job,Expert
Build a Radiomic library,"I need a Radiomic library to be built for PET imaging. The library should be able to extract features such as shape-based, intensity-based, and texture-based features. It should be compatible with Python programming language. The ideal candidate should have experience/good knowledge in medical imaging and knowledge of Radiomics. Proficiency in Python programming language is a must.The main goal is to create a radiomic library using pyradiomicsi have a csv file with DICOM metadata which should be used to train the modelthe library should include all the steps like segmentation of the PET images , feature extraction and feature selection","['Python', 'Machine Learning', 'Data Science']",United Kingdom,305,5.00,2.9,,,"['10.00', '15.00']",Remote Job,Expert
Extract Data from Website and put in Excel (Make script),"Hello I need someone to extract a list of airplane records from the Canadian Aircraft Civil Registry. The address is:https://wwwapps.tc.gc.ca/saf-sec-sur/2/ccarcs-riacc/RchSimp.aspxThen in model name I am looking for PA18 that is what needs to be searched.There are 386 records found. I need an excel spreadsheet with one row for each record, but I also need the owner name, address, and all details that we find only once we CLICK on each aircraft mark. Only by clicking each mark do we get the rest of the information that I also need in the excel.I believe someone can build a script to get this information easily and automatically. We may use it again to search for other models.","['Microsoft Excel', 'Data Scraping']",Canada,44,17.51,6.7,,100.00,,Remote Job,Intermediate
Part-time Research and Quantitative Analysis Support with some project management responsibilities.,"Hi. Thank you for your interest in our position. We are a small company that provides quantitative research, coaching, and consulting on research projects with an equity focus. This includes clients across the globe in sectors such as education, health, government, and social sector.We need a part-time research assistant to join our team. The main responsibilities will include quantitative research with an equity focus, attending coaching sessions, and managing client projects.The team member will need to be available consistently for remote meetings and sessions at least some of the following hours: Mondays 1pm - 5pm, Thursdays noon - 6pm, Fridays 11am - 4pm Eastern US time.The ideal candidate will have experience with quantitative analysis, and familiarity with concepts around equity, anti-racism, and inclusion.","['R', 'Data Analysis', 'Project Management']",Canada,570,48.92,352,,,"['30.00', '65.00']",Remote Job,Expert
Virtual Assistant - Data Scraping - Lead Checking,"Looking for a virtual assistant to help me find new leads for my business.I work with ecommerce businesses with over $1,000,000 per year revenueThis will be an ongoing job, so I'm looking for a long term relationship. I have an existing lead document, you will need to double check for duplications before adding your data. In your proposal, please let me know if you can use Slack","['Data Scraping', 'Data Analysis', 'Web Scraping', 'Data Mining', 'Data Mining']",United Kingdom,44,17.63,15,"['Sales', 'Marketing']",,"['5.00', '15.00']",Remote Job,Intermediate
Tableau Dashboard Development,Looking for an expert Tableau dashboard developer with advanced knowledge of calculations and a clean and tidy dashboard design.Needs to be familiarized with the latest Tableau functionalities. Please send relevant examples of previous work or your portfolio.Thanks!,"['Tableau', 'Data Visualization', 'Data Analysis', 'Business Intelligence', 'Data Analysis', 'Business Intelligence']",Mexico,1,,,"['Tech', 'IT']",,"['50.00', '80.00']",Remote Job,Expert
Business Analyst,"I would need a set of business analysis queries to be built for sales analysis, product analysis, HR analysis, and Finance analysis. I can help you with a few ChatGPT prompts and a ChatGPT Plus account. Primary help required is validation of the business analysis queries that GPT provides and also use other forms of research to create new queries.Math QueriesWhich sources generate the most qualified leads?Which industries are most of our leads coming from?Which marketing campaigns have generated the most leads?What is the typical size of the companies that our leads come from?Data Science QueriesHow does the sales representative's experience affect the win rate?How does the geographical location influence the average deal size?How does the company size (in terms of number of employees) affect the subscription status (active, expired, renewal due)?What is the effect of the customer's industry on the sales conversion rate?The task here is to build a robust database of business analysis queries for a select domain like sales, marketing, HR, etc. While these business analysis queries can be generated using ChatGPT with the right prompting, you should vet them to ensure that only high-quality queries make the cut to the database. Queries that don&#39;t make sense should not make it to the database.1. You will have to identify 20 categories for the given domain and then build business analysis queries for the domain. Refer to the sample data (link below).2. you must generate 20 math queries and 80 data science queries for each category. Refer to the sample data (link below).3. The data science queries for each category should be spread across the 8 algorithms provided in the attached sheet.4. And once you have all 2000 queries in, the fields used for analysis should be collated and normalized, and shared separately as fields.Is this something that you can do? If yes, of the domains below (refer to sample data), which ones do you better understand? Please remember that the business analysis queries will have to make sense.Link to sample data: https://docs.google.com/spreadsheets/d/1L1dFt4pExcpSUIGi-92xjcY27TjBEpwQyFvlt3bGw9A/edit?usp=sharing","['Sales Analytics', 'Product Analytics', 'Marketing Analytics', 'Data Analysis', 'Query Development', 'SQL', 'Python', 'Business Analysis', 'Business Intelligence']",United States,4,,,"['Tech', 'IT']",,"['20.00', '75.00']",Remote Job,Expert
Google Analytics Data Export,"We are looking for support in saving and exporting our Universal Google Analytics data. We have several google analytics accounts, going back a number of years and we need as much data saved for the future as possible before Google takes it away.","['Google Analytics', 'Importing & Exporting Data', 'Data Scraping', 'Data Extraction', 'Data Scraping', 'Data Extraction']",United States,1,,,,,"['45.00', '75.00']",Remote Job,Intermediate
Backend Developer (Filipino) for a Japan-based Fashion Tech Startup,"A Forbes Japan Top 200 fashion tech startup based in Tokyo is looking for a Backend Developer (Ph-based) to help the company become a standard within the fashion industry globally by helping to scale and develop products.Responsibilities:Maintaining and updating our recommendation engine working closely with our Data-Science team and our Product team.Communicating and collaborating closely with other backend engineers working on our different product lines in order to ingest new data points in the recommendation system.Updating and maintaining the documentation of the serviceQualifications:The Backend Developer needs to have the following experience:Creating performant data-structures to ingest large data streams in production environmentWorking with containerized Python3 applicationsManaging and querying ElasticSearch / OpenSearch on large indexes with custom ranking algorithms.Working with relational databasesProficiency with Git and industry best practicesAt least 3 years working experience in backend developmentEnglish intermediate levelThe following are nice to have:Experience with AWSExperience with Django / Fast APIExperience with DockerExperience with Machine LearningCompensation and benefits:Competitive salary and benefits, negotiable depending on experienceFlexible working conditions and remote workCoverage of hardware and software expensesRegular trainings and team building activitiesIf you think you are a good fit, we are waiting for you to apply!","['Amazon Web Services', 'Git', 'Web Development', 'python3', 'Elasticsearch', 'Elasticsearch']",Philippines,49,,5,,,,Remote Job,Intermediate
Data Collection Manager,"Description: The Data Collection Manager is expected to manage a team of data collection professionals to do data sourcing and cleaning contact databases. The candidate would also be expected to source, clean or update data manually by checking via sources, contact details of senior people within organization. The incumbent will be sourcing data such as; email address, office number, cell number, social media links and website of the particular organization’s HR directors, HR managers and senior managers and more.  Candidate must be diligent in his/her work making sure that the data is correct, valid, up-to-date and authentic.  He will be also working on existing list to clean the data besides sourcing. The tasks are governed by KPIs and paid as per the measure of time. Hence, the candidate is expected to learn fast and deliver at a faster pace to be able to do deliver quality outcome and finish the task/target in a certain period of time.   ResponsibilitiesCandidate will be:1.	Working on assigned batches of contacts everyday2.	Expected to do data sourcing manually3.	Expected to do data cleaning or sorting of existing database4.	Generating  new contact database time to time as per the requirements5.	Expected that the databases they will be completing will be accurate (We don't want receptionists’ details. We want the details of the person that we are aiming to get information about)6.	They will be completing the task in time and give an authentic database7.	Expected to manage the team of data collectors and be able to generate outcomes8.	Expected to deliver outcomes through self-sourced data and also through the team management 9.	Generating reports for each and every Data Collector10.	Generating KPIs Checklist for the Data Collectors and marking their Scorecards 11.	Liaising with Compliance team for regular scheduled complianceRequirements and skillsCandidates are expected to possess:1.	Proven 5-10 years’ work experience in a data collecting  2.	Strong communication / interpersonal skills  3.	Exceptional time management skills and be able to prioritize and complete given assignments within the timeline 4.	Prior experience with various sourcing platforms for the required data5.	Familiarization with creation and maintenance of such contact databases6.	Proven track record of managing a team or professionals and generating outcome from each team member7.	Skilled at working effectively with cross-functional teams in a matrix organization8.	Ability to engage with team and management 9.	Strong communication, interpersonal and reporting skills  10.	Numeracy, accuracy and attention to detail  11.	Strong analytical and psychometric skills12.	Exceptional leadership and team management skills13.	Intermediate to Advanced level experience with MS Office and certain CRM systems  14.	Excellent written and oral skills and proficiency in English language15.	Strong familiarity with social media, especially LinkedInWhat’s in it for you?	Per hour remuneration with an hourly rate of 5-7 USD for team management (2-4 hrs per day according to CET working hours)	For Data collection:	Remuneration with a rate of 50 USD for 500 sorted entries (per day).  	Remuneration with a rate of 250 USD for 2500 sorted entries (per week). 	An exposure of European market 	An experience to work closely with a diverse global workforce","['Data Entry', 'Data Scraping', 'Lead Generation', 'Data Collection', 'Lead Generation', 'Data Collection']",Malta,565,,2.8,"['HR', 'Business Services']",,"['5.00', '7.00']",Remote Job,Expert
PDF Artificial Intelligence,"Looking to build an AI that allows you to chat with any document or PDF. Examples:- https://pdf.ai/- https://www.chatpdf.com/I'm only needing the actual app, and not the front end website. In your proposal, please include how many estimated hours you think it would take to complete a similar app. Additionally, provide another quote that quotes how much a chrome extension would cost to create. Thanks!Best,Taylor B.","['Machine Learning', 'Machine Learning Model', 'Model Optimization', 'Artificial Neural Network', 'Feature Extraction', 'Artificial Intelligence', 'PDF Conversion', 'Deep Learning', 'Data Science', 'PDF Conversion', 'Deep Learning', 'Data Science']",United States,9,148.73,12,"['Finance', 'Accounting']",,,Remote Job,Expert
AI Developer to White Label ChatGPT for Business,"Hello, we are an investment firm looking to re-skin ChatGPT to run our queries internally. Ideally, what this would look like is a custom URL that our team members all have log-ins for, and then can run queries with a custom precursor query on it as we ask more specific questions (i.e., ""answer this question as if you were a X"" or similar). We were looking for someone who can set up the custom webpage for us and re-skin GPT so it has our branding. If this project goes well, we would be interested in exploring AutoGPT and similar tools down the line. We can explore OpenAI's API or using a headless browser to do this.","['Azure OpenAI', 'ChatGPT', 'API Integration', 'Front End']",United States,2,,,"['Finance', 'Accounting']",200.00,,Remote Job,Intermediate
Virtual Assistant Data Mining,Graystone International is hiring a Virtual Assistant who is very experienced in researching and compiling lead data.  This position is completely remote and has potential to be ongoing.  Daily duties include: - Researching and gathering lead data from various web sources.- Inputing data into a spreadsheets and organizing data points by defined criteria- Full-filling the minimum number of leads in a given time-frame- Cross-referencing leads for validity and accuracy- Daily reporting on level of project completion,"['Data Mining', 'Email Communication', 'Online Research', 'Google Sheets', 'Microsoft Excel', 'Contact List', 'Data Extraction', 'Accuracy Verification', 'Company Research', 'Lead Generation', 'Online Research', 'Google Sheets', 'Microsoft Excel', 'Contact List', 'Data Extraction', 'Accuracy Verification', 'Company Research', 'Lead Generation']",United States,1,,,,,,Remote Job,Intermediate
AI and ML expert for a prediction/recommendation engine,"Need AI/ML expert to work on a Prediction / Recommendation Engine with these steps:1. Get data with multiple attributes using APIs from specified source based on request (either based on a click from a web-app or a voice activated request via the app)2. Gather relevant data sorted based on pre-set criteria for analysis3. Store data if needed or do analysis in real time, and chart data points to display trend based upon pre-set criteria4. Generate recommendations based on programming (or feeding sub-set to Open AI via APIs) and generating predictions/recommendations5. Present output in a desired and consistent format6. Feedback loop for refinement and more accurate predictions/ recommendations going forward","['Artificial Intelligence', 'Machine Learning', 'Data Science', 'Python', 'Machine Learning', 'Data Science', 'Python']",United States,14,,530,,250.00,,Remote Job,Expert
Seeking Power BI Expert for Data Visualization and Maps,"Seeking Power BI expert for data visualization to aid in making quick business decisions. We would like work with a Power BI expert to help us discover the best practices to organize our data and discover ways to best visualize data. For one example, we would like to take our projects, vendors, and associated attributes and put them on a world or city map. This will be an ongoing relationship as it develops.","['Dashboard', 'Digital Mapping', 'Presentations', 'Microsoft Power BI', 'Data Visualization', 'Business Intelligence', 'Data Analysis', 'Data Modeling', 'Microsoft Excel', 'Business Intelligence', 'Data Analysis', 'Data Modeling', 'Microsoft Excel']",United States,90,5.28,25,"['Engineering', 'Architecture']",,,Remote Job,Expert
Analytics + Google Tag Manager Consultant,"Conjured Media is seeking to contract an analytics consultant to help connect and report on client accounts.Responsibilities / Skills:- Cross domain tracking implementation: Our clients use third party payment platforms for purchasing. We need to connect the website, payment platform and ad platforms for accurate tracking via Google Tag Manager.- Google Analytics: Upgrade accounts to GA4 and implement a reporting framework.- Pixels / API Connection: Meta Pixel / API, Adwords Pixel, Tiktok Pixel, Snapchat Pixel etc.- Reporting: Perform audits of Adwords accounts and provide suggestions on how to improve performance.- Search Console/ Mybusiness: Work with us to create a setup procedure.To start we will work together on:- one client ad account audit - one client tracking implementation via tag manager- one GA account transfer to GA4","['Google Tag Manager', 'Google Analytics', 'Google Ads', 'Analytics', 'Marketing Analytics', 'Campaign Reporting', 'Google Analytics API', 'meta api', 'meta pixel', 'Google Search Console', 'Google Ads', 'Analytics', 'Marketing Analytics', 'Campaign Reporting', 'Google Analytics API', 'meta api', 'meta pixel', 'Google Search Console']",United States,20,17.00,4.7,"['Sales', 'Marketing']",,"['25.00', '85.00']",Remote Job,Intermediate
"ARC GIS Professional, Part time","ARC GIS: specifically oil and gas industry-Use geospatial technologies and analysis to creatively solve challenges for our clients-Uses geospatial data to complete tasks using knowledge of Geographical Information Systems-Format and maintain GIS map templates-GIS Map/Plat production, Shapefile, Layer, and Geodatabase creation and management.-GIS Experience with data editing and manipulation, QC/QA, Validation, Versioning, ArcSDE, SQL, Data-Driven Pages, and Georeferencing","['ArcGIS', 'Microsoft Excel', 'Data Entry', 'GIS', 'Data Entry', 'GIS']",United States,1,,,,,"['20.00', '50.00']",Remote Job,Intermediate
Dashboard development using Tableau (5 to 8 Pages),"Develop dashboard using Tableau (5 to 8 pages), dashboard content and mokup will be provided, the expected from the developer is to implement the desig using Tableau","['Dashboard', 'Tableau', 'Data Visualization']",United Arab Emirates,41,,6.1,,200.00,,Remote Job,Intermediate
Scrape,"Seeking Talented Upwork Freelancer: Comprehensive Email Scraping for Interior Designers, Professional Organizers, and Home Builders in FloridaHello Upwork Freelancers,We are currently looking for a highly skilled and reliable freelancer who specializes in email scraping and lead generation. Our goal is to acquire a comprehensive list of interior designers, professional organizers, and home builders located in Florida, specifically in Hillsborough, Manatee, Sarasota, Pinellas, Lee, Charlotte, and Collier counties.Project Requirements:Email Scraping: We require accurate and verified email addresses of interior designers, professional organizers, and home builders in the specified Florida counties.Additional Information: Along with email addresses, we also need their names, phone numbers, and positions within their respective companies or organizations as well as their mailing addresses.Validation and Verification: Every lead must be validated and verified to ensure data accuracy.Skills and Expertise:Proficiency in email scraping tools and techniques.Experience in lead generation and data extraction.Knowledge of Florida's interior design, professional organizing, and home building industries.Attention to detail to ensure accurate data collection.Ability to validate and verify leads for data quality.Deliverables:A comprehensive spreadsheet with the collected data, including email addresses, names, phone numbers, and positions.Documentation on the validation and verification process undertaken for each lead.If you believe you have the necessary skills, expertise, and dedication to deliver accurate and verified leads, we would love to hear from you.To apply, please provide the following information:Relevant experience in email scraping and lead generation.Examples of similar projects you have completed in the past.Your proposed approach to validating and verifying the leads.Estimated timeframe for completing the project.Please note that confidentiality and data security are of utmost importance to us. We expect the freelancer to handle all information provided with strict confidentiality and adhere to ethical practices.If selected, this project has the potential for future collaborations, as we have ongoing lead generation needs. We value professionalism, communication, and timely delivery.Thank you for your interest, and we look forward to reviewing your proposals.","['Data Integration', 'Data Scraping', 'Apollo', 'Microsoft Excel', 'Data Extraction', 'Data Mining', 'html2text', 'Scrapy', 'Python', 'Data Extraction', 'Data Mining', 'html2text', 'Scrapy', 'Python']",United States,6,,,,,,Remote Job,Intermediate
Inov,"Job Description:We are seeking a skilled and innovative Software Engineer to join our dynamic team at our education management company. As a Software Engineer, you will play a crucial role in developing and maintaining software solutions that effectively manage and optimize various aspects of our education sector operations. You will have the opportunity to contribute to the growth and success of our company while making a positive impact on the education industry as a whole.Responsibilities:Develop and maintain scalable software solutions: Design, code, test, and debug software applications that meet business requirements and enhance the functionality and efficiency of our education management systems.Collaborate with cross-functional teams: Work closely with product managers, UI/UX designers, and other stakeholders to understand business needs, translate requirements into technical specifications, and deliver high-quality software solutions.Full-stack development: Be involved in both front-end and back-end development, ensuring seamless integration and smooth functionality across different components of the software.Database design and optimization: Design and implement efficient database structures and queries to support data storage, retrieval, and reporting requirements.Perform software testing and debugging: Conduct thorough testing of software applications, identify and fix bugs, and continuously improve the performance, usability, and reliability of the software.Stay up to date with industry trends: Keep abreast of emerging technologies, frameworks, and best practices in software engineering and the education sector to propose innovative solutions and improve existing systems.Documentation and maintenance: Create technical documentation, user guides, and support materials to assist end-users and maintain software integrity over time.Collaborate on product roadmap and strategy: Provide technical expertise and contribute to discussions on software architecture, system scalability, and future enhancements to our education management software.Requirements:Education: Bachelor's degree in Computer Science, Software Engineering, or a related field. A master's degree would be a plus.Proven experience: Minimum of [X] years of experience as a Software Engineer, with a focus on full-stack development and delivering scalable software solutions. Experience in the education sector or EdTech industry is highly desirable.Technical skills:Proficiency in programming languages such as Java, C++, Python, or JavaScript.Strong knowledge of web technologies (HTML5, CSS3, JavaScript frameworks like React or Angular).Experience with database systems (e.g., SQL, NoSQL) and data modeling.Familiarity with software development methodologies (Agile, Scrum) and version control systems (Git, SVN).Understanding of cloud platforms (AWS, Azure, GCP) and experience with deploying applications in a cloud environment.Problem-solving and analytical mindset: Ability to analyze complex problems, propose innovative solutions, and implement them effectively.Strong communication and collaboration skills: Ability to work effectively in a team, communicate technical concepts to non-technical stakeholders, and actively participate in discussions.Continuous learning: Enthusiasm for learning new technologies, staying updated with industry trends, and applying them to enhance software solutions.Attention to detail and quality: Commitment to delivering high-quality software through rigorous testing, code reviews, and best coding practices.We offer competitive compensation packages, a supportive work environment, and the opportunity to work on cutting-edge solutions that revolutionize the education sector. If you are passionate about software engineering and want to make a difference in the education industry, we would love to hear from you.To apply, please submit your resume, portfolio (if applicable), and a cover letter highlighting your relevant experience and why you are interested in this role.","['Flutter', 'C++', 'Java', 'full stack developer']",India,1,,,,200.00,,Remote Job,Intermediate
Ringba Call Tracking Setup,Pay per call network in need of ringba call tracking analytics integration,['ringba'],United States,122,8.43,325,,,"['10.00', '30.00']",Remote Job,Entry level
Web Scraping project,Looking to scrape the followers of a company Linkedin Page. - First Name- Last Name- Company Name- Email Address- Linkedin Profile URLYou would need a Linkedin Sales Navigator account. Ideal candidates have scraped Linkedin followers before.,"['Data Scraping', 'Data Mining', 'Python', 'Scrapy', 'Python', 'Scrapy']",United States,68,9.10,12,"['Sales', 'Marketing']",200.00,,Remote Job,Intermediate
Oracle PL/SQL Developer,"Job Description:This position will be responsible for supporting our Domestic Retail Warehouse Management System processes. This individual will work with our business partners to enhance the warehousing process and support day-to-day activities. They will be responsible for application support, design/analysis, estimating, coding, testing, application performance, documenting all code, and maintaining/upgrading existing applications.  The engineer must: be comfortable working in a fast-paced, demanding environment; be able to multi-task across several projects simultaneously; and possess strong interpersonal communication skills to be able to effectively communicate with technical and non-technical resources alike.What Will You Be Doing? -    Writing and interpreting both high-level and detailed designs both individually and with peers.-    Taking part in code reviews of business logic and interfaces with other systems in custom Oracle PL/SQL and Java applications. -    Analyzing code, configuration, data, and logs to find causes of errors and revises applications as needed.-    Providing testing support during the testing phase and assisting in troubleshooting testing defects.-    Providing on-call support including off-hours on nights/weekends (as required) for end users of the system and responds to reports of system malfunctions. -    Discussing and fundamentally understanding business needs and problems and speaking to the business about technical designs and functionality. -    Breaking down, evaluating, and communicating complex business and technical processes, problems, and risks.-    Developing accurate estimates and assisting other team members with the estimation process.-    Analyzing, defining, and documenting technical requirements for data, workflow, logical processes, hardware and operating system environments, and interfaces with other systems.-    Defining, building, and tuning monitors and reports.-    Planning and execution of production code deployments.-    Working with all levels of the business and the development team to establish, practice, promote, and enforce sound design, coding, and testing practices.-    Mentoring junior team members, contractors, and external teams as needed.-    Ensuring work meets functionality and quality expectations within given timelines. What Do You Need To Bring? -    Bachelor’s degree in a Management Information Systems (MIS), Computer Science (CS)/Computer & Information Science (CIS), or IT related field or related experience -    8+ years’ experience in development and support of WMS applications, preferably Oracle RDM and/or Manhattan WMOS.  Retail fulfillment is preferred.  DTC fulfillment is nice to have.-    Technical experience with RDBMS (Oracle, SQL Server, MySQL), SQL, PL/SQL, XML, and Unix commands to manage application servers.-    Working experience of object-oriented concepts, patterns, and practices on the Java platform.-    Experience using K8, Cloud Services, Docker Containers, and/or OpenShift.-    Experience in Agile Methodology and CI/CD development, Streaming and API based integrations.-    Excellent written and verbal communications skills to facilitate communications between and among highly experienced business and IT associates.-    Excellent analytical, problem solving, design and development skills.-    Excellent organization skills and attention to detail, including the ability to prioritize and manage a variety of complex tasks and activities. -    Ability to understand the long-term (""big picture"") and short-term perspectives of situations.-    Ability to work in a fast-paced, team-orientated, collaborative, and cross-functional environment","['Oracle PLSQL', 'SQL', 'Oracle Database', 'Database Programming', 'Java', 'MySQL', 'SQL Programming', 'Oracle Database Administration', 'Docker', 'CI/CD', 'Database Programming', 'Java', 'MySQL', 'SQL Programming', 'Oracle Database Administration', 'Docker', 'CI/CD']",United States,6,,,"['Tech', 'IT']",,"['5.00', '30.00']",Remote Job,Intermediate
Statistician to help in advanced analytics,"We are looking for advanced statistics consultant with prior experience in advanced analytics. The consultant's responsibilities are but not limited to build statistical models, building regression analysis, identifying the correlation and relationships between the data, build predictive models, and identifying the relationships between deafferent variables to build recommendations and insights.The topic of the data: employment and HR (prior experience in giving advanced recommendations to enhance the employment rates and support the job seekers is very appreciated)","['Python', 'Statistics', 'Pattern Recognition', 'Regression Analysis', 'Trend Analysis', 'Predictive Analytics', 'Statistical Analysis', 'Data Science', 'R', 'Regression Analysis', 'Trend Analysis', 'Predictive Analytics', 'Statistical Analysis', 'Data Science', 'R']",Saudi Arabia,17,,,"['Tech', 'IT']",,"['40.00', '60.00']",Remote Job,Expert
"AI No-code automation expert needed to help built out AI SDR using GHL, Make & OpenAI","I'm having troubles building out a solution to qualify prospects using GoHighLevel, Make and OpenAI. I need an expert who is familiar with these tools to help improve on the already built workflows and scenario plus add any additional value to the flow they may see fit.","['Chatbot', 'Artificial Intelligence', 'Machine Learning', 'gohighlevel', 'Integromat', 'Automation', 'Machine Learning', 'gohighlevel', 'Integromat', 'Automation']",Canada,13,50.00,1.6,"['Sales', 'Marketing']",,,Remote Job,Expert
Data scientist with ChatGPT knowledge,We are looking for a data scientist with chat GPT knowledge whos interested in exploring datasets and APIs using chatgpt.,"['Machine Learning', 'Data Science', 'ChatGPT', 'Statistics', 'ChatGPT', 'Statistics']",Spain,597,16.90,354,,,"['20.00', '35.00']",Remote Job,Expert
Looking for Chat GTP data expert.,We are looking to plugin to several APIs for several services and several data sources. We want to use CHATGPT to query these APIs and data sources and get insides.,"['ChatGPT', 'ChatGPT API', 'ChatGPT Expert']",Spain,597,16.90,354,,,"['20.00', '35.00']",Remote Job,Expert
Long term Python Software Engineer,"Job Brief:We are a fast-paced startup, developing AI solutions for the legal industry. We're seeking an experienced Software Engineer for a contract role to work on our existing code base. Your work will involve both development and production tasks, and you'll be collaborating closely with our team.Responsibilities:Improve, implement, and test new features in our AI applications.Troubleshoot and resolve software-related issues.Collaborate with cross-functional teams to deliver new features.Provide production support and handle escalations.Skills Required:Proficiency in Python, SOLR, PostgreSQL, AWS, and FastAPI.Strong problem-solving skills and understanding of data structures.Knowledge of RESTful APIs and version control systems (like Git).Excellent collaboration and communication skills.Qualifications:Minimum of 3 years of software engineering experience.Formal education in Computer Science or related field is advantageous, but not mandatory.This contract role is ideal for someone who is passionate about technology, enjoys working in a fast-paced startup environment, and is ready to make a significant contribution. We're committed to diversity and inclusion, and we welcome applicants from all backgrounds.","['Web Application', 'Database Development', 'PostgreSQL', 'Python', 'RESTful API', 'Amazon Web Services', 'Apache Solr', 'Apache Solr']",United States,72,29.75,137,,,"['25.00', '50.00']",Remote Job,Expert
Contractor(s) for visual search POC,"Are you a contractor with experience in building visual search engines using PyTorch, Keras and/or Tensorflow? We are looking for someone to help us build a proof-of-concept (POC) visual search engine that will be primarily deployed on AWS.We need help with a variety of tasks, including image scraping, image classification, object detection, feature extraction, color analysis, and model training. The ideal candidate will have experience with these technologies and be able to work independently to help us build a high-quality POC. However, anyone can respond to work on individual components based on specific expertise.Budget is open to discussion based on deliverables.This is an exciting opportunity to work on a cutting-edge project that has the potential to revolutionize the way people search for images. If you're interested in working with us, please reach out to us with your resume and a brief description of your experience with Keras and/or Tensorflow. We look forward to hearing from you!","['TensorFlow', 'Keras', 'PyTorch', 'Model Tuning', 'Deep Neural Network', 'Python', 'Docker', 'Object Detection', 'AI-Enhanced Classification', 'AWS Development', 'AI-Enhanced Classification', 'AWS Development']",United States,15,47.59,13,,,,Remote Job,Intermediate
Contractor(s) for visual search POC,"Are you a contractor with experience in building visual search engines using PyTorch, Keras and/or Tensorflow? We are looking for someone to help us build a proof-of-concept (POC) visual search engine that will be primarily deployed on AWS.We need help with a variety of tasks, including image scraping, image classification, object detection, feature extraction, color analysis, and model training. The ideal candidate will have experience with these technologies and be able to work independently to help us build a high-quality POC. However, anyone can respond to work on individual components based on specific expertise.Budget is open to discussion based on deliverables.This is an exciting opportunity to work on a cutting-edge project that has the potential to revolutionize the way people search for images. If you're interested in working with us, please reach out to us with your resume and a brief description of your experience with Keras and/or Tensorflow. We look forward to hearing from you!","['TensorFlow', 'Keras', 'PyTorch', 'Model Tuning', 'Deep Neural Network', 'Python', 'Docker', 'Object Detection', 'AI-Enhanced Classification', 'AWS Development', 'AI-Enhanced Classification', 'AWS Development']",United States,15,47.59,13,,,,Remote Job,Intermediate
Implement real data into a new model,"Description:We are seeking a talented and detail-oriented Data Specialist to join our team and contribute to a new cannabis model we are developing. As a Data Specialist, your primary responsibility will be to collect, analyze, and input real and current data into our cannabis model to ensure its accuracy and relevance.Responsibilities:Conduct extensive research to gather relevant data on the cannabis industry, including market trends, product information, legal regulations, and consumer behavior.Verify the accuracy and reliability of the collected data from various sources.Organize and structure the data in a standardized format suitable for integration into the cannabis model.Collaborate with the development team to define data requirements and ensure data integrity.Regularly update the model with new and updated data, ensuring its timeliness and relevance.Identify data gaps and propose strategies for acquiring missing information.Perform data quality checks and resolve any inconsistencies or errors.Stay informed about industry developments and trends to ensure the model reflects the latest information.Requirements:Proven experience as a Data Specialist, Data Analyst, or similar role, preferably in a related industry.In-depth knowledge of the cannabis industry, including its market dynamics, regulations, and product landscape.Strong research and analytical skills, with the ability to gather and interpret data from diverse sources.Proficiency in data management tools and techniques.Attention to detail and a commitment to maintaining data accuracy.Excellent organizational and time management skills to meet project deadlines.Strong communication skills to effectively collaborate with cross-functional teams.Bachelor's degree in Data Science, Statistics, Business, or a related field (preferred but not mandatory).If you are passionate about the cannabis industry and have a knack for working with data, we would love to hear from you. Join our team and contribute to the development of a cutting-edge cannabis model that will have a significant impact on the industry. Please provide examples of relevant projects or work samples when applying.Note: This is a remote position.","['Data Science', 'Machine Learning', 'JavaScript', 'JavaScript']",United States,306,6.65,18,['Legal'],30.00,,Remote Job,Entry level
Langchain Help - quick python project using langchain + SERP to scrape data from online,"* Must have experience with Langchain* 1-2 day deadline.* I have most of the code ready, it just needs work to improve accuracy.The Project:I have a large CSV of car part numbers and their brands, organized in this way:Car Part # | Brandeg:63829127 | NissanI need to use langchain, openai + Serp to search online for that car part, and then find a list of this data:1. Name of the product2. Description 3. Price (multiple prices so gather multiple sources)4. Product Category (AC Part, Body Part, Electrical etc.)5. Years of cars its compatible with6. Models of cars its compatible with7. Sources of each dataI already have a basic code for this, my issue is that the data it returns isn't very accurate. Would prefer to use GPT-3.5-Turbo API but it's up to you. I will provide you with an openai API key and a a SERP API keyDeliverables:* Read the Excel file and search online for part number - DONE* Find data for each Part - Done but does it badly* Write data to CSV - DONE but just needs to be split into separate rows* Determine which of our 15 categories the part belongs to based on it's information ( simple openai API call to ask what it best fits into)Needs to be done in 24-48 hours. Like I said I have most of the code, the output is just not very accurate so I need someone who has experience with langchain to see what I'm doing wrong and improve the prompt/resulting data.Here is the code for you to get an idea: https://colab.research.google.com/drive/1LMIO7lULAmQoBv-BxKvQvciCWMc2qI10?usp=sharing","['Python', 'Data Mining', 'Data Scraping', 'langchain', 'langchain']",Qatar,9,,420,,100.00,,Remote Job,Intermediate
Seeking an Experienced Tableau Viz Wiz,"We are looking for a talented and experienced Tableau freelancer to join our team and help us develop and maintain our business dashboards. The ideal candidate will have a strong understanding of Tableau, as well as experience with data analysis and visualization. They will also be able to work independently and as part of a team and be able to meet deadlines, and deliver high-quality work.ResponsibilitiesDevelop and maintain business dashboards using TableauWork with data analysts to gather and clean dataCreate interactive and visually appealing dashboardsPublish dashboards to the web and mobile devicesTroubleshoot dashboard issuesStay up-to-date on the latest Tableau features and best practicesQualifications3+ years of experience with TableauExperience with data analysis and visualizationStrong analytical and problem-solving skillsExcellent communication and teamwork skillsAbility to work independently and meet deadlines","['Data Analysis', 'Tableau', 'Data Visualization', 'SQL', 'SQL']",United States,3,,,,,"['16.00', '30.00']",Remote Job,Intermediate
"Adobe Target, CDP and Website Tagging Engineer needed from LATAM",We are looking for Digital Solution Resources for the below roles.1. Adobe Target Developer2. Adobe CDP Developer3. Website Tagging Engineer/Data Collection EngineerThese roles are for LATAM-based candidates only and the candidate should have excellent English skills.Please ping me if you are interested or if you know someone who is interested.,"['Google Tag Manager', 'Adobe Target', 'Google Analytics', 'Cloud Engineering', 'Cloud Engineering']",United States,294,8.70,172,"['Tech', 'IT']",,,Remote Job,Intermediate
Google Data Studio Expert with Fivetran connectors experience - Active Campaign(Data),Looking for someone who has great experience working with Google Data Studio and can set up data connectors in Fivetran.I have many projectsConnectors experience required: Active Campaign,"['API Integration', 'SQL', 'Google Data Studio', 'API', 'Fivetran', 'Fivetran']",United Kingdom,12,17.17,827,"['Tech', 'IT']",,"['20.00', '25.00']",Remote Job,Intermediate
Geolocation Dataset Consultant,"We are a global real estate portal. We want to improve our geolocation dataset for the different markets we operate in, meaning accurate and updated information regarding: regions/muicipalities/cities(/vllages)/neighbourhoods across a number of countries, namely... USA Norway Greece AustriaSchweizNew Zealand Turkey Spain Belgium Italy Finland Poland  Portugal  Croatia Germany Denmark Sweden Netherlands United Kingdom       Australia           France         Ireland           Canada     What we basically need is someone who has expertise knowledge of geocoding and available tools and services to acquire this dataset, QA the data, and provide it for us. We need coordinates and postcodes and a clear structured dataset per country to feed to our applications.In your application for this job, please provide a your approach and how your would start on this project so I can get an idea of your workflow and the size of the task.Thank you and looking forward to your application.","['GIS', 'ArcGIS', 'Geolocation', 'GeoAPI', 'GeoJSON', 'Geocoding', 'Python', 'Data Science', 'GeoJSON', 'Geocoding', 'Python', 'Data Science']",Denmark,216,15.95,118,,1000.00,,Remote Job,Expert
AI engineer needed,Needed AI engineer to develop a photo generator algorithm.,"['Artificial Intelligence', 'Machine Learning', 'Neural Network', 'Deep Learning', 'Data Science', 'React', 'Web Development', 'backend', 'Machine Learning', 'Neural Network', 'Deep Learning', 'Data Science', 'React', 'Web Development', 'backend']",United States,11,,350,['Education'],500.00,,Remote Job,Expert
I am looking for a product researcher to find the best tweet scraper for our business,"We are looking for a qualified product researcher to help us find the best tweet scraper for our business. The project will take less than a month to complete. The ideal candidate should have experience in data science, data scrapping, and data extractionAs a product researcher, your main responsibility will be to find the best tweet scraper that fits our business needs. You will be expected to conduct thorough research, analyze the different APIs, and present your findings to our team. You should be able to work independently and have excellent attention to detail.To apply for this position, please submit a proposal that outlines your relevant experience and how you can help us with this project. Please include links to past completed projects that demonstrate your expertise in the area of product research.We look forward to hearing from you and working with you to find the best tweet scraper for our business needs.","['Market Research', 'Data Entry']",South Korea,90,27.59,8.8,,20.00,,Remote Job,Expert
LLM - TTS expert to create near gold standard human voice,We'd like to explore the possibility of introducing a new voice for our voicebot. This shlould be near human experience & should have the ability to scale vertically & horizontally.,"['Female', 'Communications', 'US English Dialect', 'Video Production', 'Voice-Over', 'Audio Production', 'Audio Editing', 'Machine Learning', 'English', 'Python', 'Video Production', 'Voice-Over', 'Audio Production', 'Audio Editing', 'Machine Learning', 'English', 'Python']",India,1,,,"['Tech', 'IT']",,"['10.00', '20.00']",Remote Job,Entry level
Custom Excel Spreadsheet (For Shopify Business),"Built a spreadsheet for a shopify business1) Daily sales recording2) Daily expenses recording 3) Different credit card for different business expenses4) Inventory tracking (customer refund, exchange, sales inventory, influencer marketing inventory) 5) Payment for allowance6) Platform fees + GST 7) COGS (estimated) 8) Facebook advertising cost tracking9) ROI tracking10) Final balance with all bank account/sales/expenses11) Inflow/Outflow of bank statementNeed an advance template where its easy to use and can be used to identify simple PNL table.I have a lot of existing data, I can share with you.","['Data Analysis', 'Data Analytics', 'Microsoft Excel', 'Excel Macros', 'Excel Formula', 'Excel Formula']",Singapore,69,,4.4,"['Retail', 'Consumer Goods']",30.00,,Remote Job,Expert
Google Analytics 4 Expert,"Our team at NOWATCH is in need of assistance with the setup and verification of Google Analytics 4. Considering your expertise in this area, we were wondering if you would be available this month to lend your expertise for approximately 3-4 hours.We would greatly appreciate it if you could kindly inform us of your availability and provide your rates for the requested assistance. Once we have these details, we can share further information regarding the specific requirements and objectives of the task at hand.","['Google Analytics', 'Google Tag Manager', 'facebook tag manager', 'Google Analytics 4', 'facebook tag manager', 'Google Analytics 4']",Netherlands,1,,,,,"['40.00', '90.00']",Remote Job,Expert
Scrape Glassdoor,"Scrape Glassdoor: Company name, job name, location, salary.  ONGOING WORK - PLEASE BID PER THOUSAND RECORDS AND ADVISE NUMBER OF RECORDS PER DAY YOU ARE CAPABILITY OF SCRAPING.Sample search: https://www.glassdoor.co.in/Job/united-states-customer-service-jobs-SRCH_IL.0,13_IN1_KO14,30.htm?remoteWorkType=1",['Data Scraping'],United States,82,8.41,23,,300.00,,Remote Job,Intermediate
AI Machine Learning and Python expert,"I'm looking for a Machine Learning and Python expert to work on our client project:Please put python on top of the cover letter so I know you have ready thisJob description:We are looking to build a custom solution to monitor vendor invoices each month. This means the solution would do the following. We have already built #1 and use a 3rd party API for #2. We just need someone to integrate everything together, with our database (Salesforce) and then incorporate some machine learning and AI to fine tune the process to give us the best results and insights. d1. Use a scraper to login to vendor websites, extract the current months' PDF, download it, label it, and store it in One Drive (we currently already have a script that does this)2. Extract the data from the PDF, put it in JSON (or CSV) so that it can be imported into our database. (We use a 3rd party site for the OCR technology here. It works well, but there are some kinks that need to be worked out and improved on the data extraction templates)...in either case we are not asking anyone to design our own proprietary OCR technology, unless there is some AI plugin or software that could do this already? We are open to suggestions but had planned on just using the 3rd party API and paying for their service. We just need someone who can work with that API to really fine tune our use case.In this step we may need to incorporate some AI as well. For example, the OCR technology has a hard time discerning the vendor address from the client address. Some AI to query the internet and discern the difference from vendor location to client location could be useful to help make sure the data integrity is there.3. Take this data and put it into a database (we have been using Salesforce)...4. This data would then be compared to the vendor contract for contract compliance and overcharges.5. Ideally we would then have some AI prepare a simple email to the vendor stating the amount overcharged, account number affected, and a simple request for refund (this email would get reviewed by a human before being sent off). AI would then manage any follow up communication.","['Python', 'Machine Learning', 'Artificial Intelligence', 'Artificial Intelligence']",India,119,11.27,97,"['Tech', 'IT']",,"['15.00', '50.00']",Remote Job,Expert
Data Engineering Tutor,"Looking for a mentor or tutor to help me learn data engineering and work on 1-2 data engineering projects.  I work in operations  but have taken classes in python, and have some exposure to PostgreSQL, Java, C#, however I am interested in working with someone who has industry experience in the field and can be a guide for me to help me get some experience.","['Apache Spark', 'Apache Airflow', 'SQL', 'Python', 'dbt', 'Snowflake', 'Amazon Redshift', 'English', 'English']",United States,12,18.75,705,,,"['5.00', '20.00']",Remote Job,Intermediate
AI + Full Stack Developer Team Needed,"Hello there, we are searching for an AI + full-stack developer team that can help us with the future development of our platform.In order to hire your team, we need you to have solid experience in:- Node.js- React.js- API- Python- AWSWe need you to be able to work even during the weekend if it is needed. But to also be or have a person (project manager) from your team that can be very responsive and fast in his/her answers.This is a long-term project. And we may need your services for the next few years.","['ChatGPT', 'JavaScript', 'API', 'Artificial Intelligence', 'React', 'Python', 'Node.js', 'Amazon Web Services', 'API Integration', 'React', 'Python', 'Node.js', 'Amazon Web Services', 'API Integration']",Bulgaria,496,9.68,34,,,"['15.00', '35.00']",Remote Job,Intermediate
Web scraping,Scrape and organize all info contained in 111 links (where the webpage is always organized the same) into a df,"['Data Scraping', 'Python', 'Web Crawling', 'Data Extraction', 'Data Extraction']",Switzerland,4,40.00,45,['Education'],,"['5.00', '10.00']",Remote Job,Intermediate
Website Scraping,"We have two websites called daft.ie & myhome.ie. What we need to analyse on-going basis is the market share of the real estate agents. So for example dng.ie is a real estate franchise, so we need to calculate in all areas in Ireland (There is alot of areas). What their market share is for 1) daft.ie2) myhome.ieIdeally would be good for this information to be on a cloud Google sheet or Google Data Studio. I will need to know how long this will take you to do.","['Data Scraping', 'Data Mining', 'Web Crawling', 'Web Crawling']",Ireland,122,8.12,8.7,,150.00,,Remote Job,Intermediate
GA4 Conversion Tracking Help,"Hello,We're a WP Development company that is helping a client set up GA4 including conversion tracking.  We don't really do much in that area though and the new GA4 conversion tracking is a bit over our head.  We're looking for someone with specific knowledge of conversion tracking in the new GA4 that can video meet with us for an hour or two to look over this clients previous conversion tracking and help us get the new system set up.We're also talking about getting more into providing Analytics services and looking to partner with someone that can work with us to learn the systems, set up our processes/procedures, and process work as it comes in.Thanks!","['Google Analytics', 'Google Tag Manager']",United States,64,16.98,33,,,"['40.00', '100.00']",Remote Job,Expert
Machine learning expert to help to build model,"Hi! Please help me build a model for predicting electricity prices. I have data hourly per day for several years. I need the model to account for behavior during peak hours of the day (9am-7pm) and behavior on different days of the week. Seasonality must also be taken into account. Also, I would be very grateful if you could explain the code itself to me","['Machine Learning', 'Data Science', 'Python', 'TensorFlow', 'Deep Learning', 'Artificial Intelligence', 'Data Analysis', 'Natural Language Processing', 'Keras', 'Artificial Neural Network', 'Python', 'TensorFlow', 'Deep Learning', 'Artificial Intelligence', 'Data Analysis', 'Natural Language Processing', 'Keras', 'Artificial Neural Network']",Ukraine,1,,,"['Energy', 'Utilities']",,"['5.00', '30.00']",Remote Job,Intermediate
Data scraping on Linkedin,"We want to automate the following task. 1) Search for renewable companies in the US, UK, Australia, UAE, and Saudi Arabia on LinkedIn. You will need to apply the following filters in the industry section: - Renewable Energy Power Generation- Renewable Energy Equipment Manufacturing- Services for Renewable Energy- Renewable Energy Semiconductor Manufacturing- Solar Electric Power Generation2)Go to the people section of each company and search Pakistan. - If it shows people in there, the program notes the name of the company and the list of employees in the people section. - If you have a better way to search for people whose active location is Pakistan, that's even better.The final output file will be CSV. You might need to utilize both web scraping and API calls.This is just a small task, we are interested in the code, and how you approach this problem. It can open the doors to huge opportunities if you show promise. Before applying for the proposal, you need to approach this problem, run the code, and share the file with sample results of at least 20 companies for each country mentioned. We will test the result, and if satisfactory, we will have an online session for the long-term plans.","['Linkedin API', 'Data Scraping', 'Python', 'Data Entry', 'Python', 'Data Entry']",Pakistan,2,,15,"['Tech', 'IT']",150.00,,Remote Job,Intermediate
Data mining / Researcher - need contact info for corporate execs.,"I have an excel list with company names.  Many need info filled in such as person's name, title, email and office phone.  I need specific senior level execs and all emails must be verified.Good and immediate communication a must. If interested we can have a zoom to show you the list, what is needed, and you can send proposal for fee for entries completed. Thanks.",['Online Research'],United States,58,8.58,12,,,,Remote Job,Intermediate
Optimization project on gurobi MATLAB,"I have an optimisation programming problem that should be solved on gurobi MATLAB, so I'm looking for talents experts in optimization problems. Please let me know if you are interested this project to provide you with the full details.","['MATLAB', 'Mathematical Optimization', 'MATLAB Script', 'Mathematics', 'Data Science', 'gurobi ', 'MATLAB Script', 'Mathematics', 'Data Science', 'gurobi ']",Poland,2,,50,,50.00,,Remote Job,Entry level
Cadastral Map Auto digitization with python AI,I want to build an AI model that will extract lines or ploygon of plot boundary automatically from raster mouza map.,"['Python', 'Machine Learning', 'Artificial Intelligence', 'GIS', 'Artificial Intelligence', 'GIS']",Bangladesh,6,8.95,52,,,"['10.00', '40.00']",Remote Job,Intermediate
Scrape products from multiple websites,We are looking for someone who either develops a script or uses any tool or handles it manually. We have a list of around 3000 websites of companies manufacturing different product.The task is to find all products from all those websites and extract them into an excel file and every downloadable file of each product into a folder structure referencing to the companyId of the excel provided.Delivery expectation is described in the attached PDF along with two example on how an extraction would work.,"['Data Scraping', 'Data Mining', 'Microsoft Excel', 'Microsoft Excel']",Germany,3,,,,2000.00,,Remote Job,Intermediate
Speaker or Trainer about Using AI or ChatGPT,"We are seeking a talented Speaker or Trainer who is an expert in AI and chatbot technology, particularly in using ChatGPT. This job is a short-term project that will require someone who can deliver clear and engaging presentations or training sessions on the topic for an hour . The ideal candidate should have a strong background in AI, data science, and machine learning, with extensive experience in using chatbots and other similar technologies. The candidate should be able to explain complex concepts in a way that is easy to understand and digest.The successful candidate will be responsible for conducting training sessions or presentations for our team, providing detailed information about the use of ChatGPT and AI chatbot technology. They should also be able to answer any questions we may have related to the topic.To apply, please submit a proposal detailing your relevant experience and skills. Please include links to any relevant past projects that showcase your expertise in AI and chatbot technology. We look forward to hearing from you!","['AI Chatbot', 'Artificial Intelligence', 'Data Science', 'Machine Learning', 'Data Science', 'Machine Learning']",Canada,132,11.69,22,,,"['13.00', '50.00']",Remote Job,Entry level
Data Mining Course | Expert level,"Hello there.I need an expert person that knows ""Data Mining Course"", It is a course in Computer Engineering, If you know this course very well, please send me your proposl.Note: Book name: ""772s Data Mining Concepts and Techniques 2nd Ed""We will talk about the rate later.Regards.","['Data Analytics', 'Data Visualization', 'A/B Testing', 'Big Data', 'Business Intelligence', 'Data Interpretation', 'Funnel Testing', 'Hypothesis Testing', 'Statistical Analysis', 'Machine Learning', 'Operations Analytics', 'Customer Service Analytics', 'Growth Analytics', 'Report', 'Data Analysis', 'Query Development', 'Presentations', 'Dashboard', 'Google Analytics', 'ActivTrak', 'Altair Monarch', 'AnyLogic', 'Apache Hive', 'BigQuery', 'BIRT', 'Chartio', 'Google Tag Manager', 'Cognos', 'Domo', 'Grow', 'Google Sheets', 'Python', 'Lead Generation', 'Microsoft Excel', 'Data Entry', 'Statistics', 'Data Mining', 'Data Science', 'Online Research', 'Calculus', 'Mathematics', 'Electrical Engineering', 'Engineering Physics', 'Physics', 'Probability Theory', 'Advanced Analytics', 'Algorithms', 'Analytics', 'Microsoft Excel', 'Data Entry', 'Statistics', 'Data Mining', 'Data Science', 'Online Research', 'Calculus', 'Mathematics', 'Electrical Engineering', 'Engineering Physics', 'Physics', 'Probability Theory', 'Advanced Analytics', 'Algorithms', 'Analytics']",Turkey,131,,1.1,"['Tech', 'IT']",100.00,,Remote Job,Intermediate
Stata-code,I am looking for a Stata user able to add code to a function that's already written,['Stata'],San Marino,247,,1.7,,20.00,,Remote Job,Expert
Google Data Studio Design Required,Google Data Studio Design RequiredTo produce KPI reports.full details provided,"['Google Data Studio', 'Data Visualization']",United Kingdom,1940,10.12,82,,,"['20.00', '50.00']",Remote Job,Intermediate
Looking for Analytics Developer / Forecasting Expert for ML Project,"BOLD is an eCommerce software and services provider focused on the Consumer Packaged Goods (CPG) sector. We are looking for a proven analytics experts to help progress our TestPilot tool, a predictive analytics tool used to forecast the retail potential of new product launches.Our candidate will have experience on forecasting projects involving diverse data sources and will know how to work as part of a team. Proven academic or commercial experience developing and / or implementing forecasting algorithms.You'll work with different members of our 36-person team including Leadership, Web Developers, and Client Strategy experts.Areas of focus include:•	Data collection & prep from syndicated online & store/POS data•	Rapid model development, testing, and deployment. Run many automated tests across large data sets•	Incorporate new variables into the testing process to refine the forecast, focus in on the most effective model(s) and variablesWe view this as a long-term engagement that could lead to full-time opportunities for the right person.We look forward to meeting you soon!","['Machine Learning', 'Statistical Analysis', 'Sales Analytics', 'Data Visualization', 'Data Analytics', 'Python', 'R', 'Data Analysis', 'Python', 'R', 'Data Analysis']",United States,117,53.59,369,"['Sales', 'Marketing']",,"['30.00', '125.00']",Remote Job,Expert
Looking for Machine Learning Developer,"Hello Developers,We are seeking a skilled and experienced Machine Learning Developer to join our team on a freelance basis. As a Machine Learning Developer, you will be responsible for developing, implementing, and maintaining machine learning models and algorithms to solve complex problems and extract valuable insights from data.Responsibilities:• Collaborate with cross-functional teams to understand project requirements and translate them into machine learning solutions.• Design and develop machine learning models and algorithms to analyse large datasets and extract meaningful patterns.• Implement data reprocessing techniques, feature engineering, and model selection to optimise model performance.• Evaluate and fine-tune machine learning models using appropriate evaluation metrics and validation techniques.• Conduct experiments and perform statistical analysis to validate model performance and reliability.Requirements:• Proven experience as a Machine Learning Developer or similar role, with a strong portfolio showcasing successful machine learning projects.• Proficiency in Python programming language and popular machine learning libraries.• Solid understanding of machine learning algorithms, including supervised and unsupervised learning techniques.• Experience with data preprocessing, feature engineering, and data visualization.• Strong knowledge of statistics and probability theory.If you are a passionate Machine Learning Developer with a strong track record of delivering high-quality solutions, we would love to hear from you. Please submit your resume, and any relevant project examples for consideration.Look forward to hearing from you!","['Python', 'Machine Learning', 'Deep Learning', 'Artificial Intelligence', 'JavaScript', 'Deep Learning', 'Artificial Intelligence', 'JavaScript']",India,34,,84,"['Tech', 'IT']",850.00,,Remote Job,Intermediate
Google Data Studio help needed to support marketing analytics dashboards using Supermetrics,"Our marketing agency would like to provide marketing analytics dashboards for our customers using Google Data Studio. We had an employee who set up a dashboard template, but they no longer work for us. We need to fix some issues with current customer dashboards and find a resource who can help us set up new dashboards when we onboard new customers.We use Supermetrics to connect to various data sources, including:Website Analytics - SEMrush, Google Analytics, Google Search ConsoleEmail Analytics - MailChimpSocial Media Analytics - Facebook, Instagram, LinkedInAdvertising Analytics - Google Ads, Facebook AdsWe are also looking for someone who can implement Google Tag Manager for Google Ads, form conversions, etc.Our marketing agency is a small 4-year-old startup agency that is part of a family-owned group of businesses, including a 29-year-old IT company, based in Chattanooga, TN.","['Google Data Studio', 'Supermetrics', 'Meta Business Suite', 'Facebook Insights', 'Instagram Insights', 'Google Tag Manager', 'Google Analytics', 'Meta Business Suite', 'Facebook Insights', 'Instagram Insights', 'Google Tag Manager', 'Google Analytics']",United States,2,50.54,8.9,"['Sales', 'Marketing']",,"['30.00', '60.00']",Remote Job,Intermediate
Tableau Technical Trainer Required !!," Trainer Recruitment: Seeking Experienced Trainers in TableauAre you a skilled trainer with a passion for imparting knowledge? We have many openings for Trainer positions with our esteemed organization iamneo (Formerly Examly). Here are the details: Requirements:Minimum 4+ years preferred in training roles.Willingness to travel to any of the following locations: Chennai, Bangalore, Mumbai, Bhubaneshwar. Trainer Expertise Needed:Tableau:Sound Understanding of Java, Linux, and MongoDB.Knowledge of NoSQL and DevOps.Hands-on experience in IICS - Informatica and Snowflake.Experience in Tableau. If you meet the requirements and are passionate about training, we want to hear from you! Please share your CV with me through DM and join our dynamic organization.Join us as a Trainer and empower learners with your expertise!","['Python', 'SQL', 'Tableau', 'MongoDB', 'Snowflake', 'Informatica Cloud', 'Cloud Database', 'Data Structure', 'DevOps', 'Data Analysis', 'Snowflake', 'Informatica Cloud', 'Cloud Database', 'Data Structure', 'DevOps', 'Data Analysis']",India,5,,,,2425.00,,Remote Job,Expert
Update a Tableau dashboard,"Hi there. Thank you for your interest in our project. We have a Tableau workbook that was a draft dashboard for a model. We've updated the model and made changes to some of the variables and we need the Tableau dashboard to be updated. We need you to either update our current workbook, or start from scratch and create a new one.We will supply you with updated Excel spreadsheet and written notes by the end of the day today and we need you to create the updated version by the end of the day Sunday, at the latest.The deliverable is a packaged Tableau workbook.Thanks!",['Tableau'],Canada,570,48.92,352,,,"['35.00', '100.00']",Remote Job,Expert
"Full Stack developer typescript openAI RVC ChatGPT Next.js React Node.js Python, Vercel","We are currently seeking a skilled team or individual to develop a web application for our platform, which will allow users to utilize pre-existing voice models or create their own. The application will offer TTS (Text-to-Speech) functionality as well as a Retrieval-based Voice Conversion.To support AI image generation, we will be utilizing AWS S3 bucket and the stable diffusion.For the backend Node.js Python and Docker as our primary technologies. As a headless CMS solution, we are considering implementing StrapiIn terms of text processing and prompts, we will be leveraging the OpenAI ChatGPT.On the frontend Next.js, React.js Tailwind CSS. Integration of payment gateways, particularly PayPal, will be facilitated through Stripe.Deployment docker hub, runpod. Vercel for deploying the Next.js application.Prior experience with AWS and expertise in data science are highly desired qualifications for this role.If you are an experienced data scientist with proficiency in AWS and a passion for working on AI-driven projects, we encourage you to apply. Please include examples of your previous work and relevant experience in your application.","['Python', 'Amazon Web Services', 'Next.js', 'React', 'Node.js', 'MongoDB']",United States,24,41.58,73,,,"['25.00', '50.00']",Remote Job,Expert
Google sheet experts for reporting,I am running ca practice firm Need an experts who can develop Google sheets through which we can control on targets given to staff and continuous monitoring of same,['Google Sheets'],India,1,,,,,"['18.00', '45.00']",Remote Job,Intermediate
Sankey Diagram using Javascript/D3,I want to create a sankey diagram with JavaScript and D3. The task is straight forward if you know how to do it. I will send you the image like what I want.,"['JavaScript', 'D3.js', 'CSS', 'HTML', 'Data Visualization', 'Data Visualization']",Canada,5,8.00,224,,15.00,,Remote Job,Intermediate
Data Analysis,"Work with stakeholders across the organization to understand their SCM reporting needs and develop BI solutions to meet those needs.Analyze complex data sets to identify trends, patterns, and insights related to supply chain performanceDevelop and maintain reports and dashboards using Microsoft Power BI that provide real-time, actionable insights into the organization's SCM performance.Collaborate with cross-functional teams to identify, gather, and analyze data from various sources, including ERP systems, data warehouses, and external sources.Design and maintain data models, ETL processes, and data pipelines to support business needsUse statistical analysis techniques to identify trends, patterns, and insights in data that can be used to drive process improvements.Provide support and training to end-users on the use of BI solutions, including Microsoft Power BI.Continuously evaluate and improve BI solutions to ensure they meet the evolving needs of the organization.Develop and maintain documentation for data models, reports, and dashboards.Communicate findings and insights to key stakeholders through presentations and written reports.","['Data Interpretation', 'Data Analysis', 'Statistics', 'Data Science', 'Data Visualization', 'Microsoft Excel', 'Quantitative Analysis', 'Supply Chain Management', 'Data Science', 'Data Visualization', 'Microsoft Excel', 'Quantitative Analysis', 'Supply Chain Management']",United States,2,,,,,,Remote Job,Expert
Data Extraction,"We are looking for a skilled and experienced freelancer to help with a data extraction project. The project will last less than one month, and the skills required include screen scraping, web scraping, data extraction, data mining, data scraping, and proficiency in Microsoft Excel.The ideal candidate should be able to extract data from various websites and online sources, and organize it in a clear and structured format. They should have experience with automated data extraction tools, as well as the ability to manually extract data when necessary. To be considered for this project, please submit a proposal outlining your experience with data extraction, and how you can help us complete this project successfully. Please include links to any relevant past projects that demonstrate your expertise in this area.We look forward to hearing from you and potentially working together!","['Screen Scraping', 'Web Scraping', 'Data Extraction', 'Microsoft Excel', 'Data Scraping', 'Data Mining', 'Data Scraping', 'Data Mining']",United States,50,9.99,17,['Legal'],,,Remote Job,Expert
Front End Developer,"Job Description-Front End Software Developer Company:VeriFast is the #1 verification-as-a-service platform, bundling capabilities and analytics for Digital ID – KYC, Income Verifications, Employment Validations, Tax Transcript Data and rich analyses including full P&L, Cash Flow and Underwriting Transaction Management.We’re on a mission to make verification better for everyone. So whether you’re a business, applicant or developer, you’ve come to the right place, a place where you’re in control of your financial credentials.Think of us as an all-in-one verification station. By streamlining the process with an industry-leading platform, you can get verified and get on with your business faster. Safe, reliable, affordable- and with you every step of the way. That’s the promise of VeriFast.URL: https://www.verifast.com/Role Summary:We are looking for a Front End software developer who is motivated to develop and test new features and technical improvements in our existing platform. The individual should enjoy working with product stakeholders, software engineers and  developers, designers, and testers to improve and build great digital experiences.Responsibilities:Participate and collaborate in planning, development, testing, and delivery/deployment of solid, structured, and standards-compliant codeUnderstand the scope, project goals, and requirements and provide input towards practical solutions, innovations, and time estimationParticipate in ideation sessions, workshops, and road-mapping, contributing a perspective on improved production and development approaches, tools, and techniquesBring a perspective to the team that blends design sensibilities with the practicalities of web and mobile engineeringCollaborate in strategic planning of web, assessing opportunities for driving innovation from a development perspectiveTest, refactor, and optimize code to achieve the best performanceStrive for flawless and bug-free deliverables by making quality assurance a top priorityFollow industry best practices, and coding standards developed by TireWizard and contribute to internal and external knowledge sharingUnderstand our customers' business, their needs, and the technical opportunities and challenges that exist within their industriesQualifications:Bachelor Degree in Computer sciences or a related area is preferredExperience and proficiency in HTML, CSS, Java script, vueJS, UI/UX implementationsExperience and proficiency in Typescript, Responsive Design, Frameworks and libraries, cross-browser compatibility and  web performanceExperience working on GitHub, and cloud infrastructureAbility to translate technical requirements into elegant code solutions  Experience planning, prototyping, developing, and testing for web, mobile/tablet productsStrive for flawless and bug-free deliverables by making quality assurance a top priorityFocus on continuous improvement and UXExperience working in Agile/Scrum teamsStrong knowledge of software implementation best practicesAbility to adapt quickly to an existing, complex environment, and learn new concepts and softwareSelf-motivated, independent, detail-oriented, responsible team player, exhibiting exceptional relationship management skillsPassionate about building high-quality systems with software implementationProfessionalism and integrityStrong interpersonal and written communication skillsAbility to work in a fast-paced environment","['HTML', 'CSS', 'JavaScript', 'jQuery', 'Web Development', 'Website', 'Landing Page', 'Web Development', 'Website', 'Landing Page']",Canada,4,35.00,26,"['Tech', 'IT']",,"['25.00', '45.00']",Remote Job,Expert
Expert in GPT embedding (sentence embedding) (Portuguese language),"We need an Expert in GPT embedding (sentence embedding) (Portuguese language)For working advising our team on sentence embedding on our dataNOTE: A ideia é que a depender do resultado, a gente possa contratar full time. Mas a ideia é q inicialmente seja freelancer","['Machine Learning', 'Deep Learning', 'Data Science', 'Data Science']",Brazil,189,17.59,30,,,"['13.00', '40.00']",Remote Job,Intermediate
Senior/Staff Platform Engineer (Services team),"Location: Remote in EuropeSeniority: Senior/StaffHours: Full TimeAbout CraftAt Craft we are on a mission at re-defining productivity through software. We believe that current solutions are outdated, and bloated. We are building products which are fun - and effortless to use. Software which blends in the background, allowing individuals to focus on their tasks at hand - as it should be. Part of this goal is to provide a strong platform, so users can access & modify their data through APIs, or extend functionality through plug-ins.We’re looking for individuals who share this vision, and want to help us build a rock-solid and easy to use platform on top of the existing product.About the roleYou'll be working on Craft's core platform (including both client and backend side platform code), focusing on the APIs under the hood that ensure data operations work flawlessly with high performance and reliability.You'll be working together with a small, but highly experienced team, meaning you'll be able to have a strong impact on both technical and product decisions - as well as learn from experts in this domain.We're setting the bar extremely high when it comes to API flexibility, ease of use and performance - meaning we're looking to re-evaluate core architectural decisions and technologies we use in order to reach our desired goals - in other words, nothing is set in stone!Your responsibilities will include- Build APIs in the Core Platform to support new capabilities within Craft- Work with backend and client side databases- Design and implement algorithms that are highly performant, scalable and resilient against failures, and are easy to use by application developers- Build up solid knowledge of all of our platforms (Craft Web/Mac/iOS app, Craft Backend) to understand end to end system behaviour and data flow- Execute performance profiling on existing systems to understand key bottlenecks and improve on their performance characteristicsWhat we're looking for- You have strong computer science fundamentals, including knowledge of data structures, algorithmic complexity, and designing for performance and scalability- You have 2-5 years experience in building APIs or Platforms- You have strong analytical thinking, planning, and problem-solving skills- You have experience working with databases- You have experience with unit / automated testing- You have experience in NodeJS / Typescript or Swift, or you are able to learn and get up to speed quicklyOur CultureWe are looking for individuals who love APIs & Platforms - and are willing to go the extra mile to create a platform which is both easy to use, yet powerful.- You think outside the box. We are a small team, competing with giants - we won't succeed by just following the playbook. Identifying technological, leadership and cultural aspects which can help us deliver will be critical.- You put people first. You understand that we are a team of people, building a product for other people to use. You prioritize professional relationships with the broader team, and desire to be actively engaged in the wider community of Craft users.- You're pragmatic. You're an expert in technology and you also understand how certain components can impact the product. You can choose the right tradeoffs according to the maturity of the team, product and business needs.- You're a great communicator. Most of your impact will be achieved through communicating with people - both individuals you manage, and leaders from other parts of the business. You'll need to be able to express yourself and thoughts clearly, in a way which others can understand & learn from.","['Node.js', 'TypeScript', 'Database', 'Algorithms']",Hungary,2,,,"['Tech', 'IT']",,,Remote Job,Expert
A successful YT channel needs help migrating to Google Analytics 4 / Tag Manager,"Hello, I currently have a YouTube channel that is connected to Google Analytics and Google Tag Manager in order to sell my video course / e-commerce through ClickFunnels, a WordPress site, and UTMs.I am receiving an alert from Google Analytics that it is migrating to ""Google Analytics 4"" and I need someone to help my company move through this transition seamlessly through the end of the month. I assume it will be not a difficult job, maybe one day's worth of work, but since I do not know how to operate the technology in a way that doesn't 'mess up' the UTMs, tags, etc. I need your help :) Looking forward to hearing from you and if the work is done well, instant five star rating! :) Payment offer: $50","['Growth Analytics', 'Marketing Analytics', 'Data Analysis', 'Google Analytics', 'Google Tag Manager']",United States,35,12.49,27,"['Media', 'Entertainment']",50.00,,Remote Job,Expert
"SEO content writer experienced in Technology, AI, Data Science and Machine Learning topics.","We are looking for an experienced SEO content writer for website landing pages related to the Technology, AI, Data Science and Machine Learning topics.The copywriter should be familiar with the tech and AI development industries in order to prepare really engaging and relevant content.It’s a long-term project. Each landing page will be around 1000-3500 words. Detailed content plan with references and SEO tasks with keyword requirements will be provided.The content should be delivered as a Google Doc file. Only unique content will be accepted.Please provide:Similar concepts you have done in the past (in English), preferably in the AI, ML, Data Science and your rate per word (or per 500 words).","['Content SEO', 'Tech & IT', 'Content Writing']",Germany,30,31.33,33,,100.00,,Remote Job,Expert
Develop algorithm for image background removal,"We are looking for an experienced Python algorithm developer to develop an algorithm for image background removal.The algorithm should remove the background from images showing people, clothing, and objects shot before a white background in a photo studio. You should have experience developing machine learning models and optimizing them for performance. Please notice that standard models regularly used in Python library removebg will not be sufficient for that task.The expected quality should be on the same level as provided by https://www.remove.bg/","['Machine Learning Model', 'Model Optimization', 'Computer Vision', 'Image Processing', 'Python', 'Machine Learning', 'Algorithm Development', 'Machine Learning', 'Algorithm Development']",Germany,48,30.62,4.5,,,"['50.00', '180.00']",Remote Job,Expert
"Solution Engineer or Architect (Python, SQL and Databricks)","We are seeking a highly motivated and experienced Senior Professional Services Specialist to join our dynamic team. The ideal candidate will be responsible for providing professional and technical services to our clients. As a Senior Professional Services Specialist, you will be responsible for overseeing and leading complex projects for our clients in the real estate industry, providing expert-level guidance and support to our clients, ensuring successful implementation and adoption of our technology solutions, building and maintaining strong client relationships, managing project timelines, and ensuring client satisfaction. This is a senior-level position that requires excellent communication, leadership, and project management skills. The ideal candidate will have a strong background in professional services, client services, and technical expertise in the property technology industry.Duties and Responsibilities:- Work with clients to understand their business needs, requirements and expectations and develop customized solutions that meet those needs- Conduct products and services demonstrations and presentations to clients.- Lead complex implementation projects and act as the primary point of contact for clients throughout the project lifecycle.- Lead and manage multiple projects simultaneously, ensuring on-time and on-budget delivery- Provide expert-level guidance and support to clients on best practices for utilizing our solutions to meet their business needs.- Build and maintain strong relationships with clients, serving as the primary point of contact for all project-related matters and to ensure ongoing customer satisfaction and identify opportunities for upselling or cross-selling.- Collaborate with cross-functional teams, including product development, sales, and marketing, to ensure project success- Act as a subject matter expert for our technology solutions and provide training to clients and internal teams as needed to ensure successful adoption of our products and services.- Collaborate with internal teams to identify and prioritize product enhancements and new features based on client feedback and market trends.- Monitor project performance metrics and make data-driven decisions to optimize project outcomes- Stay up-to-date with industry trends and best practices and share knowledge with the team- Contribute to the development of best practices, methodologies, and tools to improve project delivery and client satisfactionSkills and Qualifications:- Bachelor's degree in a relevant field, such as computer science, data science, information technology or engineering- Minimum of 6 years of experience in professional services, client services or consulting, ideally in the property technology or real estate industries- Minimum 5 years of working experience in SQL, Python, data analysis, and business intelligence is mandatory- Minimum 3 years of working experience in Databricks is mandatoryProven track record of successfully leading complex projects and delivering high-quality results on-time and on-budget- Excellent communication and interpersonal skills, with the ability to build and maintain strong relationships with clients and internal stakeholders.- Strong analytical and problem-solving skills, with the ability to make data-driven decisions- Proven experience in project management methodologies, such as Agile or waterfall- Ability to work independently and collaboratively in a fast-paced, dynamic environment with multiple priorities and tight deadlines.- Strong attention to detail, organizational skills and a commitment to quality.Preferred Qualifications:- Master's degree in a relevant field- Experience with property technology (Prop Tech) products and services- PMP certification or equivalent project management certification- Experience with CRM systems and project management tools such as Salesforce and Jira.- Experience with data analysis and reporting tools such as Tableau","['Real Estate', 'Python', 'SQL', 'Databricks Platform']",Pakistan,95,12.43,32,,,"['12.00', '25.00']",Remote Job,Expert
Configure Google Analytics 4 for WordPress Site that has a 3rd party Booking/Payment solution,Hello! We are looking for an analytics specialist to quickly and effectively transition our analytics to GA4. We take bookings and payments on our WordPress website via a 3rd Party booking software called Fareharbor and the current analytics are installed via Tag Manager. Verification of accurate conversion tracking is essential to job completion.Ideally we are looking for someone who can complete the project by the end of this week at latest. Experience with cross-domain tracking and 3rd party conversion tracking is a bonus to us. Any questions at all please feel free to ask away. Thankyou for applying!,"['Google Analytics', 'Google Tag Manager', 'WordPress', 'Google Ads', 'Cross-Device Compatibility', 'WordPress', 'Google Ads', 'Cross-Device Compatibility']",Poland,4,25.83,312,,,"['15.00', '75.00']",Remote Job,Expert
"Data Scraping, Collection and Cleaning",Collect label and clean images for datasets. Typically in jpeg formats of large resolution.,"['Data Scraping', 'Data Entry', 'Data Collection', 'Data Collection']",Singapore,1,,,,,"['8.00', '25.00']",Remote Job,Intermediate
ML Engineer (Full-time/Part-time),"We have a quite complex full-stack python developer position for our ML startup.You'll need to closely collaborate with data science team and develop high quality deliverables for our customers.Requirements for the candidats: At least 5 years of experience of software development and strong competence in MLWillingness to learn new technologiesAbility to write clean and efficient codeExperience with Python, .NET, Javascript, Docker, Kubernetes, Argo, Spark and AWS as a plus","['API Integration', 'Python', 'Machine Learning', 'Node.js', 'JavaScript', 'Artificial Intelligence', 'Node.js', 'JavaScript', 'Artificial Intelligence']",Poland,3,22.00,2.3,"['Tech', 'IT']",,"['25.00', '36.00']",Remote Job,Intermediate
Ai tools,"hello there!i am looking for someone to create a desktop application withAI tools ( content generator, landing, opting creation, optin thanks vidéo scrip, welcome post, squeeze page copy generator,lead magnet idea generator,content tools, free report tools, emails tools, hooks idea generator, Facebook post, etc...) any propostions will be welcome.thanks","['Artificial Intelligence', 'Machine Learning', 'Desktop Application', 'Machine Learning', 'Desktop Application']",United Kingdom,13,8.05,220,,,"['18.00', '40.00']",Remote Job,Intermediate
Python Scripting,"I am trying to solve a data science problem to which meals I can make and need help generating a script to do so. I am imagining I run a restaurant. I have a csv of all the possible meals my restaurant can make attached here. Each meal has 6 courses. Each course has different dishes that I can only make a certain number of times because i don't have enough ingredients. The csv I have attached contains every possible combination if meals I could make if i was not constrained by supply. However, because I am constrained by supply, and i want certain dishes to be rarer than others, I have included next to each dish, the probability for how many times that dish can appear in my end result (for example, .5 means when i look at my end result, I want that dish to appear 50% of the time).The csv I provided gives every possible combination if ingredients were not a constraint. However, because they are, we need to ensure that not every meal on this list is created. The end output of this should be a list of meals (that will be less than X) that each meal only appears once and is subjected to constraints i have on ingredients.What i need back is a script that will generate what my list of meals could look like.The end output needs to adhere to the following conditions to be successful:1) Each meal must be unique (it can only appear once in the final set). It's fine if items appear more than once but each unique combination of all 6 courses should only appear one time. We want to give each person a unique meal experience.2) In the final output, each dish should appear as close as possible to the distribution provided next to it. For example, Lettuce has a distribution of .5 so it should appear in as close to half of the meals as possible.Thanks for this food based data science problem! Happy to explain more.","['Python', 'Data Scraping', 'Automation', 'Data Science', 'Data Science']",United States,1,,,,500.00,,Remote Job,Expert
Full Stack Developer - Aedeon,"Mactores is a trusted leader among businesses in providing modern data platform solutions. Since 2008, Mactores have been enabling businesses to accelerate their value through automation by providing End-to-End Data Solutions that are automated, agile, and secure. We collaborate with customers to strategize, navigate, and accelerate an ideal path forward with a digital transformation via assessments, migration, or modernization.Mactores is embarking on a journey to create a cutting-edge Solutions Marketplace platform, and we're seeking a Full Stack Developer to join us in this mission. As a team member, you'll be part of a talented group of engineers, product managers, and designers responsible for building our platform to its full potential.With a focus on delivering high-quality and top-performing solutions, you'll bring your expertise to the table by owning Full Stack Development and writing code that is efficient, reliable, and adheres to industry standards. You'll have the opportunity to work on various projects and apply your knowledge of software architecture to design, develop, and debug applications while continuously improving our platform's architecture.If you're passionate about problem-solving and eager to be part of a dynamic, world-class team, then Mactores is the perfect place for you. Our office culture is inclusive, promoting creativity, productivity, and a supportive environment for you to be your best self. Join the Mactores team today and contribute to shaping the future of the Solutions Marketplace.What you will do?1. Design, develop, and maintain web applications using Node, Angular, React, and Document DB2. Write clean, maintainable, and efficient code3. Collaborate with cross-functional teams to identify and solve complex technical problems.4. Contribute to the development of new features and improvements to existing ones.5. Ensure the technical feasibility of UI/UX designs6. Optimize applications for maximum speed and scalability7. Participate in code reviews and contribute to the development of best practices and standardsWhat are we looking for?1. Bachelor's degree in Computer Science or a related field2. Strong experience with Node, Angular, React, and Document DB3. Experience with Agile development methodologies, particularly Scrum4. Strong understanding of RESTful API development5. Knowledge of front-end technologies such as HTML, CSS, and JavaScript6. Experience with Git and version control systems7. Ability to work in a fast-paced, deadline-driven environmentLife at MactoresWe care about creating a culture that makes a real difference in the lives of every Mactorian. Our 10 Core Leadership Principles that honour Decision-making, Leadership, Collaboration, and Curiosity drive how we work.1. Be one step ahead2. Deliver the best3. Be bold4. Pay attention to the detail5. Enjoy the challenge6. Be curious and take action7. Take leadership8. Own it9. Deliver value10. Be collaborativeWe would like you to read more details about the work culture on https://mactores.com/careers The Path to Joining the Mactores TeamAt Mactores, our recruitment process is structured around three distinct stages:Pre-Employment Assessment: You will be invited to participate in a series of pre-employment evaluations to assess your technical proficiency and suitability for the role.Managerial Interview: The hiring manager will engage with you in multiple discussions, lasting anywhere from 30 minutes to an hour, to assess your technical skills, hands-on experience, leadership potential, and communication abilities.HR Discussion: During this 30-minute session, you'll have the opportunity to discuss the offer and next steps with a member of the HR team.At Mactores, we are committed to providing equal opportunities in all of our employment practices, and we do not discriminate based on race, religion, gender, national origin, age, disability, marital status, military status, genetic information, or any other category protected by federal, state, and local laws. This policy extends to all aspects of the employment relationship, including recruitment, compensation, promotions, transfers, disciplinary action, layoff, training, and social and recreational programs. All employment decisions will be made in compliance with these principles.","['Node.js', 'Angular', 'React', 'Git', 'HTML', 'CSS', 'JavaScript', 'DocumentDB', 'Web Application', 'API Integration', 'API Integration']",United States,69,20.55,25,,,"['15.00', '20.00']",Remote Job,Expert
Data analyst,I’m currently looking for a data analyst with extensive experience building retail and commercial dashboard for a small startup  business,"['Microsoft Excel', 'Data Visualization', 'Data Science', 'Data Analysis', 'Analytics', 'Artificial Intelligence', 'Big Data', 'Data Science', 'Data Analysis', 'Analytics', 'Artificial Intelligence', 'Big Data']",United Arab Emirates,1,,,"['Retail', 'Consumer Goods']",2000.00,,Remote Job,Expert
Scrape website protected by Kasada without using browser automation,"I am looking for an expert in reverse engineering websites protected by Kasada.io. Kasada uses an obfuscated JavaScript code to protect websites from scraping.I have a working solution using browser automation tool like selenium and playwright. This solution is very slow and resource intensive.I need this to be done using pure http requests if possible, preferably using Python. If someone has experience in it, I would love to work with you. There will be future opportunity as it will certainly break and we need someone to be around for maintaining it.I will share a website that uses Kasada in chat. You can also find some in their website too.","['Data Extraction', 'Scrapy', 'Python', 'Data Scraping', 'JavaScript']",Australia,7,,515,,,"['25.00', '40.00']",Remote Job,Expert
Dashboard Builder,Dashboard to place multiple bets on online betting/exchange accounts simultaneously.,"['API', 'API Integration']",United Kingdom,2,,,"['Media', 'Entertainment']",,"['15.00', '40.00']",Remote Job,Entry level
Google Tag Manager & Analytics Specialist for Hydrogen/Shopify Platform,"We're searching for a highly experienced Google Tag Manager and Analytics Specialist to integrate and optimize our website tracking across multiple advertising platforms on our Hydrogen and Shopify-based website - https://eloesports.com/.This role requires extensive expertise in deploying and managing pixels/data streams across the following advertising platforms:MetaGoogleMicrosoftRedditSnapchatTwitterTikTokKey responsibilities:Set up, verify, and troubleshoot the tracking of a multitude of events including, but not limited to, page views, content views (blogs and products), lead generations, add-to-cart actions, shipping info addition, checkout initiation, checkout progress, and lead captures.Establish advanced analytics and conversion tracking across all advertising platforms.Ensure the passing through of all browser and server-side events (Conversions API) for maximizing tracking capabilities and audience building. Also to block any local traffic or subdomain traffic that we do not want in the dashboards and pixel analytics. Collaborate with the internal team to understand what data needs to be collected and ensure it aligns with our analytics goals.The successful candidate will be familiar with working on Hydrogen, Oxygen, Remix, Shopify, and Google Tag Manager.Qualifications:Proven experience in implementing and managing Google Tag Manager, as well as setting up analytics and pixels on various platforms.Working knowledge of Shopify's native integrations.Expertise in Hydrogen, Oxygen, and Remix platforms.Proficient in managing and optimizing analytics across Meta, Google, Microsoft, Reddit, Snapchat, Twitter, and TikTok.A deep understanding of both browser events and server-side events (Conversions API).Excellent problem-solving skills and the ability to troubleshoot data/analytics issues.Ability to work independently and collaborate with a team.Please apply if you are up to the challenge of navigating the complexities of our systems to help us maximize our tracking and audience-building capabilities. We look forward to seeing how you can elevate our analytics strategy.Note: Only candidates with proven experience in the specific platforms listed above will be considered. Please provide examples of your work in this area.","['Google Analytics', 'Google Tag Manager', 'Shopify', 'Shopify']",Canada,8,35.00,49,"['Engineering', 'Architecture']",,,Remote Job,Expert
Social Media Analytics Scraping Expert,"Looking for a data scraping expert who can scrape data for Social media channels - Instagram, Facebook, Twitter etc.,Most Critical - InstagramEg: Assume there are 04 brands - A, B, C, D on Instagram for a particular Industry (Fashion). Requirement is to fetch the data from the Accounts of Brands A, B, C, D.","['Data Scraping', 'Data Mining', 'Python', 'Python']",India,1,,,,,"['9.00', '59.00']",Remote Job,Expert
need Data science Trainer for training,"HiWe are looking for experienced person in ""Data science  "" For Training.Payment will be : 1 student : 150002 students : 250003 students : 320004 students :400005 Students : 50000Duration- 50HrsTimings- Anytime After 7pm IST will worksAny 2hrs Before 10am IST","['Python', 'Data Science', 'Excel sessions', 'SQL session', 'powerBi', 'SQL session', 'powerBi']",India,19,,,,181.00,,Remote Job,Expert
Senior Big Data Engineer,"Experience with Big Data technologies such as Snowflake, Databricks, PySpark.Expert level skills writing and optimizing complex SQL. Experience with complex data modeling and ETL/ELT design, including defining SLAs, performance measurements, tuning and monitoring. Experience building/operating highly available, distributed systems of data extraction, ingestion, and processing of large data sets. Demonstrated efficiency in treating data: data lineage, data quality, data observability and data discoverability. In-depth and hands-on knowledge of the modern AWS Data Ecosystem, including AWS Glue, AWS Athena, AWS S3, and AWS Lambda. Experience with relational and NoSQL databases. Experience with programming languages such as Python, Java and/or Scala. Proficiency with Linux command line and systems administrations. Knowledge of cloud data warehouse concepts. While not mandatory, experience in building and operating data pipelines and products in compliance with the data mesh philosophy would be beneficial. Work Experience:8+ years experience in commercial software development.Experience directing and delegating 4+ engineers for 2 or more years with a proven record of driving multiple projects to successful and timely completion.","['SQL', 'Java', 'AWS Glue', 'Big Data', 'Snowflake', 'PySpark', 'ETL Pipeline', 'Python', 'Scala', 'ETL Pipeline', 'Python', 'Scala']",India,112,,,"['Tech', 'IT']",1500.00,,Remote Job,Intermediate
Power BI Consultant,"We are an Insurance Broker and we are looking to create 3x Dashboards for our firm for 3 different audiences. Our data source is a custom-built CRM system using 2x JSON Exports and an Excel. We would like support, advice and guidance on the best way to future proof our reporting by getting the most out of POWER BI to ensure that we make the right choices to develop our reporting capabilities in the future. We would like the succesful applicant to be able to create the framework for our long term reporting capabilities by creating relationships between different data sets and create simple dashboards that we can build on after the project has finished. Remote Work is Fine","['Microsoft Power BI', 'Data Modeling', 'Microsoft Power BI Data Visualization', 'Business Intelligence', 'Microsoft Power BI Data Visualization', 'Business Intelligence']",United Kingdom,2,,,,,"['20.00', '50.00']",Remote Job,Intermediate
Experienced Data Scientist with AWS Expertise for Model Deployment and MLOPS,"Background:I am currently working on building a platform that utilizes React and AWS as the backend infrastructure. My objective is to develop a powerful classification model trained on customer data and deploy it onto the cloud. Additionally, I need to incorporate company-specific data for data visualization on the front-end.Responsibilities:As an experienced data scientist with expertise in Python and model building, I have already created the model locally in a Jupyter notebook. I require assistance from a knowledgeable AWS professional who can demonstrate and teach me the following tasks through an audio call with screen sharing:Uploading tabulated datasets onto AWS for training purposes.Uploading tabulated company-specific datasets onto AWS for visualization purposes.Training and uploading the model onto AWS using SageMaker Studio, including the necessary pip installation of required packages.Running the model on the original customer dataset and creating a new column with the model's predictions.Creating an automated pipeline to execute the model on newly ingested customer data, generating predictions, and appending them to the original dataset.Implementing MLOPS strategies to monitor the model's performance and developing an automated function for model retraining.Requirements:I am specifically looking for an individual with prior experience working extensively with AWS. If you have a success rate of 95% or higher in similar projects, I encourage you to apply. Your expertise in AWS and proficiency in executing tasks such as data engineering and machine learning on the platform are essential.If you are an AWS professional with a proven track record in data engineering and model deployment, I would appreciate your support. Please provide examples of your prior work and indicate your availability for an interview.ONLY APPLY if you have 90%+ user rating. MUST speak fluent English","['Amazon Web Services', 'Python', 'Machine Learning', 'MLOps', 'Data Science', 'Machine Learning', 'MLOps', 'Data Science']",United Kingdom,2,,,,,"['15.00', '20.00']",Remote Job,Expert
Power Bi,"A Power BI developer is a professional who is responsible for developing and administering Power BI tools. They are responsible for transforming raw data into meaningful insights through interactive and user-friendly dashboards and reports.The role of a Power BI developer is vital for businesses because of the executive, strategic, and managerial roles and responsibilities that come with it. Power BI developers are expected to perform a wide range of tasks such as reporting, building dashboards, building data models, analyzing datasets, and administration of Power BI tools.","['Microsoft Power BI', 'Data Visualization', 'Data Analysis', 'SQL', 'Microsoft Excel', 'Data Analysis', 'SQL', 'Microsoft Excel']",India,1,,,,,"['15.00', '40.00']",Remote Job,Entry level
Matillion Expert for ongoing consulting,"We are looking for an expert level Matillion user to join our team part time for a period of 1 month initially with the option to extend to 3 months or more once we are satisfied with the performance.You will be working closely with our team and will be part of our extended team servicing our client requirements and consulting with us on a regular basis.What we are looking for- Ninja level expertise on Matillion, execution complex chains and transformations- Really good at troubleshooting- Good exposure to Snowflake- SAP exposure and working with SAP data is an added advantageLooking forward to working with wonderful people. Feel free to ask any questions.","['Data Processing', 'Matillion', 'Data Warehousing & ETL Software', 'ETL', 'Snowflake', 'ETL', 'Snowflake']",India,45,20.82,9.8,"['Tech', 'IT']",,"['15.00', '25.00']",Remote Job,Expert
ML Platform Engineer,"Take responsibility for all aspects of software engineering, from design to implementation, QA, maintenance, and support.Touch code at every level – from the UI, backend microservices, database, big data processing, and operations, to CD/CI automation.Collaborate closely with data science teams to define requirements, discuss solutions, and develop high quality deliverables for our customers.Take ownership for the quality of the codeSkills: Computer Science degree or equivalent experienceAt least 5 years’ experience of commercial software development with exposure to ML practices.Willingness and ability to take on new projects and technologies.Ability to break down complex problems into simple solutions.Strong analytical skills and desire to write clean, correct and efficient code.Sense of ownership, urgency and pride in your work.Experience with Python, Java, Docker, Kubernetes, Argo, Spark and AWS / Azure cloud services are plus","['Java', 'Apache Spark', 'MLflow', 'Python', 'Kubernetes', 'PostgreSQL', 'AWS CloudFormation', 'Machine Learning', 'AWS CloudFormation', 'Machine Learning']",India,112,,,"['Tech', 'IT']",1200.00,,Remote Job,Intermediate
Seeking GTM Expert to Track Events on LearnWorlds Platform,Seeking a GTM expert to resolve event tracking issues on the LearnWorlds e-learning platform. Quick and efficient setup of basic events required. Prior experience with GTM and familiarity with LearnWorlds preferred. Requirements:- Proficiency in GTM setup and troubleshooting- Strong event tracking and data integration skills- Knowledge of LearnWorlds platform a plus,"['Google Tag Manager', 'Google Analytics', 'learnworlds', 'learnworlds']",Portugal,1,,,['Education'],,"['18.00', '45.00']",Remote Job,Intermediate
Data Mining Course,"Hello there.I need an expert person that knows ""Data Mining Course"", It is a course in Computer Engineering, If you know this course very well, please send me your proposl.Note: Book name: ""772s Data Mining Concepts and Techniques 2nd Ed""Regards.","['Scala', 'SQL', 'Data Analysis Expressions', 'Multidimensional Expressions', 'Wolfram Language', 'R', 'Google Analytics', 'ActivTrak', 'Altair Monarch', 'AnyLogic', 'Apache Hive', 'BigQuery', 'BIRT', 'Chartio', 'Cognos', 'Domo', 'GoodData', 'Google Tag Manager', 'Grow', 'Kissmetrics', 'KNIME', 'Looker', 'Microsoft Power BI', 'Data Visualization', 'A/B Testing', 'Big Data', 'Business Intelligence', 'Data Analytics', 'Data Interpretation', 'Funnel Testing', 'Hypothesis Testing', 'Machine Learning', 'Statistical Analysis', 'Statistics', 'Dashboard', 'Data Analysis', 'Presentations', 'Query Development', 'Report', 'Marketing Analytics', 'Customer Service Analytics', 'Growth Analytics', 'Data Mining', 'Python', 'Data Entry', 'Lead Generation', 'Microsoft Excel', 'RapidMiner', 'Data Scraping', 'Lead Generation', 'Microsoft Excel', 'RapidMiner', 'Data Scraping']",Turkey,131,,1.1,"['Tech', 'IT']",20.00,,Remote Job,Intermediate
Data Clean Up and Validation,Manually clean up data and verify accuracy.I have two Google Sheets. Both have 50 columns with names and 65 rows with dates.  Need someone to manually go through and make sure the right values are assigned in the right cell under each name and date.See attached screenshot for task example.,"['Google Sheets', 'Data Entry', 'Accuracy Verification']",Canada,5,7.91,409,"['Tech', 'IT']",,"['4.00', '8.00']",Remote Job,Entry level
Google Analytics Developer,"Hi there,We are looking for someone who can help us deploy GA-4 on our website. It's a simple job that would require a bit of handholding from your side to us. You would be required to deploy the code and flows required for us to manage the analytics of our side. Looking forward to work with you on this project soon.","['Google Analytics', 'Google Tag Manager', 'Analytics', 'Analytics']",India,2,,,,60.00,,Remote Job,Expert
"Power BI - Un-pivot Dataset add running totals column for each (Actual, Budget, Remaining)","I have table with Date field called ATTRIBUTE, Field called Spreadsheet field and column called VALUE. I need to create a new table and un-pivot the dataset by the Spreadsheet field (Actual, Budget Remaining)Then Running totals for the Actual, Running total for the Budget and running total for Remaining columns must be added.","['Microsoft Power BI', 'Data Analysis', 'Business Intelligence', 'Business Intelligence']",South Africa,1,,,,15.00,,Remote Job,Intermediate
Langchain App (Generative AI),"I want to build this: Product: User wants to create the marketing plan (marketing plan include advance marketing channels like NFT). Input: user will define about his market, audience etc Out put: A marketing plan based on his market and advance marketing techniques (based on the data we will give to the model).",[],,14,,,"['Media', 'Entertainment']",150.00,,Remote Job,Intermediate
Langchain App (Generative AI),"I want to build this: Product: User wants to create the marketing plan (marketing plan include advance marketing channels like NFT). Input: user will define about his market, audience etc Out put: A marketing plan based on his market and advance marketing techniques (based on the data we will give to the model).",[],,14,,,"['Media', 'Entertainment']",150.00,,Remote Job,Intermediate
Google Analytics 4: secret & client keys for API calls,"Hello,I have done the migration of UA3 websites to GA4. Unfortunately, I don't understand how Google API is working and how to provide secret key and client id/key.Please let me know if you can help on this quickly.Thakns","['API', 'Google Analytics API']",Belgium,12,6.00,2.4,,30.00,,Remote Job,Expert
LLM advice for Automated Mortgage Underwriting,"MortgageBloc (www.Mgb.ai) aims to disrupt mortgage underwriting through automation, replacing slow and fraud-prone processes with a fast and secure one. We need advice on which LLM’s we should be using to:1. Provide accurate bank transaction analysis: to categorize user bank transactions2. Automate income and expenditure calculations to provide summaries The LLM should improve accuracy over time. We will also need advise and assistance on implementing the correct LLM.","['Machine Learning', 'AI Model Integration']",United Kingdom,4,,,,,,Remote Job,Expert
Google Looker Studio Specialist,"We are looking for a skilled professional to assist us in utilizing Google Looker Studio for our data analysis needs. The ideal candidate will be knowledgeable in Google Data Studio and have experience in implementing data visualization tools. This is a short-term project, with a duration of less than 1 month, but we are looking for a long term partner.As our Google Looker Studio Specialist, you will be responsible for creating and managing data visualizations for our team. You must have strong communication skills to collaborate with our team effectively. We are looking for someone who can help us optimize our data analysis process by providing insights into our data.If you are interested in this project, please submit a proposal with details on how you can help us with this project. Please include links to your past projects that showcase your experience with Google Looker Studio and data visualization tools. We look forward to working with you!We integrate with the following platforms into Looker Studio, which you need to understand:- Bitrix24- Salesforce- Google Analytics- Google Sheets- Google Ads- Meta Ads/Platform- LinkedIn Ads",['Google Data Studio'],Denmark,46,31.21,60,,,"['10.00', '20.00']",Remote Job,Expert
Microsoft Power Automate & Power BI Developer,"Opportunity for an Onsite Power Automate and Power BI DeveloperWe have an exciting opportunity for a skilled Power Automate and Power BI developer to join our team and take on an onsite role in the United Kingdom. We are seeking a professional who can effectively automate workflows using Power Apps and has a strong grasp of Power BI for building insightful reports. Please find the detailed responsibilities and requirements below - Responsibilities:* Design, develop, and deploy Power Apps solutions to address business needs and streamline processes.* Create and maintain Power BI reports and dashboards for data analysis and visualization.* Collaborate with business stakeholders to gather requirements, understand user needs, and recommend appropriate solutions.* Develop and customize Power Apps components, including canvas apps, model-driven apps, and portals, to meet specific business requirements.* Integrate Power Apps with various data sources, such as SharePoint, Dynamics 365, Azure, SQL databases, and external APIs.* Implement data modeling, data transformation, and data cleansing techniques within Power BI.* Optimize Power Apps and Power BI solutions for performance, scalability, and security.* Conduct testing and debugging of applications and provide ongoing support and maintenance.* Stay updated with the latest trends, features, and best practices in the Microsoft Power Platform ecosystem. Requirements:* Bachelor's degree in Computer Science, Information Technology, or a related field.* Minimum of 2 years of hands-on experience in developing solutions using Microsoft Power Apps and Power BI.* Strong proficiency in Power Apps development, including building canvas apps, model-driven apps, and using Power Apps formulas, controls, and connectors.* Proficiency in Power BI development, including creating reports, dashboards, data modeling, and implementing advanced visualizations.* Solid understanding of data integration techniques and experience integrating Power Apps with various data sources.* Experience with Microsoft Azure services and SharePoint integration is a plus.* Knowledge of Power Automate (formerly Microsoft Flow) for workflow automation is desirable.* Strong analytical and problem-solving skills with the ability to translate business requirements into technical solutions.* Excellent communication and collaboration skills to work effectively with cross-functional teams and stakeholders.* Self-motivated, detail-oriented, and able to work independently with minimal supervision.* Microsoft Power Platform certifications, such as Power Apps and Power BI certifications, are highly desirable.Interested candidates are kindly requested to share their updated resumes. Interviews will be conducted next week. Successful candidates will have the opportunity to join our company in the United Kingdom within the next 2-3 weeks. Please note - I am preferred to freelancers for this position.Regards,Chetan","['API Integration', 'Presentations', 'Microsoft Power BI', 'Data Visualization', 'Microsoft Power BI Data Visualization', 'Microsoft Power BI Development', 'Power Query', 'Data Modeling', 'SQL', 'Data Analysis', 'Microsoft Power BI Data Visualization', 'Microsoft Power BI Development', 'Power Query', 'Data Modeling', 'SQL', 'Data Analysis']",India,57,11.14,563,,,"['20.00', '50.00']",Remote Job,Intermediate
"Data scientist with oracle ,ODI - Job Support","HiWe need Freelancer who had experience in""  Data scientist with oracle ,ODI ""1. Data scientist with oracle (text mining) 2. Experience in oracle text mining (ODI), oracle expertise, coding - in ODI they have to build data models, model optimizations and model cataloguing 3. Dashboard creation Main stack: DW - oracle 19C ODI - oracle data integrator SSIS to push data into oracle DW OSI PIIt's  a Job Supporting Projectyou need to connect with our consultant through Zoom Meeting and help him to complete the tasksyou need to work on his system(Remotely) by taking mouse controls using Zoom2hrs/day  5days/weekFor that we will pay youUSD 300$ MonthTiming - anytime before 10a.m IST Or anytime after 7p.m IST will be fine","['Data Science', 'Oracle Database', 'Oracle Data Integrator', 'Oracle Data Integrator']",India,30,,,,300.00,,Remote Job,Expert
Data analyst,"I need my data analysed for a presentation in the report, its a scownrific report so I need to see correlations","['Data Analysis', 'Microsoft Excel']",Israel,1,,,,,,Remote Job,Intermediate
Artificial Intelligence Health Technology Application,"I'm looking for somebody with excellent development experience, and some experience with artificial intelligence to help me plan the building of a health technology application that leverages psychology and artificial intelligence to improve user health outcomes. You must be easy to work withHave a track record of lean and iterative development You must be extremely creative and an excellent problem solverThis MVP will form the basis of the application for user testing, and then will be used for fundraising.","['Artificial Intelligence', 'Machine Learning', 'Python', 'Data Science', 'Machine Learning', 'Python', 'Data Science']",United Kingdom,28,14.78,2.8,,,,Remote Job,Expert
Freelance Julia Optimization Engineer (Potential for Long-Term Contract),"We are currently seeking a Freelance Julia Optimization Engineer with expertise in Docker and RabbitMQ to join our dynamic team on an hourly basis. The ideal candidate will have a strong background in mathematical optimization, combined with substantial proficiency in Julia (or Python) programming. This role is an exciting chance to contribute to our cutting-edge optimization engine and, for the right person, may transition into a long-term, full-time contract.Responsibilities:-Maintain and enhance our optimization engine, currently developed in Julia, and deployed using Docker.-Understand and optimize our mathematical models, improving their efficiency and effectiveness.-Utilize RabbitMQ to ensure reliable and efficient communication between various service components.-Debug, troubleshoot, and enhance the existing system for optimal performance and scalability.-Collaborate with our team to comprehend requirements, implement solutions, and provide technical consultation.-Document all work clearly and comprehensively.Requirements:-Robust experience in Julia or Python programming, with a preference for candidates proficient in Julia.-Deep knowledge of mathematical optimization techniques and their practical applications.-Practical experience with Docker, including the deployment, scaling, and management of Docker containerized applications.-Proficient understanding of RabbitMQ and AMQP for handling message-oriented middleware.-Excellent problem-solving skills, capable of debugging complex software systems.-Strong written and verbal communication skills in English.Nice to have:-Familiarity with other message brokers like Kafka or ActiveMQ.-Previous experience in a similar role maintaining and optimizing software systems.-Background in Mathematics or Computer Science.We're looking for a passionate optimizer, capable of solving complex problems and enjoying a dynamic, fast-paced environment. This role is remote, allowing for flexible work arrangements. As such, solid communication skills and the ability to work autonomously, as well as with teams across different time zones, are key.If you're interested in the possibility of transitioning from freelance to a more permanent position, please highlight this in your application.Include the phrase ""Freelance Julia Optimizer"" in your application to confirm you've read the entire job description.We look forward to exploring the potential of this professional relationship!","['Docker', 'Python', 'Julia', 'Operations Research', 'Mathematical Optimization', 'Data Science', 'Mathematical Optimization', 'Data Science']",Sweden,1,,,,,"['15.00', '60.00']",Remote Job,Intermediate
Six degrees Intelligence - Technology Consultant,"-Sixdegrees Intelligence IntroductionI am Harper and I represent Six Degrees Intelligence (www.sixdegrees.cn), a premier expert network service provider with over 1 million global experts available in our expert pool. We are currently the third largest expert network research provider in China and quickly expanding worldwide. We are always looking for various experts in every field to support our global clients'market research. The consultation could be a 60 mins call conference or in person meeting. And we will compensate our advisors hourly. (50-500USD/hr, at choice) # Our End clientCurrently we are serving various clients from Global Private Fund/Hedge Fund/VC/Tier 1 Consulting institutions.  # Consultation process1. Once we recieve a new request from client, we will contact related advisors to check if he/she could share and participate in. 2. We will send advisor's brief profile to client, if client select, we will arrange an online conference or in-person meeting. 3. Issuing payment through here or other methods. If you are interested to be our advisor, please feel free to contact me and leave you CV or Linkedin or Contacts, or ping me here!","['Tech & IT', 'Artificial Intelligence', 'Business Intelligence', 'Business Intelligence']",China,1,350.00,0,"['Tech', 'IT']",,"['50.00', '400.00']",Remote Job,Expert
Powerful Data Visualisation: social and sustainability. Mock up now + extension into product dev,"Creating a mockupI am in the design stage of a tool that gathers data from surveys. The tools is finalised by a powerful data visualisation that provides a good picture for my clients. The surveys allow users to include multiple answers to the same question. I would like to explore the possibility of rendering the findings as a Sankey diagram, or as an Heat, Circular Map.At this stage I need a good Mockup, hence the budget, that allows me to gather market interest. I would prefer to work with someone that can stay on board later on for a longer implementation, if the market response is positive. This person should also help me at this stage making a good decision as to what representation to use (I am not fixed on either Sankey or Circular).The data are in the realm of social / sustainable impact. Bonus point if you already have work to show powerful narrative in this realm.I would start with a call to share the data set, understand the source and the format I get back from it, and what I would like the story to tell. As an output, a Mockup of the diagrams that the data could produce.","['Data Visualization', 'Microsoft Excel']",Netherlands,2,,,['Education'],200.00,,Remote Job,Expert
Expert in Data Studio Reports,"Hi there!I am seeking a highly trained Google Data Studio Expert to help me out with creating (good looking!) reports for multiple clients. Depending on the client, different measures are important, e.g.: - Website traffic overview: totalclicks/usersconversionssales volumeGender and Age (by impressions and clicks)region (map)or- Online shop salesFeatured ArticleIn the shopping trolleyPurchased productstotal salesrevenue per order- Website traffic overview: a look at the different pathsDirect accessclicks/usersconversionsSales volumeGender and Age (by impressions and clicks)region (map)- Organic Trafficclicks/usersconversionsSales volumeGender and Age (by impressions and clicks)region (map)- Google adsclicks/usersconversionsSales volumeGender and Age (by impressions and clicks)region (map)- Social media (Facebook, Instagram, Pinterest)clicks/usersconversionsSales volumeGender and Age (by impressions and clicks)region (map)- Ads (for each campaign)CostsimpressionsclicksClick Rate (CTR)Cost per click (CPC)conversionsExchange ratecost per conversionConvert value/costCallsSearch terms (by impressions, clicks and CTR, conversions)Gender and Age (by impressions and clicks)region (map)Keyword Quality Score (Top 20 Impressions)- Website behavior (by pages)dwell timeNumber of pagesScrollbouncing- Social Media (each for Facebook, Instagram, Pinterest)Highlights, Reels, Posts,..Likes, Shares,..Gender and Age (by impressions and clicks)region (map)- Website behavior (by pages)dwell timeNumber of pagesScrollbouncing- organicclicks/usersconversionsExchange rateTop 30 keywords including positionTop 5 organic competitorsGender and Age (by impressions and clicks)region (map)- Website behavior (by pages)dwell timeNumber of pagesScrollbouncing- Google business profileviewswebsite clicksDirections clicksphone callsAverage ratingNumber of all ratingsLast 2 reviews- Website behavior (by pages)dwell timeNumber of pagesScrollbouncingWithin the next 3-4 weeks we will have to create around 15 reports. Are you interested in this job? Then I will be very happy to hear from you!","['Google Data Studio', 'Data Visualization', 'Data Analysis', 'Google Analytics', 'Data Modeling', 'Data Analysis', 'Google Analytics', 'Data Modeling']",Spain,2,20.00,0,"['Sales', 'Marketing']",,"['5.00', '50.00']",Remote Job,Expert
GA Tracking + GA Developer needed,Need someone who knows the following:Knows how to upgrade from UA to GA4Knows how to trasnfer UTM paramters across different pages and cross domain trackingKnows how to set up goals and events (via GTM)Knows how to set up or fix data layerKnows how to do 3rd party tool integrations fro conversions etcKnows how to use JS for rules in GAKnows how to use data on screen and pass it as conversion/ecmmorcer- WITHOUT datalyer being present,"['Google Analytics', 'Google Tag Manager', 'JavaScript', 'Analytics', 'JavaScript', 'Analytics']",India,60,10.67,41,"['Engineering', 'Architecture']",,"['15.00', '25.00']",Remote Job,Intermediate
Create OCR models for the Burmese Language (Myanmar),We need OCR model Burmese Language for handwriting NRC,"['Deep Learning', 'Machine Learning', 'Machine Learning Model', 'OCR Algorithm']",Vietnam,1,,,,1000.00,,Remote Job,Expert
Prompt engineer ChatGPT AI,"Hi,I am getting perfect results with one prompt on ChatGPT-4 on the chat version.I am looking to get similar results with one prompt on ChatGPT-3.5 with the OpenAI APII will give you my prompt on ChatGPT-4 and you will have to help my dev getting the perfect prompt to get similar results with ChatGPT-3.5 with the OpenAI API",['Artificial Intelligence'],United States,240,6.22,334,,250.00,,Remote Job,Expert
Implementation of Python data connectors,"We are looking for the development of several connectors in Python inside our software product for analytics on machine data. There are two types of connectors: data sources and alert channels. Data sources fetch either historic or live data from various sources, typically REST APIs, and send them either to Elastic or Kafka. The alert channels listen to Kafka topics, apply certain criteria to the data and if the criteria are met, send an event to a data sink (also typically a REST API). The framework code and examples of other connectors are already available. We are looking for a medior or senior developer who can write clean, well documented and tested code that is robust against edge cases such as missing data, and who can work with a certain level of independence. We can give an introduction to our existing codebase and indicate where the connectors should be implemented. Experience with timeseries data engineering or Elastic or Kafka is a big plus. Being able to work (partially) in our offices close to Ghent is a plus. Being able to start quickly is a big plus.","['Data Engineering', 'Apache Kafka', 'Elasticsearch', 'Python', 'API']",Belgium,18,39.54,156,,,"['25.00', '50.00']",Remote Job,Intermediate
Algorithm,"for project in the medical devices industry , we are looking for Data science / time series engineer to improve algorithms and develop new ones.the algorithm shall recommend different decisions based on real-time data.Main Duties1. Analyze raw signal data and design operating algorithms in Matlab\Python2. Translate algorithms to pseudo-code for implementation in SW.3. Map logical data flows with the R&D team – Optics, System Engineering, Software4. Minimum 3 Years’ experience in signal processing \ signal analysis – Experience in calibration flows and calibration algorithms5. Proficient in Python \ Matlab6. Experience in low SNR signal processing and signal extraction –","['Algorithm Development', 'Python', 'Data Science', 'Data Analysis', 'Python', 'Data Science', 'Data Analysis']",Israel,1,,,,,"['18.00', '45.00']",Remote Job,Intermediate
Senior Data Engineer - Full time,"OverviewWe are seeking an experienced Senior Data Engineer to join our growing team and help design and implement scalable and highly available analytics solutions for our Software as a Service (SaaS) e-commerce platform. The successful candidate will play a critical role in driving the development and maintenance of data infrastructure, enabling data-driven decision-making, and optimizing sales, customer behavior, and inventory management.Responsibilitieso Design, develop, and maintain data architecture that supports scalable and highly available analytics requirements for the e-commerce platform.o Implement efficient data ingestion and processing pipelines from multiple sources, such as user interactions, transactional data, and inventory updates.o Leverage cloud infrastructure to ensure scalability, high availability, and cost-effectiveness of the data platform.o Design and implement data models that accommodate the necessary entities, relationships, and attributes while considering scalability and high availability.o Utilize data transformation tools such as dbt to build and maintain data transformation pipelines that prepare ingested data for analytics.o Ensure data quality and consistency by implementing robust data validation and monitoring processes.o Collaborate with data warehouse and data lake technologies to create scalable and highly available data storage solutions.o Design and implement APIs that provide secure, efficient, scalable, and highly available access to analytics data for external applications or services.o Work closely with data analysts, data scientists, and other stakeholders to understand and address their data requirements and challenges.o Stay current with industry best practices and emerging technologies in data engineering, analytics, and infrastructure.Requirementso Bachelor's or Master's degree in Computer Science, Engineering, or a related field.o 5+ years of experience in data engineering, with a focus on developing scalable and highly available data solutions.o Strong expertise in SQL and database design.o Hands-on experience with cloud infrastructure, such as AWS, Azure, or GCP.o Proficiency in ETL / ELT design and implementation, using tools like Airbyte, Airflow, Prefect, Spark, Kafka, etc.o Fluency with at least one interpreted language, such as Python, and another compiled, such as Scala, C++, or Rust. You must also be familiar with version control systems like Git.o Comfortable working on Unix environments.o Proficiency in data transformation tools, such as dbt, and data validation frameworks like Great Expectations or Monte Carlo.o Familiarity with containerization (Docker) and container orchestration (Kubernetes) technologies.o Experience with data warehouse and data lake technologies, such as Snowflake, Clickhouse, Redshift, BigQuery or the Hadoop Ecosystem.o Strong understanding of API design and implementation, with a focus on security, efficiency, and high availability.o Excellent communication and collaboration skills, with the ability to work effectively with cross- functional teams.o Knowledge on message brokers like Redis, ZeroMQ, RabbitMQ, etc. is a plus.o Knowledge of data management and data governance frameworks, such as DAMA, is a plus.o Knowledge of data privacy best practices and related regulations, such as GDPR, CCPA or the new Saudi PDPL, is a plus.","['Apache Kafka', 'Scala', 'Python', 'PostgreSQL', 'Amazon Redshift', 'Presto ', 'MySQL', 'Metabase', 'API', 'PostgreSQL Programming', 'Presto ', 'MySQL', 'Metabase', 'API', 'PostgreSQL Programming']",Saudi Arabia,17,,195,"['Tech', 'IT']",,,Remote Job,Expert
OCR for seven segment fonts in medical devices,"I am new to data science and I need help reviewing the code I have done, explaining why it didn't work, and creating a new plan on how you would approach and solve this problem. What tools you would use, and what are the steps in the project from the start until the end solution [which will be used in a mobile application].What I have tried doing:- Using Keras and Easy OCR [Cannot detect seven segments], you can see the code in easy_keras_ocr.ipynb- Manually detecting seven segments using python, you can see the code in opencv_and_tesseract.ipynb- image preprocessing using open cv and using tesseract ocr to recognize the digits.Note: Tesseract ocr was trained for seven segment font using this tutorial: https://www.youtube.com/watch?v=1v8BPw0Dn0I&ab_channel=TheCode Deliverables:- Meetings discussing and presenting your proposed approach- Documentation with detailed steps on how you would approach this problem and why it is better than alternate options.","['Computer Vision', 'Optical Character Recognition']",Indonesia,1,,,,100.00,,Remote Job,Intermediate
Scrape content from a search bar,"Please note all generic bids will be ignored. Make sure you read my requirements and let me know if you have worked on something similar--------When the user starts typing in the search bar, it auto populates with options. When one of the options is clicked, an info page is displayed. I need to capture one field from these info pages (for each option from the search bar)The only way for a user to get to the info pages, is through typing in the search bar The website is behind a login. I will provide with login detailsI don't have keywords to input in the search bar","['Selenium', 'Beautiful Soup', 'Data Scraping', 'Python', 'Data Mining']",Australia,28,,1.3,,100.00,,Remote Job,Expert
PowerBI expertise Needed,Need PowerBI Expertise to help with doubts I have. Interested to calculate monthly metrics for web analytics data.,"['Microsoft Power BI', 'Data Visualization']",United States,38,15.13,2.6,,,"['10.00', '15.00']",Remote Job,Intermediate
Full Stack Data Visualization Expert,"Arcanis Capital has just started in Switzerland and is focused on Venture Capital research and investments. We are an agile and disciplined team of investment and transaction management professionals distributed across Switzerland, Cyprus, and Indonesia. We praise our non-bureaucratic entrepreneurial culture, with plenty of personal and professional growth possibilities within various investment topics.A short presentation about the company: https://drive.google.com/file/d/16esNMYU9MYHVSwtxsP-R6WJ8tUWyqz1b/viewThe roleCreate data apps on Streamlit/Dash using Python visualization libraries like Plotly, Seaborn, Matplotlib which will be implemented in web apps or automated reportsDesign custom components and graphs using React (.js/.css)Develop data visualization widgets in BI tools like Tableau, Superset, Google Looker Closely collaborate with the designer to maintain and improve the corporate style in all the widgets and appsExpertise must-havesAdvanced knowledge of Python visualization libraries like Plotly, Seaborn, MatplotlibGood knowledge of Graph.js, CSS and React	Experience with Data Visualization tools (Tableau, Superset, Google Looker, Libs Streamlit, Plotly, or Dash) Fluent in functional design approachesProven ability to extract, optimize and communicate core business logic with infographicsUnderstanding business logic and methods to bring it up to conscious and subconscious through managing attention of viewer using graphical methodsFluent English (verbal and written communication daily), Russian nice to haveBase analytical skills, strong systematic thinking and self-organization skillsHas a strong portfolio of previous projects/mockupsPersonalityCreative and systematic, quick learner, flexible mind, structuredEffective communication skillsAbility to perform multiple tasks and to be productiveAttention to details while understanding and seeing complete big pictureSeriously oriented on personal and professional growthWork format and termsFull remote, full-timeSemi-flexible work hours. Need to be available for pre-agreed calls and team sync during 08:00 - 20:00 CETMarket salary depending on candidate’s seniority + bonus to be agreed","['JavaScript', 'Plotly', 'Seaborn', 'Matplotlib', 'Data Visualization', 'Graph.js', 'CSS', 'Infographic', 'Streamlit', 'CSS', 'Infographic', 'Streamlit']",Switzerland,3,,,"['Finance', 'Accounting']",,"['50.00', '70.00']",Remote Job,Expert
Test the nesting problem with pso algorithm using deap library,"Problem is already implemented,  you have to test it using pso algorithm using deap library","['Machine Learning', 'evolutionary algorithm ', 'deap library ', 'Python', 'deap library ', 'Python']",Pakistan,13,,275,,30.00,,Remote Job,Expert
Tableau and Python Data Analytics Consultant,"About the role:Do you enjoy having ownership of your project and directly influence decision-makers? Are you looking to broaden your perspective and get a deep understanding of new industries?Then this role could be right.Responsibilities:You will work in the field of data analysis, visualisation and data science on various projects.You raise Tableau servers in the cloud in cooperation with the DevOps team.You prepare presentations for board members and decision-makers and also actively participate in customer presentations.You handle simple data preparation and reporting yourself, but you can also break down more complex tasks and implement them in cooperation with other specialists.You identify analytical needs.You conduct customer workshops on requirements analysis, innovation and data modelling.Apart from Tableau and Python, you will have a room to use and develop new skills and technologies. We will provide you with the necessary support.About us:We are P3 Group, a German-originated Management Consultancy named one of the “World’s Best Management Consulting Firms 2022” by Forbes thanks to our innovative approaches and high level of employee satisfaction. About you:You have a degree, an affinity for data, a high degree of initiative, and problem-solving skills.You have experience in Python, write clean commented code and can control the code base with Git.You have advanced experience with Tableau, Python or PySpark.You have worked on at least 2 different projects.You are fluent in German and English.Conditions:Full-time employment in GermanyFlexible working hoursCan be mostly remote orin one of the P3 offices in GermanyIf it sounds relevant, please share your contacts so we could schedule a short call for details.","['German', 'Tableau', 'Python']",Czech Republic,2,,,"['Tech', 'IT']",,"['30.00', '150.00']",Remote Job,Intermediate
Create OpenAI ML Program Using Langchain Framework and Pinecone Vector Database,"We are looking for an experienced Machine Learning Engineer to create an OpenAI ML program using Langchain Framework and Pinecone Vector Database. A picture of the proposed application architecture is attached.The ideal candidate must have a strong background in Artificial Intelligence, Database Design, Data Science, and Python. The candidate should be proficient in using the Langchain Framework and Pinecone Vector Database. The project requires the development of a machine-learning model using the latest techniques in the field. The candidate should have experience in designing and implementing such models. The candidate should also have experience in developing and implementing data pipelines to support the model.To apply for the job, please submit a detailed proposal outlining your experience in this field, your approach to the project, and some links to past completed projects that are relevant to this job. We look forward to hearing from you.","['Python', 'Database Design', 'Machine Learning', 'Artificial Intelligence', 'Data Science', 'Machine Learning', 'Artificial Intelligence', 'Data Science']",United States,30,8.05,69,,,,Remote Job,Expert
Configuring  Google Data Studio Dashboard using SQL for magento database,Configuration of google data studioI need a team member to help me connect to my hosting so i can use MYSQL databases on my server in google data studio. The issue from what i can see is that my host guru hosting doesnt allow for direct conenction to SQLSSH Tunneled access is requiredI want to connect to my sales data base and update the info in google data studio for live results of my quotation,"['Google Data Studio', 'MySQL']",United Kingdom,336,6.85,29,,,"['20.00', '50.00']",Remote Job,Intermediate
Data Mning Course,"Hello there.I need an expert person that knows ""Data Mining Course"", It is a course in Computer Engineering, If you know this course very well, please send me your proposl.Note: Book name: ""772s Data Mining Concepts and Techniques 2nd Ed""Regards.","['Customer Service Analytics', 'Growth Analytics', 'Human Resources Analytics', 'Marketing Analytics', 'Operations Analytics', 'Product Analytics', 'Sales Analytics', 'Dashboard', 'Data Analysis', 'Presentations', 'Query Development', 'Report', 'Data Visualization', 'A/B Testing', 'Big Data', 'Business Intelligence', 'Data Analytics', 'Data Interpretation', 'Funnel Testing', 'Hypothesis Testing', 'Machine Learning', 'Statistical Analysis', 'Google Analytics', 'ActivTrak', 'Altair Monarch', 'AnyLogic', 'Apache Hive', 'BigQuery', 'BIRT', 'Chartio', 'Cognos', 'Domo', 'GoodData', 'Google Sheets', 'Google Tag Manager', 'Grow', 'Kissmetrics', 'KNIME', 'Looker', 'Microsoft Power BI', 'Minitab', 'Monetate', 'OpenRefine', 'Data Entry', 'Python', 'Microsoft Excel', 'Lead Generation', 'Statistics', 'English', 'Content Writing', 'Lead Generation', 'Statistics', 'English', 'Content Writing']",Turkey,131,,1.1,"['Tech', 'IT']",15.00,,Remote Job,Intermediate
Handwriting Recognition model using Tensorflow,I am looking for a freelancer who can create and train a deep learning model for Full Page Handwriting Recognition . The ideal candidate should have experience in the following:- Deep Learning Model Creation and Training- Image Recognition and Natural Language Processing- Working with both image and text data- Using TensorFlow as the preferred deep learning framework- Transfer Learning- The model will be trained on dataset with Hindi and Bengali Handwriting.The project will involve the following tasks:- Creating a deep learning model using TensorFlow for Full Page Handwriting Recognition- The model will be based on the architecture used here: https://www.amazon.science/publications/sequence-to-sequence-contrastive-learning-for-text-recognition- Resnet 152 (Initial weights can be taken from as the ImageNet.- I will provide you with images and corresponding annotated text files (after the model creation is done).- The images are of different sizes thus need to make a preprocessing file to bring all the images to same size before you input it to the model.- Training the model using the prepared data- Testing and evaluating the model's accuracy and performance-The code should be modular and easy to understand. (Well Commented).The candidate should have expertise in developing deep learning models and be able to deliver high-quality results within the given timeframe.The deliverables include:- Full Model code (working)- The fine tunned resnet-152 weights and other weights of the fine tuned model.I need the task to be done with priority ( Model creation should not take more than 3-4 days and training 1 day).,"['TensorFlow', 'Keras', 'Python', 'Computer Vision', 'Deep Learning', 'CUDA', 'Computer Vision', 'Deep Learning', 'CUDA']",India,1,,,"['Engineering', 'Architecture']",70.00,,Remote Job,Expert
AI Developer,"Brief description: AI to analyze data from email, structure data and provide solutions.More detailed description to be discussed.","['Artificial Intelligence', 'Algorithm Development', 'Machine Learning', 'Data Analysis', 'Algorithm Development', 'Machine Learning', 'Data Analysis']",Armenia,1,,,,,"['18.00', '60.00']",Remote Job,Intermediate
"Amazon Scrapper + Get products with reviews, price, offers","We want to regularly /fetch/scrap from amazon for some categories/subcategories to do the market study for our comparison.We want prices, offers, and reviews. It must be scrapped continuously without block, must be multi-thread, and must use multiple agents, proxies, or whatever is needed to save it to block.data must be saved to the text file, the same product will not come again if there are not changes in price/offer.","['Data Scraping', 'Scrapy', 'Data Mining', 'Market Research', 'Market Research']",India,86,6.96,3.4,,20.00,,Remote Job,Intermediate
"Amazon Scrapper + Get products with reviews, price, offers","We want to regularly /fetch/scrap from amazon for some categories/subcategories to do the market study for our comparison.We want prices, offers, and reviews. It must be scrapped continuously without block, must be multi-thread, and must use multiple agents, proxies, or whatever is needed to save it to block.data must be saved to the text file, the same product will not come again if there are not changes in price/offer.","['Data Scraping', 'Scrapy', 'Data Mining', 'Market Research', 'Market Research']",India,86,6.96,3.4,,20.00,,Remote Job,Intermediate
TensorFlow Developer (OCR),"TensorFlow (OCR) DeveloperLooking for an experienced developer who can complete the desired project in less than a month, preferably within a week. This project needs to read digits from the water meter specifically OCR. This system needs to finish as soon as possible.Qualifications for this system:-TensorFlow OCR Developer-Java Programmer","['TensorFlow', 'OCR Algorithm', 'Machine Learning', 'Machine Learning']",Philippines,1,,,['Education'],,,Remote Job,Expert
IBM Planning Analytics – Functional Developer (contract) position,"We are looking for an IBM Planning Analytics – Functional Developer to work on a project for a period of 1 year. You willinitially perform an assessment of requirements by supporting the Project Manager and all non-recurring activitiesrelated to the Functional &amp; Technical System and the processes. This could lead to an additional assignment to deploy afull implementation of IBM Planning Analytics and developments.Mission:Responsibilities include, but are not limited to... Be autonomous in the assessment of the requirements. Gather advanced functional and technical requirements from the client, offering solutions according to clientneeds and scope. Collaborate with Finance and Accounting teams to discuss &amp; understand business requirements and createtechnical specifications. Develop assessment documentation, Functional &amp; Technical Design that will present the details of the futureimplementation. Provide guidance and support to the assessment team in order to highlight opportunities and benefits of thefuture solution. Provide a list of potential interfaces. Objective is to bring new options for improvements for reporting. Ensure completion of deliverables, managing schedules with creative and technical success. Consistently communicate project status with senior management or project management team as needed.Expected starting date : July 2023Duration : 1 year. Could be extended depending on profile and activityLocation: Remote – Northern Virginia.ProfileRequired Skills and Experience: Deep understanding of all aspects of Planning Analytics. In-depth knowledge of multi-dimensionality, hierarchies, cubes design, Turbo Integrator processes, writing Rulesand Feeders, developing Active Forms &amp; Websheets, structured Planning Analytics templates, etc. (required) Knowledge of Planning Analytics and Planning Analytics Workspace security and user authentication principles.(required) Past experience in large scale E2E implementation of Planning Analytics based projects. (required) Knowledge of integrating Planning Analytics with different ERPs, Data warehouses, SQL, and Data Managementprinciples. (preferred) Knowledge of Planning Analytics administration, environment (CPU, RAM, Diskspace) management, and objectdeployment across DEV, UAT, DR, PROD. (preferred) Experience working with Planning Analytics Local hosted on a cloud platform and/or PA on IBM SaaS. (preferred) Required 3+ years of IBM Planning Analytics development experience with writing complex logic to optimizeperformance by ensuring cells are fed appropriately. Business knowledge of finance and/or accounting functions is a plus. IBM TM1/Planning Analytics Certifications a plus. Well versed with technical documentation. Strong communication, critical thinking, problem solving, and root cause analysis skills. Ability to work independently with minimal guidance and to establish priorities and proceed with objectiveswithout supervision.","['IBM Planning Analytics', 'Analytics', 'Analytics']",United States,6,,,,,"['70.00', '90.00']",Remote Job,Expert
Google Looker Data Studio Expert,"We're searching for a Google Looker Data Studio expert who can assist us with creating dashboards, scheduling them to clients, connecting multiple data sources (google sheets with multiple worksheets for now) and ensuring a great user experience with advanced features, charts, drilldowns, etc.","['Google Data Studio', 'Data Visualization', 'Data Analysis', 'Google Analytics', 'Tableau', 'Analytics', 'Data Analysis', 'Google Analytics', 'Tableau', 'Analytics']",United States,2,,,,,"['20.00', '50.00']",Remote Job,Intermediate
Use Apexcharts to create advanced charts for WP using db data,"We are looking for a skilled developer to use Apexcharts to create advanced charts for a WordPress website using data from a database. This project is estimated to take less than a month, and requires expertise in HTML, JavaScript, PHP, SQL, WordPress, and Apexcharts.Check a sample of what is required. https://apexcharts.com/javascript-chart-demos/mixed-charts/multiple-yaxis/The successful candidate will be responsible for creating charts that are visually appealing and easy to use. You should have experience working with databases and be able to pull data from them to create charts. Additionally, you should be familiar with WordPress and be able to integrate the charts into the website.","['apexcharts', 'JavaScript', 'PHP', 'WordPress', 'SQL', 'HTML', 'WordPress', 'SQL', 'HTML']",United Kingdom,226,11.29,49,,,"['20.00', '50.00']",Remote Job,Intermediate
Web/Data Scraping Expert Required,"We are seeking a highly skilled and experienced Web/Data Scraping Expert to assist us in a data extraction project. The ideal candidate should have a proven track record in web scraping and be proficient in various scraping techniques and tools. This is a freelance position, and we require someone who can dedicate sufficient time to complete the project within the agreed-upon timeline.Responsibilities:Perform web scraping and data extraction from various sources.Develop and implement efficient scraping strategies to collect large volumes of data.Clean, validate, and transform scraped data into a structured format.Ensure data integrity and accuracy throughout the scraping process.Troubleshoot and resolve any scraping-related issues that may arise.Collaborate with our team to define project requirements and objectives.Requirements:Proven work experience as a Web/Data Scraping Expert.Strong proficiency in web scraping tools and techniques (e.g., BeautifulSoup, Scrapy, Selenium, etc.).Proficient in programming languages such as Python, R.Experience with data extraction from various sources, including websites, APIs, and databases.Knowledge of HTML, CSS, and XPath to navigate and extract data from websites.Familiarity with data manipulation and cleaning techniques.Excellent problem-solving skills and attention to detail.Ability to work independently and deliver high-quality results within specified deadlines.Strong communication skills and the ability to collaborate effectively with team members.","['Selenium', 'Beautiful Soup', 'pandas', 'Data Extraction', 'Python', 'Data Scraping', 'Scrapy']",India,2,,,,,"['18.00', '25.00']",Remote Job,Intermediate
Revamp Web Scraping Bot-Python Based,"We are looking for a talented Python developer to revamp our existing web scraping bot. The ideal candidate should have experience in API development, data scraping, Python scripting, and Selenium automation. As a candidate, you will be responsible for reviewing our current web scraping bot and developing a new version that is more efficient and reliable. The new bot should be able to handle increased workloads, improve data quality, and reduce errors. You will also be responsible for testing the new bot thoroughly before deployment.To be considered for this job, please submit a proposal outlining your experience with web scraping and Python development. Please include links to any relevant projects that you have completed in the past. We are looking for someone who is a self-starter, detail-oriented, and able to work independently. We look forward to hearing from you!","['Data Scraping', 'Selenium', 'API', 'Python Script', 'Python', 'Automation', 'API', 'Python Script', 'Python', 'Automation']",Malaysia,37,,388,"['Retail', 'Consumer Goods']",25.00,,Remote Job,Intermediate
Statistical Data Analyst Required,"Project Title: Statistical Data Analyst - Competition Pricing and PlanningProject Description:We are seeking a Statistical Data Analyst to join our team. Our business revolves around hosting exciting online competitions with a diverse range of prizes. We are growing and we need an experienced Statistical Data Analyst to assist with competition planning and pricing.Scope of Work:Your primary responsibility will be to analyze our historic sales data and competitor analysis reports to plan and price our competitions effectively. You will work closely with our sales team and make data-driven recommendations for our competition strategies.Responsibilities:Analyze historic data to understand competition success rates and customer preferences.Monitor competitor offerings and pricing to ensure our competitions remain competitive.Collaborate with our Sales team to plan and price competitions effectively.Provide data-driven recommendations for competition strategies.Qualifications:A degree in Statistics, Mathematics, Economics, or a related field.Experience in a data analyst role.Proficiency in statistical analysis tools and software.Strong analytical and strategic thinking skills.Ability to understand market trends and customer behavior.Excellent planning and organizational abilities.Deliverables:Regular reports on market trends, competitor analysis, and pricing strategies.Project Duration:To be discussed (part-time, full-time, etc.).Payment Structure:Hourly rate/fixed price to be negotiated.Applying:If you're looking to apply your analytical skills in a fun and fast-paced setting, we'd love to hear from you. Interested candidates are invited to submit their application, including a cover letter and CV.","['Data Analysis', 'Microsoft Excel', 'Statistics', 'Quantitative Analysis', 'Python', 'Data Visualization', 'Data Science', 'Statistics', 'Quantitative Analysis', 'Python', 'Data Visualization', 'Data Science']",Ireland,13,7.27,44,,,"['13.00', '40.00']",Remote Job,Intermediate
Tensorflow Developer specifically OCR Optical Character Recognition,-tensorflow developer-java programmer - for 267.69- water meter scanner project,"['TensorFlow', 'Machine Learning']",Philippines,1,,,,,,Remote Job,Intermediate
Image processing using python to remove radial distortion from image (chessboard or circular grid),"I have a microscopic device which captures images of surface on which there are circles of size from 1.5 mm to  5.5 mm approx and we need to detect the diameter of these images accurately, We want a perfect circle detection algorithm (Circle May not be pure circle it may be oblong ) we need algorithm for that. Also device brightness may change for different surfaces we need to consider that. One issue that we are facing is radial distortion of lensedue to which radius of same circle at different position comes different we need correction for that as well, I will send multiple images which different size balls, also share other details","['OpenCV', 'Image Processing', 'Computer Vision', 'C++', 'Machine Learning', 'TensorFlow', 'MATLAB', 'Python', 'C++', 'Machine Learning', 'TensorFlow', 'MATLAB', 'Python']",India,9,,580,,150.00,,Remote Job,Expert
Image processing using python to remove radial distortion from image (chessboard or circular grid),"I have a microscopic device which captures images of surface on which there are circles of size from 1.5 mm to  5.5 mm approx and we need to detect the diameter of these images accurately, We want a perfect circle detection algorithm (Circle May not be pure circle it may be oblong ) we need algorithm for that. Also device brightness may change for different surfaces we need to consider that. One issue that we are facing is radial distortion of lensedue to which radius of same circle at different position comes different we need correction for that as well, I will send multiple images which different size balls, also share other details","['OpenCV', 'Image Processing', 'Computer Vision', 'C++', 'Machine Learning', 'TensorFlow', 'MATLAB', 'Python', 'C++', 'Machine Learning', 'TensorFlow', 'MATLAB', 'Python']",India,9,,580,,150.00,,Remote Job,Expert
PHP developer for a deleivery application,"Backend PHP Developer -  Delivery Platform Startup (5 years experience)We are seeking a highly skilled and experienced Backend PHP Developer to join our delivery platform startup. As a Backend PHP Developer, you will play a crucial role in designing, developing, and maintaining the server-side logic, database structures, and APIs for our mobile and web-based delivery application. If you have a solid background in PHP, MySQL, Security, and caching techniques, and are excited about building the backend infrastructure for a delivery application startup, we want to hear from you!Responsibilities:Design and develop the backend infrastructure for our delivery platform, catering to both mobile apps and web interfaces.Design and optimize the database structures, queries, and performance to ensure efficient data management and retrieval.Collaborate closely with frontend developers to integrate their components seamlessly with the backend logic.Implement and maintain secure RESTful APIs to facilitate smooth data communication between the frontend and backend systems.Employ caching strategies and techniques to optimize application performance and enhance user experience.Proactively identify and troubleshoot bugs, issues, and performance bottlenecks, ensuring timely resolutions.Work collaboratively with cross-functional teams to gather requirements, provide technical expertise, and drive successful project delivery.Requirements:Bachelor's degree in Computer Science, Engineering, or a related field.Minimum of 5 years of professional experience as a Backend PHP Developer, preferably in a startup environment.Strong proficiency in PHP and its frameworks (such as Laravel).Extensive expertise in MySQL database design, optimization, and query performance tuning.Thorough understanding of security principles, including authentication, authorization, and data protection.Experience implementing and optimizing caching techniques (e.g., Redis, Memcached) for improved application performance.Familiarity with frontend technologies (HTML, CSS, JavaScript) and their seamless integration with backend systems.Strong problem-solving skills and the ability to thrive in a fast-paced startup environment.Excellent communication skills and the ability to collaborate effectively with both technical and non-technical stakeholders.Preferred Qualifications:Experience with other databases like PostgreSQL or MongoDB.Knowledge of other backend languages like Python, Node.js, or Ruby.Familiarity with version control systems (such as Git) and Agile development methodologies.","['Database Design', 'Database Architecture', 'PHP', 'API', 'Mobile App Development', 'MySQL', 'CSS', 'HTML', 'MySQL Programming', 'MySQL', 'CSS', 'HTML', 'MySQL Programming']",Israel,4,,,,,,Remote Job,Expert
Data Scraper,"Scrape data from Grab, Gojek & Google Maps on ratings and menu of select brands.","['Data Scraping', 'Python', 'Data Extraction', 'Scrapy', 'Web Crawling', 'Scrapy', 'Web Crawling']",Indonesia,1,,,,100.00,,Remote Job,Entry level
Data Support Visualization,"Skills -  Powerbi, Data Studio, Excel, SSAS, SQL ServerAddress reporting layer data quality issues, raised by users or identified among quality checks, among the 50+ Data studio, 10+ PBI dashboards, and self-serve BI on SSASMonitor the SSAS data pipelines and rerun in case of failuresMonitor for data freshness (via the dashboard), in case of delay, flag the upstream and rerun downstream once data is releasedRerun the PBI/SSAS jobs if there is a delay in data refreshRaise internally in case a fix is requiredAlign user in case expectation is mismatchedWorking -Hours – Starting at 0800 hours, with occa","['Google Data Studio', 'Microsoft Power BI', 'Microsoft SQL Server', 'Microsoft Excel', 'SSAS data pipelines', 'Microsoft Excel', 'SSAS data pipelines']",India,30,,60,"['Tech', 'IT']",,"['5.00', '10.00']",Remote Job,Intermediate
Talend Developer with 5+ yrs of experience,"Minimum 2.5-5 years’ proven experience in Talend Real Time Big Data Platform (Spark Streaming, Talend Administration Center)Experience working on other bigdata technologies along with Talend will be excellent to haveFlexibility on availability outside work hours in emergenciesShould be comfortable working in usual week cycles where week offs would not be Saturday or SundayShould be comfortable working full time on Indian holidays in rotation with rest of the teamShould be comfortable for on-call support on weekends and holidays as per the plan decided by the Manager/Team leadExcellent written and verbal skillsPassionate in work, proactive and responsible","['Talend Data Integration', 'Spark Streaming', 'Talend Administration Center', 'ETL', 'Talend Open Studio', 'Spark Streaming', 'Talend Administration Center', 'ETL', 'Talend Open Studio']",India,281,8.42,46,,1000.00,,Remote Job,Expert
AI - Create a script either in Nodejs or Python that answers emails using ChatGPT,Create a script or API that uses a language model or the OpenAI API to answer emails based on the knowledge of the given documents.You can take https://sitegpt.ai/ as an example. The difference is that it must be trained with private documents and the bot should be trained to answer emails instead of chat. This means that the answer must be formatted in an email-like message.,"['ChatGPT', 'Chatbot', 'Langchain', 'Python', 'Node.js']",Spain,1,,,"['Tech', 'IT']",200.00,,Remote Job,Intermediate
Solve few short questions related to Mathematics and Analysis,Sample questions: 1. [image] A graph showing technology usage in the uk over time    [task] Analyse the graph and choose the correct options     [option] Smartphones and tablets appeared in 2010 and followed a                                          steep curve     [option] The uptake of technology increased drastically in this period                                      .... more options2. Define the second derivative of the following function     y = ln(x + sqrt(1+x ^2),"['Mathematics', 'Data Analysis']",Czech Republic,54,24.98,8,,60.00,,Remote Job,Expert
Somatic analysis of tumor/normal whole genome sequencing data from cancer patients,We’re looking for an experienced professional that can perform bioinformatics analysis for clinical applications of tumor/normal whole genome sequencing data from patients with colorectal cancer,[],Italy,1,,,,,"['18.00', '100.00']",Remote Job,Intermediate
generating data results using SPSS,"I want to hire a data analyst/ person with strong research experience to generate my data results (~400 samples only) using SPSS *an online demonstration with your illustration is required. Language of medium: EnglishI will book you at least 1.5 hours(no need to show your face)it requires -descriptive statistics to explore the profile of the participants- central tendency of the research data. - correlation and regression data analysis model  to explore the relationship between the study variables.  (including reliability, correlation, and regression).there are 2 IV and 5 DV in my research","['IBM SPSS', 'Statistics', 'Data Analysis']",Hong Kong,16,,603,,,"['25.00', '30.00']",Remote Job,Intermediate
Financial data storytelling,"We are seeking a skilled individual to help us with a financial data storytelling project. The ideal candidate should have experience with accounting and financial analysis & valuation. The project requires the ability to analyze, interpret, and visualize data to create compelling financial stories. The candidate should be able to create presentations and reports that effectively communicate financial data to a non-technical audience. The project's length is less than one month, and we are open to remote work arrangements. The candidate should have excellent communication skills and be able to work independently. We would like the candidate to submit a proposal detailing how they can help us with this project. Please include links to past completed projects that demonstrate your ability to create engaging financial stories. We look forward to reviewing your proposal and working with you.Note: Some of the content in this job post may have been auto-generated using advanced AI.","['Presentations', 'Report', 'Data Analysis', 'Data Visualization', 'Data Interpretation', 'storytelling ', 'Financial Analysis', 'Financial Analysis & Valuation', 'Accounting', 'Financial Analysis & Valuation', 'Accounting']",France,24,,9.6,['Education'],40.00,,Remote Job,Expert
Shopify Analytics Expert Needed to Fix N/A Data Reporting Issue,"We are currently experiencing a data reporting issue in our Shopify store where several reports are displaying ""N/A"" instead of the actual data. We are seeking a skilled Shopify Analytics Expert on Upwork to help diagnose and resolve this problem.","['Growth Analytics', 'Human Resources Analytics', 'Customer Service Analytics', 'Product Analytics', 'Sales Analytics', 'Marketing Analytics', 'Operations Analytics', 'Data Analysis', 'Google Analytics', 'Shopify']",Israel,6,5.00,33,,,"['20.00', '75.00']",Remote Job,Expert
Web Scraping Engineer/Developer,"As a Web Scraping Engineer/Developer, you will be responsible for developing and implementing web scraping solutions to extract and process data from various online sources. Your primary focus will be on building efficient and reliable web scraping applications using technologies such as Python, Node.js, C++/C#, and web scraping libraries/frameworks.Experience with AWS: Proficiency in working with Amazon Web Services (AWS) and its various services, such as EC2, S3, Lambda, and CloudWatch. Knowledge of deploying and managing web scraping applications on AWS infrastructure.REST API and HTTP Knowledge: Strong understanding of RESTful principles and experience in interacting with REST APIs. Knowledge of HTTP methods, headers, cookies, and handling different status codes.Network Knowledge: In-depth understanding of networking concepts, including TCP/IP, DNS, proxies, and different protocols like HTTP and HTTPS. Ability to analyze network traffic for debugging and optimization purposes.Reverse Engineering: Familiarity with reverse engineering techniques to understand and work with complex web applications, deciphering AJAX requests, deciphering APIs, and understanding the underlying data structures.Proxy Management: Experience in managing proxies and rotating IP addresses to avoid IP blocking and anti-scraping measures. Knowledge of proxy providers, proxy rotation strategies, and handling proxy authentication.Node.js and Python: Strong programming skills in both Node.js and Python. Proficiency in using Node.js for building scalable and efficient web scraping applications. Knowledge of Python libraries such as Beautiful Soup, Scrapy, and asyncio for web scraping tasks.XPath and CSS Selectors: Strong understanding and experience in using XPath and CSS selectors to navigate and extract data from HTML documents efficiently.Data Processing: Proficiency in processing and manipulating scraped dataAuthentication and Session Management: Proficiency in handling authentication mechanisms such as login forms, cookies, and session management. Ability to simulate user login, handle session cookies, and maintain authenticated sessions while scraping websites that require authentication.Websockets: Understanding and experience with websockets, allowing real-time communication between the scraper and web applications. This can be useful for scraping websites that utilize websockets for data updates or notifications.","['API', 'Data Scraping', 'Python', 'Node.js', 'JavaScript', 'Web Scraping', 'Data Mining', 'HTTP', 'AWS Application', 'Node.js', 'JavaScript', 'Web Scraping', 'Data Mining', 'HTTP', 'AWS Application']",Turkey,7,43.86,9.7,"['Engineering', 'Architecture']",,,Remote Job,Expert
Machine learning engineer to create synthetic data,"We are looking for a machine learning engineer to create synthetic data for our upcoming project. The ideal candidate should have a strong background in machine learning and be proficient in Python. The job will last for a period of 1 to 3 months.As a machine learning engineer, you will be working closely with our team to develop and implement algorithms that generate high-quality synthetic data. You will also be responsible for testing and validating the generated data to ensure that it is accurate and meets the project requirements.To be considered for this job, you must have experience with machine learning, data analysis, and Python programming. Experience with deep learning frameworks such as TensorFlow or PyTorch is also highly desirable.If you are interested in this job, please submit a proposal outlining your experience and how you can help us with this project. Please include links to any past projects that demonstrate your expertise in machine learning and data analysis. We look forward to hearing from you.","['Python', 'Machine Learning']",India,9,29.00,704,,,"['18.00', '40.00']",Remote Job,Intermediate
AI Engineer,"Job Description:We are seeking an experienced AI Engineer with a strong background in deep learning and expertise in working with various types of data, including image processing. As an AI Engineer, you will play a critical role in developing and implementing advanced AI solutions using deep learning techniques. You will collaborate with a team of data scientists, software engineers to build and deploy powerful AI models that address complex challenges.Responsibilities:•	Develop and implement advanced image processing using deep learning algorithms.•	Utilize machine learning and deep learning techniques to extract meaningful insights from unstructured image.•	Collaborate with specialized teams to understand business needs and translate them into technical solutions.•	Research and experiment with new algorithms and methods to improve model performance and accuracy.•	Pre-process and clean large datasets for model training and evaluation.•	Optimize and fine-tune AI models to achieve desired performance metrics.•	Stay up to date with the latest advancements in deep learning, and image processing research and apply them to ongoing projects.•	Collaborate with cross-functional teams to integrate AI solutions into existing systems or applications.Requirements:Master degree in Computer Science, Engineering, or a related field.Proven experience in working with deep learning frameworks and libraries.Strong understanding of machine learning principles and algorithms.Proficiency in programming languages such as Python and experience with deep learning libraries such as TensorFlow or PyTorch.Experience with image processing frameworks (e.g., OpenCV, scikit-image) , deep learning models for computer vision tasks, object detection algorithm  such as YOLO .Strong communication and teamwork skills to collaborate effectively with interdisciplinary teams.","['Deep Learning', 'Python', 'Object Detection', 'image segmentation', 'Generative Adversarial Networks', 'image segmentation', 'Generative Adversarial Networks']",Australia,1,,,,,"['3.00', '5.00']",Remote Job,Intermediate
Excel guru needed for small projects,"I'm looking for a right-hand person for excel tasks.  Tasks can range from dashboard creation, fixing excel sheets to specs, data analysis, formation of graphs, and teaching end users about the processes and how to maneuver around the product.  If successful, I'd like to have this person as my go-to person for all and any excel questions/projects that I will have.","['Dashboard', 'Presentations', 'Query Development', 'Data Analytics', 'Data Visualization', 'Data Interpretation', 'Microsoft Excel', 'Data Analysis', 'Data Entry', 'Financial Analysis', 'Data Entry', 'Financial Analysis']",United States,5,40.00,1.1,,,,Remote Job,Intermediate
"Lead Building, Contact Scraping and Data Extraction","We are seeking a skilled and efficient Lead Scraping and Contact List Compilation Specialist to support our company's marketing and sales efforts. As a specialist in this role, you will be responsible for gathering valuable leads and compiling comprehensive contact lists that align with our target audience. Your work will directly contribute to expanding our customer base and driving business growth.","['Data Scraping', 'Lead Generation', 'Prospect List', 'Data Extraction', 'List Building', 'Prospect List', 'Data Extraction', 'List Building']",Canada,1,,25,,,,Remote Job,Intermediate
Expert in scraping large quantities of data,I'm looking for someone that can provide me with a high quality lists of emails and phone numbers for as many gyms as possible located in the United States.,"['Web Scraping', 'Data Scraping', 'Data Mining', 'Scrapy', 'Data Extraction', 'Scrapy', 'Data Extraction']",United States,1,,,"['Health', 'Fitness']",,"['5.00', '10.00']",Remote Job,Intermediate
Write Macros to calculate data & populate reporting template,"I would like to automate some of my reporting processes.I have several large reporting templates that I need to complete each qtr. I have spreadsheets that pull the data from raw data export, calculate the data etc. there are stages that require subjective decisions so would need to run a macro that summaries data that needs my attention, I would amend it as needed then continue to run the data through to the final template, update my records & save the files appropriately.We will look at these one at a time.","['Microsoft Excel', 'Visual Basic for Applications', 'Macro Programming', 'Spreadsheet Software', 'Macro Programming', 'Spreadsheet Software']",Australia,4,27.90,972,,,"['19.00', '40.00']",Remote Job,Expert
Quantitative risk assessment consultant,Qra engineers woth safty and process safety management software skills needed,"['safty', 'Process Safety', 'hazard identification', 'Risk Assessment', 'Risk Assessment']",Egypt,1,,,,,"['40.00', '75.00']",Remote Job,Expert
Data Scientist to scrape data from a website,"Scrape public trial data from 2018 to 2023 from the following website: ""https://ensaiosclinicos.gov.br/list""Provide code in python with the following steps in mind:1. Click into each trial and extract all data in English2. Iterate through all trials on all pages and store results in one dataframe3. Each trial data should be stored on one row",['Data Extraction'],Australia,1,,,,,"['15.00', '40.00']",Remote Job,Expert
Azure Data Engineer (Remote) on Contract,"We are looking for a Senior Data Engineer (Azure) with 5-8 years of experience on contract (REMOTE). The selected candidate would have to work REMOTELY with team in India during India office hours 9:30 am to 6:30 pm (5 days a week).Our Budget: INR 1,00,000 per monthJob Description•   5-8 years of experience in IT Industry  •   3+ years of experience with Azure Data Engineering Stack (Event Hub, Data Factory, Cosmos DB, Synapse, SQL DB, Databricks, Data Explorer)•   3+ years of experience with Python / Pyspark, Spark, Scala, Hive, Impala•   Excellent knowledge of SQL and coding skills•   Good understanding of other Azure services like Azure Data Lake Analytics, U-SQL, Azure SQL DW  •   Good Understanding of Modern Data Warehouse/Lambda Architecture, Data warehousing concepts•   Experience with scripting languages such as shell.•   Excellent analytical and organization skills.•   Effective working in a team as well as working independently.•   Experience of working in Agile delivery  •   Knowledge of software development best practices.•   Strong written and verbal communication skills.•   Azure Data Engineer certification is added advantage","['Apache Spark', 'Apache Hadoop', 'Apache Hive', 'Apache Kafka', 'Microsoft Azure', 'Microsoft Azure SQL Database', 'ETL Pipeline', 'Azure Data Factory', 'Azure Synapse', 'Azure Event Hub', 'Azure Cosmos DB', 'Azure Data Bricks', 'Azure Data Explorer', 'PySpark', 'Apache Impala', 'ETL Pipeline', 'Azure Data Factory', 'Azure Synapse', 'Azure Event Hub', 'Azure Cosmos DB', 'Azure Data Bricks', 'Azure Data Explorer', 'PySpark', 'Apache Impala']",India,273,5.00,3.1,,,"['5.00', '7.00']",Remote Job,Intermediate
Convert 2D lines to density map using Python,"Updating grid size for converting 2D lines to color-meshI have multiple 2D lines in the file (format is (x1,y1),(x2,y2). This task is a bit simple, and I can provide my script, which has done more than half of it.Step 1: Divide the study area into grid size (0.001*0.001)Step 2: Plot the 2D lines in the study areaStep 3: Count the lines crossing in each gridStep 4: Convert this into a density map. Additional: we should mask the region where no lines are present.","['Data Visualization', 'Python']",Pakistan,3,,,['Education'],10.00,,Remote Job,Intermediate
Business Data Analyst needed to create/build weekly reports,"- Follow step-by-step given instructions on creating/building presentations using Excel and PowerPoint on a weekly and monthly basis- Analyze basic ticketing data to recognize trends, find potential solutions to recurring issues, and determine what information is relevant to certain stakeholders- Create ad hoc reports based upon specifications provided in advance- Proficiency in the Microsoft Office Suite preferred","['Microsoft Excel', 'Data Analysis', 'Data Entry', 'Business Intelligence', 'Analytics', 'Data Entry', 'Business Intelligence', 'Analytics']",United States,1,,,"['Tech', 'IT']",,,Remote Job,Entry level
Tutor for excel data visualization,Hello I’m looking for someone to help me with data visualization using excel! I need someone who can lead me by teaching the data and how effectively use excel.,"['Microsoft Excel', 'Data Analysis', 'Data Visualization', 'Data Visualization']",United States,4,,,,,"['5.00', '10.00']",Remote Job,Expert
Excel Expert,"Developing a script in Google sheet that fetches live football statistics and upcoming fixtures from https://tipsterarea.com/facts.The script should then cross-reference the teams from these statistics with the teams in the upcoming fixtures. If a team from the statistics matches a team in the fixtures, the script should display the team and the date of their next match on a Google Spreadsheet.You will get the stats from (facts~form and trends) on www.tipsterarea.com e.g. Most Wins, Losses, Draws, etc.Also from the said website you'll get ""Matches"" i.e everyday fixtures. Thank you","['Google Sheets', 'Microsoft Excel', 'Visual Basic for Applications', 'Data Mining', 'Spreadsheet Software', 'Data Analysis', 'Data Mining', 'Spreadsheet Software', 'Data Analysis']",Kenya,8,,30,,15.00,,Remote Job,Intermediate
AI Chatbot for Create a AI Avatar no code website,"Project Description:We are seeking an experienced AI developer to create a robust and efficient AI chatbot for customer support. The chatbot will be trained on a diverse dataset consisting of YouTube videos, helpdesk documents, FAQs, and chat data. The goal is to develop an intelligent and natural language processing model capable of understanding and responding to customer queries accurately and promptly.We will provide the step by step workflow for the webapp template.Responsibilities and Duties:* Develop a web application template using Bubble.io, mimicking the design and functionality of profilepicture.ai* Integrate the specified aipaintr.com APIs to enable avatar generation functionality* Implement a system for storing and managing user information and generated avatars; if this requires setting up a database, this will be part of the job* Ensure the site's user interface is intuitive and user-friendly, aligning with our specified user journey* Develop a responsive design that automatically adjusts to accommodate different device types* Conduct testing to ensure all functionalities are working properly and the user experience is optimized* Provide documentation on how to use the template and how to fix issues.Familiarity with relevant programming languages such as Python and libraries like TensorFlow, PyTorch, or similar.Proficiency in data preprocessing, including cleaning, normalization, and feature extraction.Ability to deploy and integrate the chatbot within existing customer support systems (optional but desirable).Deliverables:Trained AI chatbot model capable of understanding and responding to customer queries.Well-documented codebase explaining the implementation and training process.User-friendly interface for the chatbot, ensuring smooth integration into existing systems.","['Chatbot Development', 'Adobe Illustrator', 'Artificial Intelligence', 'Artificial Neural Network', 'Python', 'Natural Language Processing', 'Neural Network', 'Machine Learning', 'Deep Learning', 'deeplearn.js', 'Artificial Intelligence', 'Artificial Neural Network', 'Python', 'Natural Language Processing', 'Neural Network', 'Machine Learning', 'Deep Learning', 'deeplearn.js']",Algeria,1,,,,,,Remote Job,Entry level
Looking for Freelance Salesforce Developer,"We are currently seeking an experienced Freelance Salesforce Developer to join our team. The ideal candidate will have a robust knowledge of Salesforce architecture and APIs, with a passion for problem-solving. This individual will play a key role in developing, enhancing, and maintaining applications within the Salesforce.com environment.Responsibilities:Design, develop, and implement software solutions on the Salesforce platform.Integrate Salesforce with other applications using SOAP, REST, BULK and Streaming APIs.Design and implement data models, user roles, security, workflows, and complex business rules within Salesforce.Translate business requirements into well-architected solutions that best leverage the Salesforce platform.Ensure code and design quality through the execution of test plans and adherence to coding standards.Support and troubleshoot software systems as required, optimizing performance, resolving problems, and providing follow-up on all issues and solutions.Maintain a flexible and proactive work environment to facilitate a quick response to changing project requirements and customer objectives.Qualifications:Bachelor's Degree in Computer Science, Information Technology, or related field.Proven experience as a Salesforce Developer.Salesforce Developer Certification is strongly preferred.Strong experience in Agile development methodologies.Proficiency with Salesforce development including modification of standard objects and fields and creation of custom objects and fields.Proficiency with Salesforce.com development tools and techniques including the APEX language, Visualforce, Lightning, and Entity Relationship data modeling.Good knowledge of integration techniques, including SOAP APIs, REST APIs, and bulk data APIs.Excellent problem-solving capabilities and critical thinking skills.Strong communication skills with the ability to work well in a team.How to Apply:Interested candidates are invited to submit their resume and a cover letter highlighting relevant experience and why they are the best fit for this role.Please note that this is a remote position. Applicants can be based anywhere but must be able to maintain a consistent working schedule and attend virtual meetings as required.Only candidates who have been shortlisted will be contacted. We look forward to hearing from you!",['Salesforce CRM'],Vietnam,431,14.77,2,"['Tech', 'IT']",,"['5.00', '40.00']",Remote Job,Expert
Product Manager,"Our company is looking for product managers and platform testers that can test  and use our software based solutions, in our case SaaS web based solutions for our clients;As an expert in representing similar platforms, online or software based, ideally, you have already tested similar platforms in the past, and you also have strong business development skills including client prospecting and engagement as well as international payment systems experience. Our online based solutions are low cost, and you understand the value in representing a platform with low cost solutions for our subscribers;Another asset would be previous experience in the following industries and/or roles:•                    Portfolio construction•                    Investment strategy•                    Private wealth•                    Investment banking•                    Commercial banking•                    Hedge funds•                    Corporate finance•                    Data science•                    Quantitative investing•                    Regulatory entities or standard setters","['Software Testing', 'Functional Testing', 'Bug Reports', 'Automated Testing', 'Software QA', 'Usability Testing', 'Web Testing', 'Test Case Design', 'Bug Reports', 'Automated Testing', 'Software QA', 'Usability Testing', 'Web Testing', 'Test Case Design']",Canada,22,,,"['Finance', 'Accounting']",,,Remote Job,Intermediate
Product Manager,"Our company is looking for product managers and platform testers that can test  and use our software based solutions, in our case SaaS web based solutions for our clients;As an expert in representing similar platforms, online or software based, ideally, you have already tested similar platforms in the past, and you also have strong business development skills including client prospecting and engagement as well as international payment systems experience. Our online based solutions are low cost, and you understand the value in representing a platform with low cost solutions for our subscribers;Another asset would be previous experience in the following industries and/or roles:•                    Portfolio construction•                    Investment strategy•                    Private wealth•                    Investment banking•                    Commercial banking•                    Hedge funds•                    Corporate finance•                    Data science•                    Quantitative investing•                    Regulatory entities or standard setters","['Software Testing', 'Functional Testing', 'Bug Reports', 'Automated Testing', 'Software QA', 'Usability Testing', 'Web Testing', 'Test Case Design', 'Bug Reports', 'Automated Testing', 'Software QA', 'Usability Testing', 'Web Testing', 'Test Case Design']",Canada,22,,,"['Finance', 'Accounting']",,,Remote Job,Intermediate
Q/A AI chatbot,"Use at least two different deep networks such as BERT-base (Transformer) to create a question-and-answer feature of a chatbot.Optionally on top of using one pre-trained model, you can think of using openai's library that utilises GPT. Will share rest of the details via chat. Thanks.","['Natural Language Processing', 'Artificial Intelligence', 'Machine Learning', 'Artificial Intelligence', 'Machine Learning']",Malaysia,2,,12,,10.00,,Remote Job,Intermediate
Grafana Updates for Company Dashboard (SQL),"We are in search of a skilled developer with experience in Grafana to collaborate with us in refining and expanding our current dashboard. Our dashboard is already functional and retrieves data from our SQL database. We require assistance in fixing issues with existing reports and designing new ones.Initially, you will work with our team to gain a better understanding of our database and the current reports. By the end of June, we hope you will be able to work independently. The project will start with some catch-up work to get you up to speed and resolving a few backlogged issues. Afterward, we would like to establish an ongoing partnership with someone who is familiar with our setup and can dedicate a few hours per month to fulfilling our requests.We are seeking someone who can showcase their prior work experience and expertise in Grafana. It is essential for the candidate to have a good grasp of Grafana's features.Please share specific examples and what your favorite desert is (so we know you actually read this thing). :)","['Grafana', 'Data Visualization', 'Dashboard', 'SQL']",United States,6,15.00,258,,,"['10.00', '50.00']",Remote Job,Expert
Data Scraper,"I am looking for someone that is is able to scrape data off the internet, The goal is to get a list of every single property manager in Brisbane, I need their phone numbers. I also need a list of every real estate business and the phone number of the Principle/director/manager of the business. I am looking for someone that can start immediately","['Data Scraping', 'Data Mining', 'Lead Generation', 'Web Crawling', 'Data Entry', 'Lead Generation', 'Web Crawling', 'Data Entry']",Australia,4,4.00,0,['Real Estate'],4.00,,Remote Job,Entry level
Data analysis with pyspark,"In this task, you must find the 10 products with the greatest price variation, between the value found in online retail (Americanas) and that stipulated by the manufacturer, and the 10 products that have the greatest unavailability. With this task, I want to see if there are products that are being sold with values that are far from ideal. For this, I'll provide data collected at retailers on different dates so that you can develop this activity. Some important points about the structure of this data:""retailerPrice"" -- is the retail price;""manufacturerPrice"" -- is the price indicated by the manufacturer;""priceVariation"" -- is the price variation, it can be negative or positive.“available” – whether the product is available for purchaseThe scope of testing must include, but not be limited to:Data ingestion;File storage;Data processing;Calculation of metrics;Also:PyLint application or similar;Application of Clean Code;Pipeline diagram;Readme;Coverage and Unit Testing;I'll be providing the files for the task.","['Python', 'PySpark', 'pylint', 'pytest', 'Apache Spark', 'ETL Pipeline', 'Apache Spark', 'ETL Pipeline']",Brazil,1,,,"['Tech', 'IT']",,,Remote Job,Entry level
DJANGO Flask Deep learning,"i need a develop who is available full time for developing a system. work daily atleast 10 hours online and discuss thingsneed to do machine learning, web based python system","['Python', 'Django', 'Flask', 'Machine Learning', 'Deep Learning', 'Python Script', 'Deep Learning', 'Python Script']",Switzerland,54,,3.2,,,"['3.00', '5.00']",Remote Job,Expert
Data Scraper,"I am looking for someone that is is able to scrape data off the internet, The goal is to get a list of every single property manager in Brisbane, I need their phone numbers. I also need a list of every real estate business and the phone number of the Principle/director/manager of the business.","['Data Scraping', 'Data Mining', 'Lead Generation', 'Web Crawling', 'Data Entry', 'Lead Generation', 'Web Crawling', 'Data Entry']",Australia,4,4.00,0,['Real Estate'],,"['3.00', '4.00']",Remote Job,Entry level
Scraping electoral data for villages in Rural India,I would like to extract data on Indian states of Uttar Pradesh and Rajasthan panchayat (village parliament) reservations from the following links: UP: https://sec.up.nic.in/ElecLive/SearchReservationOnPost.aspxRajhasthan: https://sec.rajasthan.gov.in/grampanchayatdetails.aspxWill need to setup a call with interested person to discuss the job and desired output further. Need completion by or before June 20th.Thank you!,"['Data Scraping', 'Microsoft Excel', 'Data Entry', 'Data Entry']",India,3,,175,,,"['15.00', '40.00']",Remote Job,Expert
Set up Google Analytics 4 and create reports,"Hi! I need someone to set out default reports within Google Analytics 4 and dashboards in Looker Studio. I need the same reports set up for three separate websites.An example of the reports I need created are:- User Acquisition- Traffic quisition- Sales attribution including multiple attribution settings such as linear, data, first click, last click, etc- Most viewed pages- Referrers- Customer journeys- Bounce rate- Conversions report- Landing page report- Organic Traffic vs. All Traffic- Customer Behavior report- Traffic Acquisition From Social Media report- Keyword Hero Keyword Performance reportSome of the above reports may be duplicates; I'll need you to advise on this.I am looking for an expert who can help me on an ongoing basis.  Please provide examples of Looker Studio dashboards you have created.","['Google Tag Manager', 'Google Analytics', 'google analytics 4', 'Analytics', 'looker studio', 'Analytics', 'looker studio']",Australia,11,11.20,4.3,,,"['10.00', '50.00']",Remote Job,Expert
Convert two Inventory at risk reports from Excel to Power BI plus training.,"Scope of Work for Converting Excel Stock at Risk Reports to Power BIBackground and Objectives:The objective of this project is to convert two existing Excel-based stock at risk reports into interactive and visually appealing dashboards using Power BI. The current Excel reports use macros to calculate sell-down or at-risk dates based on expiry minus shelf life and consumed forecast. The goal is to replicate the existing functionality while leveraging Power BI's data modeling, visualization, and interactivity capabilities.Requirements Gathering:Understand the existing Excel reports, including their structure, formulas, and macro functionalities.Identify the specific data sources used in the Excel reports (e.g., Excel tables, external data connections) and ensure their availability for integration into Power BI.Determine the desired layout, visualizations, and interactivity required for the Power BI dashboards.Discuss any additional enhancements or modifications desired for the Power BI dashboards beyond replicating the existing functionality.Data Modeling and Integration:Extract the relevant data from the existing data sources used in the Excel reports.Transform and cleanse the data as necessary to align with the desired data model in Power BI.Design and implement the data model in Power BI, including establishing relationships between the data tables as required.Validate the accuracy and integrity of the data model through testing and verification.Calculation and Forecasting:Replicate the existing calculations and forecasting logic used in the Excel reports within Power BI.Implement any necessary measures, calculated columns, or DAX expressions to perform the sell-down or at-risk date calculations based on expiry, shelf life, and consumed forecast.Validate the accuracy of the calculations by comparing results with the original Excel reports.Visualization and Interactivity:Design and create visually appealing and intuitive dashboards in Power BI that represent the key metrics and information from the original Excel reports.Utilize appropriate visuals (e.g., charts, tables, cards) to present the stock at risk data, sell-down dates, and other relevant information.Enable user interactivity by incorporating slicers, filters, and drill-through functionality to allow users to explore and analyze the data from various perspectives.Testing and Validation:Conduct comprehensive testing of the Power BI dashboards to ensure all calculations, visuals, and interactivity are functioning as expected.Validate the accuracy and consistency of the data and calculations by comparing with the original Excel reports.Seek feedback and input from stakeholders and incorporate any necessary refinements or adjustments based on their feedback.Documentation and Training:Document the data sources, data model, calculations, and any custom functionalities implemented in Power BI.Prepare user documentation or a user guide to help users understand and navigate the Power BI dashboards effectively.Provide training sessions or knowledge transfer to key users or stakeholders on how to use and maintain the Power BI dashboards.","['Microsoft Excel', 'Microsoft Power BI', 'Data Analysis', 'Data Visualization', 'Data Modeling', 'Data Analysis', 'Data Visualization', 'Data Modeling']",Australia,1,,,,,"['18.00', '45.00']",Remote Job,Intermediate
Data extraction from online for Real Estate,We are looking for someone to gather details of real estate agents that have sold properties in different locations.We would like to build up an email lists for all suburbs in Brisbane. Open to a software or AI integration that can also do this?,['Data Scraping'],Australia,19,7.00,1.8,['Real Estate'],,,Remote Job,Entry level
Stock Predictive Model,"We are looking for a skilled data scientist who has experience building stock predictive models. The project length is less than one month, and we require expertise in machine learning, mathematical modeling, and statistics. Your primary responsibility will be to develop a predictive model that can forecast the future performance of our stock portfolio. You should be able to gather, analyze, and interpret large datasets. You will also need to have a strong background in statistical modeling and time-series analysis. To be considered for this project, please submit a detailed proposal outlining your experience and how you can help us achieve our goal. Please include links to some of your past completed projects, specifically those related to stock predictive modeling. We are excited to work with someone who is passionate about data science and has a proven track record of success in this field. If you are up for the challenge, please submit your proposal to us today.Machine Learning to analyze the stock exchange, make stock market predictions, and take informed investment decisionsNote: Some of the content in this job post may have been auto-generated using advanced AI.","['Deep Learning', 'Machine Learning', 'Statistics', 'Data Science', 'Mathematical Modeling', 'Financial Analysis', 'Data Science', 'Mathematical Modeling', 'Financial Analysis']",United States,11,,573,,60.00,,Remote Job,Expert
Webscraping project - FAST TURNAROUND required,"Hello,We need help to scrape the following website:https://locator.infusioncenter.org/We want the output to be an excel file with columns similar to what is attached. This is TIME-SENSITIVE.We would like to get the output for the top 25 MSAs in the US: https://en.wikipedia.org/wiki/Metropolitan_statistical_area[just pick a zip code in the middle of the MSA then use the radius of 100 miles]Note: someone might be able to use parsehub to do this taskLet me know if any questions.Maxime","['Web Scraping', 'Data Scraping', 'Data Entry', 'Microsoft Excel', 'parsehub', 'JavaScript', 'Python', 'Microsoft Excel', 'parsehub', 'JavaScript', 'Python']",United States,7,5.79,1.6,"['Tech', 'IT']",80.00,,Remote Job,Intermediate
Machine Learning (ML) model optimization expert,"We are in the process of optimizing our deep language model which is implemented as PyTorch/Hugging Face.We are looking for someone with knowledge of the latest transformer libraries and optimizations (such as flash attention, faster or better transform, etc.) and hands-on experience in:1- Pruning2- Compression3- Quantisation4- DistillationSpecifically seq-2-seq models (T5) family.","['Deep Learning', 'Deep Learning Modeling', 'Model Optimization', 'Model Tuning', 'Machine Learning', 'Artificial Intelligence', 'Python', 'Natural Language Processing', 'Large Language Model', 'Multimodal Large Language Model', 'Python', 'Natural Language Processing', 'Large Language Model', 'Multimodal Large Language Model']",United States,9,52.36,80,"['Tech', 'IT']",,"['50.00', '110.00']",Remote Job,Expert
Writer experienced in computer science topics. Topic is on statistically evaluating randomised algo,"I have a Research  topic ""Statistical Evaluation of Randomised algorithms"". This topic will center on Randomised algorithm and software testing. It is a minimum 80 page document, however I have written 25 pages and established the research questions and the path to follow in this paper. I can share the document to you and you can decide if this is a good starting point.The work will require someone who is great in statistics with expertise in computer science research writing. The template of the paper will be provided; it could be written in Ms Word or preferably LaTex(Overleaf).  The paper does not require any implementation but rather a concrete review, critique and backed opinion on the topic.  I like to add that the level of this work is graduate (masters) level and as such requires professionalism. Plagiarism and irregular sentences will result in an overall bad work for me. Looking forward to your support and proposals. Thank you.","['Writing', 'Data Science', 'Computer Science', 'Statistics', 'Thesis', 'Dissertation Writing', 'Research Paper Writing', 'Research Papers', 'Artificial Intelligence', 'Statistics', 'Thesis', 'Dissertation Writing', 'Research Paper Writing', 'Research Papers', 'Artificial Intelligence']",Germany,1,,,"['Tech', 'IT']",450.00,,Remote Job,Expert
"LORA file for Stable Diffusion needed, hiring a dev.",Need a professional at creating LORA files for stable diffusion. Please show other LORA files you've made on Civit.ai or whatnot. Need a style lora created from series of images.,['Stable Diffusion'],United States,61,13.82,61,,150.00,,Remote Job,Intermediate
Google Sheets and Looker Studio Maste,"Job Title: Google Sheets and Looker Studio MasterLocation: PhilippinesJob Type: Ongoing Task-Based WorkAbout the Job:We are looking for a Google Sheets and Looker Studio Master to help us improve our reports and build them into Google Looker dashboards. The ideal candidate will have experience with both Google Sheets and Looker Studio, as well as strong analytical and problem-solving skills.Responsibilities:Improve existing reports and create new ones using Google SheetsBuild reports into Google Looker dashboardsWork with other team members to gather data and requirementsTroubleshoot and resolve data issuesStay up-to-date on the latest trends in data analysis and visualizationQualifications:3+ years of experience with Google Sheets2+ years of experience with Looker StudioStrong analytical and problem-solving skillsExcellent communication and teamwork skillsAbility to work independently and as part of a teamBenefits:Competitive salaryOpportunity to work with a talented team on challenging and interesting projectsAccess to cutting-edge technologyFlexible work hoursOpportunity for growth and developmentIf you are interested in this position, please send your resume and a cover letter","['Google Data Studio', 'Google Sheets', 'Supermetrics', 'Supermetrics']",Australia,55,,1.5,"['Media', 'Entertainment']",,"['5.00', '10.00']",Remote Job,Expert
AI & Machine Learning Writing,"We are looking for a new writer to join us on: xhttps://www.unite.ai (remove x).You should have examples of published articles that you can link to. I am looking for writers with experience in:- Machine Learning- Data Science- Deep Learning- Generative AIYou will be responsible for sourcing your own articles to write, and you will also be responsible for writing on designated topics. If there is nothing designated you will source content (while ensuring that you don't post duplicate content with our other writer)Please visit our website to get a feel for the type of writing.Also, please post how many hours you expect for an average 1000 word article.Lastly, we are looking for writers who can introduce a new type of content to our website. When applying please describe why you would be a match for our team, what type of unique articles you could contribute, etc. It is possible that with your unique skill set that you could offer something not touched upon on this job description. I am open to suggestions.To begin we would have a 1 article a day publishing process.Please note we do not want writing agencies, we want UNIQUE voices that understand machine learning.","['Artificial Intelligence', 'Deep Learning', 'Data Science', 'Deep Learning', 'Data Science']",Cayman Islands,502,21.23,277,,,"['18.00', '40.00']",Remote Job,Intermediate
Data analyst to help with multivariate time series analysis,I need a data analyst to assist with a multivariate time series analysis of crude oil prices and some other economic indicators. Please see attached file for more information on what is required.,"['R', 'Data Analysis', 'Data Modeling', 'Analytics', 'Data Visualization', 'Data Science', 'Analytics', 'Data Visualization', 'Data Science']",Togo,1,,0,,,"['40.00', '75.00']",Remote Job,Expert
Geographic matching,"I am looking for an individual to help me merge congressional district codes with zip codes and latitude and longitude data. I need the final output to be in Excel or STATA.Steps:1)  Use https://mcdc.missouri.edu/geography/ZCTAs-2010.htmlto extract ""New ZCTA Master Data Set"" (the crosswalk between congressional district code and zip codes). 2)  Use the crosswalk to map on my master file (attached)3) Link the merged files with latitude and longitude4) Use two redistrict events in 2000 and 2010 to identify districts that went through the redistricting process.","['ArcGIS', 'Geographic Infographic', 'ArcMap', 'Geocoding', 'ArcMap', 'Geocoding']",United States,45,15.84,7.7,"['Finance', 'Accounting']",100.00,,Remote Job,Intermediate
Fix an error in the pre-trained language model,"I am looking for a freelancer who can fix an error in my pre-trained language model. The model that needs to be fixed is the ""yikuan8/Clinical-Longformer"". The specific error that needs to be fixed is the ValueError: not enough values to unpack (expected 2, got 1). The desired outcome for the fixed language model is to train the model and ensure that it is ready for evaluation. Therefore, I am looking for someone with experience in natural language processing and pre-trained language models.","['Machine Learning Model', 'Transfer Learning', 'Python', 'Pytroch', 'Natural Language Processing']",Spain,24,,130,,8.00,,Remote Job,Intermediate
API Data Extraction,"A few years ago, someone pulled the information attached from the Allergan websites. The information is a list of all the merchants that sell specific Allergan products (Botox, Juvederm, Coolsculpting), and it has a column for ""points earned"" which helps to indicate how big the merchant is. The first goal of this job is to pull the same information set for each product for the entire US (the attached was only focused on certain states). The important criteria that at a minimum should be in the final product is the merchant name, location and points earned.Allergan sites, but feel free to search and find other ways to get in: https://www.botoxcosmetic.com/find-a-botox-cosmetic-specialist  https://www.juvederm.com/find-a-specialist https://find.coolsculpting.com/find-a-center  The site/APls may have changed since I last had this updated, so its possible that this project is not possible. If you could let me know (a) feasibility (b) the fixed rate you would charge and (c) timeline - that would be very helpful!Thank you so much for your consideration.","['Data Scraping', 'Data Extraction']",United States,9,41.12,1.3,,200.00,,Remote Job,Intermediate
Data scraping and Analysis from LinkedIn Sales Navigators and Job Boards,"Need data from LinkedIn Sales Navigator, Indeed, and Perhaps some other job boards. I need data extracted and basic analysis, this has the potential to be a long-running contract.","['Data Mining', 'Data Scraping', 'LinkedIn', 'Data Extraction', 'Python', 'Market Research', 'LinkedIn', 'Data Extraction', 'Python', 'Market Research']",United States,1,,,"['HR', 'Business Services']",,,Remote Job,Intermediate
LIDAR processing specialist,"The job is to participate to a long term project of forestry mapping with LIDAR. Collecting data on field is done regularly, by missions, and we are building a team for organizing the data, creating the maps of the areas of activity, and we are looking for an experienced LIDAR processing specialist to work on long term on this project located in Brazil","['lidar', 'Remote Sensing', 'forest mapping']",United Arab Emirates,27,8.32,4.3,"['Tech', 'IT']",,"['5.00', '15.00']",Remote Job,Expert
Fix a SAS macro bug,"Please help fix a bug (in a concise way) in the SAS macro code (the attached SAS code).The output should be as attached dataset. This code works for ending with number 1~2047. But now the ending change to 1fee1~127fee15. There are both serial numbers befroe and after ""fee"".The are datasets to be extract are attached zip file.","['SAS', 'SAS macro']",United States,40,,386,,10.00,,Remote Job,Expert
ShopifyQL Analyst,"Growth Gurus is seeking a skilled ShopifyQL Analyst for a one-off project. If you are a data enthusiast with a deep understanding of ShopifyQL and enjoy the challenge of extracting and analyzing complex data sets, this role is for you.Project Overview:The project involves extracting customer records linked to transactional events from a Shopify platform. This extracted data will be used to conduct a lapsed customer / winback analysis for a client.Responsibilities:- Use ShopifyQL to extract customer records linked to transactional events.- Perform custom queries and analysis based on the extracted data.- Contribute to the lapsed customer/winback analysis using the data extracted.- Collaborate with our team to interpret the findings and translate them into actionable strategies.Qualifications:- Proven experience with ShopifyQL, preferably with a focus on data extraction and analysis.- Excellent analytical skills and the ability to turn data into actionable insights.- Proficiency in handling large data sets and databases.- Strong communication skills and the ability to work well with remote teams.We estimate that this project will require 10-15 hours of work, and the ideal candidate will be able to deliver quality results efficiently. Apply now!","['Marketing Analytics', 'Sales Analytics', 'Growth Analytics', 'Report', 'Data Analysis', 'Analytics', 'Python', 'SQL', 'Python', 'SQL']",Australia,267,19.97,428,"['Sales', 'Marketing']",,,Remote Job,Expert
Create Visual Sales KPI Dashboard for Coaching Business [G-Sheets or G-Data Studio],"Straight forward job as the data is already automated and set up in a tidy G-Sheet. For the most part, all that is required is for the right candidate, is to create a Dashboard of visual charts / line graphs etc using the data sheet. The data is already automated and displayed in well laid out set of data tables ready to be used for the dashboard.Although I can do this myself as I have done in the past, I would prefer to have some do it that can create it quicker an more tidily.If you think you can get this done, apply and let's arrange a call to walk through the data and make sure we are on the same page.[pictures of the data to be visualised are attached below]Thank you.","['Google Sheets', 'Dashboard', 'Data Visualization', 'Google Data Studio', 'Data Analysis', 'Data Analysis']",United Kingdom,11,10.46,8.6,,70.00,,Remote Job,Intermediate
Verification and analysis of sources of GIS data in China,"We are looking for a consultant to help with investigation and the verification of sources of GIS data in China. We have already a list of data sources and data providers. The candidate should be able to leverage his/her experience to advice and suggest which data sources can be suitable or not and to identify the most suitable one(s) according to the requirements. The job length is around 1 month or less. The ideal candidate should have expertise in GIS data analysis consultation, accuracy verification, data analysis, data extraction, and GIS.The consultant will be responsible for searching and providing information of the GIS data access and quality of GIS data in China  The candidate should be able to provide a detailed analysis of the sources of data and identify any inconsistencies or inaccuracies. We are looking for a candidate with a proven track record in data analysis and GIS. Please submit a proposal outlining your experience and how you can help with this project. Please also include links to past completed projects that demonstrate your expertise in this area.We look forward to hearing from you.","['Data Extraction', 'API Integration', 'GIS', 'Data Analysis', 'Data Analysis Consultation', 'Accuracy Verification', 'Accuracy Verification']",Switzerland,21,29.79,27,"['Energy', 'Utilities']",,"['10.00', '25.00']",Remote Job,Intermediate
LUDWIG.ai Engineer,"We are looking for an experienced engineer to work on our artificial intelligence project using the Ludwig.ai platform. The project will last between 1 to 3 months. As an AI Engineer, you will be responsible for developing and implementing machine learning models using Python and the Ludwig framework. The ideal candidate should have a strong background in machine learning and experience with the Ludwig framework.PLEASE ONLY APPLY IF YOU HAVE SOLID EXPERIENCE WITH LUDWIG","['Machine Learning Model', 'Python', 'ludwig', 'Artificial Intelligence', 'Machine Learning', 'Machine Learning']",United States,9,17.00,563,"['Tech', 'IT']",,"['40.00', '80.00']",Remote Job,Expert
Expert Node Developer,"Job Description:We are seeking an experienced and skilled Node.js developer to join our team for an exciting project. As an expert Node developer, you will be responsible for designing, developing, and maintaining scalable and high-performance web applications using Node.js and related technologies.Responsibilities:Develop and maintain server-side applications using Node.js and frameworks like Express.js.Design and implement robust and scalable APIs and web services.Collaborate with cross-functional teams to understand project requirements and translate them into technical specifications.Write clean, efficient, and well-documented code following best practices and coding standards.Troubleshoot and debug application issues, ensuring high performance and availability.Optimize applications for maximum speed and scalability.Work with databases (both SQL and NoSQL) to design and optimize data models and queries.Stay up-to-date with the latest trends and advancements in Node.js and related technologies.Conduct code reviews and provide constructive feedback to ensure code quality.Collaborate with front-end developers to integrate server-side logic with user interfaces.Implement security and data protection measures to safeguard the application and user data.Continuously improve development processes and tools to enhance productivity and efficiency.Requirements:Bachelor's degree in Computer Science, Engineering, or a related field (or equivalent experience).Proven experience working as a Node.js developer, with a strong portfolio of completed projects.Proficiency in JavaScript and Node.js, along with frameworks like Express.js.Solid understanding of asynchronous programming and event-driven architecture.Experience with databases such as MongoDB, MySQL, or PostgreSQL.Familiarity with front-end technologies like HTML, CSS, and JavaScript frameworks (e.g., React, Angular) is a plus.Knowledge of version control systems (e.g., Git) and agile development methodologies.Strong problem-solving skills and attention to detail.Excellent communication and collaboration abilities.Ability to work independently as well as in a team environment.If you are a highly skilled and passionate Node.js developer looking for a challenging opportunity, we would love to hear from you. Join our team and contribute to the success of our innovative project.","['Web Development', 'HTML']",United States,1,,,,40.00,,Remote Job,Expert
Energy Data and Pricing Analyst - Junior Level,"Job Summary:As a Junior Analyst for an Electric and Gas Supplier, you will play a crucial role in supporting the operations and decision-making processes of the company. Your primary responsibility will be to analyze data, assess market trends, and provide insights to optimize the company's electric and gas supply operations. You will work closely with the senior analysts, managers, and other cross-functional teams to ensure an efficient and reliable energy supply to customers. This position offers an excellent opportunity for growth and development in the energy industry.Key Responsibilities:•	Data Analysis:-	Collect, organize, and analyze energy consumption, pricing, and market data.-	Utilize statistical techniques and software tools to identify data patterns, trends, and anomalies.-	Prepare reports, charts, and presentations to communicate findings and recommendations.•	Market Research and Forecasting:-	Monitor industry trends, regulatory changes, and market conditions impacting electric and gas supply.-	Research emerging technologies, renewable energy, and energy efficiency initiatives.-	Collaborate with senior analysts to develop accurate forecasts for energy demand and supply.•	Operational Support:-	Assist in optimizing energy procurement and supply strategies to ensure cost-effectiveness and reliability.-	Identify opportunities to enhance operational efficiency and mitigate risks in energy procurement processes.-	Support cross-functional teams in managing contracts, pricing agreements, and supplier relationships.•	Financial Analysis:-	Contribute to financial modeling and analysis to evaluate the economic viability of energy projects.-	Assist in budgeting, cost tracking, and variance analysis for energy procurement activities.-	Help prepare business cases and presentations for investment decisions.•	Reporting and Communication:-	Prepare regular reports, dashboards, and presentations for internal stakeholders.-	Present analytical findings, insights, and recommendations to management.-	Collaborate with teams across the organization to ensure effective communication and coordination.•	Pricing and Cost Management: -	Collaborate with the finance and sales teams to manage pricing models and strategies for electric and gas services.-	Conduct cost build-up analysis to understand the components and factors impacting the total supply cost. -	Monitor and update pricing models based on market conditions, regulatory changes, and cost fluctuations.-	Assist in calculating and tracking commissions for sales teams and partners, ensuring accurate and timely payouts.•	Financial Modeling: -	Assist in developing and maintaining financial models, including pricing and cost models.-	Analyze the impact of price changes on profitability and provide insights to support pricing decisions.-	Collaborate with cross-functional teams to align pricing models with business strategies and market conditions.Qualifications and Skills:- Bachelor's degree in a relevant field such as economics, finance, mathematics, or engineering.- Strong analytical and problem-solving skills, with a keen eye for detail.- Proficiency in data analysis tools and software (e.g., Excel, Python, R, SQL).- Familiarity with energy markets, regulations, and industry trends is desirable.- Excellent written and verbal communication skills.- Ability to work independently and collaborate effectively within a team.- Strong time management and organizational skills to handle multiple tasks and meet deadlines.- A proactive and self-motivated attitude with a willingness to learn and adapt to a dynamic industry.- Basic knowledge of pricing strategies and cost analysis in the energy sector.- Understanding of commission structures and calculations.- Ability to work with financial and pricing models, with the capability to analyze and interpret complex data sets.","['Microsoft Excel', 'Data Analysis']",United States,8,31.50,4.8,"['Energy', 'Utilities']",,"['30.00', '75.00']",Remote Job,Expert
Node.js or Python scraping data feeds,"I need scripts for a data scraping microservice (in any language, Node.js preferred). Accessing the data will be high complexity and may require headless browser automation etc. though it is preferred to have a solution that doesn't use headless.I have at least 2 data sources that I'll want feeds for, the feeds should be configurable to a particular class of page hosted on the domain.","['Web Scraping', 'ETL', 'Data Scraping', 'Data Mining', 'Data Extraction', 'Data Extraction']",United States,2,,0,,,"['15.00', '40.00']",Remote Job,Expert
